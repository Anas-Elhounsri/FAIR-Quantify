{
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/schmeing/ReSeq"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2019-08-05T08:54:22Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2024-09-13T08:21:05Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "More realistic simulator for genomic DNA sequences from Illumina machines that achieves a similar k-mer spectrum as the original"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 0.8193985373738187,
      "result": {
        "original_header": "ReSeq",
        "type": "Text_excerpt",
        "value": "More realistic simulator for genomic DNA sequences from Illumina machines that achieves a similar k-mer spectrum as the original sequences.\n \n"
      },
      "source": "https://raw.githubusercontent.com/schmeing/ReSeq/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9930865346919644,
      "result": {
        "original_header": "<a name=\"abstract\"></a>Abstract",
        "type": "Text_excerpt",
        "value": "Even though sequencing biases and errors have been deeply researched to adequately account for them, comparison studies, e.g. for error correction, assembly or variant calling, face the problem that synthetic datasets resemble the real output of high-throughput sequencers only in very limited ways, resulting in optimistic estimated performance of programs run on simulated data compared to real data. Therefore, comparison studies are often based on real data. However, this approach has its own difficulties, since the ground truth is unknown and can only be estimated, which introduces its own biases and circularity towards easy solutions and the methods used. \n**Re**al **Seq**uence Reproducer shortens the gap between simulated and real data evaluations by adequately reproducing key statistics of real data, like the coverage profile, systematic errors and the k-mer spectrum. When these characteristics are translated into new synthetic computational experiments (i.e. simulated data), the performance can be more accurately estimated. Combining our simulator and real data gives two valuable perspectives on the performance of tools to minimize biases.\n \n"
      },
      "source": "https://raw.githubusercontent.com/schmeing/ReSeq/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9658305306704353,
      "result": {
        "original_header": "<a name=\"parameter\"></a>Parameter",
        "type": "Text_excerpt",
        "value": "| Parameter         | Default | Description |\n|-------------------|---------|-------------|\n| **General**       |\n| `-h` `--help`     |         | Prints help information and exits |\n| `-j` `--threads`  | 0       | Number of threads used (0=auto) |\n| `--verbosity`     | 4       | Sets the level of verbosity (4=everything, 0=nothing) |\n| `--version`       |         | Prints version info and exits |\n| **Stats**         |\n| `--adapterFile`   | (AutoDetect) | Fasta file with adapter sequences |\n| `--adapterMatrix` | (AutoDetect) | 0/1 matrix with valid adapter pairing (first read in rows, second read in columns) |\n| `-b` `--bamIn`    | None    | Position sorted bam/sam file with reads mapped to `--refIn` |\n| `--binSizeBiasFit`| 100000000 | Reference sequences large then this are split for bias fitting to limit memory consumption |\n| `--maxFragLen`    | 2000    | Maximum fragment length to include pairs into statistics |\n| `--minMapQ`       | 10      | Minimum mapping quality to include pairs into statistics |\n| `--noBias`        |         | Do not perform bias fit. Results in uniform coverage if simulated from |\n| `--noTiles`       |         | Ignore tiles for the statistics [default] |\n| `-r` `--refIn`    | None    | Reference sequences in fasta format (gz and bz2 supported) |\n| `--statsOnly`     |         | Only generate the statistics |\n| `-s` `--statsIn`  | None    | Skips statistics generation and reads directly from stats file |\n| `-S` `--statsOut` | `--bamIn`.reseq | Stores the real data statistics for reuse in given file |\n| `--tiles`         |         | Use tiles for the statistics |\n| `-v` `--vcfIn`    | None    | Ignore all positions with a listed variant for stats generation |\n| **Probabilities** |\n| `--ipfIterations` | 200     | Maximum number of iterations for iterative proportional fitting |\n| `--ipfPrecision`  | 5       | Iterative proportional fitting procedure stops after reaching this precision (%) |\n| `-p` `--probabilitiesIn` | `--statsIn`.ipf | Loads last estimated probabilities and continues from there if precision is not met |\n| `-P` `--probabilitiesOut` | `--probabilitiesIn` | Stores the probabilities estimated by iterative proportional fitting |\n| `--stopAfterEstimation` |   | Stop after estimating the probabilities |\n| **Simulation**    |\n| `-1` `--firstReadsOut` | reseq-R1.fq | Writes the simulated first reads into this file |\n| `-2` `--secondReadsOut` | reseq-R2.fq | Writes the simulated second reads into this file |\n| `-c` `--coverage` | 0       | Approximate average read depth simulated (0 = Corrected original coverage) |\n| `--errorMutliplier` | 1.0   | Divides the original probability of correct base calls(no substitution error) by this value and renormalizes |\n| `--methylation`   |         | Extended bed graph file specifying methylation for regions. Multiple score columns for individual alleles are possible, but must match with vcfSim. C->T conversions for 1-specified value in region. |\n| `--noInDelErrors` |         | Simulate reads without InDel errors |\n| `--noSubstitutionErrors` |  | Simulate reads without substitution errors |\n| `--numReads`      | 0       | Approximate number of read pairs simulated (0 = Use `--coverage`) |\n| `--readSysError`  | None    | Read systematic errors from file in fastq format (seq=dominant error, qual=error percentage) |\n| `--recordBaseIdentifier` | ReseqRead | Base Identifier for the simulated fastq records, followed by a count and other information about the read |\n| `--refBias`       | keep/no | Way to select the reference biases for simulation (keep [from refIn] / no [biases] / draw [with replacement from original biases] / file) |\n| `--refBiasFile`   | None    | File to read reference biases from: One sequence per file (identifier bias) |\n| `-R` `--refSim`   | `--refIn` | Reference sequences in fasta format to simulate from |\n| `--seed`          | None    | Seed used for simulation, if none is given random seed will be used |\n| `-V` `--vcfSim`   | None    | Defines genotypes to simulate alleles or populations |\n| `--writeSysError` | None    | Write the randomly drawn systematic errors to file in fastq format (seq=dominant error, qual=error percentage) | \n `reseq queryProfile [options]`\n \n| Parameter         | Default | Description |\n|-------------------|---------|-------------|\n| **General**       |\n| `-h` `--help`     |         | Prints help information and exits |\n| `-j` `--threads`  | 0       | Number of threads used (0=auto) |\n| `--verbosity`     | 4       | Sets the level of verbosity (4=everything, 0=nothing) |\n| `--version`       |         | Prints version info and exits |\n| **queryProfile**  |\n| `--maxLenDeletion`| None    | Output lengths of longest detected deletion to stdout |\n| `--maxReadLength` | None    | Output lengths of longest detected read to stdout |\n| `-r` `--ref`      | None    | Reference sequences in fasta format (gz and bz2 supported) |\n| `--refSeqBias`    | None    | Output reference sequence bias to file (tsv format; `-` for stdout) |\n| `-s` `--stats`    | None    | Reseq statistics file to extract reference sequence bias | \n| Parameter         | Default | Description |\n|-------------------|---------|-------------|\n| **General**       |\n| `-h` `--help`     |         | Prints help information and exits |\n| `-j` `--threads`  | 0       | Number of threads used (0=auto) |\n| `--verbosity`     | 4       | Sets the level of verbosity (4=everything, 0=nothing) |\n| `--version`       |         | Prints version info and exits |\n| **ReplaceN**      |\n| `-r` `--refIn`    | None    | Reference sequences in fasta format (gz and bz2 supported) |\n| `-R` `--refSim`   | None    | File to where reference sequences in fasta format with N's randomly replace should be written to |\n| `--seed`          | None    | Seed used for replacing N, if none is given random seed will be used | \n| Parameter         | Default | Description |\n|-------------------|---------|-------------|\n| **General**       |\n| `-h` `--help`     |         | Prints help information and exits |\n| `-j` `--threads`  | 0       | Number of threads used (0=auto) |\n| `--verbosity`     | 4       | Sets the level of verbosity (4=everything, 0=nothing) |\n| `--version`       |         | Prints version info and exits |\n| **seqToIllumina** |\n| `--errorMutliplier` | 1.0   | Divides the original probability of correct base calls(no substitution error) by this value and renormalizes |\n| `-i` `--input`    | `stdin` | Input file (fasta format, gz and bz2 supported) |\n| `--ipfIterations` | 200     | Maximum number of iterations for iterative proportional fitting |\n| `--ipfPrecision`  | 5       | Iterative proportional fitting procedure stops after reaching this precision (%) |\n| `--noInDelErrors` |         | Simulate reads without InDel errors |\n| `--noSubstitutionErrors` |  | Simulate reads without substitution errors |\n| `-o` `--output`   | `stdout`| Output file (fastq format, gz and bz2 supported) |\n| `-p` `--probabilitiesIn` | `--statsIn`.ipf | Loads last estimated probabilities and continues from there if precision is not met |\n| `-P` `--probabilitiesOut` | `--probabilitiesIn` | Stores the probabilities estimated by iterative proportional fitting |\n| `--seed`          | None    | Seed used for simulation, if none is given random seed will be used |\n| `-s` `--statsIn`  | None    | Profile file that contains the statistics used for simulation |\n \n"
      },
      "source": "https://raw.githubusercontent.com/schmeing/ReSeq/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.969611514468424,
      "result": {
        "original_header": "<a name=\"formats\"></a>File Formats",
        "type": "Text_excerpt",
        "value": "| File type             | Ending     | Information |\n|-----------------------|------------|-------------|\n| Reference file        | .fa        | Standard reference file in fasta format. Everything not an A,C,G,T is randomly replaced by one of those before simulating. To consistently simulate the same base over multiple simulations use the replaceN mode of reseq before starting the simulation to create a reference without N(or other ambiguous bases, which are all treated as N). A single reference sequence is only supported up to  a maximum length of 4294967295 bases. The complete reference can be much bigger. |\n| Mapping file          | .bam       | Standard mapping file in bam format. Reference information need to match the provided reference. To include tiles the tile information needs to stay in the QNAME field. Only primary alignments are used. |\n| Adapter file          | .fa        | File in fasta format giving the sequences of possibly used adapters. The shorter this list the less missidentification can happen. Some files to use are in the adapter folder. The direction of the adapters is irrelevant as always the adapter given and its reverse complement are checked, due to sequencing-machine dependence on the direction. |\n| Adapter matrix        | .mat       | 0/1 matrix stating if the adapters can occur in a read pair together. (0:no; 1:yes). The n-th row/column is the n-th entry in the adapter file. Rows represent the adapter in the first read and columns represent the adapter in the second read. Columns are consecutive digits in a row. Number of rows and columns need to match the number of entries in the adapter file. |\n| Variant file          | .vcf       | Standard vcf format. The reference information in the header and in the reference column must match the given reference file. Ambiguous bases (e.g. N's) are not supported in the reference and alternative column. Except of this only the CHROM, POS, ALT columns and the genotype information are used. No filtering by quality etc. takes place. All genotypes in the file will be simulated. No distinction is made if genotypes are in a single sample or spread out over multiple samples. All genotype information is considered phased independent of what is encoded in the file. At most 128 genotypes are supported by default (see FAQ). |\n| Methylation file\t| .bed\t     | Extended bed graph format with possibility of multiple score columns for individual alleles. Number of columns must be either 1 or the same number of alleles specified in the variant file. The number of columns need to be the same within each reference sequence. Bisulfite sequencing is simulated, so C->T conversions are inserted with a probability of 1-methylation value specified in this file. |\n| Stats file            | .reseq     | Boost archive: Not recommended to modify or create by hand even though it is in ASCII format |\n| Probability file      | .reseq.ipf | Boost archive: Not recommended to modify or create by hand even though it is in ASCII format |\n| Systematic error file | .fq        | Standard fastq format. The sequence represents the error tendency and the quality the error rate in percent at that position. There are two entries per reference sequence. The order of the reference sequences must be kept. The length must match the length of the reference sequence. The first entry per reference sequence is the reverse strand and reverse complemented. So an A in the first position means that a systematic error towards a T is simulated for the last base of the reference sequence in reads on the reverse strand. The second entry is the forward strand taken as is, so not reverse complemented. The error rate in percent is encoded similar to quality values with an offset of 33. Since the fastq format is limited to 94 quality values odd percentages over 86 are omitted. This mean `~` encodes 100% and `}` 98%. |\n| Reference bias file   | .txt       | One line per specified bias. The line starts by a unique identifier of the reference sequence (the part before the first space in the reference sequence name in the reference file). The identifier can be followed by a space and after it some arbitrary information. The line ends with a space or tab separating a floating point number representing the bias for this sequence. It must be positive. All reference sequences in the reference file must have a bias given. However, the order of the sequences doesn't need to be kept and the bias for additional reference sequences could be specified. The biases will be automatically normalized and define the relative base coverage of the reference sequences. Simulated base coverage will differ from this due to other biases additionally taken into account. |\n \n"
      },
      "source": "https://raw.githubusercontent.com/schmeing/ReSeq/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9198954455824533,
      "result": {
        "original_header": "<a name=\"faq\"></a>FAQ",
        "type": "Text_excerpt",
        "value": "**Can I simulate more than the default 128 alleles?**\nYes. You can set `kMaxAlleles` in `reseq/Reference.h` to any multiple of 64. After recompilation the new maximum number of alleles will be your chosen value. \n**Can I simulate exome sequencing?**\nYes. You need to use a reference that only contains the exons as individual scaffolds. Using `--refBiasFile` you can specify the coverage of individual exons. To simulate intron contamination you can add the whole reference to the reference containing the exons and strongly reduce the coverage for these scaffolds using `--refBiasFile`. \n**Can I train on datasets without adapters?**\nGenerally, it is not advised to use trimmed datasets, because they result in worse perfomance. However, by specifying decoy adapters with `--adapterFile TruSeq_single` you can skip the automatic adapter detection, which otherwise will prevent you from training on datasets without adapters. \n**When I train the model a large part of the genome is excluded, because the sequences are too short.**\nLowering the `--maxFragLen` parameter most likely helps in this situation, because sequences that are not at least 100 bases longer than this parameter are excluded in any case. However, you need to check that you are not truncating your fragment lengths distribution by setting `--maxFragLen` too low.\n \n"
      },
      "source": "https://raw.githubusercontent.com/schmeing/ReSeq/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "documentation": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/schmeing/ReSeq/tree/master/nlopt/doc/docs"
      },
      "technique": "file_exploration"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/schmeing/ReSeq/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "faq": [
    {
      "confidence": 1,
      "result": {
        "original_header": "<a name=\"errormodel\"></a>Apply errors and qualities directly to sequences",
        "parent_header": [
          "ReSeq"
        ],
        "type": "Text_excerpt",
        "value": "In case you cannot use the coverage model, you can directly provide sequences to ReSeq, which will be converted to reads. This includes adding qualities as well as InDel and substitution errors and cutting the sequence to the read length. If sequences are shorter than the read length ReSeq automatically adds an adapter.\n```\nreseq seqToIllumina -j2 -i my_sequences.fa -o my_simulated_reads.fq -s my_stats_profile.reseq\n```\nFor it to work, all necessary informations need to be provided to ReSeq's error and quality model. Therefore, each input sequence in the fasta file must have the following form:\n```\n>{sequence id} {template segment};{fragment length};{error tendencies};{error rates}\n{sequence to convert}\n```\n`{sequence id}`: The desired sequence id. It can contain spaces. The final read description in the output fastq will be:\n@{sequence id} {cigar} E{number of errors in read}`\n\n`{template segment}`: 1 for first reads or 2 for second reads.\n\n`{sequence to convert}`: Sequence to which errors and qualities will be added. It may only contain A, C, G or T. Ns are not permitted, since a conversion should be performed in a consistent manner for all reads stemming from a given position in the reference (see `reseq replaceN`).\n\n`{error tendencies}` and `{error rates}`: Both must have the same length as `{sequence to convert}` and the nth position always corresponds to the nth position in the sequence. Their format is described in detail for the Systematic error file under [File Formats](#formats). All bases stemming from the same position and strand in the reference must have the same values to properly simulate systematic errors. For insertions that are specific to one read use `N` and `!` respectively. The systematic errors for a reference can be simulated by calling:\n\n`reseq illuminaPE -r my_reference.fa -s my_stats_profile.reseq --stopAfterEstimation --writeSysError my_systematic_errors.fq`\n\nThis call creates a fastq file with two sequences per reference sequence (one for each strand with the reverse strand first). From this file the corresponding error tendencies and rates can be extracted. Note that the the sequence for the reverse strand is already reverse complemented.\n"
      },
      "source": "https://raw.githubusercontent.com/schmeing/ReSeq/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 3
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/schmeing/ReSeq/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "schmeing/ReSeq"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "ReSeq"
      },
      "source": "https://raw.githubusercontent.com/schmeing/ReSeq/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "has_script_file": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/schmeing/ReSeq/master/nlopt/src/octave/mkconstants.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/schmeing/ReSeq/master/conda/reseq/build.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/schmeing/ReSeq/master/seqan/util/linux_binary_tests.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/schmeing/ReSeq/master/seqan/util/travis/linux-cibuild.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/schmeing/ReSeq/master/seqan/util/bin/adjust_copyright_years.sh"
      },
      "technique": "file_exploration"
    }
  ],
  "installation": [
    {
      "confidence": 1,
      "result": {
        "type": "File_dump",
        "value": "---\n# NLopt Installation\n---\n\nThe installation of NLopt is fairly standard and straightforward, at least on Unix-like systems (GNU/Linux is fine). It doesn't require any particular packages to be installed except for a C compiler, although you need to have [Octave](https://en.wikipedia.org/wiki/GNU_Octave) and/or Matlab installed if you want to install the Octave and/or Matlab plugins, respectively.\n\nIn particular, NLopt uses the standard [CMake](https://cmake.org/) `cmake` build system, which means that you compile it via:\n\n```sh\nmkdir build\ncd build\ncmake ..\nmake\n```\n\nin the `nlopt` directory. Then install the NLopt libraries and header files via:\n\n```sh\nsudo make\u00a0install\n```\n\nBy default, this installs the NLopt shared library (`libnlopt.so`) in `/usr/local/lib` and the NLopt header file (`nlopt.h`) in `/usr/local/include`, as well manual pages and a few other files.\n\nIn the following, we describe a few details of this installation process, including how to change the installation location.\n\nChanging the installation directory\n-----------------------------------\n\nYou may wish to install NLopt in a directory other than `/usr/local`, especially if you do not have administrator access to your machine. You can do this using the `CMAKE_INSTALL_PREFIX` variable of the `cmake` utility.\n\nFor example, suppose that you want to install into the `install` subdirectory of your home directory (`$HOME`). You would do:\n\n```sh\ncmake -DCMAKE_INSTALL_PREFIX=$HOME/install ..\nmake\nmake\u00a0install\n```\n\nThis will create the directories `$HOME/install/lib` etcetera and install NLopt into them. However, now when you compile code using NLopt, you will need to tell the compiler where to find the NLopt header files (using `-I`) and libraries (using `-L`) with something like:\n\n```sh\ncc\u00a0-I$HOME/install/include\u00a0myprogram.c\u00a0-L$HOME/install/lib\u00a0-lnlopt\u00a0-lm\u00a0-o\u00a0myprogram\n```\n\nSee also below for how to change the installation directories for Octave, Matlab, and Guile plugins, if you are installing those.\n\nNote also that the `-DCMAKE_INSTALL_PREFIX` flag will change the location where the Python plugins are installed, so you may need to change the [Python module search path](http://docs.python.org/tutorial/modules.html#the-module-search-path) via the `PYTHONPATH` environment variable.\n\nHowever, at this point you need to tell the operating system where to find the shared library, so that the runtime linker works properly. There are at least two ways to do this. First, you can use the `LD_LIBRARY_PATH` environment variable. For example, if you installed into the `/foo/bar` directory, so that the library is in `/foo/bar/lib`, then you would do\n\n```sh\nexport\u00a0LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/foo/bar/lib\n```\n\nin the [bash](https://en.wikipedia.org/wiki/Bash) shell, or\n\n```sh\nsetenv\u00a0LD_LIBRARY_PATH\u00a0${LD_LIBRARY_PATH}:/foo/bar/lib\n```\n\nin [csh](https://en.wikipedia.org/wiki/csh) or [w:tcsh](https://en.wikipedia.org/wiki/tcsh).\n\nAlternatively, in GNU/Linux systems, you can add the library directory to the system-wide file `/etc/ld.so.conf` and then (as root) run `/sbin/ldconfig`.\n\nStatic libraries\n----------------\n\nBy default, NLopt compiles as a shared library (also called a dynamic-link library). The alternative is to compile NLopt as a static library.\n\nCompiling NLopt as a static library is easy. Just add `-DBUILD_SHARED_LIBS=OFF` to the `cmake` flags, as in:\n\n```sh\ncmake -DBUILD_SHARED_LIBS=OFF ..\n```\n\nThen you run `make` and `make` `install` as usual.\n\n\nOctave and Matlab plugins\n-------------------------\n\nWhen you compile NLopt using the above commands, it will automatically compile plugins for both Matlab and GNU Octave (a free Matlab clone) if the latter programs are installed. On most current systems, Matlab and Octave plugins require NLopt to be compiled as a shared library (see above).\n\n### Matlab\n\nIn particular, for Matlab plugins to be installed, you should provide the Matlab installation dir, eg:\n\n```sh\ncmake -DMatlab_ROOT_DIR=/opt/matlab/RYYYYx/ ..\n```\n\nSome versions of Matlab also require that you compile NLopt as a shared library in order to produce a Matlab plugin; see below.\n\nThe Matlab plugins (along with help files and other `.m` files) are installed into `INSTALL_MEX_DIR`. You can override the default by passing a `INSTALL_MEX_DIR` to `cmake`, via (in addition to other `cmake` arguments):\n\n```sh\ncmake -DINSTALL_MEX_DIR=dir ..\n```\n\nto install the Matlab plugins in directory *dir*. In this case, however, when you run Matlab you will either need to run in the *dir* directory or explicitly add *dir* to your Matlab path (see the Matlab `path` command).\n\nMatlab's standard C++ library might be incompatible with the one used by your compiler, in that case you can try to disable the C++ algorithms:\n\n```sh\ncmake -DNLOPT_CXX=OFF ..\n```\n\n### Octave\n\nFor the Octave plugins to be installed, you need to have the Octave `mkoctfile` program in your PATH. `mkoctfile` is Octave's equivalent of `mex`. If you are using a GNU/Linux system, and you installed Octave using one of the precompiled packages for your distribution, then you probably need to install a *separate package* to get `mkoctfile`. For example, on Debian you need to install the `octave-headers` package, and on Redhat you need the `octave-devel` package.\n\nBy default, the compiled Octave plugins (`.oct` files) are installed into the octave extension binary directory relatively to the installation prefix (usually something like `/usr/local/lib/octave/2.1.73/site/oct/i486-pc-linux-gnu`), and the .m script files are installed into the site extension directory relatively the the installation prefix (usually something like `/usr/local/share/octave/2.1.73/site/m/`). You can change these defaults by passing `INSTALL_OCT_DIR` and `INSTALL_M_DIR`, respectively, to the cmake script, via:\n\n```sh\ncmake -DINSTALL_OCT_DIR=octdir\u00a0-DINSTALL_M_DIR=mdir ..\n```\n\nPython plugins\n--------------\n\nIf [Python](https://en.wikipedia.org/wiki/Python_(programming_language)) is installed on your machine, and you configured NLopt as a shared library (see above), then NLopt will automatically compile and install a Python `nlopt` module. You also need [NumPy](https://en.wikipedia.org/wiki/NumPy) to be installed, as NLopt's Python interface uses NumPy array types.\n\nTo specify a particular version or location of Python, use the `PYTHON_EXECUTABLE` variable to set the full path to the `python` executable:\n\n```sh\ncmake -DPYTHON_EXECUTABLE=/usr/bin/python ..\n```\n\nGNU Guile plugins\n-----------------\n\nIf [Guile](https://en.wikipedia.org/wiki/GNU_Guile) is installed on your machine, and you configured NLopt as a shared library (see above), then a Guile `nlopt` module will automatically be compiled and installed.\n\nNote that many GNU/Linux distributions come with only the Guile program and shared libraries pre-installed; to compile the NLopt plugin you will also need the Guile programming header files, which are usually in a `guile-dev` or `guile-devel` package that you must install separately.\n\nIf you want to specify a particular version or a nonstandard location of Guile, you should use the `GUILE_CONFIG_EXECUTABLE` and `GUILE_EXECUTABLE` variables to specify the locations of the `guile-config` and `guile` programs:\n\n```sh\ncmake -DGUILE_EXECUTABLE=/usr/bin/guile\u00a0GUILE_CONFIG_EXECUTABLE=/usr/bin/guile-config ..\n```\n\n(The `cmake` script uses these programs to determine the compiler flags and installation directories for Guile plugins.)\n\nBy default, the Guile plugin is installed in the guile extension directory defined relatively to the installation prefix.\n\nNote, however, that if you do this then Guile may not know where to load the `nlopt` module from. You can [update the Guile load path](http://www.gnu.org/software/guile/manual/html_node/Build-Config.html) by changing the `%load-path` variable in Guile or using the `GUILE_LOAD_PATH` environment variable.\n\nNLopt with C++ algorithms\n-------------------------\n\nNLopt, as-is, is callable from C, C++, and Fortran, with optional Matlab and GNU Octave plugins (and even installs an `nlopt.hpp` C++ header file to allow you to call it in a more C++ style). By default, it includes subroutines written in C (or written in Fortran and converted to C) and C++. If you configure with:\n\n```sh\ncmake -DNLOPT_CXX=OFF ..\n```\n\nhowever, it will disable algorithms implemented in C++ (StoGO and AGS algorithms).\n\nThe resulting library has the *same* interface as the ordinary NLopt library, and can *still* be called from ordinary C, C++, and Fortran programs. However, one no longer has to link with the C++ standard libraries, which can sometimes be convenient for non-C++ programs, and allows libnlopt to be compatible with multiple C++ compilers simultaneously.\n\n"
      },
      "source": "https://raw.githubusercontent.com/schmeing/ReSeq/master/nlopt/doc/docs/NLopt_Installation.md",
      "technique": "file_exploration"
    },
    {
      "confidence": 1.0,
      "result": {
        "original_header": "<a name=\"requirements\"></a>Requirements",
        "type": "Text_excerpt",
        "value": "| Requirement               | Ubuntu/Debian                      | CentOS | Manual installation | Comments | Tested version |\n|---------------------------|------------------------------------|--------|---------------------|----------|----------------|\n| Linux system              |\n| Compiler supporting C++14 | `sudo apt install build-essential` | `sudo yum install gcc gcc-c++ glibc-devel make` | | On CentOs 7 the g++ compiler is too old to support C++14 so you need to additionally to the yum command install a newer version following for example this guide (https://linuxhostsupport.com/blog/how-to-install-gcc-on-centos-7/). If the standard install path `usr/local/` was used, afterwards the `CXX` variable has to be set to `/usr/local/bin/c++`, the `CC` variable to `/usr/local/bin/gcc`, `/usr/local/lib64/` has to be added to your `LD_LIBRARY_PATH` and `/usr/local/bin` to your `PATH` before installing boost. | 7.2.1 20171019|\n| ZLIB                      | `sudo apt-get install zlib1g-dev`  | `sudo yum install zlib-devel`   | | | |\n| BZip2                     | `sudo apt-get install libbz2-dev`  | `sudo yum install bzip2-devel`  | | | |\n| Python 3                  |                                    |                                 | | | 3.6.11 |\n| Python libraries          | `sudo apt-get install python3-dev`  | `sudo yum install python3-devel.x86_64` | | | |\n| Git                       | `sudo apt-get install git`         | `sudo yum install git`          | | | |\n| CMake                     | `sudo apt-get install cmake`       | (too old version)               | https://cmake.org/install/  | The newest versions (starting 3.16) require `sudo apt-get install libssl-dev` or `sudo yum install openssl-devel` | 3.5.1 |\n| Boost C++ libraries       | `sudo apt-get install libboost-all-dev` | (version not working) | https://www.boost.org/doc/libs/1_71_0/more/getting_started/unix-variants.html | Only download and extraction in section 1 and library builds in section 5 are strictly needed, if you set a prefix you need to set `BOOST_ROOT` to this `prefix` before the installation process below or you will get boost library errors at the cmake and make step. If you manually installed g++ run `./b2` without sudo so the environment variables `CXX` and `CC` are found. | 1.67.0 |\n| SWIG                      | `sudo apt-get install swig`        | (too old version)               | http://www.swig.org/Doc4.0/Preface.html | If you set a prefix you need to add prefix/bin to your PATH variable | 3.0.8 |\n \n"
      },
      "source": "https://raw.githubusercontent.com/schmeing/ReSeq/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9974725451263783,
      "result": {
        "original_header": "<a name=\"installation\"></a>Installation",
        "type": "Text_excerpt",
        "value": "To install to the standard folder `usr/local` or to keep everything in the build folder:\n```\ncd /where/you/want/to/build/ReSeq\ngit clone https://github.com/schmeing/ReSeq.git\ncd ReSeq\nmkdir build\ncd build\ncmake ..\nmake\n``` \nTo install to a different folder the same steps apply but the `cmake ..` line has to be exchange with:\n```\ncmake -DCMAKE_INSTALL_PREFIX=/where/you/want/to/install/ReSeq/ ..\n``` \nThe executable file will afterwards be `/where/you/want/to/build/ReSeq/ReSeq/build/bin/reseq` and can be added to the PATH variable or copied to the desired place. \nAlternatively ReSeq can be install to the standard folder `usr/local` or the previously defined folder by:\n```\nmake install\n``` \nTo test the installation run:\n```\nreseq test\n``` \nSome useful python scripts can be found in `/where/you/want/to/install/ReSeq/ReSeq/python` or after an installation in `usr/local/bin` or `/where/you/want/to/install/ReSeq/bin/`.\n \n"
      },
      "source": "https://raw.githubusercontent.com/schmeing/ReSeq/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 1.0,
      "result": {
        "original_header": "<a name=\"conda\"></a>Bioconda",
        "type": "Text_excerpt",
        "value": "ReSeq can also be installed in an automatic fashion via anaconda/miniconda(https://docs.conda.io/projects/continuumio-conda/en/latest/user-guide/install/index.html) with the following command:\n```\nconda install -c bioconda -c conda-forge reseq\n```\nHowever, updates will not be as frequent and the option to switch to the devel branch to get the most recent bugfixes is missing.\n \n"
      },
      "source": "https://raw.githubusercontent.com/schmeing/ReSeq/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8368832970752611,
      "result": {
        "original_header": "<a name=\"faq\"></a>FAQ",
        "type": "Text_excerpt",
        "value": "**Can I simulate exome sequencing?**\nYes. You need to use a reference that only contains the exons as individual scaffolds. Using `--refBiasFile` you can specify the coverage of individual exons. To simulate intron contamination you can add the whole reference to the reference containing the exons and strongly reduce the coverage for these scaffolds using `--refBiasFile`. \n"
      },
      "source": "https://raw.githubusercontent.com/schmeing/ReSeq/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9999999999995453,
      "result": {
        "original_header": "<a name=\"libraries\"></a>Included libraries",
        "type": "Text_excerpt",
        "value": "Googletest (https://github.com/google/googletest.git, BSD 3-Clause license)\\\nNLopt (https://github.com/stevengj/nlopt.git, MIT license)\\\nSeqAn (https://github.com/seqan/seqan, BSD 3-Clause license)\\\nskewer (https://github.com/relipmoc/skewer, MIT license, made slight adaptations to the code to be able to include it)\n \n"
      },
      "source": "https://raw.githubusercontent.com/schmeing/ReSeq/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "invocation": [
    {
      "confidence": 0.8324934826391838,
      "result": {
        "original_header": "<a name=\"installation\"></a>Installation",
        "type": "Text_excerpt",
        "value": "To test the installation run:\n```\nreseq test\n``` \n"
      },
      "source": "https://raw.githubusercontent.com/schmeing/ReSeq/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/schmeing/ReSeq/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ""
      },
      "technique": "GitHub_API"
    }
  ],
  "license": [
    {
      "confidence": 1,
      "result": {
        "name": "MIT License",
        "spdx_id": "MIT",
        "type": "License",
        "url": "https://api.github.com/licenses/mit",
        "value": "https://api.github.com/licenses/mit"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "type": "File_dump",
        "value": "MIT License\n\nCopyright (c) 2019 schmeing\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
      },
      "source": "https://raw.githubusercontent.com/schmeing/ReSeq/master/LICENSE",
      "technique": "file_exploration"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "ReSeq"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "User",
        "value": "schmeing"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "C++",
        "size": 17053887,
        "type": "Programming_language",
        "value": "C++"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "C",
        "size": 1760813,
        "type": "Programming_language",
        "value": "C"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 589104,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Fortran",
        "size": 364892,
        "type": "Programming_language",
        "value": "Fortran"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "CMake",
        "size": 275957,
        "type": "Programming_language",
        "value": "CMake"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Roff",
        "size": 66687,
        "type": "Programming_language",
        "value": "Roff"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Shell",
        "size": 45720,
        "type": "Programming_language",
        "value": "Shell"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "MATLAB",
        "size": 26762,
        "type": "Programming_language",
        "value": "MATLAB"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Starlark",
        "size": 22813,
        "type": "Programming_language",
        "value": "Starlark"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Batchfile",
        "size": 7624,
        "type": "Programming_language",
        "value": "Batchfile"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "SWIG",
        "size": 6284,
        "type": "Programming_language",
        "value": "SWIG"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Tcl",
        "size": 3861,
        "type": "Programming_language",
        "value": "Tcl"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Makefile",
        "size": 2106,
        "type": "Programming_language",
        "value": "Makefile"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Scheme",
        "size": 1204,
        "type": "Programming_language",
        "value": "Scheme"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/schmeing/ReSeq/master/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "releases": [
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "schmeing",
          "type": "User"
        },
        "date_created": "2020-12-01T08:31:34Z",
        "date_published": "2020-12-01T09:52:24Z",
        "description": "The first release of ReSeq (v1.1)",
        "html_url": "https://github.com/schmeing/ReSeq/releases/tag/v1.1",
        "name": "First Release",
        "release_id": 34623088,
        "tag": "v1.1",
        "tarball_url": "https://api.github.com/repos/schmeing/ReSeq/tarball/v1.1",
        "type": "Release",
        "url": "https://api.github.com/repos/schmeing/ReSeq/releases/34623088",
        "value": "https://api.github.com/repos/schmeing/ReSeq/releases/34623088",
        "zipball_url": "https://api.github.com/repos/schmeing/ReSeq/zipball/v1.1"
      },
      "technique": "GitHub_API"
    }
  ],
  "somef_missing_categories": [
    "citation",
    "acknowledgement",
    "run",
    "download",
    "requirements",
    "contact",
    "contributors",
    "support",
    "identifier",
    "has_build_file",
    "executable_example"
  ],
  "somef_provenance": {
    "date": "2024-10-06 14:51:21",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 52
      },
      "technique": "GitHub_API"
    }
  ],
  "usage": [
    {
      "confidence": 1,
      "result": {
        "original_header": "<a name=\"quickstart\"></a>Quick start examples",
        "parent_header": [
          "ReSeq"
        ],
        "type": "Text_excerpt",
        "value": "To create simulated data similar to real data you first need to map the real data to a reference. For example with `bowtie2`:\n```\nbowtie2-build my_reference.fa my_reference\nbowtie2 -p 32 -X 2000 -x my_reference -1 my_data_1.fq -2 my_data_2.fq | samtools sort -m 10G -@ 4 -T _tmp -o my_mappings.bam -\n```\n\nTo run the full simulation pipeline (Stats creation, Probability estimation, Simulation) execute:\n```\nreseq illuminaPE -j 32 -r my_reference.fa -b my_mappings.bam -1 my_simulated_data_1.fq -2 my_simulated_data_2.fq\n```\n\nThe same is done by the following three commands for the three different steps (So you can run for example only the simulation the second time you want to simulate from the same real data):\n```\nreseq illuminaPE -j 32 -r my_reference.fa -b my_mappings.bam --statsOnly\nreseq illuminaPE -j 32 -s my_mappings.bam.reseq --stopAfterEstimation\nreseq illuminaPE -j 32 -R my_reference.fa -s my_mappings.bam.reseq --ipfIterations 0 -1 my_simulated_data_1.fq -2 my_simulated_data_2.fq\n```\nIn order to add variation (to simulate diploid genomes or populations) the parameter `-V` needs to be added:\n```\nreseq illuminaPE -j 32 -r my_reference.fa -b my_mappings.bam -V my_variation.vcf -1 my_simulated_data_1.fq -2 my_simulated_data_2.fq\n```\nor\n```\nreseq illuminaPE -j 32 -R my_reference.fa -s my_mappings.bam.reseq -V my_variation.vcf --ipfIterations 0 -1 my_simulated_data_1.fq -2 my_simulated_data_2.fq\n```\n\nTo run a simulation with tiles the tile information needs to stay in the read names after the mapping. This means there must not be a space before it, like it is often the case for read archive data. To replace the space on the fly with an underscore the reseq-prepare-names.py script is provided. In this case run the mapping like this:\n```\nbowtie2 -p 32 -X 2000 -x my_reference -1 <(reseq-prepare-names.py my_data_1.fq my_data_2.fq) -2 <(reseq-prepare-names.py my_data_2.fq my_data_1.fq) | samtools sort -m 10G -@ 4 -T _tmp -o my_mappings.bam -\n```\nFor best results it is always advised to create your own profiles from a dataset very closely matching the desired sequencer, chemistry, fragmentation, adapters, PCR cycles, etc. Furthermore, training on the same or a closely related species, is best to be sure that the necessary profile space (e.g. range of GC content) is well populated. However, in many situations there is no specific case that should be simulated, but a wide variety of datasets is important. Under this condition finding good datasets is tedious work and recreating the same profile from a given dataset does not help to ensure the quality of the simulated data. Therefore, [this repository](https://github.com/schmeing/ReSeq-profiles) is designed to provide high-quality profiles with detailed information on the original datasets. Whenever possible, method benchmarks should be performed on the simulated and the original dataset to verify that the simulation created realistic conditions for the particular use case.\n"
      },
      "source": "https://raw.githubusercontent.com/schmeing/ReSeq/master/README.md",
      "technique": "header_analysis"
    }
  ]
}