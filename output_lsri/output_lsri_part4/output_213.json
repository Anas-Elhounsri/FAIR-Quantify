{
  "application_domain": [
    {
      "confidence": 63.83,
      "result": {
        "type": "String",
        "value": "Natural Language Processing"
      },
      "technique": "supervised_classification"
    }
  ],
  "citation": [
    {
      "confidence": 1,
      "result": {
        "author": "Heinzinger, Michael and Elnaggar, Ahmed and Wang, Yu and Dallago, Christian and Nechaev, Dmitrii and Matthes, Florian and Rost, Burkhard",
        "format": "bibtex",
        "title": "Modeling aspects of the language of life through transfer-learning protein sequences",
        "type": "Text_excerpt",
        "value": "@article{heinzinger2019modeling,\n    publisher = {Springer},\n    year = {2019},\n    pages = {723},\n    number = {1},\n    volume = {20},\n    journal = {BMC bioinformatics},\n    author = {Heinzinger, Michael and Elnaggar, Ahmed and Wang, Yu and Dallago, Christian and Nechaev, Dmitrii and Matthes, Florian and Rost, Burkhard},\n    title = {Modeling aspects of the language of life through transfer-learning protein sequences},\n}"
      },
      "source": "https://raw.githubusercontent.com/Rostlab/SeqVec/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/Rostlab/SeqVec"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2019-05-01T11:08:56Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2024-08-31T18:09:06Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "Modelling the Language of Life - Deep Learning Protein Sequences"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 0.939538182029588,
      "result": {
        "original_header": "SeqVec",
        "type": "Text_excerpt",
        "value": "Repository for the paper [Modeling aspects of the language of life through transfer-learning protein sequences](https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-019-3220-8).\nHolds pre-trained SeqVec model for creating embeddings for amino acid sequences. Also, contains checkpoint for fine-tuning.\n \n"
      },
      "source": "https://raw.githubusercontent.com/Rostlab/SeqVec/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9797665454769838,
      "result": {
        "original_header": "Abstract",
        "type": "Text_excerpt",
        "value": "**Background**: One common task in Computational Biology is the prediction of aspects of protein function and structure from their amino acid sequence. For 26 years, most state-of-the-art approaches toward this end have been marrying machine learning and evolutionary information. The retrieval of related proteins from ever growing sequence databases is becoming so time-consuming that the analysis of entire proteomes becomes challenging. On top, evolutionary information is less powerful for small families, e.g. for proteins from the Dark Proteome. \n**Results**: We introduce a novel way to represent protein sequences as continuous vectors (embeddings) by using the deep bi-directional model ELMo taken from natural language processing (NLP). The model has effectively captured the biophysical properties of protein sequences from unlabeled big data (UniRef50). After training, this knowledge is transferred to single protein sequences by predicting relevant sequence features. We refer to these new embeddings as SeqVec (Sequence-to-Vector) and demonstrate their effectiveness by training simple convolutional neural networks on existing data sets for two completely different prediction tasks. At the per-residue level, we significantly improved secondary structure (for NetSurfP-2.0 data set: Q3=79%\u00b11, Q8=68%\u00b11) and disorder predictions (MCC=0.59\u00b10.03) over methods not using evolutionary information. At the per-protein level, we predicted subcellular localization in ten classes (for DeepLoc data set: Q10=68%\u00b11) and distinguished membrane- bound from water-soluble proteins (Q2= 87%\u00b11). All results built upon the embeddings gained from the new tool SeqVec neither explicitly nor implicitly using evolutionary information. Nevertheless, it improved over some methods using such information. Where the lightning-fast HHblits needed on average about two minutes to generate the evolutionary information for a target protein, SeqVec created the vector representation on average in 0.03 seconds. \n**Conclusion**: We have shown that transfer learning can be used to capture biochemical or biophysical properties of protein sequences from large unlabeled sequence databases. The effectiveness of the proposed approach was showcased for different prediction tasks using only single protein sequences. SeqVec embeddings enable predictions that outperform even some methods using evolutionary information. Thus, they prove to condense the underlying principles of protein sequences. This might be the first step towards competitive predictions based only on single protein sequences.\n \n"
      },
      "source": "https://raw.githubusercontent.com/Rostlab/SeqVec/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9971653441436654,
      "result": {
        "original_header": "t-SNE projections of SeqVec",
        "type": "Text_excerpt",
        "value": "![2D t-SNE projections](seqvec_tsne.png \"2D t-SNE projections of SeqVec\")\n*2D t-SNE projections of unsupervised SeqVec embeddings highlight different realities of proteins and their constituent parts, amino acids.* Panels (b) to (d) are based on the same data set (Structural Classification of Proteins \u2013 extended (SCOPe) 2.07, redundancy reduced at 40%). For these plots, only subsets of SCOPe containing proteins with the annotation of interest (enzymatic activity (c) and kingdom (d)) may be displayed. **Panel (a)**: the embedding space confirms: the 20 standard amino acids are clustered according to their biochemical and biophysical properties, i.e. hydrophobicity, charge or size. The unique role of Cysteine (C, mostly hydrophobic and polar) is conserved. **Panel (b)**: SeqVec embeddings capture structural information as annotated in the main classes in SCOPe without ever having been explicitly trained on structural features. **Panel (c)**: many small, local clusters share function as given by the main classes in the Enzyme Commission Number (E.C.). **Panel (d)**: similarly, small, local clusters represent different kingdoms of life.\n \n"
      },
      "source": "https://raw.githubusercontent.com/Rostlab/SeqVec/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/Rostlab/SeqVec/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "faq": [
    {
      "confidence": 1,
      "result": {
        "original_header": "FAQ",
        "type": "Text_excerpt",
        "value": "**Torch version conflict**\nIf you encounter a version conflict while pip-installing seqvec (```ERROR: No matching distribution found for torch<1.3,>=1.2 (from seqvec)```), creating a new conda-environment with Python 3.7 can resolve your issue.\n\n**Slow embedding of very long sequences**\nWe've added an option which automatically falls back to CPU mode if even single-sequence processing fails on GPU due to memory problems. While this allows you to embed also very long proteins, e.g. Q8WZ42 (Titin, ~35k residues), it slows down the embedding process.\n\n"
      },
      "source": "https://raw.githubusercontent.com/Rostlab/SeqVec/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 13
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/Rostlab/SeqVec/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "Rostlab/SeqVec"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "SeqVec"
      },
      "source": "https://raw.githubusercontent.com/Rostlab/SeqVec/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "has_build_file": [
    {
      "confidence": 1,
      "result": {
        "format": "dockerfile",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Rostlab/SeqVec/master/Dockerfile"
      },
      "source": "https://raw.githubusercontent.com/Rostlab/SeqVec/master/Dockerfile",
      "technique": "file_exploration"
    }
  ],
  "images": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Rostlab/SeqVec/master/seqvec_tsne.png"
      },
      "source": "https://raw.githubusercontent.com/Rostlab/SeqVec/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "installation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Installation",
        "type": "Text_excerpt",
        "value": "If you are interested in running seqvec, you can use the convenience `seqvec` pip package:\n```\npip install seqvec\n```\n\nAdditionally, we provide a pipeline that integrates SeqVec, as well as other language models through a shared interface, see [bio_embeddings](https://github.com/sacdallago/bio_embeddings). The pipeline also includes secondary structure and subcellular localization prediction models, and more tools for embedding space visualization and embedding annotation transfer.\n"
      },
      "source": "https://raw.githubusercontent.com/Rostlab/SeqVec/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/Rostlab/SeqVec/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "bioinformatics, protein, protein-function, protein-structure"
      },
      "technique": "GitHub_API"
    }
  ],
  "license": [
    {
      "confidence": 1,
      "result": {
        "name": "MIT License",
        "spdx_id": "MIT",
        "type": "License",
        "url": "https://api.github.com/licenses/mit",
        "value": "https://api.github.com/licenses/mit"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "type": "File_dump",
        "value": "MIT License\n\nCopyright (c) 2019 Rostlab, Prof. Dr. Burkhard Rost\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
      },
      "source": "https://raw.githubusercontent.com/Rostlab/SeqVec/master/LICENSE",
      "technique": "file_exploration"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "SeqVec"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "Organization",
        "value": "Rostlab"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 20716,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Dockerfile",
        "size": 1177,
        "type": "Programming_language",
        "value": "Dockerfile"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Rostlab/SeqVec/master/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "somef_missing_categories": [
    "acknowledgement",
    "run",
    "download",
    "requirements",
    "contact",
    "contributors",
    "documentation",
    "support",
    "identifier",
    "executable_example"
  ],
  "somef_provenance": {
    "date": "2024-11-04 02:30:09",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 116
      },
      "technique": "GitHub_API"
    }
  ],
  "usage": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Example",
        "type": "Text_excerpt",
        "value": "In the [bio_embeddings](https://github.com/sacdallago/bio_embeddings) github repo, you can find several examples in the [`examples`](https://github.com/sacdallago/bio_embeddings/tree/develop/examples) folder.\n\nFor a general example on how to extract embeddings using ELMo, please check the\nofficial ELMo implementation: [ELMo-Tutorial](https://github.com/allenai/bilm-tf)\n\nVia the `seqvec` pip package, you can compute embeddings for a fasta file with the `seqvec` command. Add `--protein True` to get an embedding per sequence instead of per residue.\n\n```\nseqvec -i sequences.fasta -o embeddings.npz\n```\n\nLoad the embeddings with numpy:\n\n```python\nimport numpy as np\ndata = np.load(\"embeddings.npz\")  # type: Dict[str, np.ndarray]\n```\n\nIf you specify `.npy` as output format (e.g. with `-o embeddings.npy`), the script will save the embeddings as an numpy array and the corresponding identifiers (as extracted from the header line in the fasta file) in a json file besides it. The sorting in the json file corresponds to the indexing in the npy file. The npy file can be loaded via:\n\n```python\nimport json\nimport numpy as np\n\ndata = np.load(\"embeddings.npy\") # shape=(n_proteins,)\nwith open(\"embeddings.json\") as fp:\n    labels = json.load(fp)\n```\n\n**How to integrate the embedder into an existing workflow:**\n\n\nLoad pre-trained model:\n\n```python\nfrom allennlp.commands.elmo import ElmoEmbedder\nfrom pathlib import Path\n\nmodel_dir = Path('path/to/pretrained/SeqVec_directory')\nweights = model_dir / 'weights.hdf5'\noptions = model_dir / 'options.json'\nembedder = ElmoEmbedder(options,weights, cuda_device=0) # cuda_device=-1 for CPU\n```\n\nGet embedding for amino acid sequence:\n\n```python\nseq = 'SEQWENCE' # your amino acid sequence\nembedding = embedder.embed_sentence(list(seq)) # List-of-Lists with shape [3,L,1024]\n```\n\nBatch embed sequences:\n\n```python\nseq1 = 'SEQWENCE' # your amino acid sequence\nseq2 = 'PROTEIN'\nseqs = [list(seq1), list(seq2)]\nseqs.sort(key=len) # sorting is crucial for speed\nembedding = embedder.embed_sentences(seqs) # returns: List-of-Lists with shape [3,L,1024]\n```\n\nGet 1024-dimensional embedding for per-residue predictions:\n\n```python\nimport torch\nresidue_embd = torch.tensor(embedding).sum(dim=0) # Tensor with shape [L,1024]\n```\n\nGet 1024-dimensional embedding for per-protein predictions:\n```python\nprotein_embd = torch.tensor(embedding).sum(dim=0).mean(dim=0) # Vector with shape [1024]\n```"
      },
      "source": "https://raw.githubusercontent.com/Rostlab/SeqVec/master/README.md",
      "technique": "header_analysis"
    }
  ]
}