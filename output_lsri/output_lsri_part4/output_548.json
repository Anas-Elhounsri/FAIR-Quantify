{
  "application_domain": [
    {
      "confidence": 104.59,
      "result": {
        "type": "String",
        "value": "Natural Language Processing"
      },
      "technique": "supervised_classification"
    }
  ],
  "citation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Citation",
        "parent_header": [
          "BioBERT Pre-trained Weights"
        ],
        "type": "Text_excerpt",
        "value": "```\n@article{10.1093/bioinformatics/btz682,\n    author = {Lee, Jinhyuk and Yoon, Wonjin and Kim, Sungdong and Kim, Donghyeon and Kim, Sunkyu and So, Chan Ho and Kang, Jaewoo},\n    title = \"{BioBERT: a pre-trained biomedical language representation model for biomedical text mining}\",\n    journal = {Bioinformatics},\n    year = {2019},\n    month = {09},\n    issn = {1367-4803},\n    doi = {10.1093/bioinformatics/btz682},\n    url = {https://doi.org/10.1093/bioinformatics/btz682},\n}\n```\n"
      },
      "source": "https://raw.githubusercontent.com/naver/biobert-pretrained/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "author": "Lee, Jinhyuk and Yoon, Wonjin and Kim, Sungdong and Kim, Donghyeon and Kim, Sunkyu and So, Chan Ho and Kang, Jaewoo",
        "doi": "10.1093/bioinformatics/btz682",
        "format": "bibtex",
        "title": "{BioBERT: a pre-trained biomedical language representation model for biomedical text mining}",
        "type": "Text_excerpt",
        "url": "https://doi.org/10.1093/bioinformatics/btz682",
        "value": "@article{10.1093/bioinformatics/btz682,\n    url = {https://doi.org/10.1093/bioinformatics/btz682},\n    doi = {10.1093/bioinformatics/btz682},\n    issn = {1367-4803},\n    month = {09},\n    year = {2019},\n    journal = {Bioinformatics},\n    title = {{BioBERT: a pre-trained biomedical language representation model for biomedical text mining}},\n    author = {Lee, Jinhyuk and Yoon, Wonjin and Kim, Sungdong and Kim, Donghyeon and Kim, Sunkyu and So, Chan Ho and Kang, Jaewoo},\n}"
      },
      "source": "https://raw.githubusercontent.com/naver/biobert-pretrained/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/naver/biobert-pretrained"
      },
      "technique": "GitHub_API"
    }
  ],
  "contact": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Contact information",
        "parent_header": [
          "BioBERT Pre-trained Weights"
        ],
        "type": "Text_excerpt",
        "value": "For help or issues using pre-trained weights of BioBERT, please submit a GitHub issue. Please contact Jinhyuk Lee\n(`lee.jnhk@gmail.com`), or Sungdong Kim (`sungdong.kim@navercorp.com`) for communication related to pre-trained weights of BioBERT.\n"
      },
      "source": "https://raw.githubusercontent.com/naver/biobert-pretrained/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2019-01-28T02:05:23Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2024-11-03T21:16:38Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "BioBERT: a pre-trained biomedical language representation model for biomedical text mining"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 0.9780891888490352,
      "result": {
        "original_header": "BioBERT Pre-trained Weights",
        "type": "Text_excerpt",
        "value": "This repository provides pre-trained weights of BioBERT, a language representation model for biomedical domain, especially designed for biomedical text mining tasks such as biomedical named entity recognition, relation extraction, question answering, etc.\nPlease refer to our paper [BioBERT: a pre-trained biomedical language representation model for biomedical text mining](https://arxiv.org/abs/1901.08746) for more details.\n \n"
      },
      "source": "https://raw.githubusercontent.com/naver/biobert-pretrained/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9733540236823021,
      "result": {
        "original_header": "Pre-training corpus",
        "type": "Text_excerpt",
        "value": "We do not provide pre-processed version of each corpus. However, each pre-training corpus could be found in the following links:\n*   **`PubMed Abstracts1`**: ftp://ftp.ncbi.nlm.nih.gov/pubmed/baseline/\n*   **`PubMed Abstracts2`**: ftp://ftp.ncbi.nlm.nih.gov/pubmed/updatefiles/\n*   **`PubMed Central Full Texts`**: ftp://ftp.ncbi.nlm.nih.gov/pub/pmc/oa_bulk/ \nEstimated size of each corpus is 4.5 billion words for **`PubMed Abstracts1`** + **`PubMed Abstracts2`**, and 13.5 billion words for **`PubMed Central Full Texts`**.\n \n"
      },
      "source": "https://raw.githubusercontent.com/naver/biobert-pretrained/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "download": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Downloading pre-trained weights",
        "parent_header": [
          "BioBERT Pre-trained Weights"
        ],
        "type": "Text_excerpt",
        "value": "Go to [releases](https://github.com/naver/biobert-pretrained/releases) section of this repository or click links below to download pre-trained weights of BioBERT.\nWe provide three combinations of pre-trained weights: BioBERT (+ PubMed), BioBERT (+ PMC), and BioBERT (+ PubMed + PMC).\nPre-training was based on the [original BERT code](https://github.com/google-research/bert) provided by Google, and training details are described in our paper. Currently available versions of pre-trained weights are as follows:\n\n* **[BioBERT-Base v1.1 (+ PubMed 1M)](https://drive.google.com/file/d/1R84voFKHfWV9xjzeLzWBbmY1uOMYpnyD/view?usp=sharing)** - based on BERT-base-Cased (same vocabulary)\n* **[BioBERT-Large v1.1 (+ PubMed 1M)](https://drive.google.com/file/d/1GJpGjQj6aZPV-EfbiQELpBkvlGtoKiyA/view?usp=sharing)** - based on BERT-large-Cased (custom 30k vocabulary), [NER/QA Results](https://github.com/dmis-lab/biobert/wiki/BioBERT-Large-Results)\n* **[BioBERT-Base v1.0 (+ PubMed 200K)](https://drive.google.com/file/d/17j6pSKZt5TtJ8oQCDNIwlSZ0q5w7NNBg/view?usp=sharing)** - based on BERT-base-Cased (same vocabulary)\n* **[BioBERT-Base v1.0 (+ PMC 270K)](https://drive.google.com/file/d/1LiAJklso-DCAJmBekRTVEvqUOfm0a9fX/view?usp=sharing)** - based on BERT-base-Cased (same vocabulary)\n* **[BioBERT-Base v1.0 (+ PubMed 200K + PMC 270K)](https://drive.google.com/file/d/1jGUu2dWB1RaeXmezeJmdiPKQp3ZCmNb7/view?usp=sharing)** - based on BERT-base-Cased (same vocabulary)\n\nMake sure to specify the versions of pre-trained weights used in your works.\nIf you have difficulty choosing which one to use, we recommend using **BioBERT-Base v1.1 (+ PubMed 1M)** or **BioBERT-Large v1.1 (+ PubMed 1M)** depending on your GPU resources.\nNote that for BioBERT-Base, we are using WordPiece vocabulary (`vocab.txt`) provided by Google as any new words in biomedical corpus can be represented with subwords (for instance, Leukemia => Leu + ##ke + ##mia).\nMore details are in the closed [issue #1](https://github.com/naver/biobert-pretrained/issues/1).\n"
      },
      "source": "https://raw.githubusercontent.com/naver/biobert-pretrained/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/naver/biobert-pretrained/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 88
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/naver/biobert-pretrained/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "naver/biobert-pretrained"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "BioBERT Pre-trained Weights"
      },
      "source": "https://raw.githubusercontent.com/naver/biobert-pretrained/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/naver/biobert-pretrained/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ""
      },
      "technique": "GitHub_API"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "biobert-pretrained"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "Organization",
        "value": "naver"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/naver/biobert-pretrained/master/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "related_papers": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://arxiv.org/abs/1901.08746"
      },
      "source": "https://raw.githubusercontent.com/naver/biobert-pretrained/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "releases": [
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "jhyuklee",
          "type": "User"
        },
        "date_created": "2019-04-11T00:53:33Z",
        "date_published": "2019-05-16T08:52:17Z",
        "description": "Pre-trained weight of BioBERT v1.1 (+PubMed 1M)",
        "html_url": "https://github.com/naver/biobert-pretrained/releases/tag/v1.1-pubmed",
        "name": "Pre-trained weight of BioBERT v1.1 (+PubMed 1M)",
        "release_id": 17389597,
        "tag": "v1.1-pubmed",
        "tarball_url": "https://api.github.com/repos/naver/biobert-pretrained/tarball/v1.1-pubmed",
        "type": "Release",
        "url": "https://api.github.com/repos/naver/biobert-pretrained/releases/17389597",
        "value": "https://api.github.com/repos/naver/biobert-pretrained/releases/17389597",
        "zipball_url": "https://api.github.com/repos/naver/biobert-pretrained/zipball/v1.1-pubmed"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "DSKSD",
          "type": "User"
        },
        "date_created": "2019-01-28T02:15:12Z",
        "date_published": "2019-01-28T02:30:16Z",
        "description": "Pre-trained weight of BioBERT v1.0 (+PubMed 200K +PMC 270K)\r\nWe excluded optimizer parameters, and the size of file has decreased to less than 400MB.",
        "html_url": "https://github.com/naver/biobert-pretrained/releases/tag/v1.0-pubmed-pmc",
        "name": "Pre-trained weight of BioBERT v1.0 (+PubMed 200K +PMC 270K)",
        "release_id": 15206850,
        "tag": "v1.0-pubmed-pmc",
        "tarball_url": "https://api.github.com/repos/naver/biobert-pretrained/tarball/v1.0-pubmed-pmc",
        "type": "Release",
        "url": "https://api.github.com/repos/naver/biobert-pretrained/releases/15206850",
        "value": "https://api.github.com/repos/naver/biobert-pretrained/releases/15206850",
        "zipball_url": "https://api.github.com/repos/naver/biobert-pretrained/zipball/v1.0-pubmed-pmc"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "DSKSD",
          "type": "User"
        },
        "date_created": "2019-01-28T02:15:12Z",
        "date_published": "2019-01-28T02:29:43Z",
        "description": "Pre-trained weight of BioBERT v1.0 (+PubMed 200K)\r\nWe excluded optimizer parameters, and the size of file has decreased to less than 400MB.",
        "html_url": "https://github.com/naver/biobert-pretrained/releases/tag/v1.0-pubmed",
        "name": "Pre-trained weight of BioBERT v1.0 (+PubMed 200K)",
        "release_id": 15206827,
        "tag": "v1.0-pubmed",
        "tarball_url": "https://api.github.com/repos/naver/biobert-pretrained/tarball/v1.0-pubmed",
        "type": "Release",
        "url": "https://api.github.com/repos/naver/biobert-pretrained/releases/15206827",
        "value": "https://api.github.com/repos/naver/biobert-pretrained/releases/15206827",
        "zipball_url": "https://api.github.com/repos/naver/biobert-pretrained/zipball/v1.0-pubmed"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "DSKSD",
          "type": "User"
        },
        "date_created": "2019-01-28T02:15:12Z",
        "date_published": "2019-01-28T02:29:48Z",
        "description": "Pre-trained weight of BioBERT v1.0 (+PMC 270K) (deprecated)\r\nWe excluded optimizer parameters, and the size of file has decreased to less than 400MB.",
        "html_url": "https://github.com/naver/biobert-pretrained/releases/tag/v1.0-pmc",
        "name": "Pre-trained weight of BioBERT v1.0 (+PMC 270K)",
        "release_id": 15206843,
        "tag": "v1.0-pmc",
        "tarball_url": "https://api.github.com/repos/naver/biobert-pretrained/tarball/v1.0-pmc",
        "type": "Release",
        "url": "https://api.github.com/repos/naver/biobert-pretrained/releases/15206843",
        "value": "https://api.github.com/repos/naver/biobert-pretrained/releases/15206843",
        "zipball_url": "https://api.github.com/repos/naver/biobert-pretrained/zipball/v1.0-pmc"
      },
      "technique": "GitHub_API"
    }
  ],
  "somef_missing_categories": [
    "installation",
    "acknowledgement",
    "run",
    "requirements",
    "contributors",
    "documentation",
    "license",
    "usage",
    "faq",
    "support",
    "identifier",
    "has_build_file",
    "executable_example"
  ],
  "somef_provenance": {
    "date": "2024-11-04 03:55:17",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 663
      },
      "technique": "GitHub_API"
    }
  ],
  "type": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "non-software"
      },
      "technique": "software_type_heuristics"
    }
  ]
}