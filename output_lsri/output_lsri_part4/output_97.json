{
  "application_domain": [
    {
      "confidence": 35.44,
      "result": {
        "type": "String",
        "value": "Computer Vision"
      },
      "technique": "supervised_classification"
    }
  ],
  "citation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Citing LSTD",
        "parent_header": [
          "LSTD: A Low-Shot Transfer Detector for Object Detection"
        ],
        "type": "Text_excerpt",
        "value": "Please cite LSTD in your publicatins if it helps ypur research.\n\n    @inproceedings{hao2018lstd,\n      title = {LSTD: A Low-Shot Transfer Detector for Object Detection},\n      author = {Hao Chen and Yali Wang and Guoyou Wang and Yu Qiao},\n      booktitle = {AAAI},\n      year = {2018}\n    }\n"
      },
      "source": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "author": "Hao Chen and Yali Wang and Guoyou Wang and Yu Qiao",
        "format": "bibtex",
        "title": "LSTD: A Low-Shot Transfer Detector for Object Detection",
        "type": "Text_excerpt",
        "value": "@inproceedings{hao2018lstd,\n    year = {2018},\n    booktitle = {AAAI},\n    author = {Hao Chen and Yali Wang and Guoyou Wang and Yu Qiao},\n    title = {LSTD: A Low-Shot Transfer Detector for Object Detection},\n}"
      },
      "source": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/README.md",
      "technique": "regular_expression"
    }
  ],
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/haochen-rye/LSTD"
      },
      "technique": "GitHub_API"
    }
  ],
  "contributing_guidelines": [
    {
      "confidence": 1,
      "result": {
        "type": "File_dump",
        "value": "# Contributing\n\n## Issues\n\nSpecific Caffe design and development issues, bugs, and feature requests are maintained by GitHub Issues.\n\n_Please do not post usage, installation, or modeling questions, or other requests for help to Issues._\nUse the [caffe-users list](https://groups.google.com/forum/#!forum/caffe-users) instead. This helps developers maintain a clear, uncluttered, and efficient view of the state of Caffe.\n\nWhen reporting a bug, it's most helpful to provide the following information, where applicable:\n\n* What steps reproduce the bug?\n* Can you reproduce the bug using the latest [master](https://github.com/BVLC/caffe/tree/master), compiled with the `DEBUG` make option?\n* What hardware and operating system/distribution are you running?\n* If the bug is a crash, provide the backtrace (usually printed by Caffe; always obtainable with `gdb`).\n\nTry to give your issue a title that is succinct and specific. The devs will rename issues as needed to keep track of them.\n\n## Pull Requests\n\nCaffe welcomes all contributions.\n\nSee the [contributing guide](http://caffe.berkeleyvision.org/development.html) for details.\n\nBriefly: read commit by commit, a PR should tell a clean, compelling story of _one_ improvement to Caffe. In particular:\n\n* A PR should do one clear thing that obviously improves Caffe, and nothing more. Making many smaller PRs is better than making one large PR; review effort is superlinear in the amount of code involved.\n* Similarly, each commit should be a small, atomic change representing one step in development. PRs should be made of many commits where appropriate.\n* Please do rewrite PR history to be clean rather than chronological. Within-PR bugfixes, style cleanups, reversions, etc. should be squashed and should not appear in merged PR history.\n* Anything nonobvious from the code should be explained in comments, commit messages, or the PR description, as appropriate.\n"
      },
      "source": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/CONTRIBUTING.md",
      "technique": "file_exploration"
    }
  ],
  "contributors": [
    {
      "confidence": 1,
      "result": {
        "type": "File_dump",
        "value": "# Contributors\n\nCaffe is developed by a core set of BVLC members and the open-source community.\n\nWe thank all of our [contributors](https://github.com/BVLC/caffe/graphs/contributors)!\n\n**For the detailed history of contributions** of a given file, try\n\n    git blame file\n\nto see line-by-line credits and\n\n    git log --follow file\n\nto see the change log even across renames and rewrites.\n\nPlease refer to the [acknowledgements](http://caffe.berkeleyvision.org/#acknowledgements) on the Caffe site for further details.\n\n**Copyright** is held by the original contributor according to the versioning history; see LICENSE.\n"
      },
      "source": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/CONTRIBUTORS.md",
      "technique": "file_exploration"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2017-09-06T02:44:00Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2023-12-28T07:59:57Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "An object detection architecture combines the advantage of SSD and Faster-RCNN."
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Introduction",
        "parent_header": [
          "LSTD: A Low-Shot Transfer Detector for Object Detection"
        ],
        "type": "Text_excerpt",
        "value": "LSTD is an unified framework for transfer object detetction with a single network. For more details, please refer to our [AAAI 2018 paper](https://arxiv.org/abs/1803.01529v1).\n"
      },
      "source": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 0.9222726445450519,
      "result": {
        "original_header": "Framework",
        "type": "Text_excerpt",
        "value": "LSTD is a network combining the advantage of SSD and Faster-RCNN, where it shares the two-stage detection framework with \nthe feature pyramid of SSD. \nSpecifically, SSD acts as the region proposal network (RPN) in LSTD.\nAdditionally, we propose Transfer Knowledge (TK) and Background Depression (BD) modules for transfer detection task.\nMore details can be found in [LSTD](https://arxiv.org/abs/1803.01529v1).\n<p align=\"center\">\n<img src='https://github.com/Cassie94/LSTD/blob/master/models/archi.png'  width=\"800px\">\n</p> \n\nFor transfer detection, our LSTD outperforms SSD and Faster RCNN significantly.\nMore experiments can be found in [LSTD](https://arxiv.org/abs/1803.01529v1).\n<p align=\"center\">\n<img src='https://github.com/Cassie94/LSTD/blob/master/models/lstd.jpg'  width=\"600px\">\n</p> \n"
      },
      "source": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/README.md",
      "technique": "supervised_classification"
    }
  ],
  "documentation": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/Cassie94/LSTD/tree/lstd/docs"
      },
      "technique": "file_exploration"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/Cassie94/LSTD/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "executable_example": [
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/examples/convert_model.ipynb"
      },
      "source": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/examples/convert_model.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/examples/ssd_detect.ipynb"
      },
      "source": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/examples/ssd_detect.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/examples/02-fine-tuning.ipynb"
      },
      "source": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/examples/02-fine-tuning.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/examples/00-classification.ipynb"
      },
      "source": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/examples/00-classification.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/examples/ssd.ipynb"
      },
      "source": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/examples/ssd.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/examples/net_surgery.ipynb"
      },
      "source": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/examples/net_surgery.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/examples/01-learning-lenet.ipynb"
      },
      "source": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/examples/01-learning-lenet.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/examples/brewing-logreg.ipynb"
      },
      "source": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/examples/brewing-logreg.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/examples/inceptionv3.ipynb"
      },
      "source": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/examples/inceptionv3.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/examples/pascal-multilabel-with-datalayer.ipynb"
      },
      "source": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/examples/pascal-multilabel-with-datalayer.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/examples/detection.ipynb"
      },
      "source": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/examples/detection.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/examples/siamese/mnist_siamese.ipynb"
      },
      "source": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/examples/siamese/mnist_siamese.ipynb",
      "technique": "file_exploration"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 12
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/haochen-rye/LSTD/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "haochen-rye/LSTD"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "LSTD: A Low-Shot Transfer Detector for Object Detection"
      },
      "source": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/README.md",
      "technique": "regular_expression"
    }
  ],
  "has_build_file": [
    {
      "confidence": 1,
      "result": {
        "format": "dockerfile",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/docker/standalone/gpu/Dockerfile"
      },
      "source": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/docker/standalone/gpu/Dockerfile",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "dockerfile",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/docker/standalone/cpu/Dockerfile"
      },
      "source": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/docker/standalone/cpu/Dockerfile",
      "technique": "file_exploration"
    }
  ],
  "has_script_file": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/models/voc2007/kd_oicr_SSD_300x300/train_script.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/scripts/gather_examples.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/scripts/build_docs.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/scripts/download_model_from_gist.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/scripts/deploy_docs.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/scripts/upload_model_to_gist.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/scripts/travis/install-deps.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/scripts/travis/configure.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/scripts/travis/setup-venv.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/scripts/travis/build.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/scripts/travis/configure-cmake.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/scripts/travis/test.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/scripts/travis/install-python-deps.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/scripts/travis/configure-make.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/scripts/travis/defaults.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/examples/sstd/train_script.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/examples/imagenet/resume_training.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/examples/imagenet/create_imagenet.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/examples/imagenet/train_caffenet.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/examples/imagenet/make_imagenet_mean.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/examples/siamese/train_mnist_siamese.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/examples/siamese/create_mnist_siamese.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/examples/mnist/train_mnist_autoencoder_adagrad.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/examples/mnist/train_lenet.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/examples/mnist/train_mnist_autoencoder_nesterov.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/examples/mnist/train_lenet_docker.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/examples/mnist/train_lenet_adam.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/examples/mnist/train_mnist_autoencoder.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/examples/mnist/train_mnist_autoencoder_adadelta.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/examples/mnist/train_lenet_rmsprop.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/examples/mnist/train_lenet_consolidated.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/examples/mnist/create_mnist.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/examples/cifar10/train_full_sigmoid.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/examples/cifar10/train_full.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/examples/cifar10/train_quick.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/examples/cifar10/create_cifar10.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/examples/cifar10/train_full_sigmoid_bn.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/data/ILSVRC2016/create_data.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/data/VOC0712/create_data.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/data/VOC0712/create_list.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/data/ilsvrc12/get_ilsvrc_aux.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/data/mnist/get_mnist.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/data/cifar10/get_cifar10.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/data/coco/create_data.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/tools/extra/parse_log.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/tools/extra/launch_resize_and_crop_images.sh"
      },
      "technique": "file_exploration"
    }
  ],
  "images": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/LSTD: A Low-Shot Transfer Detector for Object Detection</h1>\n<h3>Introduction</h3>\n<p>LSTD is an unified framework for transfer object detetction with a single network. For more details, please refer to our <a href="
      },
      "source": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/README.md",
      "technique": "regular_expression"
    }
  ],
  "installation": [
    {
      "confidence": 1,
      "result": {
        "type": "File_dump",
        "value": "# Installation\n\nSee http://caffe.berkeleyvision.org/installation.html for the latest\ninstallation instructions.\n\nCheck the users group in case you need help:\nhttps://groups.google.com/forum/#!forum/caffe-users\n"
      },
      "source": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/INSTALL.md",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "File_dump",
        "value": "---\ntitle: \"Installation: Ubuntu\"\n---\n\n# Ubuntu Installation\n\n**General dependencies**\n\n    sudo apt-get install libprotobuf-dev libleveldb-dev libsnappy-dev libopencv-dev libhdf5-serial-dev protobuf-compiler\n    sudo apt-get install --no-install-recommends libboost-all-dev\n\n**CUDA**: Install by `apt-get` or the NVIDIA `.run` package.\nThe NVIDIA package tends to follow more recent library and driver versions, but the installation is more manual.\nIf installing from packages, install the library and latest driver separately; the driver bundled with the library is usually out-of-date.\nThis can be skipped for CPU-only installation.\n\n**BLAS**: install ATLAS by `sudo apt-get install libatlas-base-dev` or install OpenBLAS or MKL for better CPU performance.\n\n**Python** (optional): if you use the default Python you will need to `sudo apt-get install` the `python-dev` package to have the Python headers for building the pycaffe interface.\n\n**Compatibility notes, 16.04**\n\nCUDA 8 is required on Ubuntu 16.04.\n\n**Remaining dependencies, 14.04**\n\nEverything is packaged in 14.04.\n\n    sudo apt-get install libgflags-dev libgoogle-glog-dev liblmdb-dev\n\n**Remaining dependencies, 12.04**\n\nThese dependencies need manual installation in 12.04.\n\n    # glog\n    wget https://google-glog.googlecode.com/files/glog-0.3.3.tar.gz\n    tar zxvf glog-0.3.3.tar.gz\n    cd glog-0.3.3\n    ./configure\n    make && make install\n    # gflags\n    wget https://github.com/schuhschuh/gflags/archive/master.zip\n    unzip master.zip\n    cd gflags-master\n    mkdir build && cd build\n    export CXXFLAGS=\"-fPIC\" && cmake .. && make VERBOSE=1\n    make && make install\n    # lmdb\n    git clone https://github.com/LMDB/lmdb\n    cd lmdb/libraries/liblmdb\n    make && make install\n\nNote that glog does not compile with the most recent gflags version (2.1), so before that is resolved you will need to build with glog first.\n\nContinue with [compilation](installation.html#compilation).\n"
      },
      "source": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/docs/install_apt.md",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "File_dump",
        "value": "---\ntitle: Installation\n---\n\n# Installation\n\nPrior to installing, have a glance through this guide and take note of the details for your platform.\nWe install and run Caffe on Ubuntu 16.04\u201312.04, OS X 10.11\u201310.8, and through Docker and AWS.\nThe official Makefile and `Makefile.config` build are complemented by a [community CMake build](#cmake-build).\n\n**Step-by-step Instructions**:\n\n- [Docker setup](https://github.com/BVLC/caffe/tree/master/docker) *out-of-the-box brewing*\n- [Ubuntu installation](install_apt.html) *the standard platform*\n- [OS X installation](install_osx.html)\n- [RHEL / CentOS / Fedora installation](install_yum.html)\n- [Windows](https://github.com/BVLC/caffe/tree/windows) *see the Windows branch led by Guillaume Dumont*\n- [OpenCL](https://github.com/BVLC/caffe/tree/opencl) *see the OpenCL branch led by Fabian Tschopp*\n- [AWS AMI](https://github.com/bitfusionio/amis/tree/master/awsmrkt-bfboost-ubuntu14-cuda75-caffe) *pre-configured for AWS*\n\n**Overview**:\n\n- [Prerequisites](#prerequisites)\n- [Compilation](#compilation)\n- [Hardware](#hardware)\n\nWhen updating Caffe, it's best to `make clean` before re-compiling.\n\n## Prerequisites\n\nCaffe has several dependencies:\n\n* [CUDA](https://developer.nvidia.com/cuda-zone) is required for GPU mode.\n    * library version 7+ and the latest driver version are recommended, but 6.* is fine too\n    * 5.5, and 5.0 are compatible but considered legacy\n* [BLAS](http://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms) via ATLAS, MKL, or OpenBLAS.\n* [Boost](http://www.boost.org/) >= 1.55\n* `protobuf`, `glog`, `gflags`, `hdf5`\n\nOptional dependencies:\n\n* [OpenCV](http://opencv.org/) >= 2.4 including 3.0\n* IO libraries: `lmdb`, `leveldb` (note: leveldb requires `snappy`)\n* cuDNN for GPU acceleration (v6)\n\nPycaffe and Matcaffe interfaces have their own natural needs.\n\n* For Python Caffe:  `Python 2.7` or `Python 3.3+`, `numpy (>= 1.7)`, boost-provided `boost.python`\n* For MATLAB Caffe: MATLAB with the `mex` compiler.\n\n**cuDNN Caffe**: for fastest operation Caffe is accelerated by drop-in integration of [NVIDIA cuDNN](https://developer.nvidia.com/cudnn). To speed up your Caffe models, install cuDNN then uncomment the `USE_CUDNN := 1` flag in `Makefile.config` when installing Caffe. Acceleration is automatic. The current version is cuDNN v6; older versions are supported in older Caffe.\n\n**CPU-only Caffe**: for cold-brewed CPU-only Caffe uncomment the `CPU_ONLY := 1` flag in `Makefile.config` to configure and build Caffe without CUDA. This is helpful for cloud or cluster deployment.\n\n### CUDA and BLAS\n\nCaffe requires the CUDA `nvcc` compiler to compile its GPU code and CUDA driver for GPU operation.\nTo install CUDA, go to the [NVIDIA CUDA website](https://developer.nvidia.com/cuda-downloads) and follow installation instructions there. Install the library and the latest standalone driver separately; the driver bundled with the library is usually out-of-date. **Warning!** The 331.* CUDA driver series has a critical performance issue: do not use it.\n\nFor best performance, Caffe can be accelerated by [NVIDIA cuDNN](https://developer.nvidia.com/cudnn). Register for free at the cuDNN site, install it, then continue with these installation instructions. To compile with cuDNN set the `USE_CUDNN := 1` flag set in your `Makefile.config`.\n\nCaffe requires BLAS as the backend of its matrix and vector computations.\nThere are several implementations of this library. The choice is yours:\n\n* [ATLAS](http://math-atlas.sourceforge.net/): free, open source, and so the default for Caffe.\n* [Intel MKL](http://software.intel.com/en-us/intel-mkl): commercial and optimized for Intel CPUs, with a free trial and [student](http://software.intel.com/en-us/intel-education-offerings) licenses.\n    1. Install MKL.\n    2. Set up MKL environment (Details: [Linux](https://software.intel.com/en-us/node/528499), [OS X](https://software.intel.com/en-us/node/528659)). Example: *source /opt/intel/mkl/bin/mklvars.sh intel64*\n    3. Set `BLAS := mkl` in `Makefile.config`\n* [OpenBLAS](http://www.openblas.net/): free and open source; this optimized and parallel BLAS could require more effort to install, although it might offer a speedup.\n    1. Install OpenBLAS\n    2. Set `BLAS := open` in `Makefile.config`\n\n### Python and/or MATLAB Caffe (optional)\n\n#### Python\n\nThe main requirements are `numpy` and `boost.python` (provided by boost). `pandas` is useful too and needed for some examples.\n\nYou can install the dependencies with\n\n    for req in $(cat requirements.txt); do pip install $req; done\n\nbut we suggest first installing the [Anaconda](https://store.continuum.io/cshop/anaconda/) Python distribution, which provides most of the necessary packages, as well as the `hdf5` library dependency.\n\nTo import the `caffe` Python module after completing the installation, add the module directory to your `$PYTHONPATH` by `export PYTHONPATH=/path/to/caffe/python:$PYTHONPATH` or the like. You should not import the module in the `caffe/python/caffe` directory!\n\n*Caffe's Python interface works with Python 2.7. Python 3.3+ should work out of the box without protobuf support. For protobuf support please install protobuf 3.0 alpha (https://developers.google.com/protocol-buffers/). Earlier Pythons are your own adventure.*\n\n#### MATLAB\n\nInstall MATLAB, and make sure that its `mex` is in your `$PATH`.\n\n*Caffe's MATLAB interface works with versions 2015a, 2014a/b, 2013a/b, and 2012b.*\n\n## Compilation\n\nCaffe can be compiled with either Make or CMake. Make is officially supported while CMake is supported by the community.\n\n### Compilation with Make\n\nConfigure the build by copying and modifying the example `Makefile.config` for your setup. The defaults should work, but uncomment the relevant lines if using Anaconda Python.\n\n    cp Makefile.config.example Makefile.config\n    # Adjust Makefile.config (for example, if using Anaconda Python, or if cuDNN is desired)\n    make all\n    make test\n    make runtest\n\n- For CPU & GPU accelerated Caffe, no changes are needed.\n- For cuDNN acceleration using NVIDIA's proprietary cuDNN software, uncomment the `USE_CUDNN := 1` switch in `Makefile.config`. cuDNN is sometimes but not always faster than Caffe's GPU acceleration.\n- For CPU-only Caffe, uncomment `CPU_ONLY := 1` in `Makefile.config`.\n\nTo compile the Python and MATLAB wrappers do `make pycaffe` and `make matcaffe` respectively.\nBe sure to set your MATLAB and Python paths in `Makefile.config` first!\n\n**Distribution**: run `make distribute` to create a `distribute` directory with all the Caffe headers, compiled libraries, binaries, etc. needed for distribution to other machines.\n\n**Speed**: for a faster build, compile in parallel by doing `make all -j8` where 8 is the number of parallel threads for compilation (a good choice for the number of threads is the number of cores in your machine).\n\nNow that you have installed Caffe, check out the [MNIST tutorial](gathered/examples/mnist.html) and the [reference ImageNet model tutorial](gathered/examples/imagenet.html).\n\n### CMake Build\n\nIn lieu of manually editing `Makefile.config` to configure the build, Caffe offers an unofficial CMake build thanks to @Nerei, @akosiorek, and other members of the community. It requires CMake version >= 2.8.7.\nThe basic steps are as follows:\n\n    mkdir build\n    cd build\n    cmake ..\n    make all\n    make install\n    make runtest\n\nSee [PR #1667](https://github.com/BVLC/caffe/pull/1667) for options and details.\n\n## Hardware\n\n**Laboratory Tested Hardware**: Berkeley Vision runs Caffe with Titan Xs, K80s, GTX 980s, K40s, K20s, Titans, and GTX 770s including models at ImageNet/ILSVRC scale. We have not encountered any trouble in-house with devices with CUDA capability >= 3.0. All reported hardware issues thus-far have been due to GPU configuration, overheating, and the like.\n\n**CUDA compute capability**: devices with compute capability <= 2.0 may have to reduce CUDA thread numbers and batch sizes due to hardware constraints. Brew with caution; we recommend compute capability >= 3.0.\n\nOnce installed, check your times against our [reference performance numbers](performance_hardware.html) to make sure everything is configured properly.\n\nAsk hardware questions on the [caffe-users group](https://groups.google.com/forum/#!forum/caffe-users).\n"
      },
      "source": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/docs/installation.md",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "File_dump",
        "value": "---\ntitle: \"Installation: OS X\"\n---\n\n# OS X Installation\n\nWe highly recommend using the [Homebrew](http://brew.sh/) package manager.\nIdeally you could start from a clean `/usr/local` to avoid conflicts.\nIn the following, we assume that you're using Anaconda Python and Homebrew.\n\n**CUDA**: Install via the NVIDIA package that includes both CUDA and the bundled driver. **CUDA 7 is strongly suggested.** Older CUDA require `libstdc++` while clang++ is the default compiler and `libc++` the default standard library on OS X 10.9+. This disagreement makes it necessary to change the compilation settings for each of the dependencies. This is prone to error.\n\n**Library Path**: We find that everything compiles successfully if `$LD_LIBRARY_PATH` is not set at all, and `$DYLD_FALLBACK_LIBRARY_PATH` is set to provide CUDA, Python, and other relevant libraries (e.g. `/usr/local/cuda/lib:$HOME/anaconda/lib:/usr/local/lib:/usr/lib`).\nIn other `ENV` settings, things may not work as expected.\n\n**General dependencies**\n\n    brew install -vd snappy leveldb gflags glog szip lmdb\n    # need the homebrew science source for OpenCV and hdf5\n    brew tap homebrew/science\n    brew install hdf5 opencv\n\nIf using Anaconda Python, a modification to the OpenCV formula might be needed\nDo `brew edit opencv` and change the lines that look like the two lines below to exactly the two lines below.\n\n      -DPYTHON_LIBRARY=#{py_prefix}/lib/libpython2.7.dylib\n      -DPYTHON_INCLUDE_DIR=#{py_prefix}/include/python2.7\n\nIf using Anaconda Python, HDF5 is bundled and the `hdf5` formula can be skipped.\n\n**Remaining dependencies, with / without Python**\n\n    # with Python pycaffe needs dependencies built from source\n    brew install --build-from-source --with-python -vd protobuf\n    brew install --build-from-source -vd boost boost-python\n    # without Python the usual installation suffices\n    brew install protobuf boost\n\n**BLAS**: already installed as the [Accelerate / vecLib Framework](https://developer.apple.com/library/mac/documentation/Darwin/Reference/ManPages/man7/Accelerate.7.html). OpenBLAS and MKL are alternatives for faster CPU computation.\n\n**Python** (optional): Anaconda is the preferred Python.\nIf you decide against it, please use Homebrew.\nCheck that Caffe and dependencies are linking against the same, desired Python.\n\nContinue with [compilation](installation.html#compilation).\n\n## libstdc++ installation\n\nThis route is not for the faint of heart.\nFor OS X 10.10 and 10.9 you should install CUDA 7 and follow the instructions above.\nIf that is not an option, take a deep breath and carry on.\n\nIn OS X 10.9+, clang++ is the default C++ compiler and uses `libc++` as the standard library.\nHowever, NVIDIA CUDA (even version 6.0) currently links only with `libstdc++`.\nThis makes it necessary to change the compilation settings for each of the dependencies.\n\nWe do this by modifying the Homebrew formulae before installing any packages.\nMake sure that Homebrew doesn't install any software dependencies in the background; all packages must be linked to `libstdc++`.\n\nThe prerequisite Homebrew formulae are\n\n    boost snappy leveldb protobuf gflags glog szip lmdb homebrew/science/opencv\n\nFor each of these formulas, `brew edit FORMULA`, and add the ENV definitions as shown:\n\n      def install\n          # ADD THE FOLLOWING:\n          ENV.append \"CXXFLAGS\", \"-stdlib=libstdc++\"\n          ENV.append \"CFLAGS\", \"-stdlib=libstdc++\"\n          ENV.append \"LDFLAGS\", \"-stdlib=libstdc++ -lstdc++\"\n          # The following is necessary because libtool likes to strip LDFLAGS:\n          ENV[\"CXX\"] = \"/usr/bin/clang++ -stdlib=libstdc++\"\n          ...\n\nTo edit the formulae in turn, run\n\n    for x in snappy leveldb protobuf gflags glog szip boost boost-python lmdb homebrew/science/opencv; do brew edit $x; done\n\nAfter this, run\n\n    for x in snappy leveldb gflags glog szip lmdb homebrew/science/opencv; do brew uninstall $x; brew install --build-from-source -vd $x; done\n    brew uninstall protobuf; brew install --build-from-source --with-python -vd protobuf\n    brew install --build-from-source -vd boost boost-python\n\nIf this is not done exactly right then linking errors will trouble you.\n\n**Homebrew versioning** that Homebrew maintains itself as a separate git repository and making the above `brew edit FORMULA` changes will change files in your local copy of homebrew's master branch. By default, this will prevent you from updating Homebrew using `brew update`, as you will get an error message like the following:\n\n    $ brew update\n    error: Your local changes to the following files would be overwritten by merge:\n      Library/Formula/lmdb.rb\n    Please, commit your changes or stash them before you can merge.\n    Aborting\n    Error: Failure while executing: git pull -q origin refs/heads/master:refs/remotes/origin/master\n\nOne solution is to commit your changes to a separate Homebrew branch, run `brew update`, and rebase your changes onto the updated master. You'll have to do this both for the main Homebrew repository in `/usr/local/` and the Homebrew science repository that contains OpenCV in  `/usr/local/Library/Taps/homebrew/homebrew-science`, as follows:\n\n    cd /usr/local\n    git checkout -b caffe\n    git add .\n    git commit -m \"Update Caffe dependencies to use libstdc++\"\n    cd /usr/local/Library/Taps/homebrew/homebrew-science\n    git checkout -b caffe\n    git add .\n    git commit -m \"Update Caffe dependencies\"\n\nThen, whenever you want to update homebrew, switch back to the master branches, do the update, rebase the caffe branches onto master and fix any conflicts:\n\n    # Switch batch to homebrew master branches\n    cd /usr/local\n    git checkout master\n    cd /usr/local/Library/Taps/homebrew/homebrew-science\n    git checkout master\n\n    # Update homebrew; hopefully this works without errors!\n    brew update\n\n    # Switch back to the caffe branches with the formulae that you modified earlier\n    cd /usr/local\n    git rebase master caffe\n    # Fix any merge conflicts and commit to caffe branch\n    cd /usr/local/Library/Taps/homebrew/homebrew-science\n    git rebase master caffe\n    # Fix any merge conflicts and commit to caffe branch\n\n    # Done!\n\nAt this point, you should be running the latest Homebrew packages and your Caffe-related modifications will remain in place.\n"
      },
      "source": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/docs/install_osx.md",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "File_dump",
        "value": "---\ntitle: \"Installation: RHEL / Fedora / CentOS\"\n---\n\n# RHEL / Fedora / CentOS Installation\n\n**General dependencies**\n\n    sudo yum install protobuf-devel leveldb-devel snappy-devel opencv-devel boost-devel hdf5-devel\n\n**Remaining dependencies, recent OS**\n\n    sudo yum install gflags-devel glog-devel lmdb-devel\n\n**Remaining dependencies, if not found**\n\n    # glog\n    wget https://storage.googleapis.com/google-code-archive-downloads/v2/code.google.com/google-glog/glog-0.3.3.tar.gz\n    tar zxvf glog-0.3.3.tar.gz\n    cd glog-0.3.3\n    ./configure\n    make && make install\n    # gflags\n    wget https://github.com/schuhschuh/gflags/archive/master.zip\n    unzip master.zip\n    cd gflags-master\n    mkdir build && cd build\n    export CXXFLAGS=\"-fPIC\" && cmake .. && make VERBOSE=1\n    make && make install\n    # lmdb\n    git clone https://github.com/LMDB/lmdb\n    cd lmdb/libraries/liblmdb\n    make && make install\n\nNote that glog does not compile with the most recent gflags version (2.1), so before that is resolved you will need to build with glog first.\n\n**CUDA**: Install via the NVIDIA package instead of `yum` to be certain of the library and driver versions.\nInstall the library and latest driver separately; the driver bundled with the library is usually out-of-date.\n    + CentOS/RHEL/Fedora:\n\n**BLAS**: install ATLAS by `sudo yum install atlas-devel` or install OpenBLAS or MKL for better CPU performance. For the Makefile build, uncomment and set `BLAS_LIB` accordingly as ATLAS is usually installed under `/usr/lib[64]/atlas`).\n\n**Python** (optional): if you use the default Python you will need to `sudo yum install` the `python-devel` package to have the Python headers for building the pycaffe wrapper.\n\nContinue with [compilation](installation.html#compilation).\n"
      },
      "source": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/docs/install_yum.md",
      "technique": "file_exploration"
    },
    {
      "confidence": 0.9051182913649178,
      "result": {
        "original_header": "Framework",
        "type": "Text_excerpt",
        "value": "\nFor transfer detection, our LSTD outperforms SSD and Faster RCNN significantly.\nMore experiments can be found in [LSTD](https://arxiv.org/abs/1803.01529v1).\n<p align=\"center\">\n<img src='https://github.com/Cassie94/LSTD/blob/master/models/lstd.jpg'  width=\"600px\">\n</p> \n"
      },
      "source": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9995238409703783,
      "result": {
        "original_header": "Utility",
        "type": "Text_excerpt",
        "value": "First, you may need to setup the environment, as in [SSD](https://github.com/weiliu89/caffe/tree/ssd). \n"
      },
      "source": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/README.md",
      "technique": "supervised_classification"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/haochen-rye/LSTD/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ""
      },
      "technique": "GitHub_API"
    }
  ],
  "license": [
    {
      "confidence": 1,
      "result": {
        "name": "Other",
        "spdx_id": "NOASSERTION",
        "type": "License",
        "url": null,
        "value": null
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "type": "File_dump",
        "value": "COPYRIGHT\n\nAll new contributions compared to the original branch:\nCopyright (c) 2015, 2016 Wei Liu (UNC Chapel Hill), Dragomir Anguelov (Zoox),\nDumitru Erhan (Google), Christian Szegedy (Google), Scott Reed (UMich Ann Arbor),\nCheng-Yang Fu (UNC Chapel Hill), Alexander C. Berg (UNC Chapel Hill).\nAll rights reserved.\n\nAll contributions by the University of California:\nCopyright (c) 2014, 2015, The Regents of the University of California (Regents)\nAll rights reserved.\n\nAll other contributions:\nCopyright (c) 2014, 2015, the respective contributors\nAll rights reserved.\n\nCaffe uses a shared copyright model: each contributor holds copyright over\ntheir contributions to Caffe. The project versioning records all such\ncontribution and copyright details. If a contributor wants to further mark\ntheir specific copyright on a particular contribution, they should indicate\ntheir copyright solely in the commit message of the change when it is\ncommitted.\n\nLICENSE\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met: \n\n1. Redistributions of source code must retain the above copyright notice, this\n   list of conditions and the following disclaimer. \n2. Redistributions in binary form must reproduce the above copyright notice,\n   this list of conditions and the following disclaimer in the documentation\n   and/or other materials provided with the distribution. \n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND\nANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\nWARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR\nANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\n(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\nLOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND\nON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\nSOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\nCONTRIBUTION AGREEMENT\n\nBy contributing to the BVLC/caffe repository through pull-request, comment,\nor otherwise, the contributor releases their content to the\nlicense and copyright terms herein.\n"
      },
      "source": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/LICENSE",
      "technique": "file_exploration"
    }
  ],
  "logo": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/LSTD: A Low-Shot Transfer Detector for Object Detection</h1>\n<h3>Introduction</h3>\n<p>LSTD is an unified framework for transfer object detetction with a single network. For more details, please refer to our <a href="
      },
      "source": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/README.md",
      "technique": "regular_expression"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "LSTD"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "User",
        "value": "haochen-rye"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "C++",
        "size": 3534149,
        "type": "Programming_language",
        "value": "C++"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 398744,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Cuda",
        "size": 284087,
        "type": "Programming_language",
        "value": "Cuda"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "CMake",
        "size": 99487,
        "type": "Programming_language",
        "value": "CMake"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "MATLAB",
        "size": 32089,
        "type": "Programming_language",
        "value": "MATLAB"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Makefile",
        "size": 25297,
        "type": "Programming_language",
        "value": "Makefile"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Shell",
        "size": 21645,
        "type": "Programming_language",
        "value": "Shell"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Dockerfile",
        "size": 2521,
        "type": "Programming_language",
        "value": "Dockerfile"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "related_papers": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://arxiv.org/abs/1803.01529v1"
      },
      "source": "https://raw.githubusercontent.com/Cassie94/LSTD/lstd/README.md",
      "technique": "regular_expression"
    }
  ],
  "somef_missing_categories": [
    "acknowledgement",
    "run",
    "download",
    "requirements",
    "contact",
    "usage",
    "faq",
    "support",
    "identifier"
  ],
  "somef_provenance": {
    "date": "2024-11-04 01:53:06",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 72
      },
      "technique": "GitHub_API"
    }
  ]
}