{
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/BoevaLab/SV-Bay"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2015-01-21T16:51:54Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2024-01-05T14:59:40Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "Detection of structural variants in cancer mate-pair and paired-end data"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 0.9874511696189271,
      "result": {
        "original_header": "SV-Bay",
        "type": "Text_excerpt",
        "value": "SV-Bay is a tool for structural variant detection in cancer genomes using a Bayesian approach with correction for GC-content and read mappability. The algorithm description can be found [in the article](http://www.ncbi.nlm.nih.gov/pubmed/26740523).\n \n"
      },
      "source": "https://raw.githubusercontent.com/InstitutCurie/SV-Bay/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9446871392067896,
      "result": {
        "original_header": "Configuration",
        "type": "Text_excerpt",
        "value": "SV-Bay uses config file in YAML format. This file is common for all processing steps. There are following config options not related to input data (options related to input data are described in the next section): \n__working_dir : \"/.../sv-bay-data/\"__ Common directrory for all processing. All other files and folders will be created inside this one. \n__clustering_parallel_processes : 1__ Number of parallel threads for clustering. SV-Bay works fast even with one process (less then 2 hours for mate-pair data with coverge 12). If the number of processes is more than 1, clustering log would be unordered and very hard to read, so change it only if speed is crucial for you. \n__exp_num_sv: 100__ Expected number of structural variants. \n__alpha : 0.01__ Distribution cutoff used when deciding whether read is normal or abnormal. \n__read_length : 50__ Read length in input data. \n__ploidy : 4.0__ Ploidy of input data. \n"
      },
      "source": "https://raw.githubusercontent.com/InstitutCurie/SV-Bay/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.944206718508621,
      "result": {
        "original_header": "Input data",
        "type": "Text_excerpt",
        "value": "SV-Bay requires a number of input files to work. It can look a bit confusing, but most of this files are common for human genome and can be simply downloaded. Config options related to input are described below: \n__sam_files_dir : \"bam/\"__ Input directory with per-chromosome bam or sam files. Bam should be sorted and indexed, .bam.bai files should be in the same folder. Name of file for each chromosome must contain \"chrSomething\" in it's name, e.g. \"chr7_sorted.bam\" or \"chrX.sam\".\nIf you have one bam for the whole genome, use utils/separately_save_sam.py script to split it:\n```\npython src/utils/separately_save_sam_samtools.py -i yourBigBAMfile.bam -o outputDir/\n```\n \n__fa_files_dir : \"fa/\"__ Input directory with per-chromosome .fa files. Fa file names should consist exactly of chromosome name and extension, e.g. chr14.fa. You can download fa files for hg19 and hg38: http://xfer.curie.fr/get/aBxK5d1BWr6/hg19_chromosomes_fa.zip and http://xfer.curie.fr/get/2mRqHdYxzw4/hg38_chromosomes_fa.zip. \n__gem_files_dir : \"gem/\"__ Input directory with per-chromosome .gem mappability files. Gem file names should consist exactly of chromosome name and extension, e.g. chr14.gem. You can download pre-calculated gem for hg19 and hg38: http://xfer.curie.fr/get/kRScTtWDgdA/gem_hg19.tar.gz and http://xfer.curie.fr/get/pVFoxp28pBt/gem_hg38.tar.gz. If you have one gem for the whole genome, use utils/separately_save_gem.py script to split it:\n```\npython src/utils/sep_save_gem.py -i yourBigGEMfile.gem  -o outputDir/\n```\n \n__centromic_file : \"centrom_hg38.txt\"__ Input file with information about centromere positions in human genome. Files for hg19 and hg38 are availdable in data subfolder of SV-Bay repository (data/centrom_hg19.txt and data/centrom_hg38.txt). \n__cnv_file: \"simulated_reads_cnv.txt\"__ File generated by Control-FREEC. For the test data it is available in data subfolder of SV-Bay repository (data/simulated_reads_cnv.txt). \nNow change __working_dir__ in sample config and you are ready to run SV-Bay.\n \n"
      },
      "source": "https://raw.githubusercontent.com/InstitutCurie/SV-Bay/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9170083331006014,
      "result": {
        "original_header": "Workflow",
        "type": "Text_excerpt",
        "value": "SV-Bay workflow consists of 3 steps. Config file is common for all steps. \n__Normal/abnormal fragments separation and clustering__ \nOn this step SV-Bay calculates statistics of fragment length distribution, separates normal/abnormal fragments and clusters abnormal fragments.\n```\npython -B src/main_clustering.py -c config/config.yaml\n```\n \nOn this step SV-Bay calculates probability for each cluster to determine whether it is noise or real SV.\n```\npython -B src/main_probabilities.py -c config/config.yaml\n```\n \n"
      },
      "source": "https://raw.githubusercontent.com/InstitutCurie/SV-Bay/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/InstitutCurie/SV-Bay/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 2
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/BoevaLab/SV-Bay/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "BoevaLab/SV-Bay"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "SV-Bay"
      },
      "source": "https://raw.githubusercontent.com/InstitutCurie/SV-Bay/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "installation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Installation",
        "parent_header": [
          "SV-Bay"
        ],
        "type": "Text_excerpt",
        "value": "SV-Bay is implemented is Python 2 and was tested in both Linux and Mac OS X. Though it works with both Python 2.6 and 2.7, we strongly recommend to use 2.7, as it shows a significant performance improvement due to the difference in GC implementations.\n\nA number of python libraries are required to run SV-Bay. The installation from scratch for Ubuntu 14.04 is shown below:\n\n```\nsudo apt-get update\nsudo apt-get install build-essential python-dev zlib1g-dev unzip\nsudo apt-get install python-numpy python-scipy python-matplotlib\nwget https://bootstrap.pypa.io/get-pip.py\nsudo python get-pip.py\nsudo pip install pyaml pysam joblib\n```\n\nAfter that you can clone SV-Bay repository:\n\n```\nsudo apt-get install git\ngit clone https://github.com/InstitutCurie/SV-Bay.git\n```\n\nThen edit sample config.yaml file and proceed to input data preparation, as explained below.\n"
      },
      "source": "https://raw.githubusercontent.com/InstitutCurie/SV-Bay/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 0.9925573568704358,
      "result": {
        "original_header": "Input data",
        "type": "Text_excerpt",
        "value": "__fa_files_dir : \"fa/\"__ Input directory with per-chromosome .fa files. Fa file names should consist exactly of chromosome name and extension, e.g. chr14.fa. You can download fa files for hg19 and hg38: http://xfer.curie.fr/get/aBxK5d1BWr6/hg19_chromosomes_fa.zip and http://xfer.curie.fr/get/2mRqHdYxzw4/hg38_chromosomes_fa.zip. \n__gem_files_dir : \"gem/\"__ Input directory with per-chromosome .gem mappability files. Gem file names should consist exactly of chromosome name and extension, e.g. chr14.gem. You can download pre-calculated gem for hg19 and hg38: http://xfer.curie.fr/get/kRScTtWDgdA/gem_hg19.tar.gz and http://xfer.curie.fr/get/pVFoxp28pBt/gem_hg38.tar.gz. If you have one gem for the whole genome, use utils/separately_save_gem.py script to split it:\n```\npython src/utils/sep_save_gem.py -i yourBigGEMfile.gem  -o outputDir/\n```\n \nPreparation of the example data to run SV-Bay is shown below:\n```\nmkdir sv-bay-data/ && cd sv-bay-data\nmkdir bam && cd bam\nwget https://www.dropbox.com/s/zcojeehmhkygli4/bam_tumor.tar.gz && tar xzf bam_tumor.tar.gz && mv bam_tumor/* . && cd ..\nmkdir fa_files && cd fa_files\nwget http://xfer.curie.fr/get/2mRqHdYxzw4/hg38_chromosomes_fa.zip && unzip hg38_chromosomes_fa.zip && cd ..\nmkdir gem_files && cd gem_files\nwget http://xfer.curie.fr/get/pVFoxp28pBt/gem_hg38.tar.gz && tar xzf gem_hg38.tar.gz && mv gem_hg38/* . && cd ..\ncp ~/SV-Bay/data/centrom_hg38.txt .\ncp ~/SV-Bay/data/simulated_reads_cnv.txt .\n```\n \nNow change __working_dir__ in sample config and you are ready to run SV-Bay.\n \n"
      },
      "source": "https://raw.githubusercontent.com/InstitutCurie/SV-Bay/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9592219171763174,
      "result": {
        "original_header": "Workflow",
        "type": "Text_excerpt",
        "value": "SV-Bay workflow consists of 3 steps. Config file is common for all steps. \nOn this step SV-Bay calculates statistics of fragment length distribution, separates normal/abnormal fragments and clusters abnormal fragments.\n```\npython -B src/main_clustering.py -c config/config.yaml\n```\n \nOn this step SV-Bay assembles clusters to complex and simple SVs and outputs final results.\n```\npython -B src/main_assemly_links.py -c config/config.yaml > results\n```\nThe script main_assemly_links.py can also exclude germline mutations, if the respective data is available. To do so, run main_clustering.py for germline dataset using a separate working_dir and than run main_assemly_links.py with flag -n and name of the folder with germ-line clusters:\n```\npython -B src/main_clustering.py -c config/config_germ.yaml\npython -B src/main_assemly_links.py -c config/config.yaml -n '/home/sv-bay/sv-bay-data-germ/cluster_files/' > results\n```\n \n"
      },
      "source": "https://raw.githubusercontent.com/InstitutCurie/SV-Bay/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "invocation": [
    {
      "confidence": 0.8539485116843933,
      "result": {
        "original_header": "Input data",
        "type": "Text_excerpt",
        "value": "__sam_files_dir : \"bam/\"__ Input directory with per-chromosome bam or sam files. Bam should be sorted and indexed, .bam.bai files should be in the same folder. Name of file for each chromosome must contain \"chrSomething\" in it's name, e.g. \"chr7_sorted.bam\" or \"chrX.sam\".\nIf you have one bam for the whole genome, use utils/separately_save_sam.py script to split it:\n```\npython src/utils/separately_save_sam_samtools.py -i yourBigBAMfile.bam -o outputDir/\n```\n \n__gem_files_dir : \"gem/\"__ Input directory with per-chromosome .gem mappability files. Gem file names should consist exactly of chromosome name and extension, e.g. chr14.gem. You can download pre-calculated gem for hg19 and hg38: http://xfer.curie.fr/get/kRScTtWDgdA/gem_hg19.tar.gz and http://xfer.curie.fr/get/pVFoxp28pBt/gem_hg38.tar.gz. If you have one gem for the whole genome, use utils/separately_save_gem.py script to split it:\n```\npython src/utils/sep_save_gem.py -i yourBigGEMfile.gem  -o outputDir/\n```\n \nPreparation of the example data to run SV-Bay is shown below:\n```\nmkdir sv-bay-data/ && cd sv-bay-data\nmkdir bam && cd bam\nwget https://www.dropbox.com/s/zcojeehmhkygli4/bam_tumor.tar.gz && tar xzf bam_tumor.tar.gz && mv bam_tumor/* . && cd ..\nmkdir fa_files && cd fa_files\nwget http://xfer.curie.fr/get/2mRqHdYxzw4/hg38_chromosomes_fa.zip && unzip hg38_chromosomes_fa.zip && cd ..\nmkdir gem_files && cd gem_files\nwget http://xfer.curie.fr/get/pVFoxp28pBt/gem_hg38.tar.gz && tar xzf gem_hg38.tar.gz && mv gem_hg38/* . && cd ..\ncp ~/SV-Bay/data/centrom_hg38.txt .\ncp ~/SV-Bay/data/simulated_reads_cnv.txt .\n```\n \n"
      },
      "source": "https://raw.githubusercontent.com/InstitutCurie/SV-Bay/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9068578336740455,
      "result": {
        "original_header": "Workflow",
        "type": "Text_excerpt",
        "value": "On this step SV-Bay assembles clusters to complex and simple SVs and outputs final results.\n```\npython -B src/main_assemly_links.py -c config/config.yaml > results\n```\nThe script main_assemly_links.py can also exclude germline mutations, if the respective data is available. To do so, run main_clustering.py for germline dataset using a separate working_dir and than run main_assemly_links.py with flag -n and name of the folder with germ-line clusters:\n```\npython -B src/main_clustering.py -c config/config_germ.yaml\npython -B src/main_assemly_links.py -c config/config.yaml -n '/home/sv-bay/sv-bay-data-germ/cluster_files/' > results\n```\n \n"
      },
      "source": "https://raw.githubusercontent.com/InstitutCurie/SV-Bay/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/BoevaLab/SV-Bay/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ""
      },
      "technique": "GitHub_API"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "SV-Bay"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "Organization",
        "value": "BoevaLab"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 126955,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "R",
        "size": 8028,
        "type": "Programming_language",
        "value": "R"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/InstitutCurie/SV-Bay/master/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "somef_missing_categories": [
    "citation",
    "acknowledgement",
    "run",
    "download",
    "requirements",
    "contact",
    "contributors",
    "documentation",
    "license",
    "usage",
    "faq",
    "support",
    "identifier",
    "has_build_file",
    "executable_example"
  ],
  "somef_provenance": {
    "date": "2024-11-04 09:03:05",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 12
      },
      "technique": "GitHub_API"
    }
  ]
}