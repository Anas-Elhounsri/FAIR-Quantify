{
  "application_domain": [
    {
      "confidence": 36.44,
      "result": {
        "type": "String",
        "value": "Computer Vision"
      },
      "technique": "supervised_classification"
    }
  ],
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/wheaton5/souporcell"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2019-03-16T14:11:31Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2024-11-01T10:03:20Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "Clustering scRNAseq by genotypes"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 0.9210961117690433,
      "result": {
        "original_header": "souporcell",
        "type": "Text_excerpt",
        "value": "Preprint manuscript of this method available at https://www.biorxiv.org/content/10.1101/699637v1 \nsouporcell is a method for clustering mixed-genotype scRNAseq experiments by individual. \nThe inputs are just the possorted_genome_bam.bam, and barcodes.tsv as output from [cellranger](https://support.10xgenomics.com/single-cell-gene-expression/software/pipelines/latest/what-is-cell-ranger).\nsouporcell is comprised of 6 steps with the first 3 using external tools and the final using the code provided here.\n1. Remapping ([minimap2](https://github.com/lh3/minimap2))\n2. Calling candidate variants ([freebayes](https://github.com/ekg/freebayes))\n3. Cell allele counting ([vartrix](https://github.com/10XGenomics/vartrix))\n4. Clustering cells by genotype (souporcell.py)\n5. Calling doublets (troublet)\n6. Calling cluster genotypes and inferring amount of ambient RNA (consensus.py)\n \n"
      },
      "source": "https://raw.githubusercontent.com/wheaton5/souporcell/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/wheaton5/souporcell/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 46
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/wheaton5/souporcell/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "wheaton5/souporcell"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "souporcell"
      },
      "source": "https://raw.githubusercontent.com/wheaton5/souporcell/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "has_build_file": [
    {
      "confidence": 1,
      "result": {
        "format": "dockerfile",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/wheaton5/souporcell/master/Dockerfile"
      },
      "source": "https://raw.githubusercontent.com/wheaton5/souporcell/master/Dockerfile",
      "technique": "file_exploration"
    }
  ],
  "installation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Easy Installation (Linux) (recommended)",
        "parent_header": [
          "souporcell"
        ],
        "type": "Text_excerpt",
        "value": "Download singularity image (1.3gb) (singularity is similar to docker but safe for clusters)\n```\nsingularity pull --arch amd64 library://wheaton5/souporcell/souporcell:release\n```\n\nIf you are running on a scientific cluster, they will likely have singularity, contact your sysadmin for more details. \nIf you are running on your own linux box you may need to install [singularity](https://www.sylabs.io/guides/3.2/user-guide/quick_start.html#quick-installation-steps)\n\nrequires singularity >= 3.0 or apptainer version >= 1.0.0 (singularity rebranded as apptainer and changed its version numbers)\n```\nwhich singularity\nsingularity --version\n```\nYou should now be able to run souporcell_pipeline.py through the singularity container. Singularity automatically mounts the current working directory and directories downstream from where you run it, otherwise you would need to manually mount those directories. Therefor you can run it from a directory that is upstream of all of the inputs. Input files are the cellranger bam, cellranger barcodes file, and a reference fasta. The cellranger bam is located in the cellranger outs directory and is called possorted_genome_bam.bam. The barcodes file is located in the cellranger outs/filtered_gene_bc_matrices/<ref_name>/barcodes.tsv. The reference fasta should be of the same species but does not necessarily need to be the exact cellranger reference. \n\nThe options for using souporcell are:\n```\nsingularity exec souporcell_latest.sif souporcell_pipeline.py -h\nusage: souporcell_pipeline.py [-h] -i BAM -b BARCODES -f FASTA -t THREADS -o\n                              OUT_DIR -k CLUSTERS [-p PLOIDY]\n                              [--min_alt MIN_ALT] [--min_ref MIN_REF]\n                              [--max_loci MAX_LOCI] [--restarts RESTARTS]\n                              [--common_variants COMMON_VARIANTS]\n                              [--known_genotypes KNOWN_GENOTYPES]\n                              [--known_genotypes_sample_names KNOWN_GENOTYPES_SAMPLE_NAMES [KNOWN_GENOTYPES_SAMPLE_NAMES ...]]\n                              [--skip_remap SKIP_REMAP] [--ignore IGNORE]\n\nsingle cell RNAseq mixed genotype clustering using sparse mixture model\nclustering with tensorflow.\n\noptional arguments:\n  -h, --help            show this help message and exit\n  -i BAM, --bam BAM     cellranger bam\n  -b BARCODES, --barcodes BARCODES\n                        barcodes.tsv from cellranger\n  -f FASTA, --fasta FASTA\n                        reference fasta file\n  -t THREADS, --threads THREADS\n                        max threads to use\n  -o OUT_DIR, --out_dir OUT_DIR\n                        name of directory to place souporcell files\n  -k CLUSTERS, --clusters CLUSTERS\n                        number cluster, tbd add easy way to run on a range of\n                        k\n  -p PLOIDY, --ploidy PLOIDY\n                        ploidy, must be 1 or 2, default = 2\n  --min_alt MIN_ALT     min alt to use locus, default = 10.\n  --min_ref MIN_REF     min ref to use locus, default = 10.\n  --max_loci MAX_LOCI   max loci per cell, affects speed, default = 2048.\n  --restarts RESTARTS   number of restarts in clustering, when there are > 12\n                        clusters we recommend increasing this to avoid local\n                        minima\n                         --common_variants COMMON_VARIANTS\n                        common variant loci or known variant loci vcf, must be\n                        vs same reference fasta\n  --known_genotypes KNOWN_GENOTYPES\n                        known variants per clone in population vcf mode, must\n                        be .vcf right now we dont accept gzip or bcf sorry\n  --known_genotypes_sample_names KNOWN_GENOTYPES_SAMPLE_NAMES [KNOWN_GENOTYPES_SAMPLE_NAMES ...]\n                        which samples in population vcf from known genotypes\n                        option represent the donors in your sample\n  --skip_remap SKIP_REMAP\n                        don't remap with minimap2 (not recommended unless in\n                        conjunction with --common_variants\n  --ignore IGNORE       set to True to ignore data error assertions\n```\nA typical command looks like\n```\nsingularity exec /path/to/souporcell_latest.sif souporcell_pipeline.py -i /path/to/possorted_genome_bam.bam -b /path/to/barcodes.tsv -f /path/to/reference.fasta -t num_threads_to_use -o output_dir_name -k num_clusters\n```\nThe above command will run all six steps of the pipeline and it will require up to 24gb of ram for human (minimap2 bam index is high water mark for memory). For smaller genomes, fewer clusters, lower --max-loci will require less memory. Note that souporcell will require roughly 2x the amount of diskspace that the input bam file takes up. This dataset should take several hours to run on 8 threads mostly due to read processing, remapping, and variant calling.\n\nIf you have a common snps file you may want to use the --common_variants option with or without the --skip_remap option. This option will skip conversion to fastq, remapping with minimap2, and reattaching barcodes, and the --common_variants will remove the freebayes step. Each which will save a significant amount of time, but --skip-remap isn't recommended without --common_variants.\n\nCommon variant files from 1k genomes filtered to variants >= 2% allele frequency in the population and limited to SNPs can be found here for GRCh38\n```\ncurl ftp://ftp.eng.auburn.edu/pub/whh0027/common_variants_grch38.vcf.gz -o common_variants_grch38.vcf.gz\n```\nor for hg19 here\n```\ncurl ftp://ftp.eng.auburn.edu/pub/whh0027/filtered_2p_1kgenomes_hg19.vcf.gz -o common_variants_hg19.vcf.gz\n```\n"
      },
      "source": "https://raw.githubusercontent.com/wheaton5/souporcell/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Practice/Testing data set: Demuxlet paper data",
        "parent_header": [
          "souporcell"
        ],
        "type": "Text_excerpt",
        "value": "```\nwget https://sra-pub-src-1.s3.amazonaws.com/SRR5398235/A.merged.bam.1 -O A.merged.bam\nwget ftp://ftp.ncbi.nlm.nih.gov/geo/samples/GSM2560nnn/GSM2560245/suppl/GSM2560245_barcodes.tsv.gz\ngunzip GSM2560245_barcodes.tsv.gz\n```\nAnd if you don't have a human reference sitting around, grab one here\n```\nwget http://cf.10xgenomics.com/supp/cell-exp/refdata-cellranger-GRCh38-3.0.0.tar.gz\ntar -xzvf refdata-cellranger-GRCh38-3.0.0.tar.gz\n```\nNow you should be ready to test it out\n```\nsingularity exec /path/to/souporcell_latest.sif souporcell_pipeline.py -i A.merged.bam -b GSM2560245_barcodes.tsv -f refdata-cellranger-GRCh38-3.0.0/fasta/genome.fa -t 8 -o demux_data_test -k 4\n```\n\nThis should require about 20gb of ram mostly because of the minimap2 indexing step. I might soon host an index and reference for human to make this less painful.\n\nThe important files are \n1. clusters.tsv\n2. cluster_genotypes.vcf\n3. ambient_rna.txt\n\nclusters.tsv will look like\n```\nbarcode status  assignment      log_loss_singleton      log_loss_doublet        cluster0        cluster1\nAAACCTGAGATCCGAG-1      singlet 0       -152.7778890920112      -190.5463095948822      -43.95302689281067      -101.63377524087669\nAAACCTGAGCACCGTC-1      singlet 0       -78.56014177554212      -96.66255440088581      -20.949294849836267     -52.57478083591962\nAAACCTGAGTACGATA-1      singlet 0       -216.0188863327174      -281.3888392065457      -63.059016939362536     -159.5450834682198\nAAACCTGGTACATGTC-1      singlet 1       -47.189434469216565     -96.30865717225866      -62.652900832546955     -15.284168900754413\nAAACCTGTCTACTCAT-1      singlet 0       -129.30104434183454     -167.87811467946756     -41.09158213888751      -106.3201962010145\nAAACCTGTCTTGTCAT-1      singlet 0       -85.99781433701455      -110.81701038967158     -24.518165091815554     -60.05279033826837\nAAACGGGCACTGTTAG-1      singlet 0       -154.26595878718032     -191.05465308213363     -31.356408693487197     -81.61186496254497\nAAACGGGCATCATCCC-1      singlet 1       -46.33205678267174      -80.24152434540565      -50.78221280006256      -14.615983876840312\nAAACGGGGTAGGGTAC-1      singlet 0       -240.5237900569412      -302.91575436035924     -71.79370547349878      -154.08594135029728\nAAACGGGTCGGCATCG-1      singlet 0       -166.66827966974532     -226.56795157885028     -51.08790637893961      -148.04625123166286\n```\nWith the cell barcode, singlet/doublet status, cluster, log_loss_singleton, log_loss_doublet, followed by log loss for each cluster.\n\n2. cluster_genotypes.vcf is a vcf with genotypes for each cluster for each variant in the input vcf from freebayes\n\nand \n\n3. ambient_rna.txt just contains the ambient RNA percentage detected\n"
      },
      "source": "https://raw.githubusercontent.com/wheaton5/souporcell/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Hard install",
        "parent_header": [
          "souporcell"
        ],
        "type": "Text_excerpt",
        "value": "Instead of using singularity you can install everything independently (not recommended, but shouldn't be too bad)\n```\ngit clone https://github.com/wheaton5/souporcell.git\n```\nput souporcell directory on your PATH \nrequires samtools, bcftools, htslib, python3, freebayes, vartrix, minimap2 all on your PATH\nI suggest you use the conda env I have set up by using the following command if you have conda or miniconda\n```\nconda env create -f /path/to/souporcell/souporcell_env.yaml\nconda activate souporcell\n```\nYou will also need Rust and to compile the two rust binaries\n```\ncurl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh\ncd /path/to/souporcell/souporcell && cargo build --release\ncd /path/to/souporcell/troublet && cargo build --release\n```\notherwise python packages tensorflow, pyvcf, pystan, pyfaidx, numpy, scipy are required, but as the versions change, I do recommend using the presetup env.\n"
      },
      "source": "https://raw.githubusercontent.com/wheaton5/souporcell/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 0.9109224098932653,
      "result": {
        "original_header": "souporcell",
        "type": "Text_excerpt",
        "value": "<img src=\"https://github.com/wheaton5/souporcell/blob/master/souporcell_star.png\" width=\"100\"> \nPreprint manuscript of this method available at https://www.biorxiv.org/content/10.1101/699637v1 \n"
      },
      "source": "https://raw.githubusercontent.com/wheaton5/souporcell/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/wheaton5/souporcell/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "bioinformatics, computational-biology, genomics, scrna-seq, scrna-seq-analysis, scrnaseq"
      },
      "technique": "GitHub_API"
    }
  ],
  "license": [
    {
      "confidence": 1,
      "result": {
        "name": "MIT License",
        "spdx_id": "MIT",
        "type": "License",
        "url": "https://api.github.com/licenses/mit",
        "value": "https://api.github.com/licenses/mit"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "type": "File_dump",
        "value": "MIT License\n\nCopyright (c) 2019 Haynes Heaton\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
      },
      "source": "https://raw.githubusercontent.com/wheaton5/souporcell/master/LICENSE",
      "technique": "file_exploration"
    }
  ],
  "logo": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/wheaton5/souporcell/master/souporcell_star.png"
      },
      "source": "https://raw.githubusercontent.com/wheaton5/souporcell/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "souporcell"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "User",
        "value": "wheaton5"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 78197,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Rust",
        "size": 69809,
        "type": "Programming_language",
        "value": "Rust"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Roff",
        "size": 3556,
        "type": "Programming_language",
        "value": "Roff"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Singularity",
        "size": 3556,
        "type": "Programming_language",
        "value": "Singularity"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Dockerfile",
        "size": 356,
        "type": "Programming_language",
        "value": "Dockerfile"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/wheaton5/souporcell/master/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "releases": [
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "wheaton5",
          "type": "User"
        },
        "date_created": "2023-06-22T20:05:15Z",
        "date_published": "2023-06-22T20:07:13Z",
        "description": "New singularity build that supports hisat2 and updates multiple software used such as minimap2 and pystan. \r\n\r\n```\r\nsingularity pull --arch amd64 library://wheaton5/souporcell/souporcell:release\r\n```",
        "html_url": "https://github.com/wheaton5/souporcell/releases/tag/v2.5",
        "name": "v2.5",
        "release_id": 109607041,
        "tag": "v2.5",
        "tarball_url": "https://api.github.com/repos/wheaton5/souporcell/tarball/v2.5",
        "type": "Release",
        "url": "https://api.github.com/repos/wheaton5/souporcell/releases/109607041",
        "value": "https://api.github.com/repos/wheaton5/souporcell/releases/109607041",
        "zipball_url": "https://api.github.com/repos/wheaton5/souporcell/zipball/v2.5"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "wheaton5",
          "type": "User"
        },
        "date_created": "2019-11-27T16:26:52Z",
        "date_published": "2019-11-27T20:11:02Z",
        "description": "```\r\nsingularity pull shub://wheaton5/souporcell\r\n```\r\nClustering method completely reimplemented in Rust. This along with the algorithm changes gives me several advantages to speed and memory usage as well as ragged array support which allows me to use all data without going way high in memory --max_loci option no longer used (tho have not deleted as an option, TODO)\r\nNew clustering method using expectation maximization with deterministic annealing greatly improves the ability to overcome local optima with high number of donors. This method also allows us to use the binomial pdf loss function instead of the sum of squared differences loss function. So now all values are log likelihoods and not log loss.\r\nDoublet detection improved by using the same statistical urn problem setup, but then iteratively removing detected doublet cell's alleles from the singlet cluster urns and then looking for doublets again until we no longer find new doublets.\r\n--known_genotypes now available in 2.0\r\nshared_samples.py script now available to show which clusters correspond to which other clusters in experimental designs involving multiple experiments with overlapping samples\r\nvarious bug fixes",
        "html_url": "https://github.com/wheaton5/souporcell/releases/tag/2.0",
        "name": "v2.0",
        "release_id": 21812657,
        "tag": "2.0",
        "tarball_url": "https://api.github.com/repos/wheaton5/souporcell/tarball/2.0",
        "type": "Release",
        "url": "https://api.github.com/repos/wheaton5/souporcell/releases/21812657",
        "value": "https://api.github.com/repos/wheaton5/souporcell/releases/21812657",
        "zipball_url": "https://api.github.com/repos/wheaton5/souporcell/zipball/2.0"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "wheaton5",
          "type": "User"
        },
        "date_created": "2019-07-30T21:59:37Z",
        "date_published": "2019-07-30T22:05:42Z",
        "description": "This release includes new features such as\r\n\r\nDynamic restarting of pipelines that have been partially completed.\r\n--common_variants option to allow input of common variants or known variant loci in the form of a vcf such as one provided through 1kgenomes in our README\r\n--skip_remap option to skip fastq generation, remapping, and retagging (not recommended without --common_variants but otherwise use at your own risk)\r\n\r\nSingularity build here\r\n```\r\nwget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=15znQ43q-_R3k04DmbGs3pka2FXvao4TS' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=15znQ43q-_R3k04DmbGs3pka2FXvao4TS\" -O souporcell.sif && rm -rf /tmp/cookies.txt\r\n```\r\n\r\ncommon variant files here\r\nGRCh38\r\n```\r\nwget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=15s8zvIit2UO-2lnL2DnsL0YFoR3AWWRF' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=15s8zvIit2UO-2lnL2DnsL0YFoR3AWWRF\" -O filtered_2p_1kgenomes_GRCh38.vcf && rm -rf /tmp/cookies.txt\r\n```\r\nand for hg19\r\n```\r\nwget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1ICfIhpA4iGPEz_lAZf6RLMFQlrfgaskL' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1ICfIhpA4iGPEz_lAZf6RLMFQlrfgaskL\" -O filtered_2p_1kgenomes_hg19.vcf && rm -rf /tmp/cookies.txt\r\n```\r\n\r\n",
        "html_url": "https://github.com/wheaton5/souporcell/releases/tag/v1.0",
        "release_id": 18969910,
        "tag": "v1.0",
        "tarball_url": "https://api.github.com/repos/wheaton5/souporcell/tarball/v1.0",
        "type": "Release",
        "url": "https://api.github.com/repos/wheaton5/souporcell/releases/18969910",
        "value": "https://api.github.com/repos/wheaton5/souporcell/releases/18969910",
        "zipball_url": "https://api.github.com/repos/wheaton5/souporcell/zipball/v1.0"
      },
      "technique": "GitHub_API"
    }
  ],
  "run": [
    {
      "confidence": 1,
      "result": {
        "original_header": "To run through the pipeline script",
        "parent_header": [
          "souporcell"
        ],
        "type": "Text_excerpt",
        "value": "```\nsouporcell_pipeline.py -i /path/to/possorted_genome_bam.bam -b /path/to/barcodes.tsv -f /path/to/reference.fasta -t num_threads_to_use -o output_dir_name -k num_clusters\n```\n"
      },
      "source": "https://raw.githubusercontent.com/wheaton5/souporcell/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "1. Remapping",
        "parent_header": [
          "souporcell",
          "To run things step by step not through the pipeline script"
        ],
        "type": "Text_excerpt",
        "value": "We discuss the need for remapping in our manuscript. We need to keep track of cell barcodes and and UMIs, so we first create a fastq with those items encoded in the readname.\nRequires python 3.0, modules pysam, argparse (pip install/conda install depending on environment)\nEasiest to first add the souporcell directory to your PATH variable with \n```\nexport PATH=/path/to/souporcell:$PATH\n```\nThen run the renamer.py script to put some of the quality information in the read name. For human data this step will typically take several hours and the output fq file will be somewhat larger than the input bam\n```\npython renamer.py --bam possorted_genome_bam.bam --barcodes barcodes.tsv --out fq.fq\n```\nThen we must remap these reads using minimap2 (similar results have been seen with hisat2)\nRequires [minimap2](https://github.com/lh3/minimap2)\nand add /path/to/minimap2 to your PATH. For human data the remapping will typically require more than 12 Gb memory and may take a few hours to run.\n```\nminimap2 -ax splice -t 8 -G50k -k 21 -w 11 --sr -A2 -B8 -O12,32 -E2,1 -r200 -p.5 -N20 -f1000,5000 -n2 -m20 -s40 -g2000 -2K50m --secondary=no <reference_fasta_file> <fastq_file> > minimap.sam\n```\n(note the -t 8 as the number of threads, change this as needed)\nNow we must retag the reads with their cell barcodes and UMIs\n```\npython retag.py --sam minimap.sam --out minitagged.bam\n```\nThen we must sort and index our bam.\nRequires [samtools](http://www.htslib.org/)\n```\nsamtools sort minitagged.bam minitagged_sorted.bam\nsamtools index minitagged_sorted.bam\n```\n"
      },
      "source": "https://raw.githubusercontent.com/wheaton5/souporcell/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "2. Calling candidate variants",
        "parent_header": [
          "souporcell",
          "To run things step by step not through the pipeline script"
        ],
        "type": "Text_excerpt",
        "value": "You may wish to break this into multiple jobs such as 1 job per chromosome and merge after but the basic command is the following.\nRequires [freebayes](https://github.com/ekg/freebayes) and add /path/to/freebayes/bin to your PATH\n```\nfreebayes -f <reference_fasta> -iXu -C 2 -q 20 -n 3 -E 1 -m 30 --min-coverage 6 --limit-coverage 100000 minitagged_sorted.bam\n```\n"
      },
      "source": "https://raw.githubusercontent.com/wheaton5/souporcell/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "3. Cell allele counting",
        "parent_header": [
          "souporcell",
          "To run things step by step not through the pipeline script"
        ],
        "type": "Text_excerpt",
        "value": "Requires [vartrix](https://github.com/10XGenomics/vartrix)\nand add /path/to/vartrix to your PATH\n```\nvartrix --umi --mapq 30 -b <bam file> -c <barcode tsv> --scoring-method coverage --threads 8 --ref-matrix ref.mtx --out-matrix alt.mtx -v <freebayes vcf> --fasta <fasta file used for remapping>\n```\nnote the --threads argument and use an appropriate number of threads for your system.\n"
      },
      "source": "https://raw.githubusercontent.com/wheaton5/souporcell/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "4. Clustering cells by genotype",
        "parent_header": [
          "souporcell",
          "To run things step by step not through the pipeline script"
        ],
        "type": "Text_excerpt",
        "value": "Rust required. To install rust:\n```\ncurl https://sh.rustup.rs -sSf | sh\n```\nand to build souporcell clustering\n```\ncd /path/to/souporcell/souporcell\ncargo build --release\n```\nAnd add /path/to/souporcell/souporcell/target/release to your path\nusage\n```\nsouporcell -h\nsouporcell 2.4\nHaynes Heaton <whheaton@gmail.com>\nclustering scRNAseq cells by genotype\n\nUSAGE:\n    souporcell [OPTIONS] --alt_matrix <alt_matrix> --barcodes <barcodes> --num_clusters <num_clusters> --ref_matrix <ref_matrix>\n\nFLAGS:\n    -h, --help       Prints help information\n    -V, --version    Prints version information\n\nOPTIONS:\n    -a, --alt_matrix <alt_matrix>                                           alt matrix from vartrix\n    -b, --barcodes <barcodes>                                               cell barcodes\n        --initialization_strategy <initialization_strategy>\n            cluster initialization strategy, defaults to kmeans++, valid values are kmeans++, random_uniform,\n            middle_variance, random_cell_assignment\n        --known_cell_assignments <known_cell_assignments>\n            tsv with barcodes and their known assignments\n\n    -g, --known_genotypes <known_genotypes>\n            NOT YET IMPLEMENTED population vcf/bcf of known genotypes if available.\n            \n        --known_genotypes_sample_names <known_genotypes_sample_names>...\n            NOT YET IMPLEMENTED sample names, must be samples from the known_genotypes vcf\n\n        --min_alt <min_alt>\n            minimum number of cells containing the alt allele for the variant to be used for clustering\n\n        --min_alt_umis <min_alt_umis>                                       min alt umis to use locus for clustering\n        --min_ref <min_ref>\n            minimum number of cells containing the ref allele for the variant to be used for clustering\n\n        --min_ref_umis <min_ref_umis>                                       min ref umis to use locus for clustering\n    -k, --num_clusters <num_clusters>                                       number of clusters\n    -r, --ref_matrix <ref_matrix>                                           ref matrix from vartrix\n    -r, --restarts <restarts>                                               number of random seedings\n        --seed <seed>                                                       optional random seed\n    -t, --threads <threads>                                                 number of threads to use\n```\nSo generally something along the lines of\n```\nsouporcell -a alt.mtx -r ref.mtx -b barcodes.tsv -k <num_clusters> -t 8 > clusters_tmp.tsv\n```\n(note clusters_tmp.tsv output as the doublet caller outputs the final clusters file)\n"
      },
      "source": "https://raw.githubusercontent.com/wheaton5/souporcell/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "5. Calling doublets",
        "parent_header": [
          "souporcell",
          "To run things step by step not through the pipeline script"
        ],
        "type": "Text_excerpt",
        "value": "Rust required.\nBuild troublet:\n```\ncd /path/to/souporcell/troublet\ncargo build --release\n```\nAnd add /path/to/souporcell/troublet/target/release to your path\nThe usage is\n```\ntroublet -h\ntroublet 2.4\nHaynes Heaton <whheaton@gmail.com>\nIntergenotypic doublet detection given cluster assignments and cell allele counts\n\nUSAGE:\n    troublet [OPTIONS] --alts <alts> --clusters <clusters>\n\nFLAGS:\n    -h, --help       Prints help information\n    -V, --version    Prints version information\n\nOPTIONS:\n    -a, --alts <alts>                              alt allele counts per cell in sparse matrix format out of vartrix\n    -c, --clusters <clusters>                      cluster file output from schism\n    -b, --debug <debug>...                         print debug info for index of cells listed\n    -d, --doublet_prior <doublet_prior>            prior on doublets. Defaults to 0.5\n        --doublet_threshold <doublet_threshold>    doublet posterior threshold, defaults to 0.90\n    -r, --refs <refs>                              ref allele counts per cell in sparse matrix format out of vartrix\n        --singlet_threshold <singlet_threshold>    singlet posterior threshold, defaults to 0.90\n```\nSo generally\n```\ntroublet -a alt.mtx -r ref.mtx --clusters clusters_tmp.tsv > clusters.tsv\n```\n"
      },
      "source": "https://raw.githubusercontent.com/wheaton5/souporcell/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "6. Genotype and ambient RNA coinference",
        "parent_header": [
          "souporcell",
          "To run things step by step not through the pipeline script"
        ],
        "type": "Text_excerpt",
        "value": "Python3 required with modules pystan, pyvcf, pickle, math, scipy, gzip (pip install should work for each)\n```\nconsensus.py -h\nusage: consensus.py [-h] -c CLUSTERS -a ALT_MATRIX -r REF_MATRIX [-p PLOIDY]\n                    --soup_out SOUP_OUT --vcf_out VCF_OUT --output_dir\n                    OUTPUT_DIR -v VCF\n\nconsensus genotype calling and ambient RNA estimation\n\noptional arguments:\n  -h, --help            show this help message and exit\n  -c CLUSTERS, --clusters CLUSTERS\n                        tsv cluster file from the troublet output\n  -a ALT_MATRIX, --alt_matrix ALT_MATRIX\n                        alt matrix file\n  -r REF_MATRIX, --ref_matrix REF_MATRIX\n                        ref matrix file\n  -p PLOIDY, --ploidy PLOIDY\n                        ploidy, must be 1 or 2, defaults to 2\n  --soup_out SOUP_OUT   soup output\n  --vcf_out VCF_OUT     vcf output\n  --output_dir OUTPUT_DIR\n                        output directory\n  -v VCF, --vcf VCF     vcf file from which alt and ref matrix were created\n```\nSo generally\n```\nconsensus.py -c clusters.tsv -a alt.mtx -r ref.mtx --soup_out soup.txt -v <freebayes vcf> --vcf_out cluster_genotypes.vcf --output_dir .\n```\n\n\n\n"
      },
      "source": "https://raw.githubusercontent.com/wheaton5/souporcell/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "somef_missing_categories": [
    "citation",
    "acknowledgement",
    "download",
    "requirements",
    "contact",
    "contributors",
    "documentation",
    "usage",
    "faq",
    "support",
    "identifier",
    "executable_example"
  ],
  "somef_provenance": {
    "date": "2024-11-04 04:27:17",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 166
      },
      "technique": "GitHub_API"
    }
  ]
}