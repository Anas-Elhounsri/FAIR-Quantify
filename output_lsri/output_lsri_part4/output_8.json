{
  "citation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Citation",
        "type": "Text_excerpt",
        "value": "Cuesta-Zuluaga, Jacobo de la, Ruth E. Ley, and Nicholas D. Youngblut. 2019.\n\"Struo: A Pipeline for Building Custom Databases for Common Metagenome Profilers.\"\nBioinformatics , November.\n[https://doi.org/10.1093/bioinformatics/btz899](https://doi.org/10.1093/bioinformatics/btz899)\n"
      },
      "source": "https://raw.githubusercontent.com/leylabmpi/Struo/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "User-provided databases",
        "parent_header": [
          "Description",
          "Getting reference genomes for the custom databases"
        ],
        "type": "Text_excerpt",
        "value": "Users can also provide genomes as compressed fasta files (`.fna.gz`).\nThis also requires adding the corresponding information to the `samples.txt` file (see below)\n"
      },
      "source": "https://raw.githubusercontent.com/leylabmpi/Struo/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/leylabmpi/Struo"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2019-09-02T11:09:48Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2024-10-04T05:00:53Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "Ley Lab MetaGenome Profiler DataBase generator"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Struo\u2019s workflow",
        "parent_header": [
          "Description"
        ],
        "type": "Text_excerpt",
        "value": "![](./images/struo_workflow.png)\nStruo's workflow encompasses the steps from genome download to database construction\n"
      },
      "source": "https://raw.githubusercontent.com/leylabmpi/Struo/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "UniRef diamond database(s)",
        "parent_header": [
          "Description",
          "Setup"
        ],
        "type": "Text_excerpt",
        "value": "You will need a UniRef diamond database for the humann2 database construction (e.g., UniRef90).\nSee the \"Download a translated search database\" section of the\n[humann2 docs](https://bitbucket.org/biobakery/humann2/wiki/Home#markdown-header-5-download-the-databases).\n"
      },
      "source": "https://raw.githubusercontent.com/leylabmpi/Struo/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "User-provided databases",
        "parent_header": [
          "Description",
          "Getting reference genomes for the custom databases"
        ],
        "type": "Text_excerpt",
        "value": "Users can also provide genomes as compressed fasta files (`.fna.gz`).\nThis also requires adding the corresponding information to the `samples.txt` file (see below)\n"
      },
      "source": "https://raw.githubusercontent.com/leylabmpi/Struo/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Input data (`samples.txt` file)",
        "parent_header": [
          "Description"
        ],
        "type": "Text_excerpt",
        "value": "The table of input files/data can be created using the helper scripts described above. \n\n* The pipeline requires a tab-delimited table that includes the following columns (column names specified in the `config.yaml` file):\n  * Sample ID\n    * This will usually just be the species/strain names\n  * Path to the genome assembly fasta file\n    * NOTE: these must be gzip'ed\n  * taxonomy ID\n    * This should be the NCBI taxonomy ID at the species/strain level\n      * Needed for Kraken\n  * taxonomy\n    * This should at least include `g__<genus>;s__<species>`\n    * The taxonomy can include higher levels, as long as levels 6 & 7 are genus and species\n    * Any taxonomy lacking genus and/or species levels will be labeled:\n      * `g__unclassified`  (if no genus)\n      * `s__unclassified`  (if no species)\n    * This is needed for humann2\n\nOther columns in the file will be ignored. The path to the samples file should be specified in the `config.yaml` file (see below)\n"
      },
      "source": "https://raw.githubusercontent.com/leylabmpi/Struo/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Using the GTDB taxonomy instead of NCBI taxIDs",
        "parent_header": [
          "Description",
          "Input data (`samples.txt` file)"
        ],
        "type": "Text_excerpt",
        "value": "kraken2 & humann2 databases used NCBI taxIDs, and thus the NCBI taxonomy is used by default\nfor `Struo`. You can instead create custom taxIDs from the GTDB taxonomy with\n[gtdb_to_taxdump](https://github.com/nick-youngblut/gtdb_to_taxdump). \n\nThe resulting `names.dmp` and `nodes.dmp` files, along with a genome metadata file that includes the gtdb_taxids,\nthen you can modify the Struo pipeline to fully use the GTDB taxonomy & taxIDs.\nYou will need to modify the `config.yaml` file (see \"If using GTDB taxIDs\" below).\n\n\n"
      },
      "source": "https://raw.githubusercontent.com/leylabmpi/Struo/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Edit the `config.yaml`",
        "parent_header": [
          "Description",
          "Running the pipeline"
        ],
        "type": "Text_excerpt",
        "value": "* Specify the input/output paths\n* Modify parameters as needed\n  * Make sure to add the path to the UniRef diamond database for HUMAnN2\n    * see above for instructions on retrieving this file\n* The `samples_col:` column specified should contain unique values\n  * The default `ncbi_organism_name` column in the GTDB metadata does not contain unique values\n  * For the pre-built Struo databases, we merged assembly accessions with the original ncbi_organism_name\n    * eg., `GB_GCA_001784635.1_Candidatus Micrarchaeota archaeon RBG_16_49_10`\n* Modify `temp_folder:` if needed\n  * This folder is used just for read/write of temporary files\n"
      },
      "source": "https://raw.githubusercontent.com/leylabmpi/Struo/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "If using GTDB taxIDs",
        "parent_header": [
          "Description",
          "Running the pipeline",
          "Edit the `config.yaml`"
        ],
        "type": "Text_excerpt",
        "value": "If you have followed \"Using the GTDB taxonomy instead of NCBI taxIDs\" above, then\nmake the following modifications to the `config.yaml` file:\n\n```\n## column names in samples table\ntaxID_col: 'gtdb_taxid'\ntaxonomy_col: 'gtdb_taxonomy'\n\n#-- if custom NCBI taxdump files --#\nnames_dmp: /YOUR/PATH/TO/names.dmp\nnodes_dmp: /YOUR/PATH/TO/nodes.dmp\n```\n\n"
      },
      "source": "https://raw.githubusercontent.com/leylabmpi/Struo/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "General info on using `snakemake`",
        "parent_header": [
          "Description",
          "Running the pipeline"
        ],
        "type": "Text_excerpt",
        "value": "Snakemake allows for easy re-running of the pipeline on just genomes that have not yet been processed.\nYou can just add more genomes to the input table and re-run the pipeline (test first with `--dryrun`).\nSnakemake should just process the new genomes and then re-create the combined dataset files (this must be done each time).\nMake sure to not mess with the files in the `nuc_filtered` and `prot_filtered` directories! Otherwise,\nsnakemake may try to run all genomes again through the computationally expensive gene annotation process.\n\n"
      },
      "source": "https://raw.githubusercontent.com/leylabmpi/Struo/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Using the resulting databases",
        "parent_header": [
          "Description"
        ],
        "type": "Text_excerpt",
        "value": "Set the database paths in humann2, kraken2, etc. to the new, custom database files.\n\n* humann2\n  * nucleotide\n    * `all_genes_annot.fna.gz`\n  * amino acid\n    * `all_genes_annot.dmnd`\n* kraken2\n  * `database*mers.kraken`\n  "
      },
      "source": "https://raw.githubusercontent.com/leylabmpi/Struo/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Adding more samples (genomes) to an existing custom DB",
        "parent_header": [
          "Description",
          "Using the resulting databases"
        ],
        "type": "Text_excerpt",
        "value": "If you set `keep_intermediate: True` for your initial run, then the\nintermediate files from the computationally intensive steps are kept,\nand so those genomes don't have to be reprocessed. Only new genomes will\nbe processed, and then the database(s) will be re-created with old + new\ngenomes.\n\nTo create a database with more genomes:\n\n* Add new genomes to the input table.\n* **If** you want to over-write your old databases:\n  * DO NOT change the `db_name:` parameter in the config.yaml file\n* **OR if** you want to create new database:\n  * Change the `db_name:` parameter in the config.yaml file\n* Re-run the snakemake pipeline.\n  * Snakemake should skip the genomes that have already been processed.\n  * Use `--dryrun` to see what snakemake is going to do before actually running the pipeline.\n  * You may need to set `use_ancient: True` in order to have snakemake skip the diamond mapping for humann2\n    * This is needed if the timestamps on the genome gene files have been (accidently) modified since the last run.\n\n"
      },
      "source": "https://raw.githubusercontent.com/leylabmpi/Struo/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Adding existing gene sequences to humann2 databases",
        "parent_header": [
          "Description",
          "Using the resulting databases"
        ],
        "type": "Text_excerpt",
        "value": "If you have gene sequences already formatted for creating a humann2 custom DB,\nand you'd like to include them with the gene sequences generated from the\ninput genomes, then just provide the file paths to the nuc/prot fasta files\n(`humann2_nuc_seqs` and `humann2_prot_seqs` in the `config.yaml` file).\n\nAll genes (from genomes & user-provided) will be clustered altogether with `vsearch`.\nSee the `vsearch_all:` setting in the `config.yaml` for the default clustering parameters used.\nYou can use `vsearch_all: Skip` to skip the clustering and instead all of the sequences\nwill just be combined without removing redundancies.\n\n"
      },
      "source": "https://raw.githubusercontent.com/leylabmpi/Struo/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 0.9065310896500693,
      "result": {
        "original_header": "Struo",
        "type": "Text_excerpt",
        "value": "**Struo:** a pipeline for building custom databases for common metagenome profilers \n"
      },
      "source": "https://raw.githubusercontent.com/leylabmpi/Struo/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9332173186781191,
      "result": {
        "original_header": "Struo2",
        "type": "Text_excerpt",
        "value": "* Faster than Struo and allows for efficient database updating\n  * [Struo2 repo](https://github.com/leylabmpi/Struo2)\n \n"
      },
      "source": "https://raw.githubusercontent.com/leylabmpi/Struo/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8907967012711455,
      "result": {
        "original_header": "Notes/warnings",
        "type": "Text_excerpt",
        "value": "* The taxdump taxIDs are NOT stable! Do not mix and match among GTDB releases!\n* You can use `ncbi-gtdb_map.py` from the\n  [gtdb_to_taxdump](https://github.com/nick-youngblut/gtdb_to_taxdump) repo\n  to convert between NCBI and GTDB taxonomies\n \n"
      },
      "source": "https://raw.githubusercontent.com/leylabmpi/Struo/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9932156427953074,
      "result": {
        "original_header": "`GTDB_metadata_filter.R`",
        "type": "Text_excerpt",
        "value": "This tool is useful for selecting which GTDB genomes to include in a custom database. \n"
      },
      "source": "https://raw.githubusercontent.com/leylabmpi/Struo/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9032275564747316,
      "result": {
        "original_header": "`genome_download.R`",
        "type": "Text_excerpt",
        "value": "This tool is useful for downloading genomes from NCBI.  \nDownload a set of genomes based on NCBI assembly accessions provided\nin a table. The file paths of the downloaded genome fasta files will be\nappended to the input table.\n \n"
      },
      "source": "https://raw.githubusercontent.com/leylabmpi/Struo/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.996818000898934,
      "result": {
        "original_header": "`tree_prune.py`",
        "type": "Text_excerpt",
        "value": "This tool is useful for creating a GTDB archaea/bacteria phylogeny\nof all genomes in your custom database. The phylogeny can be used\nfor phylogenetic analyses of metagenomes (e.g., Faith's PD or Unifrac). \n"
      },
      "source": "https://raw.githubusercontent.com/leylabmpi/Struo/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9886592787721047,
      "result": {
        "original_header": "`gtdb_to_taxdump`",
        "type": "Text_excerpt",
        "value": "This is a [separate repo](https://github.com/nick-youngblut/gtdb_to_taxdump). \nThis is useful for creating an NCBI taxdump (names.dmp and nodes.dmp)\nfrom the GTDB taxonomy. Note that the taxIDs are arbitrary and don't\nmatch anything in the NCBI!  \n"
      },
      "source": "https://raw.githubusercontent.com/leylabmpi/Struo/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8122713854894669,
      "result": {
        "original_header": "TODO",
        "type": "Text_excerpt",
        "value": "* Create a diamond DB using `diamond >=0.9` so that users can run humann2 with\nthe most up-to-date version of diamond\n  * Note this will require creating an updated UniRef50 db\n \n"
      },
      "source": "https://raw.githubusercontent.com/leylabmpi/Struo/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "download": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Download",
        "parent_header": [
          "Description",
          "Setup"
        ],
        "type": "Text_excerpt",
        "value": "To download the pipeline, clone the Git repository:\n\n```\ngit clone git@github.com:leylabmpi/Struo.git \n```\n"
      },
      "source": "https://raw.githubusercontent.com/leylabmpi/Struo/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Downloading genomes",
        "parent_header": [
          "Description",
          "Getting reference genomes for the custom databases"
        ],
        "type": "Text_excerpt",
        "value": "* If using [GTDB](https://gtdb.ecogenomic.org/) genomes, run `GTDB_metadata_filter.R` to select genomes\n* If downloading genomes from genbank/refseq, you can use `genome_download.R`\n\nExample:\n\n```\n# Filtering GTDB metadata to certain genomes\n./GTDB_metadata_filter.R -o gtdb-r89_bac-arc.tsv https://data.ace.uq.edu.au/public/gtdb/data/releases/release89/89.0/bac120_metadata_r89.tsv https://data.ace.uq.edu.au/public/gtdb/data/releases/release89/89.0/ar122_metadata_r89.tsv\n\n# Downloading all genomes (& creating tab-delim table of genome info)\n./genome_download.R -o genomes -p 8 gtdb-r89_bac-arc.tsv > genomes.txt\n\n# Note: the output of ./genome_download.R can be directly used for running the `Struo` pipeline (see below)\n```\n"
      },
      "source": "https://raw.githubusercontent.com/leylabmpi/Struo/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/leylabmpi/Struo/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "executable_example": [
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/leylabmpi/Struo/master/notebooks/release86/02_LLMGP-DB_resources.ipynb"
      },
      "source": "https://raw.githubusercontent.com/leylabmpi/Struo/master/notebooks/release86/02_LLMGP-DB_resources.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/leylabmpi/Struo/master/notebooks/release86/01_GTDB_metadata_summary.ipynb"
      },
      "source": "https://raw.githubusercontent.com/leylabmpi/Struo/master/notebooks/release86/01_GTDB_metadata_summary.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/leylabmpi/Struo/master/notebooks/.ipynb_checkpoints/01_GTDB_metadata_summary-checkpoint.ipynb"
      },
      "source": "https://raw.githubusercontent.com/leylabmpi/Struo/master/notebooks/.ipynb_checkpoints/01_GTDB_metadata_summary-checkpoint.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/leylabmpi/Struo/master/notebooks/release89/02_LLMGP-DB_resources.ipynb"
      },
      "source": "https://raw.githubusercontent.com/leylabmpi/Struo/master/notebooks/release89/02_LLMGP-DB_resources.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/leylabmpi/Struo/master/notebooks/release89/01_GTDB_metadata_summary.ipynb"
      },
      "source": "https://raw.githubusercontent.com/leylabmpi/Struo/master/notebooks/release89/01_GTDB_metadata_summary.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/leylabmpi/Struo/master/tutorial/01_Example_Struo_Run.ipynb"
      },
      "source": "https://raw.githubusercontent.com/leylabmpi/Struo/master/tutorial/01_Example_Struo_Run.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/leylabmpi/Struo/master/benchmark/06_BGI_stats.ipynb"
      },
      "source": "https://raw.githubusercontent.com/leylabmpi/Struo/master/benchmark/06_BGI_stats.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/leylabmpi/Struo/master/benchmark/04_CAMI_stats.ipynb"
      },
      "source": "https://raw.githubusercontent.com/leylabmpi/Struo/master/benchmark/04_CAMI_stats.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/leylabmpi/Struo/master/benchmark/01_Standard-Kraken-Bracken-DBs.ipynb"
      },
      "source": "https://raw.githubusercontent.com/leylabmpi/Struo/master/benchmark/01_Standard-Kraken-Bracken-DBs.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/leylabmpi/Struo/master/benchmark/02_CAMI-QC.ipynb"
      },
      "source": "https://raw.githubusercontent.com/leylabmpi/Struo/master/benchmark/02_CAMI-QC.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/leylabmpi/Struo/master/benchmark/03_CAMI_profiles.ipynb"
      },
      "source": "https://raw.githubusercontent.com/leylabmpi/Struo/master/benchmark/03_CAMI_profiles.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/leylabmpi/Struo/master/benchmark/05_BGI_profiles.ipynb"
      },
      "source": "https://raw.githubusercontent.com/leylabmpi/Struo/master/benchmark/05_BGI_profiles.ipynb",
      "technique": "file_exploration"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 4
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/leylabmpi/Struo/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "leylabmpi/Struo"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "Struo"
      },
      "source": "https://raw.githubusercontent.com/leylabmpi/Struo/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "has_script_file": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/leylabmpi/Struo/master/snakemake_sge.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/leylabmpi/Struo/master/snakemake_conda-list.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/leylabmpi/Struo/master/snakemake_clean.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/leylabmpi/Struo/master/bin/scripts/download_taxonomy.sh"
      },
      "technique": "file_exploration"
    }
  ],
  "images": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/leylabmpi/Struo/master/./images/struo_workflow.png"
      },
      "source": "https://raw.githubusercontent.com/leylabmpi/Struo/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "installation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "conda env setup",
        "parent_header": [
          "Description",
          "Setup"
        ],
        "type": "Text_excerpt",
        "value": "> Versions listed are those that have been tested\n\n* python=3.6\n* snakemake=5.7.0\n* r-base=3.6\n* r-argparse=2.0.1\n* r-curl=4.2\n* r-data.table=1.12.4\n* r-dplyr=0.8.3\n* ncbi-genome-download=0.2.10\n* newick_utils=1.6\n"
      },
      "source": "https://raw.githubusercontent.com/leylabmpi/Struo/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "UniRef diamond database(s)",
        "parent_header": [
          "Description",
          "Setup"
        ],
        "type": "Text_excerpt",
        "value": "You will need a UniRef diamond database for the humann2 database construction (e.g., UniRef90).\nSee the \"Download a translated search database\" section of the\n[humann2 docs](https://bitbucket.org/biobakery/humann2/wiki/Home#markdown-header-5-download-the-databases).\n"
      },
      "source": "https://raw.githubusercontent.com/leylabmpi/Struo/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 0.8868802783211329,
      "result": {
        "original_header": "Struo",
        "type": "Text_excerpt",
        "value": "> \"Struo\" --> from the Latin: \u201cI build\u201d or \u201cI gather\u201d \n\n* Version: 0.1.7\n* Authors:\n  * Nick Youngblut <nyoungb2@gmail.com>\n  * Jacobo de la Cuesta <jacobo.delacuesta@tuebingen.mpg.de>\n* Maintainers:\n  * Nick Youngblut <nyoungb2@gmail.com>\n  * Jacobo de la Cuesta <jacobo.delacuesta@tuebingen.mpg.de>\n* Previous name\n  * Ley Lab MetaGenome Profiler DataBase generator (LLMGP-DB) \n"
      },
      "source": "https://raw.githubusercontent.com/leylabmpi/Struo/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.999136660733604,
      "result": {
        "original_header": "Pre-built custom databases",
        "type": "Text_excerpt",
        "value": "**GTDB releases available:**\n* Release 86 (14.03.2019)\n  * Number of genomes included: 21,276\n  * NCBI taxonomy/taxIDs used\n* Release 89 (30.08.2019)\n  * Number of genomes included: 23,361\n  * GTDB taxdump\n    * taxIDs assigned with [gtdb_to_taxdump](https://github.com/nick-youngblut/gtdb_to_taxdump)\n  * Genome phylogeny\n    * GTDB `ar122_r89.tree` & `bac120_r89.tree` grafted together\n  * Genome phenotypes\n    * Inferred with [py3-implementation of Traitar](https://github.com/nick-youngblut/traitar3)\n* Release 95 (13.07.2020)\n  * Number of genomes included: 30,989\n  * GTDB taxdump\n    * taxIDs assigned with [gtdb_to_taxdump](https://github.com/nick-youngblut/gtdb_to_taxdump)\n  * Genome phylogeny\n    * GTDB `ar122_r95.tree` & `bac120_r95.tree` grafted together\n \n"
      },
      "source": "https://raw.githubusercontent.com/leylabmpi/Struo/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9857802379120661,
      "result": {
        "original_header": "Notes/warnings",
        "type": "Text_excerpt",
        "value": "* The taxdump taxIDs are NOT stable! Do not mix and match among GTDB releases!\n* You can use `ncbi-gtdb_map.py` from the\n  [gtdb_to_taxdump](https://github.com/nick-youngblut/gtdb_to_taxdump) repo\n  to convert between NCBI and GTDB taxonomies\n \n"
      },
      "source": "https://raw.githubusercontent.com/leylabmpi/Struo/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8937613545431603,
      "result": {
        "original_header": "`tree_prune.py`",
        "type": "Text_excerpt",
        "value": "Prune >=1 phylogeny to just certain taxa. If >1 phylogeny provided,\nthen the phylogenies are merged.\n \n"
      },
      "source": "https://raw.githubusercontent.com/leylabmpi/Struo/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9936782978566672,
      "result": {
        "original_header": "TODO",
        "type": "Text_excerpt",
        "value": "* Create a diamond DB using `diamond >=0.9` so that users can run humann2 with\nthe most up-to-date version of diamond\n  * Note this will require creating an updated UniRef50 db\n \n"
      },
      "source": "https://raw.githubusercontent.com/leylabmpi/Struo/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/leylabmpi/Struo/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "database, metagenomics, ngs, pipeline"
      },
      "technique": "GitHub_API"
    }
  ],
  "license": [
    {
      "confidence": 1,
      "result": {
        "name": "MIT License",
        "spdx_id": "MIT",
        "type": "License",
        "url": "https://api.github.com/licenses/mit",
        "value": "https://api.github.com/licenses/mit"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "type": "File_dump",
        "value": "MIT License\n\nCopyright (c) 2019 Nick Youngblut\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
      },
      "source": "https://raw.githubusercontent.com/leylabmpi/Struo/master/LICENSE",
      "technique": "file_exploration"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "Struo"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "Organization",
        "value": "leylabmpi"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Jupyter Notebook",
        "size": 4214564,
        "type": "Programming_language",
        "value": "Jupyter Notebook"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 57536,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Shell",
        "size": 11171,
        "type": "Programming_language",
        "value": "Shell"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Perl",
        "size": 8875,
        "type": "Programming_language",
        "value": "Perl"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "R",
        "size": 7251,
        "type": "Programming_language",
        "value": "R"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/leylabmpi/Struo/master/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "related_documentation": [
    {
      "confidence": 1,
      "result": {
        "format": "readthedocs",
        "type": "Url",
        "value": "https://snakemake.readthedocs.io/"
      },
      "source": "https://raw.githubusercontent.com/leylabmpi/Struo/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "releases": [
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "nick-youngblut",
          "type": "User"
        },
        "date_created": "2021-03-26T08:42:45Z",
        "date_published": "2021-08-23T11:11:55Z",
        "description": "Initial release; publication release",
        "html_url": "https://github.com/leylabmpi/Struo/releases/tag/0.1.7",
        "name": "publication release",
        "release_id": 48272797,
        "tag": "0.1.7",
        "tarball_url": "https://api.github.com/repos/leylabmpi/Struo/tarball/0.1.7",
        "type": "Release",
        "url": "https://api.github.com/repos/leylabmpi/Struo/releases/48272797",
        "value": "https://api.github.com/repos/leylabmpi/Struo/releases/48272797",
        "zipball_url": "https://api.github.com/repos/leylabmpi/Struo/zipball/0.1.7"
      },
      "technique": "GitHub_API"
    }
  ],
  "run": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Edit the `config.yaml`",
        "parent_header": [
          "Description",
          "Running the pipeline"
        ],
        "type": "Text_excerpt",
        "value": "* Specify the input/output paths\n* Modify parameters as needed\n  * Make sure to add the path to the UniRef diamond database for HUMAnN2\n    * see above for instructions on retrieving this file\n* The `samples_col:` column specified should contain unique values\n  * The default `ncbi_organism_name` column in the GTDB metadata does not contain unique values\n  * For the pre-built Struo databases, we merged assembly accessions with the original ncbi_organism_name\n    * eg., `GB_GCA_001784635.1_Candidatus Micrarchaeota archaeon RBG_16_49_10`\n* Modify `temp_folder:` if needed\n  * This folder is used just for read/write of temporary files\n"
      },
      "source": "https://raw.githubusercontent.com/leylabmpi/Struo/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "If using GTDB taxIDs",
        "parent_header": [
          "Description",
          "Running the pipeline",
          "Edit the `config.yaml`"
        ],
        "type": "Text_excerpt",
        "value": "If you have followed \"Using the GTDB taxonomy instead of NCBI taxIDs\" above, then\nmake the following modifications to the `config.yaml` file:\n\n```\n## column names in samples table\ntaxID_col: 'gtdb_taxid'\ntaxonomy_col: 'gtdb_taxonomy'\n\n#-- if custom NCBI taxdump files --#\nnames_dmp: /YOUR/PATH/TO/names.dmp\nnodes_dmp: /YOUR/PATH/TO/nodes.dmp\n```\n\n"
      },
      "source": "https://raw.githubusercontent.com/leylabmpi/Struo/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Running locally",
        "parent_header": [
          "Description",
          "Running the pipeline"
        ],
        "type": "Text_excerpt",
        "value": "`snakemake --use-conda`\n"
      },
      "source": "https://raw.githubusercontent.com/leylabmpi/Struo/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Running on a cluster",
        "parent_header": [
          "Description",
          "Running the pipeline"
        ],
        "type": "Text_excerpt",
        "value": "If SGE, then you can use the `snakemake_sge.sh` script. You can create a similar bash script\nfor other cluster architectures. See the following resources for help:\n\n* [Ley Lab snakemake profiles](https://github.com/leylabmpi/snakemake_profiles)\n* [Snakemake docs on cluster config](https://snakemake.readthedocs.io/en/stable/snakefiles/configuration.html)\n* [Official snakemake profiles](https://github.com/Snakemake-Profiles)\n"
      },
      "source": "https://raw.githubusercontent.com/leylabmpi/Struo/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "General info on using `snakemake`",
        "parent_header": [
          "Description",
          "Running the pipeline"
        ],
        "type": "Text_excerpt",
        "value": "Snakemake allows for easy re-running of the pipeline on just genomes that have not yet been processed.\nYou can just add more genomes to the input table and re-run the pipeline (test first with `--dryrun`).\nSnakemake should just process the new genomes and then re-create the combined dataset files (this must be done each time).\nMake sure to not mess with the files in the `nuc_filtered` and `prot_filtered` directories! Otherwise,\nsnakemake may try to run all genomes again through the computationally expensive gene annotation process.\n\n"
      },
      "source": "https://raw.githubusercontent.com/leylabmpi/Struo/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Example of a humann2 run",
        "parent_header": [
          "Description",
          "Using the resulting databases"
        ],
        "type": "Text_excerpt",
        "value": "Run humann2 with custom databases created by Struo. Change that PATHs as necessary. \n\n```\nSTRUO_OUT_DIR=./struo_output/\nNUC_DB=`dirname $STRUO_OUT_DIR\"/all_genes_annot.fna.gz\"`\nPROT_DB=`dirname $STRUO_OUT_DIR\"/all_genes_annot.dmnd\"`\nMTPHLN_BT2_DB=`dirname ./metaphlan2_db/mpa_v20_m200/mpa_v20_m200.1.bt2`\nMTPHLN_PKL_DB=/ebio/abt3_projects2/databases_no-backup/metaphlan2/mpa_v20_m200/mpa_v20_m200.pkl\n\nhumann2 --gap-fill on --bypass-nucleotide-index  \\\n  --nucleotide-database $NUC_DB  \\\n  --protein-database $PROT_DB \\\n  --metaphlan-options \"Skip --mpa_pkl $MTPHLN_PKL_DB --bowtie2db $MTPHLN_BT2_DB\" \\\n  --tmp-dir /dev/shm/humann2_temp/ \\\n  --threads 12 \\\n  --input-format fastq  \\\n  --output-basename SRS018656 \\\n  --input SRS018656_R1.fq\n```\n  \n"
      },
      "source": "https://raw.githubusercontent.com/leylabmpi/Struo/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "somef_missing_categories": [
    "acknowledgement",
    "requirements",
    "contact",
    "contributors",
    "documentation",
    "faq",
    "support",
    "identifier",
    "has_build_file"
  ],
  "somef_provenance": {
    "date": "2024-11-04 01:27:39",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 46
      },
      "technique": "GitHub_API"
    }
  ],
  "usage": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Tutorial",
        "type": "Text_excerpt",
        "value": "For a step-by-step example of how to prepare and execute Struo, see the notebook in the `./tutorial/` folder\n"
      },
      "source": "https://raw.githubusercontent.com/leylabmpi/Struo/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "User-provided databases",
        "parent_header": [
          "Description",
          "Getting reference genomes for the custom databases"
        ],
        "type": "Text_excerpt",
        "value": "Users can also provide genomes as compressed fasta files (`.fna.gz`).\nThis also requires adding the corresponding information to the `samples.txt` file (see below)\n"
      },
      "source": "https://raw.githubusercontent.com/leylabmpi/Struo/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Example of a humann2 run",
        "parent_header": [
          "Description",
          "Using the resulting databases"
        ],
        "type": "Text_excerpt",
        "value": "Run humann2 with custom databases created by Struo. Change that PATHs as necessary. \n\n```\nSTRUO_OUT_DIR=./struo_output/\nNUC_DB=`dirname $STRUO_OUT_DIR\"/all_genes_annot.fna.gz\"`\nPROT_DB=`dirname $STRUO_OUT_DIR\"/all_genes_annot.dmnd\"`\nMTPHLN_BT2_DB=`dirname ./metaphlan2_db/mpa_v20_m200/mpa_v20_m200.1.bt2`\nMTPHLN_PKL_DB=/ebio/abt3_projects2/databases_no-backup/metaphlan2/mpa_v20_m200/mpa_v20_m200.pkl\n\nhumann2 --gap-fill on --bypass-nucleotide-index  \\\n  --nucleotide-database $NUC_DB  \\\n  --protein-database $PROT_DB \\\n  --metaphlan-options \"Skip --mpa_pkl $MTPHLN_PKL_DB --bowtie2db $MTPHLN_BT2_DB\" \\\n  --tmp-dir /dev/shm/humann2_temp/ \\\n  --threads 12 \\\n  --input-format fastq  \\\n  --output-basename SRS018656 \\\n  --input SRS018656_R1.fq\n```\n  \n"
      },
      "source": "https://raw.githubusercontent.com/leylabmpi/Struo/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "workflows": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/leylabmpi/Struo/master/bin/Snakefile"
      },
      "technique": "file_exploration"
    }
  ]
}