{
  "citation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Citation",
        "parent_header": [
          "DeepMicro"
        ],
        "type": "Text_excerpt",
        "value": "Oh, Min, and Liqing Zhang. \"DeepMicro: deep representation learning for disease prediction based on microbiome data.\" Scientific reports 10.1 (2020): 1-9.\n"
      },
      "source": "https://raw.githubusercontent.com/minoh0201/DeepMicro/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/minoh0201/DeepMicro"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2019-05-22T19:11:02Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2024-10-03T06:54:24Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "Deep representation learning for disease prediction based on microbiome data"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 0.9751216990319791,
      "result": {
        "original_header": "DeepMicro",
        "type": "Text_excerpt",
        "value": "DeepMicro is a deep representation learning framework exploiting various autoencoders to learn robust low-dimensional representations from high-dimensional data and training classification models based on the learned representation.\n \n"
      },
      "source": "https://raw.githubusercontent.com/minoh0201/DeepMicro/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/minoh0201/DeepMicro/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 15
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/minoh0201/DeepMicro/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "minoh0201/DeepMicro"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "DeepMicro"
      },
      "source": "https://raw.githubusercontent.com/minoh0201/DeepMicro/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "installation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Quick Setup Guide",
        "parent_header": [
          "DeepMicro"
        ],
        "type": "Text_excerpt",
        "value": "**Step 1:** Change the current working directory to the location where you want to install `DeepMicro`.\n\n**Step 2:** Clone the repository using git command\n```\n~$ git clone https://github.com/minoh0201/DeepMicro\n~$ cd DeepMicro\n```\n**Step 3:** Create virtual environment using Anaconda3 ([Read Anaconda3 install guide](https://www.digitalocean.com/community/tutorials/how-to-install-anaconda-on-ubuntu-18-04-quickstart)) and activate the virtual environment\n```\n~$ conda create --name deep_env python=3.6\n```\n```\n~$ conda activate deep_env\n```\n**Step 4:** Install required packages, then install tensorflow.\n```\n~$ pip install --upgrade pip && pip install numpy==1.16.2 && pip install pandas==0.24.2 && pip install scipy==1.2.1 && pip install scikit-learn==0.20.3 && pip install matplotlib==3.0.3 && pip install psutil==5.6.1 && pip install keras==2.2.4\n```\n* If your machine is *not* equipped with GPU, install tensorflow CPU version \n  ```\n  ~$ pip install tensorflow==1.13.1\n  ```\n* If it is equipped with GPU, then install tensorflow GPU version\n  ```\n  ~$ pip install tensorflow-gpu==1.13.1\n  ```\n**Step 5:** Run DeepMicro, printing out its usage.\n```\n~$ python DM.py -h\n```\n"
      },
      "source": "https://raw.githubusercontent.com/minoh0201/DeepMicro/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Quick Start Guide",
        "parent_header": [
          "DeepMicro"
        ],
        "type": "Text_excerpt",
        "value": "*Make sure you have already gone through the **Quick Setup Guide** above.*"
      },
      "source": "https://raw.githubusercontent.com/minoh0201/DeepMicro/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Learning representation with your own data",
        "parent_header": [
          "DeepMicro",
          "Quick Start Guide"
        ],
        "type": "Text_excerpt",
        "value": "__1. Copy your data under the `/data` directory.__ Your data should be a comma separated file without header and index, where each row represents a sample and each column represents a microbe. We are going to assume that your file name is `UserDataExample.csv` which is already provided.\n\n__2. Check your data can be successfully loaded and verify its shape with the following command.__\n```\n~$ python DM.py -r 1 --no_clf -cd UserDataExample.csv\n```\nThe output will show the number of rows and columns right next to `X_train.shape`. Our data `UserDataExample.csv` contains 80 rows and 200 columns.\n```\nUsing TensorFlow backend.\nNamespace(act='relu', ae=False, ae_lact=False, ae_oact=False, aeloss='mse', cae=False, custom_data='UserDataExample.csv', custom_data_labels=None, data=None, dataType='float64', data_dir='', dims='50', max_epochs=2000, method='all', no_clf=True, numFolds=5, numJobs=-2, patience=20, pca=False, repeat=1, rf_rate=0.1, rp=False, save_rep=False, scoring='roc_auc', seed=0, st_rate=0.25, svm_cache=1000, vae=False, vae_beta=1.0, vae_warmup=False, vae_warmup_rate=0.01)\nX_train.shape:  (80, 200)\nClassification task has been skipped.\n```\n    \n__3. Suppose that we want to reduce the number of dimensions of our data to 20 from 200 using a *shallow autoencoder*.__ Note that `--save_rep` argument will save your representation under the `/results` folder.\n```\n~$ python DM.py -r 1 --no_clf -cd UserDataExample.csv --ae -dm 20 --save_rep\n```\n    \n__4. Suppose that we want to use *deep autoencoder* with 2 hidden layers which has 100 units and 40 units, respectively.__ Let the size of latent layer to be 20. We are going to see the structure of deep autoencoder first.\n```\n~$ python DM.py -r 1 --no_clf -cd UserDataExample.csv --ae -dm 100,40,20 --no_trn\n```\nIt looks fine. Now, run the model and get the learned representation.\n```    \n~$ python DM.py -r 1 --no_clf -cd UserDataExample.csv --ae -dm 100,40,20 --save_rep\n```\n__5. We can try *variational autoencoder* and * convolutional autoencoder* as well.__ Note that you can see detailed argument description by using `-h` argument.\n```\n~$ python DM.py -r 1 --no_clf -cd UserDataExample.csv --vae -dm 100,20 --save_rep\n```\n```\n~$ python DM.py -r 1 --no_clf -cd UserDataExample.csv --cae -dm 100,50,1 --save_rep\n```\n"
      },
      "source": "https://raw.githubusercontent.com/minoh0201/DeepMicro/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Conducting binary classification after Learning representation with your own data",
        "parent_header": [
          "DeepMicro",
          "Quick Start Guide"
        ],
        "type": "Text_excerpt",
        "value": "__1. Copy your *data file* and *label file* under the `/data` directory.__ Your data file should be a comma separated value (CSV) format without header and index, where each row represents a sample and each column represents a microbe. __Your label file should contain a binary value (0 or 1) in each line and the number of lines should be equal to that in your data file.__ We are going to assume that your data file name is `UserDataExample.csv` and label file name is `UserLabelExample.csv` which are already provided.\n\n__2. Check your data can be successfully loaded and verify its shape with the following command.__\n```\n~$ python DM.py -r 1 --no_clf -cd UserDataExample.csv -cl UserLabelExample.csv\n```\nOur data `UserDataExample.csv` consists of 80 samples each of which has 200 features. The data will be split into the training set and the test set (in 8:2 ratio). The output will show the number of rows and columns for each data set.\n```\nNamespace(act='relu', ae=False, ae_lact=False, ae_oact=False, aeloss='mse', cae=False, custom_data='UserDataExample.csv', custom_data_labels='UserLabelExample.csv', data=None, dataType='float64', data_dir='', dims='50', max_epochs=2000, method='all', no_clf=True, no_trn=False, numFolds=5, numJobs=-2, patience=20, pca=False, repeat=1, rf_rate=0.1, rp=False, save_rep=False, scoring='roc_auc', seed=0, st_rate=0.25, svm_cache=1000, vae=False, vae_beta=1.0, vae_warmup=False, vae_warmup_rate=0.01)\nX_train.shape:  (64, 200)\ny_train.shape:  (64,)\nX_test.shape:  (16, 200)\ny_test.shape:  (16,)\nClassification task has been skipped.\n```\n\n__3. Suppose that we want to directly apply SVM algorithm on our data without representation learning.__  Remove `--no_clf` command and specify classification method with `-m svm` argument (If you don't specify classification algorithm, all three algorithms will be running). \n```\n~$ python DM.py -r 1 -cd UserDataExample.csv -cl UserLabelExample.csv -m svm\n```\nThe result will be saved under `/results` folder as a `UserDataExample_result.txt`. The resulting file will be growing as you conduct more experiments.\n\n__4. You can learn representation first, and then apply SVM algorithm on the learned representation.__\n```\n~$ python DM.py -r 1 -cd UserDataExample.csv -cl UserLabelExample.csv --ae -dm 20 -m svm\n```\n\n__5. You can repeat the same experiment by changing seeds for random partitioning of training and test set.__  Suppose we want to repeat classfication task five times. You can do it by put 5 into `-r` argument.\n```\n~$ python DM.py -r 5 -cd UserDataExample.csv -cl UserLabelExample.csv --ae -dm 20 -m svm\n```\n"
      },
      "source": "https://raw.githubusercontent.com/minoh0201/DeepMicro/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Reproducing the experiments described in our paper",
        "parent_header": [
          "DeepMicro",
          "Quick Start Guide"
        ],
        "type": "Text_excerpt",
        "value": "__1. Unzip `abundance.zip` and `marker.zip` files under the `/data` directory.__ \n```\n~$ cd data\n~$ unzip abundance.zip && unzip marker.zip\n~$ cd ..\n```\n__2. Specify dataset name to run.__ Choose dataset you want to run. You can choose one of the followings: `abundance_Cirrhosis`, `abundance_Colorectal`, `abundance_IBD`, `abundance_Obesity`, `abundance_T2D`, `abundance_WT2D`, `marker_Cirrhosis`, `marker_Colorectal`, `marker_IBD`, `marker_Obesity`, `marker_T2D`, `marker_WT2D`. Note that WT2D indicates European Women cohort (EW-T2D) and T2D indicates Chinese cohort (C-T2D).\n\n__3. Run experiments, specifying autoencoder details.__ \nSuppose we are going to run the best representation model on marker profile of EW-T2D dataset as shown in Table S1. Then, all three classification algorithms are trained and evaluated. We are going to repeat this process 5 times with the following command:\n```\n~$ python DM.py -d marker_WT2D --ae -dm 256\n```\nNote that if you don't specify `-r` argument, it will repeat five times by default. We can use all available CPU cores when we train classification models by introducing `-t -1` argument.\n\nHere are another examples using a single classification algorithm.\n```\n~$ python DM.py -d marker_T2D --cae -dm 4,2 -m mlp\n```\n```\n~$ python DM.py -d abundance_Obesity --cae -dm 4,2 -m rf\n```\n```\n~$ python DM.py -d marker_Colorectal --dae -dm 512,256,128 -m mlp\n```\n\nThe result will be saved under `/results` folder in a file whose name is ended with `_results.txt` (e.g. `marker_WT2D_result.txt`)\n"
      },
      "source": "https://raw.githubusercontent.com/minoh0201/DeepMicro/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/minoh0201/DeepMicro/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ""
      },
      "technique": "GitHub_API"
    }
  ],
  "license": [
    {
      "confidence": 1,
      "result": {
        "name": "MIT License",
        "spdx_id": "MIT",
        "type": "License",
        "url": "https://api.github.com/licenses/mit",
        "value": "https://api.github.com/licenses/mit"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "type": "File_dump",
        "value": "MIT License\n\nCopyright (c) 2019 minoh0201\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
      },
      "source": "https://raw.githubusercontent.com/minoh0201/DeepMicro/master/LICENSE",
      "technique": "file_exploration"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "DeepMicro"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "User",
        "value": "minoh0201"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 45390,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/minoh0201/DeepMicro/master/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "somef_missing_categories": [
    "acknowledgement",
    "run",
    "download",
    "requirements",
    "contact",
    "contributors",
    "documentation",
    "faq",
    "support",
    "identifier",
    "has_build_file",
    "executable_example"
  ],
  "somef_provenance": {
    "date": "2024-11-04 02:26:31",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 57
      },
      "technique": "GitHub_API"
    }
  ],
  "usage": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Quick Start Guide",
        "parent_header": [
          "DeepMicro"
        ],
        "type": "Text_excerpt",
        "value": "*Make sure you have already gone through the **Quick Setup Guide** above.*"
      },
      "source": "https://raw.githubusercontent.com/minoh0201/DeepMicro/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Learning representation with your own data",
        "parent_header": [
          "DeepMicro",
          "Quick Start Guide"
        ],
        "type": "Text_excerpt",
        "value": "__1. Copy your data under the `/data` directory.__ Your data should be a comma separated file without header and index, where each row represents a sample and each column represents a microbe. We are going to assume that your file name is `UserDataExample.csv` which is already provided.\n\n__2. Check your data can be successfully loaded and verify its shape with the following command.__\n```\n~$ python DM.py -r 1 --no_clf -cd UserDataExample.csv\n```\nThe output will show the number of rows and columns right next to `X_train.shape`. Our data `UserDataExample.csv` contains 80 rows and 200 columns.\n```\nUsing TensorFlow backend.\nNamespace(act='relu', ae=False, ae_lact=False, ae_oact=False, aeloss='mse', cae=False, custom_data='UserDataExample.csv', custom_data_labels=None, data=None, dataType='float64', data_dir='', dims='50', max_epochs=2000, method='all', no_clf=True, numFolds=5, numJobs=-2, patience=20, pca=False, repeat=1, rf_rate=0.1, rp=False, save_rep=False, scoring='roc_auc', seed=0, st_rate=0.25, svm_cache=1000, vae=False, vae_beta=1.0, vae_warmup=False, vae_warmup_rate=0.01)\nX_train.shape:  (80, 200)\nClassification task has been skipped.\n```\n    \n__3. Suppose that we want to reduce the number of dimensions of our data to 20 from 200 using a *shallow autoencoder*.__ Note that `--save_rep` argument will save your representation under the `/results` folder.\n```\n~$ python DM.py -r 1 --no_clf -cd UserDataExample.csv --ae -dm 20 --save_rep\n```\n    \n__4. Suppose that we want to use *deep autoencoder* with 2 hidden layers which has 100 units and 40 units, respectively.__ Let the size of latent layer to be 20. We are going to see the structure of deep autoencoder first.\n```\n~$ python DM.py -r 1 --no_clf -cd UserDataExample.csv --ae -dm 100,40,20 --no_trn\n```\nIt looks fine. Now, run the model and get the learned representation.\n```    \n~$ python DM.py -r 1 --no_clf -cd UserDataExample.csv --ae -dm 100,40,20 --save_rep\n```\n__5. We can try *variational autoencoder* and * convolutional autoencoder* as well.__ Note that you can see detailed argument description by using `-h` argument.\n```\n~$ python DM.py -r 1 --no_clf -cd UserDataExample.csv --vae -dm 100,20 --save_rep\n```\n```\n~$ python DM.py -r 1 --no_clf -cd UserDataExample.csv --cae -dm 100,50,1 --save_rep\n```\n"
      },
      "source": "https://raw.githubusercontent.com/minoh0201/DeepMicro/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Conducting binary classification after Learning representation with your own data",
        "parent_header": [
          "DeepMicro",
          "Quick Start Guide"
        ],
        "type": "Text_excerpt",
        "value": "__1. Copy your *data file* and *label file* under the `/data` directory.__ Your data file should be a comma separated value (CSV) format without header and index, where each row represents a sample and each column represents a microbe. __Your label file should contain a binary value (0 or 1) in each line and the number of lines should be equal to that in your data file.__ We are going to assume that your data file name is `UserDataExample.csv` and label file name is `UserLabelExample.csv` which are already provided.\n\n__2. Check your data can be successfully loaded and verify its shape with the following command.__\n```\n~$ python DM.py -r 1 --no_clf -cd UserDataExample.csv -cl UserLabelExample.csv\n```\nOur data `UserDataExample.csv` consists of 80 samples each of which has 200 features. The data will be split into the training set and the test set (in 8:2 ratio). The output will show the number of rows and columns for each data set.\n```\nNamespace(act='relu', ae=False, ae_lact=False, ae_oact=False, aeloss='mse', cae=False, custom_data='UserDataExample.csv', custom_data_labels='UserLabelExample.csv', data=None, dataType='float64', data_dir='', dims='50', max_epochs=2000, method='all', no_clf=True, no_trn=False, numFolds=5, numJobs=-2, patience=20, pca=False, repeat=1, rf_rate=0.1, rp=False, save_rep=False, scoring='roc_auc', seed=0, st_rate=0.25, svm_cache=1000, vae=False, vae_beta=1.0, vae_warmup=False, vae_warmup_rate=0.01)\nX_train.shape:  (64, 200)\ny_train.shape:  (64,)\nX_test.shape:  (16, 200)\ny_test.shape:  (16,)\nClassification task has been skipped.\n```\n\n__3. Suppose that we want to directly apply SVM algorithm on our data without representation learning.__  Remove `--no_clf` command and specify classification method with `-m svm` argument (If you don't specify classification algorithm, all three algorithms will be running). \n```\n~$ python DM.py -r 1 -cd UserDataExample.csv -cl UserLabelExample.csv -m svm\n```\nThe result will be saved under `/results` folder as a `UserDataExample_result.txt`. The resulting file will be growing as you conduct more experiments.\n\n__4. You can learn representation first, and then apply SVM algorithm on the learned representation.__\n```\n~$ python DM.py -r 1 -cd UserDataExample.csv -cl UserLabelExample.csv --ae -dm 20 -m svm\n```\n\n__5. You can repeat the same experiment by changing seeds for random partitioning of training and test set.__  Suppose we want to repeat classfication task five times. You can do it by put 5 into `-r` argument.\n```\n~$ python DM.py -r 5 -cd UserDataExample.csv -cl UserLabelExample.csv --ae -dm 20 -m svm\n```\n"
      },
      "source": "https://raw.githubusercontent.com/minoh0201/DeepMicro/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Reproducing the experiments described in our paper",
        "parent_header": [
          "DeepMicro",
          "Quick Start Guide"
        ],
        "type": "Text_excerpt",
        "value": "__1. Unzip `abundance.zip` and `marker.zip` files under the `/data` directory.__ \n```\n~$ cd data\n~$ unzip abundance.zip && unzip marker.zip\n~$ cd ..\n```\n__2. Specify dataset name to run.__ Choose dataset you want to run. You can choose one of the followings: `abundance_Cirrhosis`, `abundance_Colorectal`, `abundance_IBD`, `abundance_Obesity`, `abundance_T2D`, `abundance_WT2D`, `marker_Cirrhosis`, `marker_Colorectal`, `marker_IBD`, `marker_Obesity`, `marker_T2D`, `marker_WT2D`. Note that WT2D indicates European Women cohort (EW-T2D) and T2D indicates Chinese cohort (C-T2D).\n\n__3. Run experiments, specifying autoencoder details.__ \nSuppose we are going to run the best representation model on marker profile of EW-T2D dataset as shown in Table S1. Then, all three classification algorithms are trained and evaluated. We are going to repeat this process 5 times with the following command:\n```\n~$ python DM.py -d marker_WT2D --ae -dm 256\n```\nNote that if you don't specify `-r` argument, it will repeat five times by default. We can use all available CPU cores when we train classification models by introducing `-t -1` argument.\n\nHere are another examples using a single classification algorithm.\n```\n~$ python DM.py -d marker_T2D --cae -dm 4,2 -m mlp\n```\n```\n~$ python DM.py -d abundance_Obesity --cae -dm 4,2 -m rf\n```\n```\n~$ python DM.py -d marker_Colorectal --dae -dm 512,256,128 -m mlp\n```\n\nThe result will be saved under `/results` folder in a file whose name is ended with `_results.txt` (e.g. `marker_WT2D_result.txt`)\n"
      },
      "source": "https://raw.githubusercontent.com/minoh0201/DeepMicro/master/README.md",
      "technique": "header_analysis"
    }
  ]
}