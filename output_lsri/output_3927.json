{
  "acknowledgement": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Acknowledgment",
        "parent_header": [
          "CCNet: Criss-Cross Attention for Semantic Segmentation"
        ],
        "type": "Text_excerpt",
        "value": "We thank NSFC, ARC DECRA DE190101315, ARC DP200100938, HUST-Horizon Computer Vision ResearchCenter, and IBM-ILLINOIS Center for Cognitive ComputingSystems Research (C3SR).\n"
      },
      "source": "https://raw.githubusercontent.com/speedinghzl/CCNet/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "application_domain": [
    {
      "confidence": 65.72,
      "result": {
        "type": "String",
        "value": "Computer Vision"
      },
      "technique": "supervised_classification"
    }
  ],
  "citation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Citing CCNet",
        "parent_header": [
          "CCNet: Criss-Cross Attention for Semantic Segmentation",
          "Visualization of the attention map"
        ],
        "type": "Text_excerpt",
        "value": "If you find CCNet useful in your research, please consider citing:\n```BibTex\n@article{huang2020ccnet,\n  author={Huang, Zilong and Wang, Xinggang and Wei, Yunchao and Huang, Lichao and Shi, Humphrey and Liu, Wenyu and Huang, Thomas S.},\n  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, \n  title={CCNet: Criss-Cross Attention for Semantic Segmentation}, \n  year={2020},\n  month={},\n  volume={},\n  number={},\n  pages={1-1},\n  keywords={Semantic Segmentation;Graph Attention;Criss-Cross Network;Context Modeling},\n  doi={10.1109/TPAMI.2020.3007032},\n  ISSN={1939-3539}}\n\n@article{huang2018ccnet,\n    title={CCNet: Criss-Cross Attention for Semantic Segmentation},\n    author={Huang, Zilong and Wang, Xinggang and Huang, Lichao and Huang, Chang and Wei, Yunchao and Liu, Wenyu},\n    booktitle={ICCV},\n    year={2019}}\n```    \n"
      },
      "source": "https://raw.githubusercontent.com/speedinghzl/CCNet/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "author": "Huang, Zilong and Wang, Xinggang and Wei, Yunchao and Huang, Lichao and Shi, Humphrey and Liu, Wenyu and Huang, Thomas S.",
        "doi": "10.1109/TPAMI.2020.3007032",
        "format": "bibtex",
        "title": "CCNet: Criss-Cross Attention for Semantic Segmentation",
        "type": "Text_excerpt",
        "value": "@article{huang2020ccnet,\n    issn = {1939-3539},\n    doi = {10.1109/TPAMI.2020.3007032},\n    keywords = {Semantic Segmentation;Graph Attention;Criss-Cross Network;Context Modeling},\n    pages = {1-1},\n    number = {},\n    volume = {},\n    month = {},\n    year = {2020},\n    title = {CCNet: Criss-Cross Attention for Semantic Segmentation},\n    journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},\n    author = {Huang, Zilong and Wang, Xinggang and Wei, Yunchao and Huang, Lichao and Shi, Humphrey and Liu, Wenyu and Huang, Thomas S.},\n}"
      },
      "source": "https://raw.githubusercontent.com/speedinghzl/CCNet/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "author": "Huang, Zilong and Wang, Xinggang and Huang, Lichao and Huang, Chang and Wei, Yunchao and Liu, Wenyu",
        "format": "bibtex",
        "title": "CCNet: Criss-Cross Attention for Semantic Segmentation",
        "type": "Text_excerpt",
        "value": "@article{huang2018ccnet,\n    year = {2019},\n    booktitle = {ICCV},\n    author = {Huang, Zilong and Wang, Xinggang and Huang, Lichao and Huang, Chang and Wei, Yunchao and Liu, Wenyu},\n    title = {CCNet: Criss-Cross Attention for Semantic Segmentation},\n}"
      },
      "source": "https://raw.githubusercontent.com/speedinghzl/CCNet/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/speedinghzl/CCNet"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2018-11-26T19:39:02Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2024-10-06T12:41:00Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "CCNet: Criss-Cross Attention for Semantic Segmentation (TPAMI 2020 & ICCV 2019)."
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Introduction",
        "parent_header": [
          "CCNet: Criss-Cross Attention for Semantic Segmentation"
        ],
        "type": "Text_excerpt",
        "value": "![motivation of CCNet](https://user-images.githubusercontent.com/4509744/50546460-7df6ed00-0bed-11e9-9340-d026373b2cbe.png)\nLong-range dependencies can capture useful contextual information to benefit visual understanding problems. In this work, we propose a Criss-Cross Network (CCNet) for obtaining such important information through a more effective and efficient way. Concretely, for each pixel, our CCNet can harvest the contextual information of its surrounding pixels on the criss-cross path through a novel criss-cross attention module. By taking a further recurrent operation, each pixel can finally capture the long-range dependencies from all pixels. Overall, our CCNet is with the following merits: \n- **GPU memory friendly**  \n- **High computational efficiency** \n- **The state-of-the-art performance** \n"
      },
      "source": "https://raw.githubusercontent.com/speedinghzl/CCNet/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 0.86919962727516,
      "result": {
        "original_header": "CCNet: Criss-Cross Attention for Semantic Segmentation",
        "type": "Text_excerpt",
        "value": "By [Zilong Huang](http://speedinghzl.github.io), [Xinggang Wang](http://www.xinggangw.info/index.htm), [Yunchao Wei](https://weiyc.github.io/), [Lichao Huang](https://scholar.google.com/citations?user=F2e_jZMAAAAJ&hl=en), [Chang Huang](https://scholar.google.com/citations?user=IyyEKyIAAAAJ&hl=zh-CN), [Humphrey Shi](https://www.humphreyshi.com/), [Wenyu Liu](http://mclab.eic.hust.edu.cn/MCWebDisplay/PersonDetails.aspx?Name=Wenyu%20Liu) and [Thomas S. Huang](http://ifp-uiuc.github.io/).\n \n"
      },
      "source": "https://raw.githubusercontent.com/speedinghzl/CCNet/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9486872996092841,
      "result": {
        "original_header": "Updates",
        "type": "Text_excerpt",
        "value": "****2021/02: The pure python implementation of CCNet is released in the branch [pure-python](https://github.com/speedinghzl/CCNet/tree/pure-python). Thanks [Serge-weihao](https://github.com/Serge-weihao).**** \n2019/08: The new version CCNet is released on branch [Pytorch-1.1](https://github.com/speedinghzl/CCNet/tree/pytorch-1.1) which supports Pytorch 1.0 or later and distributed multiprocessing training and testing\nThis current code is a implementation of the experiments on Cityscapes in the [CCNet ICCV version](http://openaccess.thecvf.com/content_ICCV_2019/papers/Huang_CCNet_Criss-Cross_Attention_for_Semantic_Segmentation_ICCV_2019_paper.pdf). \nWe implement our method based on open source [pytorch segmentation toolbox](https://github.com/speedinghzl/pytorch-segmentation-toolbox).  \n2018/12: Renew the code and release trained models with R=1,2. The trained model with R=2 achieves 79.74% on val set and 79.01% on test set with single scale testing. \n"
      },
      "source": "https://raw.githubusercontent.com/speedinghzl/CCNet/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9746228451946618,
      "result": {
        "original_header": "Architecture",
        "type": "Text_excerpt",
        "value": "![Overview of CCNet](https://user-images.githubusercontent.com/4509744/50546462-851dfb00-0bed-11e9-962a-bffab2401997.png)\nOverview of the proposed CCNet for semantic segmentation. The proposed recurrent criss-cross attention takes as input feature maps **H** and output feature maps **H''** which obtain rich and dense contextual information from all pixels. Recurrent criss-cross attention module can be unrolled into R=2 loops, in which all Criss-Cross Attention modules share parameters.\n \n"
      },
      "source": "https://raw.githubusercontent.com/speedinghzl/CCNet/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.995481456149463,
      "result": {
        "original_header": "Visualization of the attention map",
        "type": "Text_excerpt",
        "value": "![Overview of Attention map](https://user-images.githubusercontent.com/4509744/50546463-88b18200-0bed-11e9-9f87-c74327c11a68.png)\nTo get a deeper understanding of our RCCA, we visualize the learned attention masks as shown in the figure.  For each input image, we select one point (green cross) and show its corresponding attention maps when **R=1** and **R=2** in columns 2 and 3 respectively. In the figure, only contextual information from the criss-cross path of the target point is capture when **R=1**. By adopting one more criss-cross module, ie, **R=2**  the RCCA can finally aggregate denser and richer contextual information compared with that of **R=1**. Besides, we observe that the attention module could capture semantic similarity and long-range dependencies. \n \n"
      },
      "source": "https://raw.githubusercontent.com/speedinghzl/CCNet/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9076156077947493,
      "result": {
        "original_header": "Models",
        "type": "Text_excerpt",
        "value": "We run CCNet with *R=1,2* three times on cityscape dataset separately and report the results in the following table.\nPlease note there exist some problems about the validation/testing set accuracy gap (1~2%). You need to run multiple times\nto achieve a small gap or turn on OHEM flag. Turning on OHEM flag also can improve the performance on the val set. In general\uff0c\nI recommend you use OHEM in training step. \nWe train all the models on fine training set and use the single scale for testing.\nThe trained model with **R=2 79.74**  can also achieve about **79.01** mIOU on **cityscape test set** with single scale testing (for saving time, we use the whole image as input). \n"
      },
      "source": "https://raw.githubusercontent.com/speedinghzl/CCNet/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/speedinghzl/CCNet/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 277
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/speedinghzl/CCNet/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "speedinghzl/CCNet"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "CCNet: Criss-Cross Attention for Semantic Segmentation"
      },
      "source": "https://raw.githubusercontent.com/speedinghzl/CCNet/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "has_script_file": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/speedinghzl/CCNet/master/run_local.sh"
      },
      "technique": "file_exploration"
    }
  ],
  "images": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://user-images.githubusercontent.com/4509744/50546460-7df6ed00-0bed-11e9-9340-d026373b2cbe.png"
      },
      "source": "https://raw.githubusercontent.com/speedinghzl/CCNet/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://user-images.githubusercontent.com/4509744/50546462-851dfb00-0bed-11e9-962a-bffab2401997.png"
      },
      "source": "https://raw.githubusercontent.com/speedinghzl/CCNet/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://user-images.githubusercontent.com/4509744/50546463-88b18200-0bed-11e9-9f87-c74327c11a68.png"
      },
      "source": "https://raw.githubusercontent.com/speedinghzl/CCNet/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "installation": [
    {
      "confidence": 1.0,
      "result": {
        "original_header": "Compiling",
        "type": "Text_excerpt",
        "value": "```bash\n# Install **Pytorch**\n$ conda install pytorch torchvision -c pytorch\n\n# Install **Apex**\n$ git clone https://github.com/NVIDIA/apex\n$ cd apex\n$ pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./\n\n# Install **Inplace-ABN**\n$ git clone https://github.com/mapillary/inplace_abn.git\n$ cd inplace_abn\n$ python setup.py install\n```\n \n"
      },
      "source": "https://raw.githubusercontent.com/speedinghzl/CCNet/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9473408758790325,
      "result": {
        "original_header": "Training and Evaluation",
        "type": "Text_excerpt",
        "value": "Evaluation script.\n```bash\npython evaluate.py --data-dir ${YOUR_CS_PATH} --restore-from snapshots/CS_scenes_60000.pth --gpu 0 --recurrence 2\n```  \nAll in one.\n```bash\n./run_local.sh YOUR_CS_PATH\n``` \n \n"
      },
      "source": "https://raw.githubusercontent.com/speedinghzl/CCNet/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "invocation": [
    {
      "confidence": 0.8156422056934404,
      "result": {
        "original_header": "Dataset and pretrained model",
        "type": "Text_excerpt",
        "value": "Plesae download cityscapes dataset and unzip the dataset into `YOUR_CS_PATH`. \nPlease download MIT imagenet pretrained [resnet101-imagenet.pth](http://sceneparsing.csail.mit.edu/model/pretrained_resnet/resnet101-imagenet.pth), and put it into `dataset` folder.\n \n"
      },
      "source": "https://raw.githubusercontent.com/speedinghzl/CCNet/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9532571986719826,
      "result": {
        "original_header": "Training and Evaluation",
        "type": "Text_excerpt",
        "value": "Training script.\n```bash\npython train.py --data-dir ${YOUR_CS_PATH} --random-mirror --random-scale --restore-from ./dataset/resnet101-imagenet.pth --gpu 0,1,2,3 --learning-rate 1e-2 --input-size 769,769 --weight-decay 1e-4 --batch-size 8 --num-steps 60000 --recurrence 2\n```  \nEvaluation script.\n```bash\npython evaluate.py --data-dir ${YOUR_CS_PATH} --restore-from snapshots/CS_scenes_60000.pth --gpu 0 --recurrence 2\n```  \n"
      },
      "source": "https://raw.githubusercontent.com/speedinghzl/CCNet/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/speedinghzl/CCNet/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "cityscape, pytorch, scene-parsing, segmentation, self-attention, semantic-segmentation"
      },
      "technique": "GitHub_API"
    }
  ],
  "license": [
    {
      "confidence": 1,
      "result": {
        "name": "MIT License",
        "spdx_id": "MIT",
        "type": "License",
        "url": "https://api.github.com/licenses/mit",
        "value": "https://api.github.com/licenses/mit"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "type": "File_dump",
        "value": "MIT License\n\nCopyright (c) 2018 Zilong Huang\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
      },
      "source": "https://raw.githubusercontent.com/speedinghzl/CCNet/master/LICENSE",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "License",
        "parent_header": [
          "CCNet: Criss-Cross Attention for Semantic Segmentation",
          "Visualization of the attention map"
        ],
        "type": "Text_excerpt",
        "value": "CCNet is released under the MIT License (refer to the LICENSE file for details).\n"
      },
      "source": "https://raw.githubusercontent.com/speedinghzl/CCNet/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "CCNet"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "User",
        "value": "speedinghzl"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 118148,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Shell",
        "size": 1092,
        "type": "Programming_language",
        "value": "Shell"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/speedinghzl/CCNet/master/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "related_papers": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://arxiv.org/abs/1811.11721"
      },
      "source": "https://raw.githubusercontent.com/speedinghzl/CCNet/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "requirements": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Requirements",
        "parent_header": [
          "CCNet: Criss-Cross Attention for Semantic Segmentation",
          "Instructions for Code (2019/08 version):"
        ],
        "type": "Text_excerpt",
        "value": "To install PyTorch==0.4.0 or 0.4.1, please refer to https://github.com/pytorch/pytorch#installation.   \n4 x 12G GPUs (_e.g._ TITAN XP)  \nPython 3.6   \ngcc (GCC) 4.8.5  \nCUDA 8.0  \n"
      },
      "source": "https://raw.githubusercontent.com/speedinghzl/CCNet/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "somef_missing_categories": [
    "run",
    "download",
    "contact",
    "contributors",
    "documentation",
    "usage",
    "faq",
    "support",
    "identifier",
    "has_build_file",
    "executable_example"
  ],
  "somef_provenance": {
    "date": "2024-10-06 14:37:11",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 1420
      },
      "technique": "GitHub_API"
    }
  ]
}