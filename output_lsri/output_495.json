{
  "application_domain": [
    {
      "confidence": 33.95,
      "result": {
        "type": "String",
        "value": "Computer Vision"
      },
      "technique": "supervised_classification"
    }
  ],
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/pixixiaonaogou/MLSDR"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2021-08-03T09:43:49Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2024-04-09T09:42:43Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Introduction",
        "type": "Text_excerpt",
        "value": "Raw code of FusionM4Net: A multi-stage multi-modal learning algorithm for multi-label skin lesion classification.\n"
      },
      "source": "https://raw.githubusercontent.com/pixixiaonaogou/MLSDR/main/README.md",
      "technique": "header_analysis"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/pixixiaonaogou/MLSDR/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "executable_example": [
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/pixixiaonaogou/MLSDR/main/second_stage_fusion.ipynb"
      },
      "source": "https://raw.githubusercontent.com/pixixiaonaogou/MLSDR/main/second_stage_fusion.ipynb",
      "technique": "file_exploration"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 4
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/pixixiaonaogou/MLSDR/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "pixixiaonaogou/MLSDR"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "Introduction"
      },
      "source": "https://raw.githubusercontent.com/pixixiaonaogou/MLSDR/main/README.md",
      "technique": "regular_expression"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/pixixiaonaogou/MLSDR/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ""
      },
      "technique": "GitHub_API"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "MLSDR"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "User",
        "value": "pixixiaonaogou"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Jupyter Notebook",
        "size": 278923,
        "type": "Programming_language",
        "value": "Jupyter Notebook"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 93095,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/pixixiaonaogou/MLSDR/main/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "requirements": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Dependencies",
        "type": "Text_excerpt",
        "value": "1. pytorch==1.8.0.\n2. sklearn ==0.24.1.\n3. opencv == 4.5.1.\n4. numpy == 1.19.2.\n5. keras == 2.4.3.\n6. pandas == 1.2.4.\n7. tqdm == 4.60.0.\n\n"
      },
      "source": "https://raw.githubusercontent.com/pixixiaonaogou/MLSDR/main/README.md",
      "technique": "header_analysis"
    }
  ],
  "somef_missing_categories": [
    "installation",
    "citation",
    "acknowledgement",
    "run",
    "download",
    "contact",
    "contributors",
    "documentation",
    "license",
    "faq",
    "support",
    "identifier",
    "has_build_file"
  ],
  "somef_provenance": {
    "date": "2024-10-06 01:08:36",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 21
      },
      "technique": "GitHub_API"
    }
  ],
  "usage": [
    {
      "confidence": 1,
      "result": {
        "original_header": "How to use it",
        "type": "Text_excerpt",
        "value": "1. Firstly, please download the Seven-Point Checklist dataset on http://derm.cs.sfu.ca.\n2. Secondly, Please change the image path in dependency.py\n3. Then, set data_mode = 'Normal' and data_mode = 'self_evaluated' to run FusionNet in main_cmv2.py\nto get the corresponding weights respectively. \n4. Finally, run second_stage_fusion.ipynb sequently to get P1, P2, P3 respectively.\nthe Fusion scheme 1 is also in this ipynb file for convience.\nNote that you need to change the image path \"source_dir\" according the dataset in your experiments.\n\nSet data_mode = 'Normal' to run FusionNet is trained on the defaulted training and validation dataset to get \nthe P_clin, P_derm and P_fusion, which are fused by Fusion Scheme 1 to obtain P_1 (the result of stage 1 of FusionM4Net) in the second_stage_fusion.ipynb.\n\nSet data_mode = 'self_evaluated' to run FusionNet is trained on our divided sub-training and sub-testing\nto get the prediction information to train the SVM cluster in second stage.\n\nMore details, please see our paper \"FusionM4Net: A multi-stage multi-modal learning algorithm for multi-label skin lesion classification\" (DOI: https://doi.org/10.1016/j.media.2021.102307). \n\n\n\n\n\n"
      },
      "source": "https://raw.githubusercontent.com/pixixiaonaogou/MLSDR/main/README.md",
      "technique": "header_analysis"
    }
  ]
}