{
  "application_domain": [
    {
      "confidence": 21.21,
      "result": {
        "type": "String",
        "value": "Computer Vision"
      },
      "technique": "supervised_classification"
    }
  ],
  "citation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "5. Citation",
        "parent_header": [
          "MedicDeepLabv3+"
        ],
        "type": "Text_excerpt",
        "value": "@article{valverde2022automatic,\n  title={Automatic Cerebral Hemisphere Segmentation in Rat MRI with Ischemic Lesions via Attention-based Convolutional Neural Networks},\n  author={Valverde, Juan Miguel and Shatillo, Artem and De Feo, Riccardo and Tohka, Jussi},\n  journal={Neuroinformatics},\n  pages={1--14},\n  year={2022},\n  publisher={Springer}\n}\n```\n"
      },
      "source": "https://raw.githubusercontent.com/jmlipman/MedicDeepLabv3Plus/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "author": "Valverde, Juan Miguel and Shatillo, Artem and De Feo, Riccardo and Tohka, Jussi",
        "format": "bibtex",
        "title": "Automatic Cerebral Hemisphere Segmentation in Rat MRI with Ischemic Lesions via Attention-based Convolutional Neural Networks",
        "type": "Text_excerpt",
        "value": "@article{valverde2022automatic,\n    publisher = {Springer},\n    year = {2022},\n    pages = {1--14},\n    journal = {Neuroinformatics},\n    author = {Valverde, Juan Miguel and Shatillo, Artem and De Feo, Riccardo and Tohka, Jussi},\n    title = {Automatic Cerebral Hemisphere Segmentation in Rat MRI with Ischemic Lesions via Attention-based Convolutional Neural Networks},\n}"
      },
      "source": "https://raw.githubusercontent.com/jmlipman/MedicDeepLabv3Plus/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/jmlipman/MedicDeepLabv3Plus"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2020-08-19T10:02:56Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2024-08-30T14:09:13Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "Official repository of MedicDeepLabv3+"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "1. Introduction",
        "parent_header": [
          "MedicDeepLabv3+"
        ],
        "type": "Text_excerpt",
        "value": "This implementation of MedicDeepLabv3+ allows combining several models trained separately. This script will generate a prediction per model and, if multiple trained models are provided, it will produce a segmentations combined with majority voting across each model prediction. Post-processing, i.e. removing small independently connected components (holes and islands) is also available and is activated by default.\n"
      },
      "source": "https://raw.githubusercontent.com/jmlipman/MedicDeepLabv3Plus/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "1.1 Files",
        "parent_header": [
          "MedicDeepLabv3+",
          "1. Introduction"
        ],
        "type": "Text_excerpt",
        "value": "```cshell\n.\n \u251c\u2500\u2500 eval.py # Generates segmentation masks. It requires a file with the trained parameters of MedicDeepLabv3+ (provided by train.py)\n \u251c\u2500\u2500 train.py # Optimizes MedicDeepLabv3+ and saves its optimized parameters (required by eval.py)\n \u2514\u2500\u2500 lib\n     \u251c\u2500\u2500 losses.py # Cross Entropy + Dice Loss functions\n     \u251c\u2500\u2500 metric.py # Metrics to quantify segmentations quality i.e. Dice coeff., Hausdorff distance, Compactness\n     \u251c\u2500\u2500 utils.py # Other functions.\n     \u251c\u2500\u2500 blocks\n     \u2502   \u251c\u2500\u2500 BasicBlocks.py # Contains basic operations of the ConvNet\n     \u2502   \u2514\u2500\u2500 MedicDeepLabv3PlusBlocks.py # Blocks of operations for MedicDeepLabv3+\n     \u251c\u2500\u2500 data\n     \u2502   \u251c\u2500\u2500 BaseDataset.py # Basic dataset operations\n     \u2502   \u2514\u2500\u2500 DataWrapper.py # Reads and parses the NIfTI files\n     \u2514\u2500\u2500 models\n        \u251c\u2500\u2500 BaseModel.py # Contains main training and evaluation procedures\n        \u2514\u2500\u2500 MedicDeepLabv3Plus.py # Pytorch definition of our model\n```\n"
      },
      "source": "https://raw.githubusercontent.com/jmlipman/MedicDeepLabv3Plus/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 0.9779699829376115,
      "result": {
        "original_header": "MedicDeepLabv3+",
        "type": "Text_excerpt",
        "value": "Repository of the paper \"Automatic Cerebral Hemisphere Segmentation in Rat MRI with Ischemic Lesions via Attention-based Convolutional Neural Networks\" \n"
      },
      "source": "https://raw.githubusercontent.com/jmlipman/MedicDeepLabv3Plus/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9345027390460046,
      "result": {
        "original_header": "3.1 Training",
        "type": "Text_excerpt",
        "value": "The code can be easily modified to adjust any optimization hyper-parameter. In addition, you can set some of these hyper-parameters directly in the terminal: --filters (initial number of filters), --epochs, --batch_size, --lr (learning rate) and --wd (weight decay). By default, Adam optimizer is used. \nDuring training, a hold-out validation set can be used to monitor the optimization. Use --validation to give the directory of this dataset, set --val_interval to adjust how often the validation will be performed (by default is done after each epoch), and choose which validation metrics you want to assess with --val_metrics (Hausdorff distance, Dice coefficient and compactness are available). \nFinally, you can load a model with tuned parameters and continue optimizing it with --model_state FILE. \nExamples:\n```cshell\n# Minimum training setup\npython train.py --input DIR --output DIR\n# Example\npython train.py --input ~/data/in/MRI_Training_Data/ --output ~/data/out/Trained_Models\n# Same example with the default training hyper-parameters\npython train.py --input ~/data/in/MRI_Training_Data/ --output ~/data/out/Trained_Models --epochs 300 --batch_size 1 --lr 1e-4 --wd 0\n\n# Adding a validation dataset, and validating the optimization after every 2 epochs with Dice coefficient, Hausdorff distance and compactness.\npython train.py --input ~/data/in/MRI_Training_Data/ --output ~/data/out/Trained_Models --validation ~/data/in/MRI_Validation_Data/ --val_interval 3 --val_metrics dice,HD,compactness\n\n# Training MedicDeepLabv3+ on GPU 2 for 50 epochs after loading a previously trained model\npython train.py --input ~/data/in/MRI_Training_Data/ --output ~/data/out/Trained_Models --validation ~/data/in/MRI_Validation_Data/ --model_state ~/data/out/Trained_Models/model-200 --gpu 2\n\n```\n \n* --input (Required): Path containing all the subfolders of the data used for training/optimizing the network. Check [2.3. Image format](#23-image-format) to see the expected path structure.\n* --output (Required): Path or name of the folder where the output files will be saved (trainin_loss, validation_loss, MedicDeepLabv3Plus-model).\n* --filters: Number of filters. By default is 32, and decreasing this number lowers the required GPU memory. Important: if you use this, don't forget to use it in eval.py as well.\n* --epochs: Number of epochs to train MedicDeepLabv3+.\n* --batch_size: Number of images per batch.\n* --lr: Learning rate used by Adam (by default) during optimization.\n* --wd: Weight decay used by Adam (by default) during optimization.\n* --validation: Path containing all the subfolders of the data used for calculating the validation error. Check [2.3. Image format](#23-image-format) to see the expected path structure. If not given, no validation will be performed during the training.\n* --val_interval: Number of epochs after which MedicDeepLabv3+ will be assessed in the validation data. For instance, if --val_interval 2, validation will be performed every 2 epochs.\n* --val_metrics: Metrics to assess MedicDeepLabv3+ during validation. Metrics available: Dice coefficient (dice), Hausdorff distance (HD), compactness. Separated them with commas, and write them in any order, e.g., --val_metrics compactness,HD,dice\n* --model_state: File containing a previously trained MedicDeepLabv3+ to resume its training.\n* --gpu: This will choose the GPU. Leaving this by default will make MedicDeepLabv3+ use the default GPU (if any). It is **highly recommended** to use a GPU to train MedicDeepLabv3+. \nFiles generated by train.py:\n* log: Contains the training (and validation) error obtained during the training.\n* MedicDeepLabv3Plus-model-N: parameters of MedicDeepLabv3+ after the optimization. **This file is necessary to generate the predictions by the eval.py script**.\n \n"
      },
      "source": "https://raw.githubusercontent.com/jmlipman/MedicDeepLabv3Plus/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8966993435510939,
      "result": {
        "original_header": "3.2 Evaluation",
        "type": "Text_excerpt",
        "value": "By default, after producing the segmentations, a post-processing procedure removes small islands (connected components) from each class. It is possible to deactivate it with --remove_islands False. \nOptionally, if the ground truth is provided in the same folder as the data (as described in [2.3. Image format](#23-image-format)), it is possible to measure the performance of MedicDeepLabv3+, which by default uses Dice coefficient and you can add other metrics with --metrics. \nNote: we provide three trained MedicDeepLabv3+ models at DOI:10.5281/zenodo.4009246\n```cshell\n# Minimum training setup\npython eval.py --input DIR --output DIR --model FILE(S)\n# Example (evaluating with 1 model)\npython eval.py --input ~/data/in/MRI_Testing_Data --output ~/data/out/Segmentation_Results --model trained_models/MedicDeepLabv3Plus-model-300_1\n# Example (evaluating with multiple models)\npython eval.py --input ~/data/in/MRI_Testing_Data --output ~/data/out/Segmentation_Results --model trained_models/MedicDeepLabv3Plus-model-300_*\n# Same example with the default training hyper-parameters\npython eval.py --input ~/data/in/MRI_Testing_Data --output ~/data/out/Segmentation_Results --model trained_models/MedicDeepLabv3Plus-model-300_1 --metrics dice --remove_islands True --gpu 0\n```\n \n* --input: Path containing all the subfolders of the scans that MedicDeepLabv3+ will segment. Check [2.3. Image format](#23-image-format) to see the expected path structure.\n* --output: Path or name of the folder where the output files will be saved.\n* --model: Location of the parameters of MedicDeepLabv3+ after the model was optimized. It is the file generated by train.py called MedicDeepLabv3Plus-model-N.\n* --filters: Number of filters. By default is 32, and decreasing this number lowers the required GPU memory.\n* --metrics: Similary to train.py, it is possible to choose which metrics to evaluate if the ground truth is provided.\n* --remove_islands: By default, masks are post-processed and small connected components are removed. To disable, write --remove_islands False\n* --gpu: This will choose the GPU. Leaving this by default will make MedicDeepLabv3+ use the default GPU (if any). For executing eval.py in the CPU write --gpu -1 \nFiles generated by eval.py:\n* Two segmentation file per scan found in the --input: Name_brainmask.nii.gz and Name_contra.nii.gz\n* If the folders where the scans are located also contain the ground truth (following the same structure in [2.3. Image format](#23-image-format) ) a file called stats.csv with the Dice coefficient, Hausdorff distance and Number of Islands will be generated. The classes measured are (in this order): non-brain tissue (background), brain, and contralateral hemisphere. \n"
      },
      "source": "https://raw.githubusercontent.com/jmlipman/MedicDeepLabv3Plus/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/jmlipman/MedicDeepLabv3Plus/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 1
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/jmlipman/MedicDeepLabv3Plus/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "jmlipman/MedicDeepLabv3Plus"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "MedicDeepLabv3+"
      },
      "source": "https://raw.githubusercontent.com/jmlipman/MedicDeepLabv3Plus/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "identifier": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://doi.org/10.5281/zenodo.4943765"
      },
      "source": "https://raw.githubusercontent.com/jmlipman/MedicDeepLabv3Plus/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://doi.org/10.5281/zenodo.4943897"
      },
      "source": "https://raw.githubusercontent.com/jmlipman/MedicDeepLabv3Plus/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "images": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/jmlipman/MedicDeepLabv3Plus/master/medicdeeplabv3plus.png"
      },
      "source": "https://raw.githubusercontent.com/jmlipman/MedicDeepLabv3Plus/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "installation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "2.2 Installation",
        "parent_header": [
          "MedicDeepLabv3+",
          "2. Installation and Requirements"
        ],
        "type": "Text_excerpt",
        "value": "0. Install all libraries from 2.1 Requirements\n\n1. Install dependencies with pip\n```cshell\npip install scipy scikit-image nibabel\n```\n\n2. Download source code\n```cshell\ngit clone git@github.com:jmlipman/MedicDeepLabv3Plus.git\n```\n"
      },
      "source": "https://raw.githubusercontent.com/jmlipman/MedicDeepLabv3Plus/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "2.3 Image format",
        "parent_header": [
          "MedicDeepLabv3+",
          "2. Installation and Requirements"
        ],
        "type": "Text_excerpt",
        "value": " * Images and their corresponding labels must be in the same folder (check below the expected path structure)\n * Images must have the following 4 dimensions: Height x Width x Depth x Modality (our images were 256x256x18x1). \n * Segmentation masks will have values of 0 (background voxels) and 1 (brain mask or contralateral hemisphere voxels) in 3 dimensions: Height x Width x Depth.\n\nExample of path containing training data:\n```cshell\nPATH\n \u2514\u2500Study 1\n   \u2514\u250024h (time-point)\n     \u251c\u250032 (id of the scan)\n     \u2502 \u251c\u2500scan.nii.gz (image)\n     \u2502 \u251c\u2500scan_brainmask.nii.gz (label)\n     \u2502 \u2514\u2500scan_contra.nii.gz (label)\n     \u2514\u250035\n       \u251c\u2500scan.nii.gz\n       \u251c\u2500scan_brainmask.nii.gz (label)\n       \u2514\u2500scan_contra.nii.gz (label)\n       ...\n```\n"
      },
      "source": "https://raw.githubusercontent.com/jmlipman/MedicDeepLabv3Plus/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "2.4 Setup",
        "parent_header": [
          "MedicDeepLabv3+",
          "2. Installation and Requirements"
        ],
        "type": "Text_excerpt",
        "value": " * The name of the scans and the ground truth are expected to be **the same** across each scan folder. In the path example described in [2.3. Image format](#23-image-format) the names are \"scan.nii.gz\", \"scan_brainmask\" and \"scan_contra.nii.gz\". You can change these names in lib/data/DataWrapper.py `self.scanName`, `self.brainmaskName` and `self.contraName`.\n"
      },
      "source": "https://raw.githubusercontent.com/jmlipman/MedicDeepLabv3Plus/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 0.9999998588070398,
      "result": {
        "original_header": "3.1 Training",
        "type": "Text_excerpt",
        "value": "In case you have multiple GPUs, you can choose in which --gpu to train, or write -1 if you don't have access to GPU (this will probably take extremely long time). If you don't know which GPUs you have, you can write a wrong GPU id and the script will tell you which GPUs are available (e.g., --gpu 99999). \n"
      },
      "source": "https://raw.githubusercontent.com/jmlipman/MedicDeepLabv3Plus/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9996056612921332,
      "result": {
        "original_header": "3.2 Evaluation",
        "type": "Text_excerpt",
        "value": "Finally, you can choose in which GPU to execute eval.py, as in train.py. Since eval.py does not take too long to execute, unlike train.py, evaluating MedicDeepLabv3+ on the CPU with --gpu -1 is a viable option. \n"
      },
      "source": "https://raw.githubusercontent.com/jmlipman/MedicDeepLabv3Plus/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "invocation": [
    {
      "confidence": 0.8846051470216572,
      "result": {
        "original_header": "3.1 Training",
        "type": "Text_excerpt",
        "value": "Examples:\n```cshell\n# Minimum training setup\npython train.py --input DIR --output DIR\n# Example\npython train.py --input ~/data/in/MRI_Training_Data/ --output ~/data/out/Trained_Models\n# Same example with the default training hyper-parameters\npython train.py --input ~/data/in/MRI_Training_Data/ --output ~/data/out/Trained_Models --epochs 300 --batch_size 1 --lr 1e-4 --wd 0\n\n# Adding a validation dataset, and validating the optimization after every 2 epochs with Dice coefficient, Hausdorff distance and compactness.\npython train.py --input ~/data/in/MRI_Training_Data/ --output ~/data/out/Trained_Models --validation ~/data/in/MRI_Validation_Data/ --val_interval 3 --val_metrics dice,HD,compactness\n\n# Training MedicDeepLabv3+ on GPU 2 for 50 epochs after loading a previously trained model\npython train.py --input ~/data/in/MRI_Training_Data/ --output ~/data/out/Trained_Models --validation ~/data/in/MRI_Validation_Data/ --model_state ~/data/out/Trained_Models/model-200 --gpu 2\n\n```\n \nFiles generated by train.py:\n* log: Contains the training (and validation) error obtained during the training.\n* MedicDeepLabv3Plus-model-N: parameters of MedicDeepLabv3+ after the optimization. **This file is necessary to generate the predictions by the eval.py script**.\n \n"
      },
      "source": "https://raw.githubusercontent.com/jmlipman/MedicDeepLabv3Plus/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8870571475562721,
      "result": {
        "original_header": "3.2 Evaluation",
        "type": "Text_excerpt",
        "value": "Finally, you can choose in which GPU to execute eval.py, as in train.py. Since eval.py does not take too long to execute, unlike train.py, evaluating MedicDeepLabv3+ on the CPU with --gpu -1 is a viable option. \nNote: we provide three trained MedicDeepLabv3+ models at DOI:10.5281/zenodo.4009246\n```cshell\n# Minimum training setup\npython eval.py --input DIR --output DIR --model FILE(S)\n# Example (evaluating with 1 model)\npython eval.py --input ~/data/in/MRI_Testing_Data --output ~/data/out/Segmentation_Results --model trained_models/MedicDeepLabv3Plus-model-300_1\n# Example (evaluating with multiple models)\npython eval.py --input ~/data/in/MRI_Testing_Data --output ~/data/out/Segmentation_Results --model trained_models/MedicDeepLabv3Plus-model-300_*\n# Same example with the default training hyper-parameters\npython eval.py --input ~/data/in/MRI_Testing_Data --output ~/data/out/Segmentation_Results --model trained_models/MedicDeepLabv3Plus-model-300_1 --metrics dice --remove_islands True --gpu 0\n```\n \n"
      },
      "source": "https://raw.githubusercontent.com/jmlipman/MedicDeepLabv3Plus/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/jmlipman/MedicDeepLabv3Plus/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ""
      },
      "technique": "GitHub_API"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "MedicDeepLabv3Plus"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "User",
        "value": "jmlipman"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 66154,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/jmlipman/MedicDeepLabv3Plus/master/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "releases": [
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "jmlipman",
          "type": "User"
        },
        "date_created": "2021-04-15T12:50:07Z",
        "date_published": "2021-06-14T09:21:32Z",
        "description": "Architecture update",
        "html_url": "https://github.com/jmlipman/MedicDeepLabv3Plus/releases/tag/1.1.0",
        "name": "MedicDeepLabv3+ 1.1.0",
        "release_id": 44558933,
        "tag": "1.1.0",
        "tarball_url": "https://api.github.com/repos/jmlipman/MedicDeepLabv3Plus/tarball/1.1.0",
        "type": "Release",
        "url": "https://api.github.com/repos/jmlipman/MedicDeepLabv3Plus/releases/44558933",
        "value": "https://api.github.com/repos/jmlipman/MedicDeepLabv3Plus/releases/44558933",
        "zipball_url": "https://api.github.com/repos/jmlipman/MedicDeepLabv3Plus/zipball/1.1.0"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "jmlipman",
          "type": "User"
        },
        "date_created": "2020-08-24T14:30:45Z",
        "date_published": "2020-08-31T13:23:10Z",
        "html_url": "https://github.com/jmlipman/MedicDeepLabv3Plus/releases/tag/v1.0.0",
        "name": "MedicDeepLabv3+ 1.0.0",
        "release_id": 30437583,
        "tag": "v1.0.0",
        "tarball_url": "https://api.github.com/repos/jmlipman/MedicDeepLabv3Plus/tarball/v1.0.0",
        "type": "Release",
        "url": "https://api.github.com/repos/jmlipman/MedicDeepLabv3Plus/releases/30437583",
        "value": "https://api.github.com/repos/jmlipman/MedicDeepLabv3Plus/releases/30437583",
        "zipball_url": "https://api.github.com/repos/jmlipman/MedicDeepLabv3Plus/zipball/v1.0.0"
      },
      "technique": "GitHub_API"
    }
  ],
  "requirements": [
    {
      "confidence": 1,
      "result": {
        "original_header": "2.1 Requirements",
        "parent_header": [
          "MedicDeepLabv3+",
          "2. Installation and Requirements"
        ],
        "type": "Text_excerpt",
        "value": " * [PyTorch](https://pytorch.org/get-started/locally/) (preferably with GPU support). Deep Learning framework.\n * [pip](https://pypi.org/project/pip/). Python package installer.\n * [Virtual Enviroment](https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/) (optional)\n"
      },
      "source": "https://raw.githubusercontent.com/jmlipman/MedicDeepLabv3Plus/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "2.3 Image format",
        "parent_header": [
          "MedicDeepLabv3+",
          "2. Installation and Requirements"
        ],
        "type": "Text_excerpt",
        "value": " * Images and their corresponding labels must be in the same folder (check below the expected path structure)\n * Images must have the following 4 dimensions: Height x Width x Depth x Modality (our images were 256x256x18x1). \n * Segmentation masks will have values of 0 (background voxels) and 1 (brain mask or contralateral hemisphere voxels) in 3 dimensions: Height x Width x Depth.\n\nExample of path containing training data:\n```cshell\nPATH\n \u2514\u2500Study 1\n   \u2514\u250024h (time-point)\n     \u251c\u250032 (id of the scan)\n     \u2502 \u251c\u2500scan.nii.gz (image)\n     \u2502 \u251c\u2500scan_brainmask.nii.gz (label)\n     \u2502 \u2514\u2500scan_contra.nii.gz (label)\n     \u2514\u250035\n       \u251c\u2500scan.nii.gz\n       \u251c\u2500scan_brainmask.nii.gz (label)\n       \u2514\u2500scan_contra.nii.gz (label)\n       ...\n```\n"
      },
      "source": "https://raw.githubusercontent.com/jmlipman/MedicDeepLabv3Plus/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "somef_missing_categories": [
    "acknowledgement",
    "run",
    "download",
    "contact",
    "contributors",
    "documentation",
    "license",
    "usage",
    "faq",
    "support",
    "has_build_file",
    "executable_example"
  ],
  "somef_provenance": {
    "date": "2024-10-04 12:47:37",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 4
      },
      "technique": "GitHub_API"
    }
  ]
}