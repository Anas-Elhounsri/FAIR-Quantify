{
  "application_domain": [
    {
      "confidence": 85.85,
      "result": {
        "type": "String",
        "value": "Natural Language Processing"
      },
      "technique": "supervised_classification"
    }
  ],
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/SuperSupermoon/MedViLL"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2022-01-17T05:32:07Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2024-09-23T10:25:46Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "MedViLL official code. (Published IEEE JBHI 2021)"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 0.9517999572243123,
      "result": {
        "original_header": "MedViLL",
        "type": "Text_excerpt",
        "value": "This repository provides the code for MedViLL(Medical Vision Language Learner). \n---\n<p align=\"center\"><img src=\"https://user-images.githubusercontent.com/47732974/149651882-bb691bc8-8343-4699-a45f-1952bd558490.png\")</p>\n \nOur proposed architecture MedViLL is a single BERT-based model that learns unified contextualized vision-language (VL) representation for both Vision Language Understanding (VLU) and Vision Language Generation (VLG). MedViLL performs pre-training with a CNN-based visual encoder and a cross-modal Transformer for VL joint representation learning. After pre-training, our model can be easily used for VLU and VLG tasks with task-specific finetuning. Please refer to our paper \"[**Multi-modal Understanding and Generation for Medical Images and Text via Vision-Language Pre-Training**](https://arxiv.org/abs/2105.11333)\" for more details. \n \n## 1) Downloads.\n### Pre-trained weights.\nWe provide five versions of BERT-based pre-trained weights with different types of self-attention masks. Pre-training for the joint embedding was built on the BERT-base architecutre(12 hidden layers, 12 attention heads, 768 hidden size), and training details are described in our paper. Currently avaliable versions of pre-trained weights are as follows:\n \n- [MedViLL](https://drive.google.com/file/d/1shOQrOWbkIeUUsQN48fEP6wj0e266jOb/view?usp=sharing) - BERT-Base model with Bidirectional Auto-regressive attention mask. \n- [Bi & Seq2Seq](https://drive.google.com/file/d/1hn8DLgPkblIew_UEP3TwoLwKZw03Pkmk/view?usp=sharing) - BERT-Base model with Seq2Seq attention mask(75%) and Bidirectional attention mask(25%) in every mini-batch. \n\n### Datasets.\nWe provide a pre-processed version of multiple datasets for each task as follows: \n Download each dataset to the path /data/preprocessed/[dataset].\n- MIMIC-CXR: We don't provide MIMIC-CXR dataset due to the policy of data use agreement. Please download original datset from [PhysioNet](https://physionet.org/content/mimic-cxr-jpg/2.0.0/).\n- [OPEN-I](https://drive.google.com/file/d/1aAKW2UcR7KhX9rckYtNfTfzNYulgrzle/view?usp=sharing) (74.1 MB): Unique study of 3,547 AP and PA image-report pairs from the official Open-I dataset.\n- [VQA-RAD](https://drive.google.com/file/d/1zlNM7kQACaorfQD8n_Qtc5wkV_lh_60V/view?usp=sharing) (402 MB): 3,515 question answer pairs on 315 images (104 head CTs or MRIs, 107 Chest X-rays, and 104 abdominal CTs).\n \nWe also provide the JSON file with the path for validation in the retrieval task, download each files to the path /data/[dataset].\n**Image to report retrieval**\n1) [MIMIC valid](https://drive.google.com/file/d/1r9NMdZEDDjIi5L3EijTzKU13bluPEIIu/view?usp=sharing), 2) [MIMIC test](https://drive.google.com/file/d/1N4zaZrAYg6gjFR2yoEUFcwycjLNXc9FL/view?usp=sharing), 3) [OpenI test](https://drive.google.com/file/d/1GtKIlF9HSGzgA_yaVmoUsIs-ccOzonIz/view?usp=sharing) \nNote that all fine-tuning models were conducted on 8 Geforce RTX-3090 GPU machines, each of which has 24GB of VRAM.  \n"
      },
      "source": "https://raw.githubusercontent.com/SuperSupermoon/MedViLL/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/SuperSupermoon/MedViLL/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 11
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/SuperSupermoon/MedViLL/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "SuperSupermoon/MedViLL"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "MedViLL"
      },
      "source": "https://raw.githubusercontent.com/SuperSupermoon/MedViLL/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "has_script_file": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/SuperSupermoon/MedViLL/master/downstream_task/report_generation_and_vqa/run.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/SuperSupermoon/MedViLL/master/downstream_task/report_generation_and_vqa/vqa_train.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/SuperSupermoon/MedViLL/master/downstream_task/report_generation_and_vqa/test.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/SuperSupermoon/MedViLL/master/downstream_task/report_generation_and_vqa/vqa_test.sh"
      },
      "technique": "file_exploration"
    }
  ],
  "images": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://user-images.githubusercontent.com/47732974/149651882-bb691bc8-8343-4699-a45f-1952bd558490.png"
      },
      "source": "https://raw.githubusercontent.com/SuperSupermoon/MedViLL/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "installation": [
    {
      "confidence": 0.9927553215511916,
      "result": {
        "original_header": "MedViLL",
        "type": "Text_excerpt",
        "value": "**Report to Image retrieval**\n1) [MIMIC valid](https://drive.google.com/file/d/1HBbq5Juxf_uh4Yk7SJTWoUH7yeyQfXGk/view?usp=sharing), 2) [MIMIC test](https://drive.google.com/file/d/11UQOId3-ErT-hkKSOKYQYUT7WrCYCywf/view?usp=sharing), 3) [OpenI test](https://drive.google.com/file/d/1CJkkDu4djlkeUTgZX7w3h1GC-IkPlgxh/view?usp=sharing)\n \n \n## 2) Reproduce.\n### Section A. Installation\nSections below describe the virtual env installation and the fine-training process of MedviLL based on pytorch version 1.7, python version 3.8. \nTo fine-tune MedViLL, you need to download the pre-trained weights of MedViLL. After downloading the pre-trained weights, use medvill.yaml to install conda based virtual env as follows:\n```\n$ git clone https://github.com/SuperSupermoon/MedViLL.git\n$ cd MedViLL; conda env create --file medvill.yaml\n```\n \nUnzip mimic, openi, and VQA-RAD tar.gz files. \n```\n$ cd MedViLL; tar -zxvf [file_name.tar.gz]\n```\n \n- Image-Report Retrieval\nExample:\n```\n$ cd MedViLL/downstream_task/retrieval\n$ python retrieval.py\n``` \n- Report Generation\nExample:\n```\n$ cd MedViLL/downstream_task/report_generation_and_vqa\n$ python finetune.py --tasks report_generation --mask_prob 0.15 --s2s_prob 1 --bi_prob 0\n```\n \n"
      },
      "source": "https://raw.githubusercontent.com/SuperSupermoon/MedViLL/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "invocation": [
    {
      "confidence": 0.9184491912607184,
      "result": {
        "original_header": "MedViLL",
        "type": "Text_excerpt",
        "value": "### Section C. Pre-training model\nExample:\n```\n$ cd MedViLL\n$ python main.py\n``` \n\n### Section D. Downstream model\n- Diagnosis Classification\nExample:\n```\n$ cd MedViLL/downstream_task/classification\n$ python cls.py\n``` \n- Image-Report Retrieval\nExample:\n```\n$ cd MedViLL/downstream_task/retrieval\n$ python retrieval.py\n``` \n- Medical Visual Qestion Answering\nExample:\n```\n$ python -m torch.distributed.launch --nproc_per_node=1 --master_port 9872 --use_env downstream_task/report_generation_and_vqa/finetune.py --model_recover_path pt_model/model.50.bin --tasks vqa --s2s_prob 0 --bi_prob 1 --mask_prob 0 --vqa_rad chest --vqa_eval\n``` \n- Report Generation\nExample:\n```\n$ cd MedViLL/downstream_task/report_generation_and_vqa\n$ python finetune.py --tasks report_generation --mask_prob 0.15 --s2s_prob 1 --bi_prob 0\n```\n \n"
      },
      "source": "https://raw.githubusercontent.com/SuperSupermoon/MedViLL/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/SuperSupermoon/MedViLL/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ""
      },
      "technique": "GitHub_API"
    }
  ],
  "license": [
    {
      "confidence": 1,
      "result": {
        "name": "MIT License",
        "spdx_id": "MIT",
        "type": "License",
        "url": "https://api.github.com/licenses/mit",
        "value": "https://api.github.com/licenses/mit"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "type": "File_dump",
        "value": "MIT License\n\nCopyright (c) 2021 SuperSuperMoon\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
      },
      "source": "https://raw.githubusercontent.com/SuperSupermoon/MedViLL/master/LICENSE",
      "technique": "file_exploration"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "MedViLL"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "User",
        "value": "SuperSupermoon"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 390190,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Shell",
        "size": 13212,
        "type": "Programming_language",
        "value": "Shell"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/SuperSupermoon/MedViLL/master/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "related_papers": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://arxiv.org/abs/2105.11333"
      },
      "source": "https://raw.githubusercontent.com/SuperSupermoon/MedViLL/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "somef_missing_categories": [
    "citation",
    "acknowledgement",
    "run",
    "download",
    "requirements",
    "contact",
    "contributors",
    "documentation",
    "usage",
    "faq",
    "support",
    "identifier",
    "has_build_file",
    "executable_example"
  ],
  "somef_provenance": {
    "date": "2024-10-04 12:47:26",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 83
      },
      "technique": "GitHub_API"
    }
  ]
}