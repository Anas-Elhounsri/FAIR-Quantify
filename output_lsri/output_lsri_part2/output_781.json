{
  "application_domain": [
    {
      "confidence": 17.86,
      "result": {
        "type": "String",
        "value": "Computer Vision"
      },
      "technique": "supervised_classification"
    }
  ],
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/bi-compbio/scrnax"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2021-03-20T10:14:19Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2023-10-02T19:16:08Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "A snakemake pipeline improves the gene annotation for cross species analysis of single cell RNA-Seq"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Two approaches for improving gene annotation",
        "parent_header": [
          "Introduction"
        ],
        "type": "Text_excerpt",
        "value": "![approaches](resources/images/approaches.png)\n"
      },
      "source": "https://raw.githubusercontent.com/bi-compbio/scrnax/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Without bulk RNA-Seq data",
        "parent_header": [
          "Introduction",
          "DAG of workflow"
        ],
        "type": "Text_excerpt",
        "value": "The GTF file can be improved by ortholog mapping. ![ortholog mapping](resources/images/dag.png)\n"
      },
      "source": "https://raw.githubusercontent.com/bi-compbio/scrnax/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "With bulk RNA-Seq data",
        "parent_header": [
          "Introduction",
          "DAG of workflow"
        ],
        "type": "Text_excerpt",
        "value": "The pipeline can take the mapped bam files as inputs, the GTF file then will be improved by denovo assembly.![denovo assembly](resources/images/dag_denovo.png)\n"
      },
      "source": "https://raw.githubusercontent.com/bi-compbio/scrnax/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "If the scRNA-Seq reads are provided",
        "parent_header": [
          "Introduction",
          "DAG of workflow"
        ],
        "type": "Text_excerpt",
        "value": "The pipeline then can quantify the provided reads by STARSolo with improved GTF file, the gene count matrix will be saved in 10X h5 format, which can be loaded via other scRNA-Seq analysis package (e.g. Seurat) .![full](resources/images/dagFull.png)\n"
      },
      "source": "https://raw.githubusercontent.com/bi-compbio/scrnax/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Performance",
        "parent_header": [
          "Introduction"
        ],
        "type": "Text_excerpt",
        "value": "By applying the workflow to pig retina data, the overall exon length can be extended by two folder on average ![exonlen](resources/images/exonlen.png).\nThe improvements on either total UMIs detected per sample![totalUMI](resources/images/totalUMI.png), or # of detect gene/cell or # of UMIs/cell ![gene_umi](resources/images/gene_umi.png) are also shown below. \n"
      },
      "source": "https://raw.githubusercontent.com/bi-compbio/scrnax/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 0.9881956018523086,
      "result": {
        "original_header": "General",
        "type": "Text_excerpt",
        "value": "A snakemake pipeline improves the gene annotation for cross species analysis of single cell RNA-Seq. \nDroplet-based single-cell RNA-Seq protocols such as 10X Genomics Chromium, cel-seq2 are widely used because of the dramatic increase of throughput for detecting cells. Since these methods only enrich cDNA fragments closed to polyadenylation (polyA) tails, data generated by these protocols is highly biased to the 3\u2019 end of transcripts where the 3\u2019UTR is normally located. The sensitivity and specificity of scRNA-Seq on detecting expressed gene therefore are confounded by the quality of 3\u2019UTR annotation.  \nHere, we implemented a computational pipeline can improve the tissue or species specific 3\u2019UTR annotation by leveraging on 1) de novo assembly of transcriptome with bulk RNA-Seq data and 2) ortholog of  3\u2019UTR from well-annotated species. We show that ~40%-70% more UMIs can be assigned back to genes after applying this approach to 10X scRNA-Seq data generated from Pig retina, of which the 3\u2019UTRs are pooly annotated.  \n"
      },
      "source": "https://raw.githubusercontent.com/bi-compbio/scrnax/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/bi-compbio/scrnax/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "faq": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Command for submitting the jobs to HPC cluster",
        "parent_header": [
          "Usage",
          "Example"
        ],
        "type": "Text_excerpt",
        "value": "```bash\nsnakemake --use-singularity --use-conda --profile config/slurm/ --configfile conf.json  --config bamDir=resources/tests/bams/ fastqDir=resources/tests/fastqs/ countBy=combined\n```\n\nThe gene count matrix (h5 format) will be stored in subfolder of featureCount folder.\n\n```bash\npigGTF/featureCount/\n\u251c\u2500\u2500 combined\n\u2502   \u251c\u2500\u2500 736_001.Aligned.sortedByCoord.out.bam.featureCounts.bam\n\u2502   \u251c\u2500\u2500 736_001.counts.txt\n\u2502   \u251c\u2500\u2500 736_001.counts.txt.summary\n\u2502   \u251c\u2500\u2500 736_001.h5\n\u2502   \u251c\u2500\u2500 736_001.tsv.gz\n\u2502   \u251c\u2500\u2500 736_008.Aligned.sortedByCoord.out.bam.featureCounts.bam\n\u2502   \u251c\u2500\u2500 736_008.counts.txt\n\u2502   \u251c\u2500\u2500 736_008.counts.txt.summary\n\u2502   \u251c\u2500\u2500 736_008.h5\n\u2502   \u2514\u2500\u2500 736_008.tsv.gz\n\u251c\u2500\u2500 denovo\n\u2502   \u251c\u2500\u2500 736_001.Aligned.sortedByCoord.out.bam.featureCounts.bam\n\u2502   \u251c\u2500\u2500 736_001.counts.txt\n\u2502   \u251c\u2500\u2500 736_001.counts.txt.summary\n\u2502   \u251c\u2500\u2500 736_001.h5\n\u2502   \u251c\u2500\u2500 736_001.tsv.gz\n\u2502   \u251c\u2500\u2500 736_008.Aligned.sortedByCoord.out.bam.featureCounts.bam\n\u2502   \u251c\u2500\u2500 736_008.counts.txt\n\u2502   \u251c\u2500\u2500 736_008.counts.txt.summary\n\u2502   \u251c\u2500\u2500 736_008.h5\n\u2502   \u2514\u2500\u2500 736_008.tsv.gz\n\u2514\u2500\u2500 ortholog\n    \u251c\u2500\u2500 736_001.Aligned.sortedByCoord.out.bam.featureCounts.bam\n    \u251c\u2500\u2500 736_001.counts.txt\n    \u251c\u2500\u2500 736_001.counts.txt.summary\n    \u251c\u2500\u2500 736_001.h5\n    \u251c\u2500\u2500 736_001.tsv.gz\n    \u251c\u2500\u2500 736_008.Aligned.sortedByCoord.out.bam.featureCounts.bam\n    \u251c\u2500\u2500 736_008.counts.txt\n    \u251c\u2500\u2500 736_008.counts.txt.summary\n    \u251c\u2500\u2500 736_008.h5\n    \u2514\u2500\u2500 736_008.tsv.gz\n\n```\n"
      },
      "source": "https://raw.githubusercontent.com/bi-compbio/scrnax/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 0
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/bi-compbio/scrnax/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "bi-compbio/scrnax"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "General"
      },
      "source": "https://raw.githubusercontent.com/bi-compbio/scrnax/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "has_script_file": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/bi-compbio/scrnax/master/config/slurm/slurm-jobscript.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/bi-compbio/scrnax/master/workflow/scripts/countBamFromSTARSolo.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/bi-compbio/scrnax/master/workflow/scripts/runSnakeSing.sh"
      },
      "technique": "file_exploration"
    }
  ],
  "images": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/bi-compbio/scrnax//master/resources/images/approaches.png"
      },
      "source": "https://raw.githubusercontent.com/bi-compbio/scrnax/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/bi-compbio/scrnax//master/resources/images/dag.png"
      },
      "source": "https://raw.githubusercontent.com/bi-compbio/scrnax/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/bi-compbio/scrnax//master/resources/images/dag_denovo.png"
      },
      "source": "https://raw.githubusercontent.com/bi-compbio/scrnax/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/bi-compbio/scrnax//master/resources/images/dagFull.png"
      },
      "source": "https://raw.githubusercontent.com/bi-compbio/scrnax/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/bi-compbio/scrnax//master/resources/images/exonlen.png"
      },
      "source": "https://raw.githubusercontent.com/bi-compbio/scrnax/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/bi-compbio/scrnax//master/resources/images/totalUMI.png"
      },
      "source": "https://raw.githubusercontent.com/bi-compbio/scrnax/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/bi-compbio/scrnax//master/resources/images/gene_umi.png"
      },
      "source": "https://raw.githubusercontent.com/bi-compbio/scrnax/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "installation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Step 1: Obtain a copy of this workflow",
        "parent_header": [
          "Usage",
          "Setup"
        ],
        "type": "Text_excerpt",
        "value": "1. Create a new github repository using this workflow [as a template](https://help.github.com/en/articles/creating-a-repository-from-a-template).\n2. [Clone](https://help.github.com/en/articles/cloning-a-repository) the newly created repository to your local system, into the place where you want to perform the data analysis.\n\n```bash\n  mkdir ~/src/\n  cd ~/src/\n  git -c http.sslVerify=\"false\" -c http.proxy=  clone https://github.com/bi-compbio/scrnax.git\n  cd scrnax/resources/\n  tar xvfz tests.tar.gz\n```"
      },
      "source": "https://raw.githubusercontent.com/bi-compbio/scrnax/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Step 2: Configure workflow",
        "parent_header": [
          "Usage",
          "Setup"
        ],
        "type": "Text_excerpt",
        "value": "Configure the workflow according to your needs via editing the files in the `config/` folder. Adjust `config.selftest.json` to configure the workflow execution.\n"
      },
      "source": "https://raw.githubusercontent.com/bi-compbio/scrnax/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Step 3: Check if Snakemake is available",
        "parent_header": [
          "Usage",
          "Setup"
        ],
        "type": "Text_excerpt",
        "value": "```bash\n  snakemake -v\n```\n"
      },
      "source": "https://raw.githubusercontent.com/bi-compbio/scrnax/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 0.9516235139217103,
      "result": {
        "original_header": "General",
        "type": "Text_excerpt",
        "value": "For version history, see the [change log](#change-log). \n \n"
      },
      "source": "https://raw.githubusercontent.com/bi-compbio/scrnax/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.834250503732454,
      "result": {
        "original_header": "v1.0.0",
        "type": "Text_excerpt",
        "value": "Initial release\n \n"
      },
      "source": "https://raw.githubusercontent.com/bi-compbio/scrnax/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/bi-compbio/scrnax/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ""
      },
      "technique": "GitHub_API"
    }
  ],
  "license": [
    {
      "confidence": 1,
      "result": {
        "name": "MIT License",
        "spdx_id": "MIT",
        "type": "License",
        "url": "https://api.github.com/licenses/mit",
        "value": "https://api.github.com/licenses/mit"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "type": "File_dump",
        "value": "MIT License\n\nCopyright (c) 2021, Yang Shen\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
      },
      "source": "https://raw.githubusercontent.com/bi-compbio/scrnax/master/LICENSE",
      "technique": "file_exploration"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "scrnax"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "Organization",
        "value": "bi-compbio"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 48856,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "R",
        "size": 12228,
        "type": "Programming_language",
        "value": "R"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Shell",
        "size": 3947,
        "type": "Programming_language",
        "value": "Shell"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/bi-compbio/scrnax/master/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "related_documentation": [
    {
      "confidence": 1,
      "result": {
        "format": "readthedocs",
        "type": "Url",
        "value": "https://snakemake.readthedocs.io/"
      },
      "source": "https://raw.githubusercontent.com/bi-compbio/scrnax/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "requirements": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Requirements",
        "type": "Text_excerpt",
        "value": "* Miniconda\n\nMiniconda can be installed with user's account:\n\n```bash\n  wget -c https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n  bash Miniconda3-latest-Linux-x86_64.sh\n  conda config --add channels defaults\n  conda config --add channels bioconda\n  conda config --add channels conda-forge\n```\n\n* Git (>=2.22.0)\n\n```bash\nconda install -c conda-forge git\n```\n\n * Snakemake (>=5.32.0)\n\nInstall Snakemake using [conda](https://conda.io/projects/conda/en/latest/user-guide/install/index.html):\nFor installation details, see the [instructions in the Snakemake documentation](https://snakemake.readthedocs.io/en/stable/getting_started/installation.html).\n\n```bash\nconda install snakemake\n```\n \n***Or the pipeline can be run via Singualrity.***\n\n* Singualrity\n\nPlease check if Singualrity is available:\n\n```bash\n  singularity run docker://godlovedc/lolcow\n _________________________________________\n/ Learn to pause -- or nothing worthwhile \\\n\\ can catch up to you.                    /\n -----------------------------------------\n        \\   ^__^\n         \\  (oo)\\_______\n            (__)\\       )\\/\\\n                ||----w |\n                ||     ||\n```\n\nYou need root permission to install singularity, please follow the [instructions on Singularity website](https://sylabs.io/guides/3.0/user-guide/installation.html).\n"
      },
      "source": "https://raw.githubusercontent.com/bi-compbio/scrnax/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "run": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Step 4: Execute workflow with self-test data",
        "parent_header": [
          "Usage",
          "Setup"
        ],
        "type": "Text_excerpt",
        "value": "Test your configuration by performing a dry-run via\n\n```bash\n  cd ~/src/scrnax/\n  snakemake --profile config/selftest/ --use-conda -n \n```\n\nExecute the workflow locally via\n\n```bash\n  snakemake --profile config/selftest/ --use-conda --cores $N\n```\n\nusing `$N` cores or run it in a HPC environment (slurm) via\n\n```bash\n    snakemake --profile config/slurm_selftest/ --use-conda\n```\n\nIf you not only want to fix the software stack but also the underlying OS, use\n\n```bash\n    snakemake --profile config/selftest/ --use-conda --use-singularity\n```\n\nin combination with any of the modes above.\nSee the [Snakemake documentation](https://snakemake.readthedocs.io/en/stable/executable.html) for further details.\n\n\n**If the files defined in config file are located outside of current working directory, then the folder or parent folder has to be mounted when running singularity**\nFor example, in the conf.json shown below, the files are all located in subfolder of  **/data/**.\n\n```\n{\n  \"resultdir\": \"pigGTF/\",\n  \"goodGTF\": \"/data/cbsync/referencedata/annotations/homo_sapiens/ensembl/95/Homo_sapiens.GRCh38.95.gtf\",\n  \"refGTF\": \"/data/cbsync/referencedata/annotations/sus_scrofa/ensembl/86/Sus_scrofa.Sscrofa10.2.86.gtf\",\n  \"liftChain\": \"/data/cbsync/referencedata/annotations/homo_sapiens/ucsc/liftOver/hg38ToSusScr3.over.chain\",\n  \"liftMinMatch\": 0.7\n}\n```\n\nTherefore, the **/data/** should be mounted by adding **--singularity-args \"-B /data\"** at the end of command:\n\n```bash\nsnakemake --profile config/selftest/ --use-conda --use-singularity --singularity-args \"-B /data\"\n```\n\n"
      },
      "source": "https://raw.githubusercontent.com/bi-compbio/scrnax/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Conda",
        "parent_header": [
          "Usage",
          "Run pipeline"
        ],
        "type": "Text_excerpt",
        "value": "```bash\nsnakemake --profile config/local/ --use-conda --cores 16 --configfile conf.json --config bamDir='bams/'\n```\n"
      },
      "source": "https://raw.githubusercontent.com/bi-compbio/scrnax/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Conda + Singularity",
        "parent_header": [
          "Usage",
          "Run pipeline"
        ],
        "type": "Text_excerpt",
        "value": "```bash\nsnakemake --profile config/local/ --use-conda --use-singularity --cores 16 --configfile conf.json --config bamDir='bams/'\n```\n"
      },
      "source": "https://raw.githubusercontent.com/bi-compbio/scrnax/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Running pipeline outside",
        "parent_header": [
          "Usage",
          "Troubleshoot"
        ],
        "type": "Text_excerpt",
        "value": "You can execute the pipeline in any directory. But you have to specify the path of pipeline script with `-s`. For example:\n\n```bash\nsnakemake --use-singularity --singularity-args \"-B /data\" --profile config/local/ -s ~/src/scrnax/workflow/Snakefile --configfile conf.json --config fastqDir=fastqsslim\n```\n"
      },
      "source": "https://raw.githubusercontent.com/bi-compbio/scrnax/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "somef_missing_categories": [
    "citation",
    "acknowledgement",
    "download",
    "contact",
    "contributors",
    "documentation",
    "support",
    "identifier",
    "has_build_file",
    "executable_example"
  ],
  "somef_provenance": {
    "date": "2024-10-04 11:59:37",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 1
      },
      "technique": "GitHub_API"
    }
  ],
  "usage": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Step 1: Obtain a copy of this workflow",
        "parent_header": [
          "Usage",
          "Setup"
        ],
        "type": "Text_excerpt",
        "value": "1. Create a new github repository using this workflow [as a template](https://help.github.com/en/articles/creating-a-repository-from-a-template).\n2. [Clone](https://help.github.com/en/articles/cloning-a-repository) the newly created repository to your local system, into the place where you want to perform the data analysis.\n\n```bash\n  mkdir ~/src/\n  cd ~/src/\n  git -c http.sslVerify=\"false\" -c http.proxy=  clone https://github.com/bi-compbio/scrnax.git\n  cd scrnax/resources/\n  tar xvfz tests.tar.gz\n```"
      },
      "source": "https://raw.githubusercontent.com/bi-compbio/scrnax/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Step 2: Configure workflow",
        "parent_header": [
          "Usage",
          "Setup"
        ],
        "type": "Text_excerpt",
        "value": "Configure the workflow according to your needs via editing the files in the `config/` folder. Adjust `config.selftest.json` to configure the workflow execution.\n"
      },
      "source": "https://raw.githubusercontent.com/bi-compbio/scrnax/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Step 3: Check if Snakemake is available",
        "parent_header": [
          "Usage",
          "Setup"
        ],
        "type": "Text_excerpt",
        "value": "```bash\n  snakemake -v\n```\n"
      },
      "source": "https://raw.githubusercontent.com/bi-compbio/scrnax/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Input",
        "parent_header": [
          "Usage"
        ],
        "type": "Text_excerpt",
        "value": "* GTF gene annotation file of poorly annotated species of which the samples are from. (e.g., [pig](http://ftp.ensembl.org/pub/release-97/gtf/sus_scrofa_usmarc/)) \n* GTF gene annotation file of well annotated species that are evolutionary closed to the species of interest. (e.g, human), which can be downloaded from Ensembl (e.g., [human](http://ftp.ensembl.org/pub/release-97/gtf/homo_sapiens/)).\n* LiftOver Chain file defines the ortholog synteny blocks by whole alignment, which can be download from UCSC (e.g, [hg38](http://hgdownload.cse.ucsc.edu/goldenpath/hg38/liftOver/))\n* Bam files of bulk RNA-Seq (optional). These files will be used for denovo assembly.\n"
      },
      "source": "https://raw.githubusercontent.com/bi-compbio/scrnax/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Config file",
        "parent_header": [
          "Usage"
        ],
        "type": "Text_excerpt",
        "value": "After downloading the files aforementioned, put the paths of those files into **conf.json**.\nThe parameters defined in conf.json are:\n"
      },
      "source": "https://raw.githubusercontent.com/bi-compbio/scrnax/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Parameters for GTF improvement",
        "parent_header": [
          "Usage",
          "Config file"
        ],
        "type": "Text_excerpt",
        "value": "- `resultdir`: the root path of outputs\n- `goodGTF`: the GTF file of well annotated species (e.g., human)\n- `refGTF`: the GTF file of pooly annotated species, of which the samples are from (e.g., pig)\n- `liftChain`: the chain file for liftOver\n- `liftMinMatch`: liftOver specific parameter, defines the minimum ratio of bases that must remap, which is range from 0~1\n- `bamDir`, optional parameters, if the bulk RNASeq data is available, the bamDir defines the path of folder of bam files\n"
      },
      "source": "https://raw.githubusercontent.com/bi-compbio/scrnax/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Parameters for quantification using STARSolo with improved GTF",
        "parent_header": [
          "Usage",
          "Config file"
        ],
        "type": "Text_excerpt",
        "value": "- `StarsoloGenome`: the path of geome index of STARSolo\n- `whitelist`: the path of barcode whitelist for correcting cell barcode. For 10X data, the whitelist can be obtained from cellRanger package, [V2] (https://github.com/10XGenomics/supernova/raw/master/tenkit/lib/python/tenkit/barcodes/737K-august-2016.txt) and V3 (local path: cellranger-3.0.2/cellranger-cs/3.0.2/lib/python/cellranger/barcodes/3M-february-2018.txt.gz)\n\n> The STARSolo can handle any data in which the cell barcode + UMI (read1 for 10X) and cDNA (read2 for 10X) are separated. User needs to define the actual cell barcode length and UMI start position and length when using STARSolo. Please refer to STARSolo manual for details\n\n- `CBLen`: cell barcode length, which is 16 for 10X data\n- `UMIStart`: start position of UMI\n- `UMILen`: length of UMI\n"
      },
      "source": "https://raw.githubusercontent.com/bi-compbio/scrnax/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Conda",
        "parent_header": [
          "Usage",
          "Run pipeline"
        ],
        "type": "Text_excerpt",
        "value": "```bash\nsnakemake --profile config/local/ --use-conda --cores 16 --configfile conf.json --config bamDir='bams/'\n```\n"
      },
      "source": "https://raw.githubusercontent.com/bi-compbio/scrnax/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Conda + Singularity",
        "parent_header": [
          "Usage",
          "Run pipeline"
        ],
        "type": "Text_excerpt",
        "value": "```bash\nsnakemake --profile config/local/ --use-conda --use-singularity --cores 16 --configfile conf.json --config bamDir='bams/'\n```\n"
      },
      "source": "https://raw.githubusercontent.com/bi-compbio/scrnax/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Output",
        "parent_header": [
          "Usage"
        ],
        "type": "Text_excerpt",
        "value": "The refined GTFs are three/two GTF files:\n1. `{resultdir}/ortholog/fixed.gtf`: GTF is refined by ortholog mapping\n2. `{resultdir}/denovo/fixed.gtf`: GTF is refined by denovo assembly (will be generated only if the bulk RNA-Seq bam files are provided)\n3. `{resultdir}/combined.fixed.gtf`: GTF is refined by combining ortholog mapping and denovo assembly.\n\nFor example:\n\n```bash\npigGTF/\n\u251c\u2500\u2500 combined.fixed.gtf\n\u251c\u2500\u2500 denovo\n\u2502   \u2514\u2500\u2500 fixed.gtf\n\u2514\u2500\u2500 ortholog\n    \u2514\u2500\u2500 fixed.gtf\n```\n"
      },
      "source": "https://raw.githubusercontent.com/bi-compbio/scrnax/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Example",
        "parent_header": [
          "Usage"
        ],
        "type": "Text_excerpt",
        "value": "In this example, the pig ensembl annotated can be refined by human annotation and scRNA-Seq matched bulk RNA-Seq. (assume the working directory is ~/src/scrnax). \n\nIf both the bam files of bulk RNA-Seq and the fastq files of scRNA-Seq are available, you can **skip `step 4` and `step 5`**. All of analyses, including GTF improvement and gene quantification can be done in **`step 6`**.\n\n* Step 1. Download the pipeline code of scrnax:\n\n```bash\nmkdir ~/src/\ncd ~/src/\ngit -c http.sslVerify=\"false\" -c http.proxy=  clone https://git.eu.boehringer.com/bibc_compbio/scrnax.git\ncd scrnax/resources/\ntar xvfz tests.tar.gz\n```\n\n* Step 2. Download the pig and human GTF from Ensembl, the chain file from UCSC:\n\n```bash\ncd ~/src/scrnax/\n# tar xvfz test.tar.gz\nmkdir gtfs\ncd gtfs\nwget -c http://ftp.ensembl.org/pub/release-97/gtf/homo_sapiens/Homo_sapiens.GRCh38.97.gtf.gz\nwget -c http://ftp.ensembl.org/pub/release-97/gtf/sus_scrofa_usmarc/Sus_scrofa_usmarc.USMARCv1.0.97.gtf.gz\ngzip -d *.gz\n\ncd ../\nmkdir liftchain\ncd liftchain\nwget -c http://hgdownload.cse.ucsc.edu/goldenpath/hg38/liftOver/hg38ToSusScr11.over.chain.gz\ngzip -d *.gz\n\n```\n\n* Step 3. Prepare the conf.json by filling the path of GTFs and liftOver chain file.\n\n```bash\ncd ~/src/scrnax/\ncat <<EOT >conf.json\n{\n  \"resultdir\": \"pigGTF/\",\n  \"goodGTF\": \"gtfs/Homo_sapiens.GRCh38.97.gtf\",\n  \"refGTF\": \"gtfs/Sus_scrofa_usmarc.USMARCv1.0.97.gtf\",\n  \"liftChain\": \"liftchain/hg38ToSusScr11.over.chain\",\n  \"liftMinMatch\": 0.7\n}\nEOT\n```\n\n* Step 4. Launch the pipeline for ortholog mapping only.\n\n```bash\nsnakemake --use-singularity --use-conda --profile config/local/ --configfile conf.json\n```\n\nThe final improved GTF files are:\n\n```bash\npigGTF/\n\u251c\u2500\u2500 combined.fixed.gtf\n\u2514\u2500\u2500 ortholog\n    \u2514\u2500\u2500 fixed.gtf\n```\n\n* Step 5. If the bam files are available, they can be added by either 1) defining in the conf.json or 2) adding \"bamDir\" when running snakemake.\nFirst, some small bam files are provided as an example.\n\n```bash\ncd ~/src/scrnax/\nls resources/tests/bams/\n```\n\nDefine the bamDir in json file (**note, the bamDir should be ended with \"/\"**):\n\n```bash\ncd ~/src/scrnax/\ncat <<EOT >conf.json\n{\n  \"resultdir\": \"pigGTF/\",\n  \"goodGTF\": \"gtfs/Homo_sapiens.GRCh38.97.gtf\",\n  \"refGTF\": \"gtfs/Sus_scrofa_usmarc.USMARCv1.0.97.gtf\",\n  \"liftChain\": \"liftchain/hg38ToSusScr11.over.chain\",\n  \"liftMinMatch\": 0.7,\n  \"bamDir\": \"resources/tests/bams/\"\n}\nEOT\nsnakemake --use-singularity --use-conda --profile config/local/ --configfile conf.json\n```\nOr it can be provided as an additional parameter: bamDir\n\n```bash\ncd ~/src/scrnax/\nsnakemake --use-singularity --use-conda --profile config/local/ --configfile conf.json --config bamDir=resources/tests/bams/\n```\n\nAlternativly, the pipeline can be run on HPC cluster:\n\n```bash\nsnakemake --use-singularity --use-conda --profile config/slurm/ --configfile conf.json --config bamDir=resources/tests/bams/\n```\n\nNow the `combined.fixed.gtf` and `denovo/fixed.gtf` should be updated/added in the result folder.\n\n```bash\npigGTF/\n\u251c\u2500\u2500 combined.fixed.gtf\n\u251c\u2500\u2500 denovo\n\u2502   \u2514\u2500\u2500 fixed.gtf\n\u2514\u2500\u2500 ortholog\n    \u2514\u2500\u2500 fixed.gtf\n```\n\n* Step 6. If the fastq files of scRNA-Seq are available, the pipeline can offer gene level quantification by using STARSolo with the improved GTF. To provide fastq files, the parameter fastqDir needs to be set in either conf.json file or provided as additional parameter when running the pipeline. By default, the \"combined GTF\" will be used for quantification. It is possible to quantify the gene expression according to other GTF file by setting `countBy`.The `countBy` can be set as: ortholog, devnovo and combined.\n\nGenerate new json config file\n\n```bash\ncd ~/src/scrnax/\ncat <<EOT >conf.fastq.json\n{\n  \"resultdir\": \"pigGTF/\",\n  \"goodGTF\": \"gtfs/Homo_sapiens.GRCh38.97.gtf\",\n  \"refGTF\": \"gtfs/Sus_scrofa_usmarc.USMARCv1.0.97.gtf\",\n  \"liftChain\": \"liftchain/hg38ToSusScr11.over.chain\",\n  \"liftMinMatch\": 0.7,\n  \n  \"_comment_\": \"starsolo\",\n  \"StarsoloGenome\": \"resources/tests/Sscrofa10.2.chr12_star2.7.1a/\",\n  \"whitelist\": \"resources/tests/737K-august-2016.txt\",\n  \"CBLen\": 16,\n  \"UMIStart\": 17,\n  \"UMILen\": 10\n}\nEOT\n```\n"
      },
      "source": "https://raw.githubusercontent.com/bi-compbio/scrnax/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Quantification with combined GTF:",
        "parent_header": [
          "Usage",
          "Example"
        ],
        "type": "Text_excerpt",
        "value": "```bash\nsnakemake --use-singularity --use-conda --profile config/local/ --configfile conf.fastq.json  --config bamDir=resources/tests/bams/ fastqDir=resources/tests/fastqs/ countBy=combined\n```\n"
      },
      "source": "https://raw.githubusercontent.com/bi-compbio/scrnax/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Quantification with ortholog GTF:",
        "parent_header": [
          "Usage",
          "Example"
        ],
        "type": "Text_excerpt",
        "value": "```bash\nsnakemake --use-singularity --use-conda --profile config/local/ --configfile conf.fastq.json  --config bamDir=resources/tests/bams/ fastqDir=resources/tests/fastqs/ countBy=ortholog\n```\n"
      },
      "source": "https://raw.githubusercontent.com/bi-compbio/scrnax/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Quantification with denovo assembled GTF:",
        "parent_header": [
          "Usage",
          "Example"
        ],
        "type": "Text_excerpt",
        "value": "```bash\nsnakemake --use-singularity --use-conda --profile config/local/ --configfile conf.fastq.json  --config bamDir=resources/tests/bams/ fastqDir=resources/tests/fastqs/ countBy=denovo\n```\n"
      },
      "source": "https://raw.githubusercontent.com/bi-compbio/scrnax/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Unlock directory",
        "parent_header": [
          "Usage",
          "Troubleshoot"
        ],
        "type": "Text_excerpt",
        "value": "If you have error like:\n\n```bash\nError: Directory cannot be locked. Please make sure that no other Snakemake process is trying to create the same files in the following directory:\n```\nPlease rerun the snakemake command with `--unlock` option.\n\n```bash\nsnakemake --use-singularity --singularity-args \"-B /data\" --profile config/local/ --configfile conf.json --config fastqDir=fastqsslim --unlock\n```\n"
      },
      "source": "https://raw.githubusercontent.com/bi-compbio/scrnax/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "workflows": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/bi-compbio/scrnax/master/workflow/rules/common.smk"
      },
      "technique": "file_exploration"
    }
  ]
}