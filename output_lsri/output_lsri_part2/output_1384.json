{
  "acknowledgement": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Acknowledgement",
        "parent_header": [
          "MP-Net"
        ],
        "type": "Text_excerpt",
        "value": "The research and development activities described in this paper were funded by Ghent University Global Campus (GUGC) and by the Special Research Fund (BOF) of Ghent University (grant no. 01N01718).\n"
      },
      "source": "https://raw.githubusercontent.com/sanghyeonp/MP-Net/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "application_domain": [
    {
      "confidence": 45.06,
      "result": {
        "type": "String",
        "value": "Computer Vision"
      },
      "technique": "supervised_classification"
    }
  ],
  "citation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Citation",
        "parent_header": [
          "MP-Net"
        ],
        "type": "Text_excerpt",
        "value": "Readers may use the following information to cite our research and the dataset.\n\nPark, H. M., Park, S., de Guzman, M. K., Baek, J. Y., Cirkovic Velickovic, T., Van Messem, A., & De Neve, W. (2022). MP-Net: Deep learning-based segmentation for fluorescence microscopy images of microplastics isolated from clams. PloS one, 17(6), e0269449.\n\nThe original paper can be found at the following URL:\n\nhttps://doi.org/10.1371/journal.pone.0269449\n\n"
      },
      "source": "https://raw.githubusercontent.com/sanghyeonp/MP-Net/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/sanghyeonp/MP-Net"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2021-06-11T13:17:15Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2021-10-07T07:02:39Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 0.8904632550035692,
      "result": {
        "original_header": "Training and Testing",
        "type": "Text_excerpt",
        "value": "Both training and testing can be performed using main.py, and a simple run sample is shown below: \n*Train U-Net with ResNet-101 encoder and evaluate the performance of the best model saved for each cross-validation fold.* \n"
      },
      "source": "https://raw.githubusercontent.com/sanghyeonp/MP-Net/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9717101855996833,
      "result": {
        "original_header": "**Rerpoducing Spiked Images Recovery Rate**",
        "type": "Text_excerpt",
        "value": "In order to reproduce recovery rate for spiked images, the mask for the spiked images must be generated which is then used to compute particle counts with ImageJ. \nThe ImageJ macro for counting number of particles for a mask is shared as `ParticleCount.ijm`. \n"
      },
      "source": "https://raw.githubusercontent.com/sanghyeonp/MP-Net/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "download": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Pre-trained weights can be downloaded from Kaggle:",
        "parent_header": [
          "MP-Net"
        ],
        "type": "Text_excerpt",
        "value": "https://www.kaggle.com/sanghyeonaustinpark/mpset\n\n*Please note that the weight that best performs among 4 cross-validation is provided.*\n\n"
      },
      "source": "https://raw.githubusercontent.com/sanghyeonp/MP-Net/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/sanghyeonp/MP-Net/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "executable_example": [
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/sanghyeonp/MP-Net/master/src/segmentation_models/examples/cars%20segmentation%20%28camvid%29.ipynb"
      },
      "source": "https://raw.githubusercontent.com/sanghyeonp/MP-Net/master/src/segmentation_models/examples/cars%20segmentation%20%28camvid%29.ipynb",
      "technique": "file_exploration"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 0
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/sanghyeonp/MP-Net/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "sanghyeonp/MP-Net"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "MP-Net"
      },
      "source": "https://raw.githubusercontent.com/sanghyeonp/MP-Net/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "has_build_file": [
    {
      "confidence": 1,
      "result": {
        "format": "dockerfile",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/sanghyeonp/MP-Net/master/src/segmentation_models/docker/Dockerfile"
      },
      "source": "https://raw.githubusercontent.com/sanghyeonp/MP-Net/master/src/segmentation_models/docker/Dockerfile",
      "technique": "file_exploration"
    }
  ],
  "installation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Data Preparation",
        "parent_header": [
          "MP-Net"
        ],
        "type": "Text_excerpt",
        "value": "*dataset* directory contains a total of 73 fluorescent patches (256x256) and their corresponding masks. They are randomly divided into 5 different datasets where dataset 1 consists of 13 patches and other datasets consist of 15 patches each. The segregation of patches is to perform 4-fold cross-validation where dataset 1 serves as test set and other datasets serve as either train or validaiton set.\n\n*Note: If you want ot use your own dataset to perform 4-fold cross-validation, then modify the DATASET_DIR variable in config.py with the path to your dataset. Be careful to construct your dataset directory structure as below.*\n\n```tree\ndataset\n\u251c\u2500\u2500 dataset_1           # Test set\n\u2502   \u251c\u2500\u2500 001.jpg         # Fluorescent patch\n\u2502   \u251c\u2500\u2500 ...\n\u2502   \u2514\u2500\u2500 labels          # Contains mask patches\n\u2502       \u251c\u2500\u2500 001.jpg     # Mask patch corresponding to the fluorescent patch\n\u2502       \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 dataset_2           # Either train or validation set\n\u2502   \u251c\u2500\u2500 082.jpg         # Fluorescent patch\n\u2502   \u251c\u2500\u2500 ...\n\u2502   \u2514\u2500\u2500 labels          # Contains mask patches\n\u2502       \u251c\u2500\u2500 082.jpg     # Mask patch corresponding to the fluorescent patch\n\u2502       \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 dataset_3           # Either train or validation set\n\u2502   \u251c\u2500\u2500 022.jpg         # Fluorescent patch\n\u2502   \u251c\u2500\u2500 ...\n\u2502   \u2514\u2500\u2500 labels          # Contains mask patches\n\u2502       \u251c\u2500\u2500 022.jpg     # Mask patch corresponding to the fluorescent patch\n\u2502       \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 dataset_4           # Either train or validation set\n\u2502   \u251c\u2500\u2500 125.jpg         # Fluorescent patch\n\u2502   \u251c\u2500\u2500 ...\n\u2502   \u2514\u2500\u2500 labels          # Contains mask patches\n\u2502       \u251c\u2500\u2500 125.jpg     # Mask patch corresponding to the fluorescent patch\n\u2502       \u2514\u2500\u2500 ...\n\u2514\u2500\u2500 dataset_5           # Either train or validation set\n    \u251c\u2500\u2500 50.jpg         # Fluorescent patch\n    \u251c\u2500\u2500 ...\n    \u2514\u2500\u2500 labels          # Contains mask patches\n        \u251c\u2500\u2500 50.jpg     # Mask patch corresponding to the fluorescent patch\n        \u2514\u2500\u2500 ...\n\n```\n"
      },
      "source": "https://raw.githubusercontent.com/sanghyeonp/MP-Net/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 0.918760713947804,
      "result": {
        "original_header": "Training and Testing",
        "type": "Text_excerpt",
        "value": "Both training and testing can be performed using main.py, and a simple run sample is shown below: \nThe result from training will be saved under **./result**, if *--out* is not given.\\\nThe directory where the results will be structured as below.\n```tree\nresult\n\u251c\u2500\u2500 train_result    # Stores evaluation result during training for every epochs.\n\u2502   \u2514\u2500\u2500 FILE NAME\n\u2502       \u2514\u2500\u2500 FILE NAME.csv\n\u251c\u2500\u2500 stdout          # Stores information printed on the terminal.\n\u2502   \u2514\u2500\u2500 FILE NAME\n\u2502       \u2514\u2500\u2500 FILE NAME.txt\n\u251c\u2500\u2500 pred_mask       # Stores the prediction masks for fluorescent patches in the test set during \n\u2502   \u2502                 evaluation.\n\u2502   \u2514\u2500\u2500 FILE NAME\n\u2502       \u251c\u2500\u2500 CV_1\n\u2502       \u2502   \u251c\u2500\u2500 005.png\n\u2502       \u2502   \u2514\u2500\u2500 018.png\n\u2502       \u251c\u2500\u2500 CV_2\n\u2502       \u2502   \u251c\u2500\u2500 005.png\n\u2502       \u2502   \u2514\u2500\u2500 018.png\n\u2502       \u251c\u2500\u2500 CV_3\n\u2502       \u2502   \u251c\u2500\u2500 005.png\n\u2502       \u2502   \u2514\u2500\u2500 018.png\n\u2502       \u251c\u2500\u2500 CV_4\n\u2502       \u2502   \u251c\u2500\u2500 005.png\n\u2502       \u2502   \u2514\u2500\u2500 018.png\n\u2502       \u2514\u2500\u2500 best_CV\n\u2502           \u251c\u2500\u2500 005.png\n\u2502           \u2514\u2500\u2500 018.png\n\u251c\u2500\u2500 model_saved     # Stores the best model at each cross-validation during training.\n\u2502   \u2514\u2500\u2500 FILE NAME\n\u2502       \u251c\u2500\u2500 FILE NAME_CV[1].pth\n\u2502       \u251c\u2500\u2500 FILE NAME_CV[2].pth\n\u2502       \u251c\u2500\u2500 FILE NAME_CV[3].pth\n\u2502       \u251c\u2500\u2500 FILE NAME_CV[4].pth\n\u2502       \u2514\u2500\u2500 FILE NAME_best_CV.pth\n\u2514\u2500\u2500 evaluation      # Stores the performance of the best model saved.\n    \u2514\u2500\u2500 FILE NAME\n        \u251c\u2500\u2500 FILE NAME.csv\n        \u2514\u2500\u2500 FILE NAME_best_CV.csv\n\n```\nThe parser arguments are as below:\n```python\nparser = argparse.ArgumentParser(description='Microplastics Segmentation')\n\nparser.add_argument('--model', type=str, required=True, choices=['unet', 'fcn', 'deeplabv3',    \n                    'unet++'], \n                    help='Specify the model (U-Net, FCN, Deeplabv3, or U-Net++).')\n\nparser.add_argument('--train', action='store_true',\n                    help='Specify whether to train the model (default=False).')\n\nparser.add_argument('--weights', type=str, default=None,\n                    help='Provide absolute path of pre-trained weights (default=None).')\n\nparser.add_argument('--test', action='store_true',\n                    help='Specify whether to evaluate the model (default=False).')\n\nparser.add_argument('--epoch', type=int, default=20,\n                    help='Specify number of epochs (default=20).')\n\nparser.add_argument('--batch_size', type=int, default=10,\n                    help='Specify the batch size (default=10).')\n\nparser.add_argument('--criterion', type=str, choices=['bce', 'dice', 'dicebce'], default='dice', \n                    help='Specify the loss function (BCEWithLogits loss == bce, SoftDice loss == dice,\n                    DiceBCE loss==dicebce).')\n\nparser.add_argument('--pos_weight', type=float, default=9, \n                    help='Specify the weight to positives when using BCEWithLogits loss. (default=9)')\n\nparser.add_argument('--optimizer', type=str, choices=['sgd', 'adam'], default='sgd', \n                    help='Specify the optimizer (SGD => sgd, ADAM => adam).')\n\nparser.add_argument('--momentum', type=float, default=0.9,\n                    help='Specify the momentum value for SGD optimizer (default=0.9).')\n\nparser.add_argument('--lr', type=float, default=0.001,\n                    help='Specify the learning rate (default=0.001).')\n\nparser.add_argument('--TTA', nargs='+', choices=['B', 'C', 'HSV'], default=None,\n                    help='Specify the image augmentation being used for test-time augmentation \n                    (default=None).')\n                    \nparser.add_argument('--cuda', type=int, default=0,\n\t\t\t\t\thelp='Specify the cuda for GPU usage (default=0).')\n\nparser.add_argument('--out', type=str, default=None,\n                    help='Specify the output directory where results will be saved (default=None).')\n```\n \n"
      },
      "source": "https://raw.githubusercontent.com/sanghyeonp/MP-Net/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9221390240280083,
      "result": {
        "original_header": "Test Model with Pre-trained Weight without Training",
        "type": "Text_excerpt",
        "value": "You can also perform only evaluation by removing --train argument.  \n"
      },
      "source": "https://raw.githubusercontent.com/sanghyeonp/MP-Net/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9997426784294062,
      "result": {
        "original_header": "Reproducing Results",
        "type": "Text_excerpt",
        "value": "Necessary data to reproduce the reuslts can be downloaded from Kaggle. (https://www.kaggle.com/sanghyeonaustinpark/mpset) \n"
      },
      "source": "https://raw.githubusercontent.com/sanghyeonp/MP-Net/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "invocation": [
    {
      "confidence": 0.9127762708283012,
      "result": {
        "original_header": "Training and Testing",
        "type": "Text_excerpt",
        "value": "Both training and testing can be performed using main.py, and a simple run sample is shown below: \n\n```shell \npython main.py --model unet --train --test --epoch 20 --batch_size 10 --criterion bce --pos_weight 9 --optimizer sgd --momentum 0.9 --lr 0.001\n``` \nThe result from training will be saved under **./result**, if *--out* is not given.\\\nThe directory where the results will be structured as below.\n```tree\nresult\n\u251c\u2500\u2500 train_result    # Stores evaluation result during training for every epochs.\n\u2502   \u2514\u2500\u2500 FILE NAME\n\u2502       \u2514\u2500\u2500 FILE NAME.csv\n\u251c\u2500\u2500 stdout          # Stores information printed on the terminal.\n\u2502   \u2514\u2500\u2500 FILE NAME\n\u2502       \u2514\u2500\u2500 FILE NAME.txt\n\u251c\u2500\u2500 pred_mask       # Stores the prediction masks for fluorescent patches in the test set during \n\u2502   \u2502                 evaluation.\n\u2502   \u2514\u2500\u2500 FILE NAME\n\u2502       \u251c\u2500\u2500 CV_1\n\u2502       \u2502   \u251c\u2500\u2500 005.png\n\u2502       \u2502   \u2514\u2500\u2500 018.png\n\u2502       \u251c\u2500\u2500 CV_2\n\u2502       \u2502   \u251c\u2500\u2500 005.png\n\u2502       \u2502   \u2514\u2500\u2500 018.png\n\u2502       \u251c\u2500\u2500 CV_3\n\u2502       \u2502   \u251c\u2500\u2500 005.png\n\u2502       \u2502   \u2514\u2500\u2500 018.png\n\u2502       \u251c\u2500\u2500 CV_4\n\u2502       \u2502   \u251c\u2500\u2500 005.png\n\u2502       \u2502   \u2514\u2500\u2500 018.png\n\u2502       \u2514\u2500\u2500 best_CV\n\u2502           \u251c\u2500\u2500 005.png\n\u2502           \u2514\u2500\u2500 018.png\n\u251c\u2500\u2500 model_saved     # Stores the best model at each cross-validation during training.\n\u2502   \u2514\u2500\u2500 FILE NAME\n\u2502       \u251c\u2500\u2500 FILE NAME_CV[1].pth\n\u2502       \u251c\u2500\u2500 FILE NAME_CV[2].pth\n\u2502       \u251c\u2500\u2500 FILE NAME_CV[3].pth\n\u2502       \u251c\u2500\u2500 FILE NAME_CV[4].pth\n\u2502       \u2514\u2500\u2500 FILE NAME_best_CV.pth\n\u2514\u2500\u2500 evaluation      # Stores the performance of the best model saved.\n    \u2514\u2500\u2500 FILE NAME\n        \u251c\u2500\u2500 FILE NAME.csv\n        \u2514\u2500\u2500 FILE NAME_best_CV.csv\n\n```\nThe parser arguments are as below:\n```python\nparser = argparse.ArgumentParser(description='Microplastics Segmentation')\n\nparser.add_argument('--model', type=str, required=True, choices=['unet', 'fcn', 'deeplabv3',    \n                    'unet++'], \n                    help='Specify the model (U-Net, FCN, Deeplabv3, or U-Net++).')\n\nparser.add_argument('--train', action='store_true',\n                    help='Specify whether to train the model (default=False).')\n\nparser.add_argument('--weights', type=str, default=None,\n                    help='Provide absolute path of pre-trained weights (default=None).')\n\nparser.add_argument('--test', action='store_true',\n                    help='Specify whether to evaluate the model (default=False).')\n\nparser.add_argument('--epoch', type=int, default=20,\n                    help='Specify number of epochs (default=20).')\n\nparser.add_argument('--batch_size', type=int, default=10,\n                    help='Specify the batch size (default=10).')\n\nparser.add_argument('--criterion', type=str, choices=['bce', 'dice', 'dicebce'], default='dice', \n                    help='Specify the loss function (BCEWithLogits loss == bce, SoftDice loss == dice,\n                    DiceBCE loss==dicebce).')\n\nparser.add_argument('--pos_weight', type=float, default=9, \n                    help='Specify the weight to positives when using BCEWithLogits loss. (default=9)')\n\nparser.add_argument('--optimizer', type=str, choices=['sgd', 'adam'], default='sgd', \n                    help='Specify the optimizer (SGD => sgd, ADAM => adam).')\n\nparser.add_argument('--momentum', type=float, default=0.9,\n                    help='Specify the momentum value for SGD optimizer (default=0.9).')\n\nparser.add_argument('--lr', type=float, default=0.001,\n                    help='Specify the learning rate (default=0.001).')\n\nparser.add_argument('--TTA', nargs='+', choices=['B', 'C', 'HSV'], default=None,\n                    help='Specify the image augmentation being used for test-time augmentation \n                    (default=None).')\n                    \nparser.add_argument('--cuda', type=int, default=0,\n\t\t\t\t\thelp='Specify the cuda for GPU usage (default=0).')\n\nparser.add_argument('--out', type=str, default=None,\n                    help='Specify the output directory where results will be saved (default=None).')\n```\n \n"
      },
      "source": "https://raw.githubusercontent.com/sanghyeonp/MP-Net/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9177217517872035,
      "result": {
        "original_header": "Implementing Test-time Augmentation",
        "type": "Text_excerpt",
        "value": "Implementation of TTA can be performed by stating --TTA like below:\n```shell\npython main.py --model unet --train --test --epoch 20 --batch_size 10 --criterion bce --pos_weight 9 --optimizer sgd --momentum 0.9 --lr 0.001 --TTA B C HSV\n```\n \n"
      },
      "source": "https://raw.githubusercontent.com/sanghyeonp/MP-Net/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8284625027024007,
      "result": {
        "original_header": "**Rerpoducing Testset Performance**",
        "type": "Text_excerpt",
        "value": "```reproduce testset\npython reproduce.py --reproduce testset \\\n                    --data <Path to downloaded testset> \\\n                    --model <Name of model to reproduce ['unet', 'fcn', 'deeplabv3', 'unet++']> \\\n                    --weights <Path to pre-trained weight for selected model> \\\n                    --cuda <Cuda number> \\\n                    --TTA \\ # Specify if pre-trained weights incorporated TTA\n                    --out <Path to where the predicted mask will be saved>\n``` \n"
      },
      "source": "https://raw.githubusercontent.com/sanghyeonp/MP-Net/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8731222221623859,
      "result": {
        "original_header": "**Rerpoducing Spiked Images Recovery Rate**",
        "type": "Text_excerpt",
        "value": "The mask for spiked images can be generated using `reproduce.py`.\n```reproduce Spiked images\npython reproduce.py --reproduce spiked \\\n                    --data <Path to downloaded spiked image set> \\\n                    --model <Name of model to reproduce ['unet', 'fcn', 'deeplabv3', 'unet++']> \\\n                    --weights <Path to pre-trained weight for selected model> \\\n                    --cuda <Cuda number> \\\n                    --out <Path to where the predicted mask will be saved>\n```\n \n"
      },
      "source": "https://raw.githubusercontent.com/sanghyeonp/MP-Net/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/sanghyeonp/MP-Net/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ""
      },
      "technique": "GitHub_API"
    }
  ],
  "license": [
    {
      "confidence": 1,
      "result": {
        "name": "MIT License",
        "spdx_id": "MIT",
        "type": "License",
        "url": "https://api.github.com/licenses/mit",
        "value": "https://api.github.com/licenses/mit"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "type": "File_dump",
        "value": "MIT License\n\nCopyright (c) 2021 Sanghyeon (Austin) Park\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
      },
      "source": "https://raw.githubusercontent.com/sanghyeonp/MP-Net/master/LICENSE",
      "technique": "file_exploration"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "MP-Net"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "User",
        "value": "sanghyeonp"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Jupyter Notebook",
        "size": 1532717,
        "type": "Programming_language",
        "value": "Jupyter Notebook"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 321402,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "ImageJ Macro",
        "size": 1542,
        "type": "Programming_language",
        "value": "ImageJ Macro"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Batchfile",
        "size": 799,
        "type": "Programming_language",
        "value": "Batchfile"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Makefile",
        "size": 633,
        "type": "Programming_language",
        "value": "Makefile"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Dockerfile",
        "size": 74,
        "type": "Programming_language",
        "value": "Dockerfile"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/sanghyeonp/MP-Net/master/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "somef_missing_categories": [
    "run",
    "requirements",
    "contact",
    "contributors",
    "documentation",
    "faq",
    "support",
    "identifier"
  ],
  "somef_provenance": {
    "date": "2024-10-04 14:13:44",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 0
      },
      "technique": "GitHub_API"
    }
  ],
  "type": [
    {
      "confidence": 0.82,
      "result": {
        "type": "String",
        "value": "commandline-application"
      },
      "technique": "software_type_heuristics"
    }
  ],
  "usage": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Getting Started",
        "parent_header": [
          "MP-Net"
        ],
        "type": "Text_excerpt",
        "value": "Set up an environment.\n\nClone the repository.\n```shell\ngit clone https://github.com/sanghyeonp/MP-Net.git\n```\n\nGo into the directory.\n```shell\ncd MP-Net\n```\n\nInstall required dependencies using the requirements.txt.\n```shell\npip install -r requirements.txt\n```\n\nNote: The code is written by utilizing and modifying other repositories. Detailed explanation and modification is listed below.\n\n* U-Net architecture and evaluation metrics: Utilized https://github.com/qubvel/segmentation_models.pytorch (Note that a modification was done to accuracy to compute balanced accuracy.)\n* Loss functions : https://www.kaggle.com/bigironsphere/loss-function-library-keras-pytorch\n\n"
      },
      "source": "https://raw.githubusercontent.com/sanghyeonp/MP-Net/master/README.md",
      "technique": "header_analysis"
    }
  ]
}