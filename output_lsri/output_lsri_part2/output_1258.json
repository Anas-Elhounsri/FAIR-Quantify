{
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/DorfnerM/SLANG"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2021-11-22T13:10:05Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2024-08-22T17:52:47Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "SLANG is a Python script pipeline for assembly, orthology estimation and SNP extraction of Nanopore-sequenced multi-locus data."
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 0.9513748501417786,
      "result": {
        "original_header": "SLANG",
        "type": "Text_excerpt",
        "value": "SLANG (Simple Long-read loci Assembly of Nanopore data for Genotyping) is a Python script pipeline for locus assembly, orthology estimation and SNP extraction of Nanopore-sequenced multi-locus data.  \nThere is no installation required for SLANG, only Python needs to be installed and either the Notebook version (.ipynb) or the Python script version (.py) needs to be downloaded and executed. SLANG was written with Python 3.7.6, but more recent versions work as well. \nSLANG is separated into three steps:\n1. Within-samples clustering (locus assembly): Input reads are clustered with vsearch according to read similarity. Similar reads are assumed to have the same origin and therefore belong to the same locus. Clustered reads are then mapped to their consensus sequence for further removal of highly erroneous reads, potential paralogs and reads of other loci (undersplitted loci).\n2. Among-samples clustering (orthology inference): Consensus sequences of the assembled loci are then clustered according to their similarity among all samples. Orthologous loci are therefore grouped together. Multiple consensus sequences of a single sample within a cluster (paralogous or oversplitted loci) are filtered. Clusters not meeting the minimum samples per locus count are also filtered.\n3. Reference-based SNP calling: SNPs are then called by mapping reads sample per sample to the consensus sequence made during among-samples clustering.  \n"
      },
      "source": "https://raw.githubusercontent.com/DorfnerM/SLANG/main/README.md",
      "technique": "supervised_classification"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/DorfnerM/SLANG/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "executable_example": [
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/DorfnerM/SLANG/main/SLANG_notebook_version.ipynb"
      },
      "source": "https://raw.githubusercontent.com/DorfnerM/SLANG/main/SLANG_notebook_version.ipynb",
      "technique": "file_exploration"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 0
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/DorfnerM/SLANG/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "DorfnerM/SLANG"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "SLANG"
      },
      "source": "https://raw.githubusercontent.com/DorfnerM/SLANG/main/README.md",
      "technique": "regular_expression"
    }
  ],
  "installation": [
    {
      "confidence": 0.9999254087500006,
      "result": {
        "original_header": "SLANG",
        "type": "Text_excerpt",
        "value": "There is no installation required for SLANG, only Python needs to be installed and either the Notebook version (.ipynb) or the Python script version (.py) needs to be downloaded and executed. SLANG was written with Python 3.7.6, but more recent versions work as well. \nHere, a Python Notebook (.ipynb) and a Python script (.py) version of SLANG are offered, depending on usage preference. For running the notebook version, [Jupyter](https://jupyter.org/) is required.\n \n"
      },
      "source": "https://raw.githubusercontent.com/DorfnerM/SLANG/main/README.md",
      "technique": "supervised_classification"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/DorfnerM/SLANG/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ""
      },
      "technique": "GitHub_API"
    }
  ],
  "license": [
    {
      "confidence": 1,
      "result": {
        "name": "MIT License",
        "spdx_id": "MIT",
        "type": "License",
        "url": "https://api.github.com/licenses/mit",
        "value": "https://api.github.com/licenses/mit"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "type": "File_dump",
        "value": "MIT License\n\nCopyright (c) 2021 DorfnerM\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
      },
      "source": "https://raw.githubusercontent.com/DorfnerM/SLANG/main/LICENSE",
      "technique": "file_exploration"
    }
  ],
  "logo": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://user-images.githubusercontent.com/94844710/161264733-1c37a2c5-4bfe-4893-ba3a-68b2b108c625.png"
      },
      "source": "https://raw.githubusercontent.com/DorfnerM/SLANG/main/README.md",
      "technique": "regular_expression"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "SLANG"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "User",
        "value": "DorfnerM"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Jupyter Notebook",
        "size": 98196,
        "type": "Programming_language",
        "value": "Jupyter Notebook"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 98111,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/DorfnerM/SLANG/main/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "requirements": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Dependencies:",
        "parent_header": [
          "SLANG"
        ],
        "type": "Text_excerpt",
        "value": "- [VSEARCH](https://github.com/torognes/vsearch): \n- [samtools/BCFtools/HTSlib](http://www.htslib.org/)\n- [minimap2](https://github.com/lh3/minimap2)\n- [vcflib](https://github.com/vcflib/vcflib)\n- [numpy](https://numpy.org/)\n- [pandas](https://pandas.pydata.org/)  \n- [matplotlib](https://matplotlib.org/)\n- [natsort](https://pypi.org/project/natsort/)\n- [nei_vcf](https://github.com/TankredO/nei_vcf) (if Nei-Li genetic distances need to be calculated from the VCF output of SLANG)\n\nInstallation with the package manager [conda](https://docs.conda.io/en/latest/) is recommended.\nCommand lines for installing the dependencies:\n- `conda install -c bioconda vsearch`\n- `conda install -c bioconda samtools`\n- `conda install -c bioconda bcftools`\n- `conda install -c bioconda htslib`\n- `conda install -c bioconda minimap2`\n- `conda install -c bioconda vcflib`\n- `conda install -c anaconda numpy`\n- `conda install -c anaconda pandas`\n- `conda install -c conda-forge matplotlib`\n- `conda install -c anaconda natsort`\n"
      },
      "source": "https://raw.githubusercontent.com/DorfnerM/SLANG/main/README.md",
      "technique": "header_analysis"
    }
  ],
  "somef_missing_categories": [
    "citation",
    "acknowledgement",
    "run",
    "download",
    "contact",
    "contributors",
    "documentation",
    "faq",
    "support",
    "identifier",
    "has_build_file"
  ],
  "somef_provenance": {
    "date": "2024-10-04 13:47:19",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 2
      },
      "technique": "GitHub_API"
    }
  ],
  "type": [
    {
      "confidence": 0.82,
      "result": {
        "type": "String",
        "value": "commandline-application"
      },
      "technique": "software_type_heuristics"
    }
  ],
  "usage": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Input and Usage:",
        "parent_header": [
          "SLANG"
        ],
        "type": "Text_excerpt",
        "value": "SLANG assembles loci, infers orthology and calls SNPs only from your preprocessed (demultiplexed and quality -and length-filtered) Nanopore reads in FASTQ format. Before running SLANG, one FASTQ file of each sample is required. The name of the FASTQ file must include the Barcode used for this sample, e.g. `bc01_samplename.fastq`. All FASTQ files should then be placed into the same directory.\n\nAfterwards, the run can be configured in the SLANG script by opening it with a text editor. In the header of the SLANG script, input and parameters for the run can be set:\n\n| parameter | explanation | example   |\n| ------------- |:-------------:|:----------------------:|\n| analysis_dir  | Defines a directory for your SLANG analysis. The directory will be made and if it already exists, you will be notified. Needs to be given in `''` and end with `/`. |'/home/mySLANGanalysis/'|\n| filtered_reads_dir | Input path to your directory containing the preprocessed FASTQ reads. Needs to be given in `''` and end with `/`. | '/home/myFASTQreads/'\n| barcodes | Insert all barcode identifiers used in the analysis. Needs to be given in `''` and as a Python list in `[]`, separated by `,` | '[bc01, bc02, bc03]'\n| within_samples_clustering_ct | Defines the similarity threshold for the within-samples clustering (locus assembly). Needs to be given as a value between 0.00 (0% similarity) and 1.00 (100% similarity) in `''`. | '0.75' |\n| in_between_samples_clustering_ct | Defines the similarity threshold for the among-samples clustering (orthology inference). Needs to be given as a value between 0.00 (0% similarity) and 1.00 (100% similarity) in `''`. This value should be higher than the within-samples clustering similarity threshold. | '0.90'\n| minimum_depth | Defines the minimum read depth for the analysis. Variant calling requires at least five reads per allele. | 10 |\n| minimum_sample_per_locus | Defines how many samples need to share the same locus for the locus to pass filters and be analyzed. The value must be at least 2. | 2 |\n| threads | Defines how many threads of your system should be used for certain tasks of SLANG, e.g. vsearch clustering and minimap2 mapping. The higher, the faster the analysis. Needs to be given in `''` | '10' |\n\nWith these parameters edited, SLANG can be executed through a command line interface by entering `python SLANG.py` and executing, if using the Python script version. \nWhen the Python Notebook version is used, execute the column of the parameters, check the printed output for errors, then execute the column below with the main script.\n"
      },
      "source": "https://raw.githubusercontent.com/DorfnerM/SLANG/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Usage example: Adjusting within-samples and among-samples clustering similarity thresholds",
        "parent_header": [
          "SLANG"
        ],
        "type": "Text_excerpt",
        "value": "An important part of the analysis is the choice of the within-samples and among-samples clustering similarity threshold. With these, loci and orthology are defined, therefore a careful selection is necessary in order to attain robust results. If similarity thresholds are too high, there is an increased risk of oversplitting the alleles of a locus into multiple clusters, and if similarity thesholds are too low, the risk of multiple loci clustered together (locus undersplitting) is increased. The goal is to find a similarity threshold, where both under- and oversplitting is minimized. While being optional and choosing the default values (0.75 and 0.90) or other non-extreme values can provide satisfactory results, it is recommended to adjust the similarity thresholds for each individual dataset. In the following, one possible way of determining similarity thresholds is explained.\n\nTo determine a valid within-samples clustering threshold, run multiple instances of the script with the within-samples similarity threshold changed in incremental steps (e.g. 0.05). Run the analysis until the `my_analysis/within_samples_clustering/unmapped_reads_log.csv` is produced (a notification is printed to the terminal), then count the number of clusters with any number of unmapped reads from it. An unmapped read could indicate a highly erroneous read, a paralogous read or a read belonging to another locus (locus undersplitting). For the reason of minimizing locus undersplitting, the number of clusters with unmapped reads should be low. Next, add up the total cluster count of all samples. The total cluster count is outputted by the script for each sample after within-samples clustering is finished. Locus oversplitting should be increased with higher total cluster count. Finally, multiply the total cluster count and the number of clusters with unmapped reads. This formula favors similarity thresholds, where high number of total clusters are formed, but with as less clusters with unmapped reads as possible. For this reason, the similarity threshold with the highest value should represent a tradeoff between locus over- and undersplitting.\n\nAfter determining a within-samples clustering threshold, again run multiple instances of the script with the previously determined within-samples clustering similarity threshold, but this time with the among-samples similarity threshold changed in incremental steps (e.g. 0.05). The value should be higher than the within-samples similarity threshold. Here, only clusters will pass if each sample is represented by a single consensus sequence. High similarity thresholds lead to many single sample clusters, which are filtered. Low similarity thresholds will result in clusters, where multiple consensus sequences of the same sample are clustered together, which are also filtered out (indication of oversplitted loci clustering back together). As a consequence, an optimal among-samples clustering similarity threshold filters out as few clusters as possible. The VCF file resulting from this analysis can then be used for downstream analysis.\n"
      },
      "source": "https://raw.githubusercontent.com/DorfnerM/SLANG/main/README.md",
      "technique": "header_analysis"
    }
  ]
}