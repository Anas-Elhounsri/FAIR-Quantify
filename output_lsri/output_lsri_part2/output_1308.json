{
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/ewissel/hAMRoaster"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2021-10-18T17:37:03Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2024-05-10T02:17:27Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "hAMRoaster is an analysis pipeline that can compare the output of tools for detecting AMR genes and provide metrics of their performance"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 0.9968382933776235,
      "result": {
        "original_header": "**H**armonized **AMR O**utput comp**A**ri**S**on **T**ool **ER**",
        "type": "Text_excerpt",
        "value": "\nhAMRoaster is an analysis pipeline that can compare the output of nine different tools for detecting AMR genes and provide metrics of their performance. For most tools, hAMRoaster requires preprocessing with hAMRonization. \n \n"
      },
      "source": "https://raw.githubusercontent.com/ewissel/hAMRoaster/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9306131132992566,
      "result": {
        "original_header": "hAMRoaster Commands",
        "type": "Text_excerpt",
        "value": "* `--AMR_key` : the full path to the file of known AMR phenotypes; the file is expected to be a tsv in the following format: taxa_name, antibiotic tested, result of antibiotic resting, and testing standard. This matches the output for the [NCBI BioSample AntiBioGram](https://www.ncbi.nlm.nih.gov/biosample/?term=antibiogram%5bfilter%5d). An example file is in `study_data/mock_2_key.csv`. If you are using the `--groupby_sample` flag, you want the sample names in the AMR_key to but the same as the `--input_file_names` flag in hamroanizer and in the `--ham_out` flag. \n \n"
      },
      "source": "https://raw.githubusercontent.com/ewissel/hAMRoaster/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.943127408884255,
      "result": {
        "original_header": "Optional Arguments",
        "type": "Text_excerpt",
        "value": "* `--abx_map` : While hAMRoaster comes with it's own classifications for antibiotics and their drug class, users can provide their own classification scheme. This expects the drug class to in the first column, and the antibiotics or drugs that fit into that drug class in the next two columns. hAMRoaster's default classification is located in `db_files/cleaned_drug_class_key.csv`.  \n* `--fargene` : If users want to test the output of fARGene runs, they can point to the directory of the fARGene output. Because fARGene requires multiple runs for all the built in models, hAMRoaster expects users to point to a generic `fargene_output` directory, and for each run to be a subdirectory named after the AMR model analyzed for that run. For example, for a fARGene run with the model flag `class_a`, hAMRoaster expects their to be a directory named `class_a` within the fargene output directory specified with this parameter, and that the `class_a` subdirectory contains the output of that fARGene run. hAMRoaster can handle empty files in the output directories, such as when fARGene runs but does not detect AMR genes.  \n* `--shortbred_map` : This flag can point to a specific file that maps the shortbred IDs to their AMR gene names. hAMRoaster included the mapping file created with the shortbred publication in 2016. It is used by default and located in `db_files/ShortBRED_ABR_Metadata.tab`.  \n"
      },
      "source": "https://raw.githubusercontent.com/ewissel/hAMRoaster/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9839129279737966,
      "result": {
        "original_header": "Understanding Output Files",
        "type": "Text_excerpt",
        "value": "* `thanksgiving_ham_{name}.csv`: This file provides the endpoint metrics for each of the tools included in a run. \n* `cooked_ham_w_true_pos_{name}.csv`: This file contains the cleaned up and labelled version of the input data (drug classes cleaned up and true positive/negative/unknowns assigned) \n \n* `grouped_by_tool_drug_class{name}.csv`: This file contains the number of detected AMR genes per drug class per tool. \n* depreciated, version 1 only: `canned_ham_{name}.csv`: This contains the results when overlapping genes are removed (i.e. AMR genes that are detected in overlapping regions of the input FASTA/Q are reduced so that none of the AMR genes provided in this file overlap). We did not find this practical for understanding results or getting closer to the \"truth\", but we are including the file for replication's sake. \n* depreciated, version 1 only: `combo_counts{name}.txt`: This file contains the count data if ALL tools are combined. In our analysis, we did not find these counts particularly useful in understanding tool performance, but we provide them anyway incase others want to replicate our findings. \n"
      },
      "source": "https://raw.githubusercontent.com/ewissel/hAMRoaster/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9418676866311035,
      "result": {
        "original_header": "Replicating hAMRoaster publication analysis",
        "type": "Text_excerpt",
        "value": "The following will walk through the code for the analysis done as an initial test of hAMRoaster and published with the hAMRoaster pipeline, from creating simulated metagenomic sequences to analyzing the data in hAMRoaster. \n \n"
      },
      "source": "https://raw.githubusercontent.com/ewissel/hAMRoaster/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9951313792461912,
      "result": {
        "original_header": "Create Simulated Mock Community with extensive resistance",
        "type": "Text_excerpt",
        "value": "With this, three mock communities were generated for the three coverage levels (5x,50x, and 100x).If you run into any issues with this section, I recommend checking that the number of reads (lines) and bases (words) is the same across your input files for each step, which you can check with `wc combo_*`. \n \n"
      },
      "source": "https://raw.githubusercontent.com/ewissel/hAMRoaster/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9924897549250803,
      "result": {
        "original_header": "Creating a community with Restrictive Resistance",
        "type": "Text_excerpt",
        "value": "We created a community profile with previously simulated human metagenomes from [CAMISIM](https://frl.publisso.de/data/frl:6425518/gastrooral/) and added a single AMR isolate collected from a human infection at 1x coverage to simulate a human metagenome with restrictive phenotypic resistance. We included samples 0 through 5 from CAMISIM and combined these with one of two isolates, [SRR17789825](https://www.ncbi.nlm.nih.gov/biosample/25295985) for even sample numbers and  [SRR16683675](https://www.ncbi.nlm.nih.gov/biosample/22824038) for odd sample numbers. \n"
      },
      "source": "https://raw.githubusercontent.com/ewissel/hAMRoaster/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9858943244274596,
      "result": {
        "original_header": "Combining the Outputs",
        "type": "Text_excerpt",
        "value": "hAMRonization is a strong tool which creates a unified format for examining the output of many different AMR analysis tools. Note that all the tools accomidated by the hAMRonization format are not included in this study as they did not meet all the eligibility criteria. For a further explanation, look at the table in the hAMRoaster publication which walks through 16 tools for AMR gene detection and their reasons for inclusion/exclusion. \nAt the time of analysis, hAMRonization was under development and documentation was not yet complete. As such, the database versions and analysis software versions, which are required flags for hAMRonization, reflect a minimally sufficient string for this and not the true version used in this analysis. This is not a recommended use of this tool or these flags, but we are including this detail for the sake of true replication. \n* RGI: `hamronize rgi --input_file_name sample_name --analysis_software_version 5.1.1  --reference_database_version v3.0.9 rgi_out/rgi_out`\n \n           * Note: hamronizer currently filters out mutational resistance from RGI, so this is a caveat to keep in mind\n \n To combine the hamronized outputs into one table: \n \n `hamronize summarize * -t tsv -o ham_sum.tsv`\n \n ## Analyzing result\n \nThis analysis was motivated by the lack of an open-source pipeline for comparing the results once compiled. hAMRoaster was built so that results can easily be compared using several metrics across tools. The ham_sum.tsv file created in the last step is the main input to hAMRoaster.  \n"
      },
      "source": "https://raw.githubusercontent.com/ewissel/hAMRoaster/main/README.md",
      "technique": "supervised_classification"
    }
  ],
  "documentation": [
    {
      "confidence": 1,
      "result": {
        "format": "wiki",
        "type": "Url",
        "value": "https://github.com/ncbi/amr/wiki"
      },
      "source": "https://raw.githubusercontent.com/ewissel/hAMRoaster/main/README.md",
      "technique": "regular_expression"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/ewissel/hAMRoaster/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 3
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/ewissel/hAMRoaster/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "ewissel/hAMRoaster"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "hAMRoaster"
      },
      "source": "https://raw.githubusercontent.com/ewissel/hAMRoaster/main/README.md",
      "technique": "regular_expression"
    }
  ],
  "has_script_file": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/ewissel/hAMRoaster/main/build.sh"
      },
      "technique": "file_exploration"
    }
  ],
  "installation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Installing hAMRoaster",
        "parent_header": [
          "hAMRoaster",
          "**H**armonized **AMR O**utput comp**A**ri**S**on **T**ool **ER**"
        ],
        "type": "Text_excerpt",
        "value": "hAMRoaster is available on Bioconda\n```\nconda create -n hamroaster -c conda-forge -c bioconda hamroaster\nconda activate hamroaster\nhAMRoaster -h\n```\n*(notice the caps in hAMRoaster)*\n"
      },
      "source": "https://raw.githubusercontent.com/ewissel/hAMRoaster/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 0.9315447188534745,
      "result": {
        "original_header": "hAMRoaster Commands",
        "type": "Text_excerpt",
        "value": "hAMRoaster has several required and optional commands. At a minimum, users **must** provide the following flags.  \n* `--name`: a unique identifier for this run. This name will be the name of the output directory created for the hAMRoaster run, and the name will be included in all the output file names.  \n"
      },
      "source": "https://raw.githubusercontent.com/ewissel/hAMRoaster/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9981904748973507,
      "result": {
        "original_header": "Optional Arguments",
        "type": "Text_excerpt",
        "value": "* `--shortbred` : If users want to test the output of a shortBRED run, they can use this flag to specifcy the full path to the output directory for shortbred (do not include the file in the path; can handle multiple files in the output directory).  \n\nExample usage:\n```\nhAMRoaster --ham_out amr-benchmarking/hAMRoaster/study_data/ham_sum.tsv  \\\n           --name test_conda \\\n           --AMR_key amr-benchmarking/hAMRoaster/study_data/mock_2_key.csv \\\n           --db_files amr-benchmarking/hAMRoaster/\n\n## the above is used to test the conda install with locally stored study data (available on this repo)\n```\n \n"
      },
      "source": "https://raw.githubusercontent.com/ewissel/hAMRoaster/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8938172419650107,
      "result": {
        "original_header": "Understanding Output Files",
        "type": "Text_excerpt",
        "value": "hAMRoaster will create all output files in a directory that the user specified with the `--name` command. Further, all files will have the `--name` argument in the file name so that different runs can be compared without confusion. \n"
      },
      "source": "https://raw.githubusercontent.com/ewissel/hAMRoaster/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9999998828084882,
      "result": {
        "original_header": "Create Simulated Mock Community with extensive resistance",
        "type": "Text_excerpt",
        "value": "Once fastqs were combined, contigs were assembled using metaSPAdes. \n```\nconda create -y -n spades-test -c conda-forge -c bioconda spades 'python=3.7.7'\nconda activate spades-test \n\nspades.py --meta  --pe1-1 combo_1.fq --pe1-2 combo_2.fq -o fasta/ \n```\n \n"
      },
      "source": "https://raw.githubusercontent.com/ewissel/hAMRoaster/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9274829858672621,
      "result": {
        "original_header": "Combining the Outputs",
        "type": "Text_excerpt",
        "value": "`conda install hAMRonization ` \n* ABRicate: `hamronize abricate  abricate_out/abricate_out.txt --reference_database_version 2021-Mar-27 --analysis_software_version v.1.0.1 --format tsv `  \n* starAMR: `hamronize staramr staramr_out/resfinder.tsv --format tsv --output hamr_out/staramr.tsv --reference_database_version 050218 --analysis_software_version v0.7.2 `   \n* ResFinder: `hamronize resfinder4 resfinder_out/ResFinder_results_tab.txt   --reference_database_version 2021-04-13 --analysis_software_version v4.1.11 --output hamr_out/resfinder.tsv --input_file_name sample_name` \n"
      },
      "source": "https://raw.githubusercontent.com/ewissel/hAMRoaster/main/README.md",
      "technique": "supervised_classification"
    }
  ],
  "invocation": [
    {
      "confidence": 0.8232881262847382,
      "result": {
        "original_header": "Combining the Outputs",
        "type": "Text_excerpt",
        "value": "* sraX: `hamronize srax sraX_out/Results/Summary_files/sraX_detected_ARGs.tsv --reference_database_version 3.0.7  --analysis_software_version v1.5 --format tsv --output hamr_out/srax.tsv  --reference_database_id basic --input_file_name sample_name ` \n"
      },
      "source": "https://raw.githubusercontent.com/ewissel/hAMRoaster/main/README.md",
      "technique": "supervised_classification"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/ewissel/hAMRoaster/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "amr, antibiotic, bioinformatics, metagenomics, microbiology"
      },
      "technique": "GitHub_API"
    }
  ],
  "license": [
    {
      "confidence": 1,
      "result": {
        "name": "Creative Commons Zero v1.0 Universal",
        "spdx_id": "CC0-1.0",
        "type": "License",
        "url": "https://api.github.com/licenses/cc0-1.0",
        "value": "https://api.github.com/licenses/cc0-1.0"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "type": "File_dump",
        "value": "Creative Commons Legal Code\n\nCC0 1.0 Universal\n\n    CREATIVE COMMONS CORPORATION IS NOT A LAW FIRM AND DOES NOT PROVIDE\n    LEGAL SERVICES. DISTRIBUTION OF THIS DOCUMENT DOES NOT CREATE AN\n    ATTORNEY-CLIENT RELATIONSHIP. CREATIVE COMMONS PROVIDES THIS\n    INFORMATION ON AN \"AS-IS\" BASIS. CREATIVE COMMONS MAKES NO WARRANTIES\n    REGARDING THE USE OF THIS DOCUMENT OR THE INFORMATION OR WORKS\n    PROVIDED HEREUNDER, AND DISCLAIMS LIABILITY FOR DAMAGES RESULTING FROM\n    THE USE OF THIS DOCUMENT OR THE INFORMATION OR WORKS PROVIDED\n    HEREUNDER.\n\nStatement of Purpose\n\nThe laws of most jurisdictions throughout the world automatically confer\nexclusive Copyright and Related Rights (defined below) upon the creator\nand subsequent owner(s) (each and all, an \"owner\") of an original work of\nauthorship and/or a database (each, a \"Work\").\n\nCertain owners wish to permanently relinquish those rights to a Work for\nthe purpose of contributing to a commons of creative, cultural and\nscientific works (\"Commons\") that the public can reliably and without fear\nof later claims of infringement build upon, modify, incorporate in other\nworks, reuse and redistribute as freely as possible in any form whatsoever\nand for any purposes, including without limitation commercial purposes.\nThese owners may contribute to the Commons to promote the ideal of a free\nculture and the further production of creative, cultural and scientific\nworks, or to gain reputation or greater distribution for their Work in\npart through the use and efforts of others.\n\nFor these and/or other purposes and motivations, and without any\nexpectation of additional consideration or compensation, the person\nassociating CC0 with a Work (the \"Affirmer\"), to the extent that he or she\nis an owner of Copyright and Related Rights in the Work, voluntarily\nelects to apply CC0 to the Work and publicly distribute the Work under its\nterms, with knowledge of his or her Copyright and Related Rights in the\nWork and the meaning and intended legal effect of CC0 on those rights.\n\n1. Copyright and Related Rights. A Work made available under CC0 may be\nprotected by copyright and related or neighboring rights (\"Copyright and\nRelated Rights\"). Copyright and Related Rights include, but are not\nlimited to, the following:\n\n  i. the right to reproduce, adapt, distribute, perform, display,\n     communicate, and translate a Work;\n ii. moral rights retained by the original author(s) and/or performer(s);\niii. publicity and privacy rights pertaining to a person's image or\n     likeness depicted in a Work;\n iv. rights protecting against unfair competition in regards to a Work,\n     subject to the limitations in paragraph 4(a), below;\n  v. rights protecting the extraction, dissemination, use and reuse of data\n     in a Work;\n vi. database rights (such as those arising under Directive 96/9/EC of the\n     European Parliament and of the Council of 11 March 1996 on the legal\n     protection of databases, and under any national implementation\n     thereof, including any amended or successor version of such\n     directive); and\nvii. other similar, equivalent or corresponding rights throughout the\n     world based on applicable law or treaty, and any national\n     implementations thereof.\n\n2. Waiver. To the greatest extent permitted by, but not in contravention\nof, applicable law, Affirmer hereby overtly, fully, permanently,\nirrevocably and unconditionally waives, abandons, and surrenders all of\nAffirmer's Copyright and Related Rights and associated claims and causes\nof action, whether now known or unknown (including existing as well as\nfuture claims and causes of action), in the Work (i) in all territories\nworldwide, (ii) for the maximum duration provided by applicable law or\ntreaty (including future time extensions), (iii) in any current or future\nmedium and for any number of copies, and (iv) for any purpose whatsoever,\nincluding without limitation commercial, advertising or promotional\npurposes (the \"Waiver\"). Affirmer makes the Waiver for the benefit of each\nmember of the public at large and to the detriment of Affirmer's heirs and\nsuccessors, fully intending that such Waiver shall not be subject to\nrevocation, rescission, cancellation, termination, or any other legal or\nequitable action to disrupt the quiet enjoyment of the Work by the public\nas contemplated by Affirmer's express Statement of Purpose.\n\n3. Public License Fallback. Should any part of the Waiver for any reason\nbe judged legally invalid or ineffective under applicable law, then the\nWaiver shall be preserved to the maximum extent permitted taking into\naccount Affirmer's express Statement of Purpose. In addition, to the\nextent the Waiver is so judged Affirmer hereby grants to each affected\nperson a royalty-free, non transferable, non sublicensable, non exclusive,\nirrevocable and unconditional license to exercise Affirmer's Copyright and\nRelated Rights in the Work (i) in all territories worldwide, (ii) for the\nmaximum duration provided by applicable law or treaty (including future\ntime extensions), (iii) in any current or future medium and for any number\nof copies, and (iv) for any purpose whatsoever, including without\nlimitation commercial, advertising or promotional purposes (the\n\"License\"). The License shall be deemed effective as of the date CC0 was\napplied by Affirmer to the Work. Should any part of the License for any\nreason be judged legally invalid or ineffective under applicable law, such\npartial invalidity or ineffectiveness shall not invalidate the remainder\nof the License, and in such case Affirmer hereby affirms that he or she\nwill not (i) exercise any of his or her remaining Copyright and Related\nRights in the Work or (ii) assert any associated claims and causes of\naction with respect to the Work, in either case contrary to Affirmer's\nexpress Statement of Purpose.\n\n4. Limitations and Disclaimers.\n\n a. No trademark or patent rights held by Affirmer are waived, abandoned,\n    surrendered, licensed or otherwise affected by this document.\n b. Affirmer offers the Work as-is and makes no representations or\n    warranties of any kind concerning the Work, express, implied,\n    statutory or otherwise, including without limitation warranties of\n    title, merchantability, fitness for a particular purpose, non\n    infringement, or the absence of latent or other defects, accuracy, or\n    the present or absence of errors, whether or not discoverable, all to\n    the greatest extent permissible under applicable law.\n c. Affirmer disclaims responsibility for clearing rights of other persons\n    that may apply to the Work or any use thereof, including without\n    limitation any person's Copyright and Related Rights in the Work.\n    Further, Affirmer disclaims responsibility for obtaining any necessary\n    consents, permissions or other rights required for any use of the\n    Work.\n d. Affirmer understands and acknowledges that Creative Commons is not a\n    party to this document and has no duty or obligation with respect to\n    this CC0 or use of the Work.\n"
      },
      "source": "https://raw.githubusercontent.com/ewissel/hAMRoaster/main/LICENSE",
      "technique": "file_exploration"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "hAMRoaster"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "User",
        "value": "ewissel"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 43210,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Shell",
        "size": 235,
        "type": "Programming_language",
        "value": "Shell"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Batchfile",
        "size": 51,
        "type": "Programming_language",
        "value": "Batchfile"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/ewissel/hAMRoaster/main/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "releases": [
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "ewissel",
          "type": "User"
        },
        "date_created": "2022-10-31T18:57:38Z",
        "date_published": "2023-01-23T16:25:49Z",
        "description": "Added new feature `--groupby_sample` and removed `canned_ham` and other confusing outputs from hAMRoaster. ",
        "html_url": "https://github.com/ewissel/hAMRoaster/releases/tag/v2.0",
        "name": "v2.0",
        "release_id": 89936765,
        "tag": "v2.0",
        "tarball_url": "https://api.github.com/repos/ewissel/hAMRoaster/tarball/v2.0",
        "type": "Release",
        "url": "https://api.github.com/repos/ewissel/hAMRoaster/releases/89936765",
        "value": "https://api.github.com/repos/ewissel/hAMRoaster/releases/89936765",
        "zipball_url": "https://api.github.com/repos/ewissel/hAMRoaster/zipball/v2.0"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "ewissel",
          "type": "User"
        },
        "date_created": "2021-11-17T03:42:20Z",
        "date_published": "2021-11-29T18:40:13Z",
        "description": "updating user args to be more friendly to command line usage ",
        "html_url": "https://github.com/ewissel/hAMRoaster/releases/tag/v1.1",
        "name": "v1.1",
        "release_id": 54264701,
        "tag": "v1.1",
        "tarball_url": "https://api.github.com/repos/ewissel/hAMRoaster/tarball/v1.1",
        "type": "Release",
        "url": "https://api.github.com/repos/ewissel/hAMRoaster/releases/54264701",
        "value": "https://api.github.com/repos/ewissel/hAMRoaster/releases/54264701",
        "zipball_url": "https://api.github.com/repos/ewissel/hAMRoaster/zipball/v1.1"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "ewissel",
          "type": "User"
        },
        "date_created": "2021-10-28T17:30:22Z",
        "date_published": "2021-10-28T17:51:24Z",
        "description": "The release is made to be a better fit for users to download via github / conda",
        "html_url": "https://github.com/ewissel/hAMRoaster/releases/tag/v1.0",
        "name": "v1.0",
        "release_id": 52258617,
        "tag": "v1.0",
        "tarball_url": "https://api.github.com/repos/ewissel/hAMRoaster/tarball/v1.0",
        "type": "Release",
        "url": "https://api.github.com/repos/ewissel/hAMRoaster/releases/52258617",
        "value": "https://api.github.com/repos/ewissel/hAMRoaster/releases/52258617",
        "zipball_url": "https://api.github.com/repos/ewissel/hAMRoaster/zipball/v1.0"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "ewissel",
          "type": "User"
        },
        "date_created": "2021-10-26T21:16:29Z",
        "date_published": "2021-10-27T16:42:41Z",
        "html_url": "https://github.com/ewissel/hAMRoaster/releases/tag/launch",
        "name": "initial release",
        "release_id": 52160533,
        "tag": "launch",
        "tarball_url": "https://api.github.com/repos/ewissel/hAMRoaster/tarball/launch",
        "type": "Release",
        "url": "https://api.github.com/repos/ewissel/hAMRoaster/releases/52160533",
        "value": "https://api.github.com/repos/ewissel/hAMRoaster/releases/52160533",
        "zipball_url": "https://api.github.com/repos/ewissel/hAMRoaster/zipball/launch"
      },
      "technique": "GitHub_API"
    }
  ],
  "run": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Running Mock Community through AMR Detection Tools",
        "parent_header": [
          "Replicating hAMRoaster publication analysis"
        ],
        "type": "Text_excerpt",
        "value": "This section will walk through how we set up a conda environment for each of the bioinformatic tools included in the hAMRoaster publication, in no particular order.\n"
      },
      "source": "https://raw.githubusercontent.com/ewissel/hAMRoaster/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "<a href=\"https://github.com/biobakery/shortbred\">shortBRED</a>",
        "parent_header": [
          "Replicating hAMRoaster publication analysis",
          "Running Mock Community through AMR Detection Tools"
        ],
        "type": "Text_excerpt",
        "value": "shortBRED13 v0.9.3 uses a set of marker genes to search metagenomic data for protein families of interest. The bioBakery team published an AMR gene marker database built from 849 AR protein families derived from the ARDB20 v1.1 and independent curation alongside shortBRED, which is used in this study.\n\n```\nconda create \u2013n shortbred -c biobakery -c conda-forge -c bioconda shortbred 'python=3.7'\nconda activate shortbred\n\n## download database  \nmkdir shortbred_database\ncd shortbred_database\nwget https://raw.githubusercontent.com/biobakery/shortbred/master/sample_markers/ShortBRED_ARDB_Evaluation_markers.faa\n\nshortbred_quantify.py --markers /full/path/to/shortbred_database/ShortBRED_ARDB_Evaluation_markers.faa \\\n                      --wgs /full/path/to/fastas/contigs.fasta \\\n                      --results combo_shortbred.tsv \\\n                      --tmp combo_quant \\\n                      --usearch /full/path/to/usearch11.0.667_i86linux32 \n```\n"
      },
      "source": "https://raw.githubusercontent.com/ewissel/hAMRoaster/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "<a href=\"https://github.com/fannyhb/fargene\">fARGene</a>",
        "parent_header": [
          "Replicating hAMRoaster publication analysis",
          "Running Mock Community through AMR Detection Tools"
        ],
        "type": "Text_excerpt",
        "value": "fARGene v.0.1 uses Hidden Markov Models to detect AMR genes from short metagenomic data or long read data. This is different from most other tools which compare the reads directly. fARGene has three pre-built models for detecting resistance to quinolone, tetracycline, and beta lactamases, which we test here.\n\n```\nconda create -n fargene -c conda-forge -c bioconda fargene \nconda activate fargene\n\nfargene -i fastq/combo* --store-peptides --hmm-model class_a -o fargene_out_fa/class_a --meta --force \n```\n\nThe following arguments were used with the `--hmm-model` flag to run all the pre-built fARGene models, with the output directory matching the name and spelling of the `--hmm-model` flag: `class_a`, `class_b_1_2`, `class_b_3`, `class_c`, `class_d_1`, `class_d_2`, qnr, `tet_efflux`, `tet_rpg`, and `tet_enzyme`.\n"
      },
      "source": "https://raw.githubusercontent.com/ewissel/hAMRoaster/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "<a href=\"https://github.com/ncbi/amr/wiki\">AMRFinderPlus</a>",
        "parent_header": [
          "Replicating hAMRoaster publication analysis",
          "Running Mock Community through AMR Detection Tools"
        ],
        "type": "Text_excerpt",
        "value": "AMR Finder Plus v.3.9.3 uses BLASTX translated searches and hierarchical tree of gene families to detect AMR genes. The database is derived from the Pathogen Detection Reference Gene Catalog and was compiled as part of the National Database of Antibiotic Resistant Organisms (NDARO).\n\n```\nconda create -n amrfinderplus -c conda-forge -c bioconda ncbi-amrfinderplus \nconda activate amrfinderplus\n\namrfinder -n fasta/contigs.fasta --plus --threads 3 -o AMRFinderPlus_out/combo_out \n```\n"
      },
      "source": "https://raw.githubusercontent.com/ewissel/hAMRoaster/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "<a href=\"https://github.com/arpcard/rgi\">RGI</a>",
        "parent_header": [
          "Replicating hAMRoaster publication analysis",
          "Running Mock Community through AMR Detection Tools"
        ],
        "type": "Text_excerpt",
        "value": "RGI v5.1.1 uses protein homology and SNP models to predict \u2018resistomes\u2019. It uses CARD\u2019s protein homolog models as a database. RGI predicts open reading frames (ORFs) using Prodigal, detects homologs with DIAMOND, and matches to CARD\u2019s database and model cut off values. \n\n```\n## note I needed to use the prefix flag for this to work\nconda create --prefix=/home/ewissel/conda/rgi -c bioconda -c conda-forge -c defaults 'rgi=5.1.1'   \nconda activate /home/ewissel/conda/rgi \n\nrgi main -i fasta/contigs.fasta -o rgi_out -t contig \n```\n"
      },
      "source": "https://raw.githubusercontent.com/ewissel/hAMRoaster/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "<a href=\"https://cge.cbs.dtu.dk/services/ResFinder/\">ResFinder</a>",
        "parent_header": [
          "Replicating hAMRoaster publication analysis",
          "Running Mock Community through AMR Detection Tools"
        ],
        "type": "Text_excerpt",
        "value": "ResFinder v4.0 is available both as a web based application or the command line. We use ResFinder 4 for this data, which was specifically designed for detecting genotypic resistance in phenotypically resistant samples. ResFinder aligns reads directly to its own curated database without need for assembly. \n\nPlease note that this was run while ResFinder was being updated to version 4.0 (and the docker version was catching up). I ran into issues with the docker version of ResFinder in May/June, and instead used the web based ResFinder results in the publication study; hyperlink to the web based ResFinder in the heading of this section. \n\n```\ndocker build -t resfinder . \n\ndocker run --rm -it \\\n           -v $(pwd)/db_resfinder/:/usr/src/db_resfinder \\\n           -v $(pwd)/results/:/usr/src/results resfinder \\\n           -v $(pwd)/dat/combo_1.fq:/usr/src/combo_1.fq \\\n           -ifq /usr/src/combo_1.fq  /usr/src/combo_2.fq \\\n           -acq \\\n           -db_res /usr/src/db_resfinder \\\n           -o /usr/src/results \n```\n\n* Note: As of August 2022 the conda version of ResFinder4 is working just fine! Here is the code I used. \n\n```\nconda activate resfinder4 \n\nconda install -c dfornika resfinder  \n\n# Example of running resfinder \nrun_resfinder.py -o path/to/outdir  -l 0.6 -t 0.8 --acquired \u2013ifa \u2013u  \n```"
      },
      "source": "https://raw.githubusercontent.com/ewissel/hAMRoaster/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "<a href=\"https://github.com/tseemann/abricate\">ABRicate</a>",
        "parent_header": [
          "Replicating hAMRoaster publication analysis",
          "Running Mock Community through AMR Detection Tools"
        ],
        "type": "Text_excerpt",
        "value": "ABRIcate v.1.0.1 takes contig FASTA files as inputs and compared reads against a large database created by compiling several existing database, including NCBI AMRFinder Plus, CARD, ResFinder, ARG-ANNOT, MEGARES, EcOH, PlasmidFinder, VFDB, and Ecoli_VF. ABRIcate reports on acquired AMR genes and not mutational resistance.\n\n```\nconda create -n abricate -c conda-forge -c bioconda -c defaults abricate perl-path-tiny \nconda activate abricate\n\nabricate --check \n \n## if you get path::tiny error, run \nconda update --all \nconda update abricate \n\n#### \nabricate --list \n\nabricate fasta/contigs.fasta \nabricate assembly.fa.gz \n```\n"
      },
      "source": "https://raw.githubusercontent.com/ewissel/hAMRoaster/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "<a href=\"https://github.com/lgpdevtools/sraX#srax\">sraX</a>",
        "parent_header": [
          "Replicating hAMRoaster publication analysis",
          "Running Mock Community through AMR Detection Tools"
        ],
        "type": "Text_excerpt",
        "value": "sraX v.1.5 is built as a one step tool; in a single command, sraX downloads a database and aligns contigs to this database with DIAMOND21. By default, sraX uses CARD, though other options can be specified. As we use default settings for all tools, only CARD is used in this study for sraX. Reproducibility note: We had to run sraX interactively in order for this to work properly on our latest iteration of data processing (as opposed to launching jobs in the background with something like `nohup`). \n\n```\nconda create \u2013n srax -c conda-forge -c bioconda srax \nconda activate srax\n\nsraX \u2013v \nsraX -i sim_dat/fasta/ -o sraX_out \n```\n"
      },
      "source": "https://raw.githubusercontent.com/ewissel/hAMRoaster/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "<a href=\"https://github.com/gaarangoa/deeparg2.0\">deepARG</a>",
        "parent_header": [
          "Replicating hAMRoaster publication analysis",
          "Running Mock Community through AMR Detection Tools"
        ],
        "type": "Text_excerpt",
        "value": "deepARG v.2.0 uses a supervised deep learning based approach for antibiotic resistance gene annotation of metagenomic sequences. It combines three databases\u2014CARD, ARDB, and UNIPROT\u2014and categorizes them into resistance categories. \n\n```\nconda create -n deeparg_env  -c conda-forge -c bioconda 'python=2.7.18' 'diamond=0.9.24' \nconda activate deeparg_env \n\npip install deeparg==1.0.2 # to resolve error, note that I HAD to do this to get deeparg to work properly with each \"new\" run\n\ndeeparg download_data -o /path/to/local/directory/ \ndeeparg predict -i fasta/contigs.fasta -o deeparg_out_combo_fasta --model SS \u2013d full/path/to/downloaded_data/deeparg_data \n ```\n \n ### [StarAMR](https://github.com/phac-nml/staramr#staramr)\n \nstarAMR v.0.7.2 uses blast+ to compare contigs against a combined database with data from ResFinder, PointFinder, and PlasmidFinder. \n\n```\nconda create -n staramr -c conda-forge -c bioconda 'staramr=0.7.2'\nconda activate staramr\n\ncpan Moo\nstaramr search fasta/contigs.fasta -o staramr_out \n```\n\nWith this, all nine bioinformatic tools were run on the same mock community at three coverage levels and combined using [hAMRonization](https://github.com/pha4ge/hAMRonization). For shortBRED and fARGene, which are not a part of hAMRonization at the time of analysis, options were added to hAMRoaster to examine its output (as decribed above in the section on hAMRoaster flags). \n"
      },
      "source": "https://raw.githubusercontent.com/ewissel/hAMRoaster/main/README.md",
      "technique": "header_analysis"
    }
  ],
  "somef_missing_categories": [
    "citation",
    "acknowledgement",
    "download",
    "requirements",
    "contact",
    "contributors",
    "usage",
    "faq",
    "support",
    "identifier",
    "has_build_file",
    "executable_example"
  ],
  "somef_provenance": {
    "date": "2024-10-04 13:56:30",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 21
      },
      "technique": "GitHub_API"
    }
  ],
  "type": [
    {
      "confidence": 0.82,
      "result": {
        "type": "String",
        "value": "commandline-application"
      },
      "technique": "software_type_heuristics"
    }
  ]
}