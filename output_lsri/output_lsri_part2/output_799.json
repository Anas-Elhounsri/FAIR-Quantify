{
  "application_domain": [
    {
      "confidence": 19.69,
      "result": {
        "type": "String",
        "value": "Computer Vision"
      },
      "technique": "supervised_classification"
    }
  ],
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/JiangBioLab/DeepST"
      },
      "technique": "GitHub_API"
    }
  ],
  "contact": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Contact",
        "parent_header": [
          "DeepST: Identification of spatial domains in spatial transcriptomics by deep learning",
          "Compared tools"
        ],
        "type": "Text_excerpt",
        "value": "Feel free to submit an issue or contact us at xuchang0214@163.com for problems about the packages.\n"
      },
      "source": "https://raw.githubusercontent.com/JiangBioLab/DeepST/main/README.md",
      "technique": "header_analysis"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2022-02-01T12:39:51Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2024-09-23T07:28:33Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "Identify spatial domain"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 0.9948465811784656,
      "result": {
        "original_header": "Overview",
        "type": "Text_excerpt",
        "value": "DeepST first uses H&E staining to extract tissue morphology information through a pre-trained deep learning model, and normalizes each spot\u2019s gene expression according to the similarity of adjacent spots. DeepST further learns a spatial adjacency matrix on spatial location for the construction of graph convolutional network. DeepST uses a graph neural network autoencoder and a denoising autoencoder to jointly generate a latent representation of augmented ST data, while domain adversarial neural networks (DAN) are used to integrate ST data from multi-batches or different technologies. The output of DeepST can be applied to identify spatial domains, batch effect correction and downstream analysis. \n"
      },
      "source": "https://raw.githubusercontent.com/JiangBioLab/DeepST/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9775000435090248,
      "result": {
        "original_header": "Package: `DeepST`",
        "type": "Text_excerpt",
        "value": "We created the python package called `DeepST` that uses [`scanpy`](https://scanpy.readthedocs.io/en/stable/) to streamline the integration of spatial transcriptomics datasets and\nevaluate the results. DeepST is implemented in the open-source python using [`PyTorch`](https://pytorch.org/) and [`PyG`](https://github.com/pyg-team/pytorch_geometric) libraries.\n \n"
      },
      "source": "https://raw.githubusercontent.com/JiangBioLab/DeepST/main/README.md",
      "technique": "supervised_classification"
    }
  ],
  "download": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Download data",
        "parent_header": [
          "DeepST: Identification of spatial domains in spatial transcriptomics by deep learning",
          "Compared tools"
        ],
        "type": "Text_excerpt",
        "value": "|      Platform      |       Tissue     |    SampleID   |\n|:----------------:|:----------------:|:------------:|\n| [10x Visium](https://support.10xgenomics.com) | Human dorsolateral pre-frontal cortex (DLPFC) | [151507,](https://spatial-dlpfc.s3.us-east-2.amazonaws.com/h5/151507_filtered_feature_bc_matrix.h5) [151508,](https://spatial-dlpfc.s3.us-east-2.amazonaws.com/h5/151508_filtered_feature_bc_matrix.h5) [151509,](https://spatial-dlpfc.s3.us-east-2.amazonaws.com/h5/151509_filtered_feature_bc_matrix.h5) [151510,](https://spatial-dlpfc.s3.us-east-2.amazonaws.com/h5/151510_filtered_feature_bc_matrix.h5) [151669,](https://spatial-dlpfc.s3.us-east-2.amazonaws.com/h5/151669_filtered_feature_bc_matrix.h5) [151670,](https://spatial-dlpfc.s3.us-east-2.amazonaws.com/h5/151570_filtered_feature_bc_matrix.h5) [151671,](https://spatial-dlpfc.s3.us-east-2.amazonaws.com/h5/151671_filtered_feature_bc_matrix.h5) [151672,](https://spatial-dlpfc.s3.us-east-2.amazonaws.com/h5/151672_filtered_feature_bc_matrix.h5) [151673,](https://spatial-dlpfc.s3.us-east-2.amazonaws.com/h5/151673_filtered_feature_bc_matrix.h5) [151674,](https://spatial-dlpfc.s3.us-east-2.amazonaws.com/h5/151674_filtered_feature_bc_matrix.h5) [151675,](https://spatial-dlpfc.s3.us-east-2.amazonaws.com/h5/151675_filtered_feature_bc_matrix.h5) [151676](https://spatial-dlpfc.s3.us-east-2.amazonaws.com/h5/151676_filtered_feature_bc_matrix.h5)\n| [10x Visium](https://support.10xgenomics.com) | Mouse brain section| [Coronal,](https://www.10xgenomics.com/resources/datasets/mouse-kidney-section-coronal-1-standard-1-1-0) [Sagittal-Anterior,](https://www.10xgenomics.com/resources/datasets/mouse-brain-serial-section-1-sagittal-anterior-1-standard-1-1-0) [Sagittal-Posterior](https://www.10xgenomics.com/resources/datasets/mouse-brain-serial-section-1-sagittal-posterior-1-standard-1-1-0)\n| [10x Visium](https://support.10xgenomics.com) | Human breast cancer| [Invasive Ductal Carcinoma breast,](https://www.10xgenomics.com/resources/datasets/human-breast-cancer-block-a-section-1-1-standard-1-1-0) [Ductal Carcinoma In Situ & Invasive Carcinoma](https://www.10xgenomics.com/resources/datasets/human-breast-cancer-ductal-carcinoma-in-situ-invasive-carcinoma-ffpe-1-standard-1-3-0) \n| [Stereo-Seq](https://www.biorxiv.org/content/10.1101/2021.01.17.427004v2) | Mouse olfactory bulb| [Olfactory bulb](https://github.com/BGIResearch/stereopy) \n| [Slide-seq](https://www.biorxiv.org/content/10.1101/2021.10.10.463829v1) |  Mouse hippocampus| [Coronal](https://www.spatialomics.org/SpatialDB/download/slideseq_30923225.tar.gz) \n| [MERFISH](https://www.pnas.org/content/116/39/19490) |  Mouse brain slice| [Hypothalamic preoptic region](https://www.spatialomics.org/SpatialDB/download/merfish_30385464.tar.gz) |\n\nSpatial transcriptomics data of other platforms can be downloaded https://www.spatialomics.org/SpatialDB/\n"
      },
      "source": "https://raw.githubusercontent.com/JiangBioLab/DeepST/main/README.md",
      "technique": "header_analysis"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/JiangBioLab/DeepST/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 14
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/JiangBioLab/DeepST/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "JiangBioLab/DeepST"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "DeepST: Identification of spatial domains in spatial transcriptomics by deep learning"
      },
      "source": "https://raw.githubusercontent.com/JiangBioLab/DeepST/main/README.md",
      "technique": "regular_expression"
    }
  ],
  "images": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/JiangBioLab/DeepST/main/./Figure/Workflow.png"
      },
      "source": "https://raw.githubusercontent.com/JiangBioLab/DeepST/main/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/JiangBioLab/DeepST/main/./Figure/Update.jpg"
      },
      "source": "https://raw.githubusercontent.com/JiangBioLab/DeepST/main/README.md",
      "technique": "regular_expression"
    }
  ],
  "installation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "(Recommended) Using python virtual environment with <a href=\"https://anaconda.org/\">`conda`</a>",
        "parent_header": [
          "DeepST: Identification of spatial domains in spatial transcriptomics by deep learning",
          "Package: `DeepST`",
          "Installation"
        ],
        "type": "Text_excerpt",
        "value": "```bash\nwget https://github.com/JiangBioLab/DeepST/archive/refs/heads/main.zip\nunzip main.zip\ncd /home/.../DeepST-main  ### your own path\nconda create -n deepst_env python=3.9\nconda activate deepst_env\n## step1 Installing PyTorch\u2019s CUDA support or CPU support on Linux\npip3 install torch==1.13.0+cu116 torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu116  #### GPU\npip3 install torch==1.13.0 torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cpu  #### CPU\n## step2 Installing PyG package. If unsuccessful, refer to the \"Install PyG package\".\npip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv torch_geometric -f https://data.pyg.org/whl/torch-1.13.0+cu116.html #### GPU\npip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv torch_geometric -f https://data.pyg.org/whl/torch-1.13.0+cpu.html  ### CPU\n## step3 Download other dependencies\npip install -r requirements.txt\n```"
      },
      "source": "https://raw.githubusercontent.com/JiangBioLab/DeepST/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Installing additional packages(optional)",
        "parent_header": [
          "DeepST: Identification of spatial domains in spatial transcriptomics by deep learning",
          "Package: `DeepST`"
        ],
        "type": "Text_excerpt",
        "value": "<details>\n  <summary> 1. Install PyTorch package </summary>\n  \n  + #### Installation via [Anaconda](https://anaconda.org/pyg/pyg).\n```bash\nconda install pytorch torchvision torchaudio cudatoolkit=10.2 -c pytorch\n```\n  + #### Installation via [Pip Wheels](https://pytorch-geometric.readthedocs.io/en/latest/notes/installation.html#installation-via-pip-wheels)\n```bash\npip3 install torch torchvision torchaudio\n```\n</details>\n\n<details>\n  <summary> 2. Install PyG package </summary>\n           \n  + Installation via [Anaconda](https://anaconda.org/pyg/pyg).\n\nYou can now install PyG via Anaconda for all major OS/PyTorch/CUDA combinations \ud83e\udd17 Given that you have [PyTorch >= 1.8.0](https://pytorch.org/get-started/locally/) installed, simply run:\n```bash\nconda install pyg -c pyg -c conda-forge\n```\n  + Installation via [Pip Wheels](https://pytorch-geometric.readthedocs.io/en/latest/notes/installation.html#installation-via-pip-wheels)\n\nWe have outsourced a lot of functionality of PyG to other packages, which needs to be installed in advance. These packages come with their own CPU and GPU kernel implementations based on the PyTorch C++/CUDA extension interface. We provide pip wheels for these packages for all major OS/PyTorch/CUDA combinations:\n```bash\npip install pyg -c pyg -c conda-forge\n```\n1). Ensure that at least PyTorch 1.4.0 is installed:\n```bash\npython -c \"import torch; print(torch.__version__)\"\n>>> 1.9.0\n```\n2). Find the CUDA version PyTorch was installed with:\n```bash\npython -c \"import torch; print(torch.version.cuda)\"\n>>> 11.1\n```\n3). Install the relevant packages:\n```bash\npip install torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}+${CUDA}.html\npip install torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}+${CUDA}.html\npip install torch-geometric\n\n#### where ${CUDA} and ${TORCH} should be replaced by the specific CUDA version (cpu, cu92, cu101, cu102, cu110, cu111) and PyTorch version (1.4.0, 1.5.0, 1.6.0, 1.7.0, 1.7.1,  1.8.0, 1.8.1, 1.9.0, 1.9.1), respectively. For example, for PyTorch 1.9.0/1.9.1 and CUDA 11.1, type:\npip install torch-scatter -f https://data.pyg.org/whl/torch-1.9.0+cu111.html\npip install torch-sparse -f https://data.pyg.org/whl/torch-1.9.0+cu111.html\npip install torch-geometric\n\n#### For PyTorch 1.8.0/1.8.1 and CUDA 10.2, type:\npip install torch-scatter -f https://data.pyg.org/whl/torch-1.8.0+cu102.html\npip install torch-sparse -f https://data.pyg.org/whl/torch-1.8.0+cu102.html\npip install torch-geometric\n```\n4). Install additional packages (optional):\nTo add additional functionality to PyG, such as k-NN and radius graph generation or SplineConv support, run\n```bash\npip install torch-cluster -f https://data.pyg.org/whl/torch-${TORCH}+${CUDA}.html\npip install torch-spline-conv -f https://data.pyg.org/whl/torch-${TORCH}+${CUDA}.html\n```\n</details>\n"
      },
      "source": "https://raw.githubusercontent.com/JiangBioLab/DeepST/main/README.md",
      "technique": "header_analysis"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/JiangBioLab/DeepST/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ""
      },
      "technique": "GitHub_API"
    }
  ],
  "license": [
    {
      "confidence": 1,
      "result": {
        "name": "MIT License",
        "spdx_id": "MIT",
        "type": "License",
        "url": "https://api.github.com/licenses/mit",
        "value": "https://api.github.com/licenses/mit"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "type": "File_dump",
        "value": "MIT License\n\nCopyright (c) 2022 spatial-Transcriptomics\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
      },
      "source": "https://raw.githubusercontent.com/JiangBioLab/DeepST/main/LICENSE",
      "technique": "file_exploration"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "DeepST"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "User",
        "value": "JiangBioLab"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 93439,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "R",
        "size": 1740,
        "type": "Programming_language",
        "value": "R"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/JiangBioLab/DeepST/main/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "related_documentation": [
    {
      "confidence": 1,
      "result": {
        "format": "readthedocs",
        "type": "Url",
        "value": "https://scanpy.readthedocs.io/"
      },
      "source": "https://raw.githubusercontent.com/JiangBioLab/DeepST/main/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "format": "readthedocs",
        "type": "Url",
        "value": "https://pytorch-geometric.readthedocs.io/"
      },
      "source": "https://raw.githubusercontent.com/JiangBioLab/DeepST/main/README.md",
      "technique": "regular_expression"
    }
  ],
  "somef_missing_categories": [
    "citation",
    "acknowledgement",
    "run",
    "requirements",
    "contributors",
    "documentation",
    "faq",
    "support",
    "identifier",
    "has_build_file",
    "executable_example"
  ],
  "somef_provenance": {
    "date": "2024-10-04 12:03:46",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 55
      },
      "technique": "GitHub_API"
    }
  ],
  "usage": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Start by grabbing this source codes:",
        "parent_header": [
          "DeepST: Identification of spatial domains in spatial transcriptomics by deep learning",
          "Package: `DeepST`",
          "Installation"
        ],
        "type": "Text_excerpt",
        "value": "```bash\ngit clone https://github.com/spatial-Transcriptomics/DeepST.git\ncd DeepST\n```\n"
      },
      "source": "https://raw.githubusercontent.com/JiangBioLab/DeepST/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Usage",
        "parent_header": [
          "DeepST: Identification of spatial domains in spatial transcriptomics by deep learning"
        ],
        "type": "Text_excerpt",
        "value": "<img src=\"./Figure/Update.jpg\" alt=\"Image Description\" width=\"20%\" height=\"20%\" />\nJuly 10, 2023\n\n(1) Due to the protocol issues of various space technology platforms, the data format is very different, and various platforms do not provide morphological images. For the convenience of users, we have changed the way of reading data to make it easier to use.\n\n(2) Fixed bugs that appeared in the integration task.\n\n(3) Expand the applicability of the model.\n\nDeepST is used on spatial transcriptomics (ST) datasets. In essence, you can refer to the following examples:\n+ #### DeepST on DLPFC from 10x Visium.\nFirst, ``` cd /home/.../DeepST-main/deepst ```\n```python\nimport os \nfrom DeepST import run\nimport matplotlib.pyplot as plt\nfrom pathlib import Path\nimport scanpy as sc\n\ndata_path = \"../data/DLPFC\" #### to your path\ndata_name = '151673' #### project name\nsave_path = \"../Results\" #### save path\nn_domains = 7 ###### the number of spatial domains.\n\ndeepen = run(save_path = save_path,\n\ttask = \"Identify_Domain\", #### DeepST includes two tasks, one is \"Identify_Domain\" and the other is \"Integration\"\n\tpre_epochs = 800, ####  choose the number of training\n\tepochs = 1000, #### choose the number of training\n\tuse_gpu = True)\n###### Read in 10x Visium data, or user can read in themselves.\nadata = deepen._get_adata(platform=\"Visium\", data_path=data_path, data_name=data_name)\n###### Segment the Morphological Image\nadata = deepen._get_image_crop(adata, data_name=data_name) \n\n###### Data augmentation. spatial_type includes three kinds of \"KDTree\", \"BallTree\" and \"LinearRegress\", among which \"LinearRegress\"\n###### is only applicable to 10x visium and the remaining omics selects the other two.\n###### \"use_morphological\" defines whether to use morphological images.\nadata = deepen._get_augment(adata, spatial_type=\"LinearRegress\", use_morphological=True)\n\n###### Build graphs. \"distType\" includes \"KDTree\", \"BallTree\", \"kneighbors_graph\", \"Radius\", etc., see adj.py\ngraph_dict = deepen._get_graph(adata.obsm[\"spatial\"], distType = \"BallTree\")\n\n###### Enhanced data preprocessing\ndata = deepen._data_process(adata, pca_n_comps = 200)\n\n###### Training models\ndeepst_embed = deepen._fit(\n\t\tdata = data,\n\t\tgraph_dict = graph_dict,)\n###### DeepST outputs\nadata.obsm[\"DeepST_embed\"] = deepst_embed\n\n###### Define the number of space domains, and the model can also be customized. If it is a model custom priori = False.\nadata = deepen._get_cluster_data(adata, n_domains=n_domains, priori = True)\n\n###### Spatial localization map of the spatial domain\nsc.pl.spatial(adata, color='DeepST_refine_domain', frameon = False, spot_size=150)\nplt.savefig(os.path.join(save_path, f'{data_name}_domains.pdf'), bbox_inches='tight', dpi=300)\n```\n+ #### DeepST integrates data from mutil-batches or different technologies.\n```python\nimport os \nfrom DeepST import run\nimport matplotlib.pyplot as plt\nfrom pathlib import Path\nimport scanpy as sc\n\ndata_path = \"../data/DLPFC\" \ndata_name_list = ['151673', '151674', '151675', '151676']\nsave_path = \"../Results\" \nn_domains = 7\n\ndeepen = run(save_path = save_path, \n\ttask = \"Integration\",\n\tpre_epochs = 800, \n\tepochs = 1000, \n\tuse_gpu = True,\n\t)\n\n###### Generate an augmented list of multiple datasets\naugement_data_list = []\ngraph_list = []\nfor i in range(len(data_name_list)):\n\tadata = deepen._get_adata(platform=\"Visium\", data_path=data_path, data_name=data_name_list[i])\n\tadata = deepen._get_image_crop(adata, data_name=data_name_list[i])\n\tadata = deepen._get_augment(adata, spatial_type=\"LinearRegress\")\n\tgraph_dict = deepen._get_graph(adata.obsm[\"spatial\"], distType = \"KDTree\")\n\taugement_data_list.append(adata)\n\tgraph_list.append(graph_dict)\n\n######## Synthetic Datasets and Graphs\nmultiple_adata, multiple_graph = deepen._get_multiple_adata(adata_list = augement_data_list, data_name_list = data_name_list, graph_list = graph_list)\n\n###### Enhanced data preprocessing\ndata = deepen._data_process(multiple_adata, pca_n_comps = 200)\n\ndeepst_embed = deepen._fit(\n\t\tdata = data,\n\t\tgraph_dict = multiple_graph,\n\t\tdomains = multiple_adata.obs[\"batch\"].values,  ##### Input to Domain Adversarial Model\n\t\tn_domains = len(data_name_list))\nmultiple_adata.obsm[\"DeepST_embed\"] = deepst_embed\nmultiple_adata = deepen._get_cluster_data(multiple_adata, n_domains=n_domains, priori = True)\n\nsc.pp.neighbors(multiple_adata, use_rep='DeepST_embed')\nsc.tl.umap(multiple_adata)\nsc.pl.umap(multiple_adata, color=[\"DeepST_refine_domain\",\"batch_name\"])\nplt.savefig(os.path.join(save_path, f'{\"_\".join(data_name_list)}_umap.pdf'), bbox_inches='tight', dpi=300)\n\nfor data_name in data_name_list:\n\tadata = multiple_adata[multiple_adata.obs[\"batch_name\"]==data_name]\n\tsc.pl.spatial(adata, color='DeepST_refine_domain', frameon = False, spot_size=150)\n\tplt.savefig(os.path.join(save_path, f'{data_name}_domains.pdf'), bbox_inches='tight', dpi=300)\n```\n+ #### DeepST works on other spatial omics data.\n```python\nimport os \nfrom DeepST import run\nimport matplotlib.pyplot as plt\nfrom pathlib import Path\nimport scanpy as sc\n\ndata_path = \"../data\" \ndata_name = 'Stereoseq' \nsave_path = \"../Results\" \nn_domains = 15 \n\ndeepen = run(save_path = save_path,\n\ttask = \"Identify_Domain\", \n\tpre_epochs = 800, \n\tepochs = 1000, \n\tuse_gpu = True)\n###### Read in other spatial data, or user can read in themselves. Including original expression\n###### information and spatial location information, where the location information is saved in .obsm[\"spatial\"]\nadata = deepen._get_adata(platform=\"Stereoseq\", data_path=data_path, data_name=data_name)\n\n###### Data augmentation. spatial_type includes three kinds of \"KDTree\", \"BallTree\" and \"LinearRegress\", among which \"LinearRegress\"\n###### is only applicable to 10x visium and the remaining omics selects the other two.\n###### \"use_morphological\" defines whether to use morphological images.\nadata = deepen._get_augment(adata, spatial_type=\"BallTree\", use_morphological=False)\n\n###### Build graphs. \"distType\" includes \"KDTree\", \"BallTree\", \"kneighbors_graph\", \"Radius\", etc., see adj.py\ngraph_dict = deepen._get_graph(adata.obsm[\"spatial\"], distType = \"BallTree\")\n\n###### Enhanced data preprocessing\ndata = deepen._data_process(adata, pca_n_comps = 200)\n\n###### Training models\ndeepst_embed = deepen._fit(\n\t\tdata = data,\n\t\tgraph_dict = graph_dict,)\n###### DeepST outputs\nadata.obsm[\"DeepST_embed\"] = deepst_embed\n\n###### Define the number of space domains, and the model can also be customized. If it is a model custom priori = False.\nadata = deepen._get_cluster_data(adata, n_domains=n_domains, priori = True)\n\n###### Spatial localization map of the spatial domain\nsc.pl.spatial(adata, color='DeepST_refine_domain', frameon = False, spot_size=150)\nplt.savefig(os.path.join(save_path, f'{data_name}_domains.pdf'), bbox_inches='tight', dpi=300)\n```"
      },
      "source": "https://raw.githubusercontent.com/JiangBioLab/DeepST/main/README.md",
      "technique": "header_analysis"
    }
  ]
}