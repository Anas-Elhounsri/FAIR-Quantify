{
  "application_domain": [
    {
      "confidence": 47.05,
      "result": {
        "type": "String",
        "value": "Computer Vision"
      },
      "technique": "supervised_classification"
    }
  ],
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/IlikeBB/SGD-Net"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2021-06-18T02:32:35Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2022-10-18T17:03:00Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/IlikeBB/SGD-Net/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "executable_example": [
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/IlikeBB/SGD-Net/main/03.evaluate.ipynb"
      },
      "source": "https://raw.githubusercontent.com/IlikeBB/SGD-Net/main/03.evaluate.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/IlikeBB/SGD-Net/main/00.nii%20data%20loading.ipynb"
      },
      "source": "https://raw.githubusercontent.com/IlikeBB/SGD-Net/main/00.nii%20data%20loading.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/IlikeBB/SGD-Net/main/03.evaluate-test.ipynb"
      },
      "source": "https://raw.githubusercontent.com/IlikeBB/SGD-Net/main/03.evaluate-test.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/IlikeBB/SGD-Net/main/utils/augmented/demo.ipynb"
      },
      "source": "https://raw.githubusercontent.com/IlikeBB/SGD-Net/main/utils/augmented/demo.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/IlikeBB/SGD-Net/main/paper_reviewer/evaluate_only_S1_median_0.ipynb"
      },
      "source": "https://raw.githubusercontent.com/IlikeBB/SGD-Net/main/paper_reviewer/evaluate_only_S1_median_0.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/IlikeBB/SGD-Net/main/paper_reviewer/read_pixel_process-all.ipynb"
      },
      "source": "https://raw.githubusercontent.com/IlikeBB/SGD-Net/main/paper_reviewer/read_pixel_process-all.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/IlikeBB/SGD-Net/main/paper_reviewer/%2A3.0T%261.5T%20S1%20single%20mode%20Perfromance.ipynb"
      },
      "source": "https://raw.githubusercontent.com/IlikeBB/SGD-Net/main/paper_reviewer/%2A3.0T%261.5T%20S1%20single%20mode%20Perfromance.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/IlikeBB/SGD-Net/main/paper_reviewer/read_pixel_process.ipynb"
      },
      "source": "https://raw.githubusercontent.com/IlikeBB/SGD-Net/main/paper_reviewer/read_pixel_process.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/IlikeBB/SGD-Net/main/paper_reviewer/evaluate_only_S1_median.ipynb"
      },
      "source": "https://raw.githubusercontent.com/IlikeBB/SGD-Net/main/paper_reviewer/evaluate_only_S1_median.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/IlikeBB/SGD-Net/main/paper_reviewer/load_sameple-20-50-100--traininglog.ipynb"
      },
      "source": "https://raw.githubusercontent.com/IlikeBB/SGD-Net/main/paper_reviewer/load_sameple-20-50-100--traininglog.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/IlikeBB/SGD-Net/main/paper_reviewer/evaluate_only_S1_0.ipynb"
      },
      "source": "https://raw.githubusercontent.com/IlikeBB/SGD-Net/main/paper_reviewer/evaluate_only_S1_0.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/IlikeBB/SGD-Net/main/paper_reviewer/evaluate_only_S1_median_1.ipynb"
      },
      "source": "https://raw.githubusercontent.com/IlikeBB/SGD-Net/main/paper_reviewer/evaluate_only_S1_median_1.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/IlikeBB/SGD-Net/main/paper_reviewer/evaluate_only_S1_1.ipynb"
      },
      "source": "https://raw.githubusercontent.com/IlikeBB/SGD-Net/main/paper_reviewer/evaluate_only_S1_1.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/IlikeBB/SGD-Net/main/paper_reviewer/evaluate_only_S1.ipynb"
      },
      "source": "https://raw.githubusercontent.com/IlikeBB/SGD-Net/main/paper_reviewer/evaluate_only_S1.ipynb",
      "technique": "file_exploration"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 1
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/IlikeBB/SGD-Net/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "IlikeBB/SGD-Net"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "Toward Explainable Semantic Segmentation Guided Detector for Segmentation and Classification of Diffusion-Weighted MRI of Acute Ischemic Stroke"
      },
      "source": "https://raw.githubusercontent.com/IlikeBB/SGD-Net/main/README.md",
      "technique": "regular_expression"
    }
  ],
  "has_script_file": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/IlikeBB/SGD-Net/main/SGD_GUI_program/MNIs/MNI_process_iter_0917.sh"
      },
      "technique": "file_exploration"
    }
  ],
  "images": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/IlikeBB/SGD-Net/main/Toward Explainable Semantic Segmentation Guided Detector for Segmentation and Classification of Diffusion-Weighted MRI of Acute Ischemic Stroke</h1>\n<h2>Abstract</h2>\n<h4>Background and Purpose</h4>\n<blockquote>\n<p>Neuroimaging is valuable for clinical decision support in acute ischemic stroke (AIS). Diffusion-weighted imaging (DWI) is the representative MRI sequence to timely, sensitively, and accurately reflect ischemia injuries to brain tissue. However, the complexity of MRI elevates the threshold for instantaneously precise interpretation of the images. Therefore, this work leverage machine learning to segment and classify the AIS lesions on DWI images. We focused on model development, performance comparisons, and utilization for decision making.</p>\n</blockquote>\n<h4>Methods</h4>\n<blockquote>\n<p>We enrolled brain MRI images of AIS during 2017-2020 in a tertiary teaching hospital. DWI were analyzed by the network for semantic segmentation guided detector (SGD-Net), composed of a U-shaped stage 1 (S1) model for segmentation and a stage 2 (S2) model for classification. An image review board labeled images to provide ground truth for model training and testing. The binary classes in S2 were AIS lesion size (lacune vs. non-lacune) and circulatory territory of lesion location (anterior vs. posterior circulation). We compared different backbones of SGD-Net and contrasted them with one-stage classifiers.</p>\n</blockquote>\n<h4>Conclusions</h4>\n<blockquote>\n<p>The SGD-Net precisely segmented AIS lesions on DWI and accurately classified lesion size and location. Based on the two-stage design, combinations of different backbones for S1 U-Net and S2 classifier performed superiorly to the one-stage 3D-ResNet and 3D-CNNs. The U-shaped architecture of S1 was considered crucial for satisfactory model performance. In the future, the deployment of SGD-Net to the emergency health care system would improve AIS patient care. </p>\n</blockquote>\n<h2>Experiment Environment</h2>\n<p><code>OS: Ubuntu 16.04\nCUDA: 10.1\nGPU: Nvidia GTX 1080Ti x 1</code></p>\n<h2>Build Virtual Environment (Using Conda)</h2>\n<p>```\n!conda env create -f SGD.yml</p>\n<p>!conda activate SGD\n```</p>\n<h2>Model Architecture</h2>\n<p><img src='https://github.com/IlikeBB/F3DD/blob/main/plot_results/%E6%9E%B6%E6%A7%8B%E5%9C%96.jpg'></p>\n<h2>Data Preparing</h2>\n<p><code>!pip install nibabel\n!pip install scikit-image</code></p>\n<blockquote>\n<ul>\n<li>Loading nii or nii.gz data and transformation to numpy data array.</li>\n<li>Please refer to <code>00.nii data loading.ipynb</code> build your dataset array or build random data array.\n<code>example:\n ./data_set/...\n     1| 00001.nii -&gt; 00001.npy\n     2| 00002.nii -&gt; 00002.npy\n     3| 00003.nii -&gt; 00003.npy\n                  .\n                  .\n     n|     n.nii -&gt;     n.npy</code>\n<code>concate data array-&gt; [Sample Number, depth, width, height] ([140,32,384,384])</code></li>\n</ul>\n</blockquote>\n<h2>Training</h2>\n<p><code>!pip install git+https://github.com/mjkvaak/ImageDataAugmentor</code></p>\n<h3>Training S1 Semantic Segmentation Network</h3>\n<p><code>!python 01.S1_Training.py</code></p>\n<blockquote>\n<ul>\n<li>Edit env parameter value in <code>/utils/model_config_S1.yam</code>.</li>\n</ul>\n</blockquote>\n<h3>Training S2 3D Classification Network</h3>\n<p><code>!python 02.S2_AP_Training.py\n!python 02.S2_NL_Training.py</code></p>\n<blockquote>\n<ul>\n<li>Edit env parameter value in <code>/utils/model_config_NL or AP.yaml</code>.</li>\n</ul>\n</blockquote>\n<h2>Testing</h2>\n<p><code>!pip install -U scikit-learn</code></p>\n<blockquote>\n<ul>\n<li>Please refer to <code>03.evaluate.ipynb</code></li>\n<li>Edit env parameter value in <code>/utils/model_config.yaml</code>.</li>\n</ul>\n</blockquote>\n<h2>Perfromace Plot</h2>\n<p><img src='https://github.com/IlikeBB/F3DD/blob/main/plot_results/fig4-5%20revise%20table.001.png'>\n<img src='https://github.com/IlikeBB/F3DD/blob/main/plot_results/fig4-5%20revise%20table.002.png'></p>\n<h2>Visual Results</h2>\n<p><img src='https://github.com/IlikeBB/F3DD/blob/main/plot_results/is0302.gif'></p>\n<img src='https://github.com/IlikeBB/F3DD/blob/main/plot_results/is0323.gif'></p>\n<img src='https://github.com/IlikeBB/F3DD/blob/main/plot_results/is0319.gif'></p>\n<img src='https://github.com/IlikeBB/F3DD/blob/main/plot_results/is0337.gif'></p></p>\n<h2>Reference</h2>\n<h4>Data Augmentation reference from<a href='https://github.com/albumentations-team/albumentations'> Albumentations</a>, <a href='https://github.com/mjkvaak/ImageDataAugmentor'> ImageDataAugmentor</a>.</h4>\n<h4>The code is heavily adapted from<a href='https://github.com/JihongJu/keras-resnet3d'> 3D ResNet</a>, <a href='https://github.com/qubvel/segmentation_models'> Segmentation Models</a>.</h4"
      },
      "source": "https://raw.githubusercontent.com/IlikeBB/SGD-Net/main/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/IlikeBB/SGD-Net/main/Toward Explainable Semantic Segmentation Guided Detector for Segmentation and Classification of Diffusion-Weighted MRI of Acute Ischemic Stroke</h1>\n<h2>Abstract</h2>\n<h4>Background and Purpose</h4>\n<blockquote>\n<p>Neuroimaging is valuable for clinical decision support in acute ischemic stroke (AIS). Diffusion-weighted imaging (DWI) is the representative MRI sequence to timely, sensitively, and accurately reflect ischemia injuries to brain tissue. However, the complexity of MRI elevates the threshold for instantaneously precise interpretation of the images. Therefore, this work leverage machine learning to segment and classify the AIS lesions on DWI images. We focused on model development, performance comparisons, and utilization for decision making.</p>\n</blockquote>\n<h4>Methods</h4>\n<blockquote>\n<p>We enrolled brain MRI images of AIS during 2017-2020 in a tertiary teaching hospital. DWI were analyzed by the network for semantic segmentation guided detector (SGD-Net), composed of a U-shaped stage 1 (S1) model for segmentation and a stage 2 (S2) model for classification. An image review board labeled images to provide ground truth for model training and testing. The binary classes in S2 were AIS lesion size (lacune vs. non-lacune) and circulatory territory of lesion location (anterior vs. posterior circulation). We compared different backbones of SGD-Net and contrasted them with one-stage classifiers.</p>\n</blockquote>\n<h4>Conclusions</h4>\n<blockquote>\n<p>The SGD-Net precisely segmented AIS lesions on DWI and accurately classified lesion size and location. Based on the two-stage design, combinations of different backbones for S1 U-Net and S2 classifier performed superiorly to the one-stage 3D-ResNet and 3D-CNNs. The U-shaped architecture of S1 was considered crucial for satisfactory model performance. In the future, the deployment of SGD-Net to the emergency health care system would improve AIS patient care. </p>\n</blockquote>\n<h2>Experiment Environment</h2>\n<p><code>OS: Ubuntu 16.04\nCUDA: 10.1\nGPU: Nvidia GTX 1080Ti x 1</code></p>\n<h2>Build Virtual Environment (Using Conda)</h2>\n<p>```\n!conda env create -f SGD.yml</p>\n<p>!conda activate SGD\n```</p>\n<h2>Model Architecture</h2>\n<p><img src='https://github.com/IlikeBB/F3DD/blob/main/plot_results/%E6%9E%B6%E6%A7%8B%E5%9C%96.jpg'></p>\n<h2>Data Preparing</h2>\n<p><code>!pip install nibabel\n!pip install scikit-image</code></p>\n<blockquote>\n<ul>\n<li>Loading nii or nii.gz data and transformation to numpy data array.</li>\n<li>Please refer to <code>00.nii data loading.ipynb</code> build your dataset array or build random data array.\n<code>example:\n ./data_set/...\n     1| 00001.nii -&gt; 00001.npy\n     2| 00002.nii -&gt; 00002.npy\n     3| 00003.nii -&gt; 00003.npy\n                  .\n                  .\n     n|     n.nii -&gt;     n.npy</code>\n<code>concate data array-&gt; [Sample Number, depth, width, height] ([140,32,384,384])</code></li>\n</ul>\n</blockquote>\n<h2>Training</h2>\n<p><code>!pip install git+https://github.com/mjkvaak/ImageDataAugmentor</code></p>\n<h3>Training S1 Semantic Segmentation Network</h3>\n<p><code>!python 01.S1_Training.py</code></p>\n<blockquote>\n<ul>\n<li>Edit env parameter value in <code>/utils/model_config_S1.yam</code>.</li>\n</ul>\n</blockquote>\n<h3>Training S2 3D Classification Network</h3>\n<p><code>!python 02.S2_AP_Training.py\n!python 02.S2_NL_Training.py</code></p>\n<blockquote>\n<ul>\n<li>Edit env parameter value in <code>/utils/model_config_NL or AP.yaml</code>.</li>\n</ul>\n</blockquote>\n<h2>Testing</h2>\n<p><code>!pip install -U scikit-learn</code></p>\n<blockquote>\n<ul>\n<li>Please refer to <code>03.evaluate.ipynb</code></li>\n<li>Edit env parameter value in <code>/utils/model_config.yaml</code>.</li>\n</ul>\n</blockquote>\n<h2>Perfromace Plot</h2>\n<p><img src='https://github.com/IlikeBB/F3DD/blob/main/plot_results/fig4-5%20revise%20table.001.png'>\n<img src='https://github.com/IlikeBB/F3DD/blob/main/plot_results/fig4-5%20revise%20table.002.png'></p>\n<h2>Visual Results</h2>\n<p><img src='https://github.com/IlikeBB/F3DD/blob/main/plot_results/is0302.gif'></p>\n<img src='https://github.com/IlikeBB/F3DD/blob/main/plot_results/is0323.gif'></p>\n<img src='https://github.com/IlikeBB/F3DD/blob/main/plot_results/is0319.gif'></p>\n<img src='https://github.com/IlikeBB/F3DD/blob/main/plot_results/is0337.gif'></p></p>\n<h2>Reference</h2>\n<h4>Data Augmentation reference from<a href='https://github.com/albumentations-team/albumentations'> Albumentations</a>, <a href='https://github.com/mjkvaak/ImageDataAugmentor'> ImageDataAugmentor</a>.</h4>\n<h4>The code is heavily adapted from<a href='https://github.com/JihongJu/keras-resnet3d'> 3D ResNet</a>, <a href='https://github.com/qubvel/segmentation_models'> Segmentation Models</a>.</h4"
      },
      "source": "https://raw.githubusercontent.com/IlikeBB/SGD-Net/main/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/IlikeBB/SGD-Net/main/Toward Explainable Semantic Segmentation Guided Detector for Segmentation and Classification of Diffusion-Weighted MRI of Acute Ischemic Stroke</h1>\n<h2>Abstract</h2>\n<h4>Background and Purpose</h4>\n<blockquote>\n<p>Neuroimaging is valuable for clinical decision support in acute ischemic stroke (AIS). Diffusion-weighted imaging (DWI) is the representative MRI sequence to timely, sensitively, and accurately reflect ischemia injuries to brain tissue. However, the complexity of MRI elevates the threshold for instantaneously precise interpretation of the images. Therefore, this work leverage machine learning to segment and classify the AIS lesions on DWI images. We focused on model development, performance comparisons, and utilization for decision making.</p>\n</blockquote>\n<h4>Methods</h4>\n<blockquote>\n<p>We enrolled brain MRI images of AIS during 2017-2020 in a tertiary teaching hospital. DWI were analyzed by the network for semantic segmentation guided detector (SGD-Net), composed of a U-shaped stage 1 (S1) model for segmentation and a stage 2 (S2) model for classification. An image review board labeled images to provide ground truth for model training and testing. The binary classes in S2 were AIS lesion size (lacune vs. non-lacune) and circulatory territory of lesion location (anterior vs. posterior circulation). We compared different backbones of SGD-Net and contrasted them with one-stage classifiers.</p>\n</blockquote>\n<h4>Conclusions</h4>\n<blockquote>\n<p>The SGD-Net precisely segmented AIS lesions on DWI and accurately classified lesion size and location. Based on the two-stage design, combinations of different backbones for S1 U-Net and S2 classifier performed superiorly to the one-stage 3D-ResNet and 3D-CNNs. The U-shaped architecture of S1 was considered crucial for satisfactory model performance. In the future, the deployment of SGD-Net to the emergency health care system would improve AIS patient care. </p>\n</blockquote>\n<h2>Experiment Environment</h2>\n<p><code>OS: Ubuntu 16.04\nCUDA: 10.1\nGPU: Nvidia GTX 1080Ti x 1</code></p>\n<h2>Build Virtual Environment (Using Conda)</h2>\n<p>```\n!conda env create -f SGD.yml</p>\n<p>!conda activate SGD\n```</p>\n<h2>Model Architecture</h2>\n<p><img src='https://github.com/IlikeBB/F3DD/blob/main/plot_results/%E6%9E%B6%E6%A7%8B%E5%9C%96.jpg'></p>\n<h2>Data Preparing</h2>\n<p><code>!pip install nibabel\n!pip install scikit-image</code></p>\n<blockquote>\n<ul>\n<li>Loading nii or nii.gz data and transformation to numpy data array.</li>\n<li>Please refer to <code>00.nii data loading.ipynb</code> build your dataset array or build random data array.\n<code>example:\n ./data_set/...\n     1| 00001.nii -&gt; 00001.npy\n     2| 00002.nii -&gt; 00002.npy\n     3| 00003.nii -&gt; 00003.npy\n                  .\n                  .\n     n|     n.nii -&gt;     n.npy</code>\n<code>concate data array-&gt; [Sample Number, depth, width, height] ([140,32,384,384])</code></li>\n</ul>\n</blockquote>\n<h2>Training</h2>\n<p><code>!pip install git+https://github.com/mjkvaak/ImageDataAugmentor</code></p>\n<h3>Training S1 Semantic Segmentation Network</h3>\n<p><code>!python 01.S1_Training.py</code></p>\n<blockquote>\n<ul>\n<li>Edit env parameter value in <code>/utils/model_config_S1.yam</code>.</li>\n</ul>\n</blockquote>\n<h3>Training S2 3D Classification Network</h3>\n<p><code>!python 02.S2_AP_Training.py\n!python 02.S2_NL_Training.py</code></p>\n<blockquote>\n<ul>\n<li>Edit env parameter value in <code>/utils/model_config_NL or AP.yaml</code>.</li>\n</ul>\n</blockquote>\n<h2>Testing</h2>\n<p><code>!pip install -U scikit-learn</code></p>\n<blockquote>\n<ul>\n<li>Please refer to <code>03.evaluate.ipynb</code></li>\n<li>Edit env parameter value in <code>/utils/model_config.yaml</code>.</li>\n</ul>\n</blockquote>\n<h2>Perfromace Plot</h2>\n<p><img src='https://github.com/IlikeBB/F3DD/blob/main/plot_results/fig4-5%20revise%20table.001.png'>\n<img src='https://github.com/IlikeBB/F3DD/blob/main/plot_results/fig4-5%20revise%20table.002.png'></p>\n<h2>Visual Results</h2>\n<p><img src='https://github.com/IlikeBB/F3DD/blob/main/plot_results/is0302.gif'></p>\n<img src='https://github.com/IlikeBB/F3DD/blob/main/plot_results/is0323.gif'></p>\n<img src='https://github.com/IlikeBB/F3DD/blob/main/plot_results/is0319.gif'></p>\n<img src='https://github.com/IlikeBB/F3DD/blob/main/plot_results/is0337.gif'></p></p>\n<h2>Reference</h2>\n<h4>Data Augmentation reference from<a href='https://github.com/albumentations-team/albumentations'> Albumentations</a>, <a href='https://github.com/mjkvaak/ImageDataAugmentor'> ImageDataAugmentor</a>.</h4>\n<h4>The code is heavily adapted from<a href='https://github.com/JihongJu/keras-resnet3d'> 3D ResNet</a>, <a href='https://github.com/qubvel/segmentation_models'> Segmentation Models</a>.</h4"
      },
      "source": "https://raw.githubusercontent.com/IlikeBB/SGD-Net/main/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/IlikeBB/SGD-Net/main/Toward Explainable Semantic Segmentation Guided Detector for Segmentation and Classification of Diffusion-Weighted MRI of Acute Ischemic Stroke</h1>\n<h2>Abstract</h2>\n<h4>Background and Purpose</h4>\n<blockquote>\n<p>Neuroimaging is valuable for clinical decision support in acute ischemic stroke (AIS). Diffusion-weighted imaging (DWI) is the representative MRI sequence to timely, sensitively, and accurately reflect ischemia injuries to brain tissue. However, the complexity of MRI elevates the threshold for instantaneously precise interpretation of the images. Therefore, this work leverage machine learning to segment and classify the AIS lesions on DWI images. We focused on model development, performance comparisons, and utilization for decision making.</p>\n</blockquote>\n<h4>Methods</h4>\n<blockquote>\n<p>We enrolled brain MRI images of AIS during 2017-2020 in a tertiary teaching hospital. DWI were analyzed by the network for semantic segmentation guided detector (SGD-Net), composed of a U-shaped stage 1 (S1) model for segmentation and a stage 2 (S2) model for classification. An image review board labeled images to provide ground truth for model training and testing. The binary classes in S2 were AIS lesion size (lacune vs. non-lacune) and circulatory territory of lesion location (anterior vs. posterior circulation). We compared different backbones of SGD-Net and contrasted them with one-stage classifiers.</p>\n</blockquote>\n<h4>Conclusions</h4>\n<blockquote>\n<p>The SGD-Net precisely segmented AIS lesions on DWI and accurately classified lesion size and location. Based on the two-stage design, combinations of different backbones for S1 U-Net and S2 classifier performed superiorly to the one-stage 3D-ResNet and 3D-CNNs. The U-shaped architecture of S1 was considered crucial for satisfactory model performance. In the future, the deployment of SGD-Net to the emergency health care system would improve AIS patient care. </p>\n</blockquote>\n<h2>Experiment Environment</h2>\n<p><code>OS: Ubuntu 16.04\nCUDA: 10.1\nGPU: Nvidia GTX 1080Ti x 1</code></p>\n<h2>Build Virtual Environment (Using Conda)</h2>\n<p>```\n!conda env create -f SGD.yml</p>\n<p>!conda activate SGD\n```</p>\n<h2>Model Architecture</h2>\n<p><img src='https://github.com/IlikeBB/F3DD/blob/main/plot_results/%E6%9E%B6%E6%A7%8B%E5%9C%96.jpg'></p>\n<h2>Data Preparing</h2>\n<p><code>!pip install nibabel\n!pip install scikit-image</code></p>\n<blockquote>\n<ul>\n<li>Loading nii or nii.gz data and transformation to numpy data array.</li>\n<li>Please refer to <code>00.nii data loading.ipynb</code> build your dataset array or build random data array.\n<code>example:\n ./data_set/...\n     1| 00001.nii -&gt; 00001.npy\n     2| 00002.nii -&gt; 00002.npy\n     3| 00003.nii -&gt; 00003.npy\n                  .\n                  .\n     n|     n.nii -&gt;     n.npy</code>\n<code>concate data array-&gt; [Sample Number, depth, width, height] ([140,32,384,384])</code></li>\n</ul>\n</blockquote>\n<h2>Training</h2>\n<p><code>!pip install git+https://github.com/mjkvaak/ImageDataAugmentor</code></p>\n<h3>Training S1 Semantic Segmentation Network</h3>\n<p><code>!python 01.S1_Training.py</code></p>\n<blockquote>\n<ul>\n<li>Edit env parameter value in <code>/utils/model_config_S1.yam</code>.</li>\n</ul>\n</blockquote>\n<h3>Training S2 3D Classification Network</h3>\n<p><code>!python 02.S2_AP_Training.py\n!python 02.S2_NL_Training.py</code></p>\n<blockquote>\n<ul>\n<li>Edit env parameter value in <code>/utils/model_config_NL or AP.yaml</code>.</li>\n</ul>\n</blockquote>\n<h2>Testing</h2>\n<p><code>!pip install -U scikit-learn</code></p>\n<blockquote>\n<ul>\n<li>Please refer to <code>03.evaluate.ipynb</code></li>\n<li>Edit env parameter value in <code>/utils/model_config.yaml</code>.</li>\n</ul>\n</blockquote>\n<h2>Perfromace Plot</h2>\n<p><img src='https://github.com/IlikeBB/F3DD/blob/main/plot_results/fig4-5%20revise%20table.001.png'>\n<img src='https://github.com/IlikeBB/F3DD/blob/main/plot_results/fig4-5%20revise%20table.002.png'></p>\n<h2>Visual Results</h2>\n<p><img src='https://github.com/IlikeBB/F3DD/blob/main/plot_results/is0302.gif'></p>\n<img src='https://github.com/IlikeBB/F3DD/blob/main/plot_results/is0323.gif'></p>\n<img src='https://github.com/IlikeBB/F3DD/blob/main/plot_results/is0319.gif'></p>\n<img src='https://github.com/IlikeBB/F3DD/blob/main/plot_results/is0337.gif'></p></p>\n<h2>Reference</h2>\n<h4>Data Augmentation reference from<a href='https://github.com/albumentations-team/albumentations'> Albumentations</a>, <a href='https://github.com/mjkvaak/ImageDataAugmentor'> ImageDataAugmentor</a>.</h4>\n<h4>The code is heavily adapted from<a href='https://github.com/JihongJu/keras-resnet3d'> 3D ResNet</a>, <a href='https://github.com/qubvel/segmentation_models'> Segmentation Models</a>.</h4"
      },
      "source": "https://raw.githubusercontent.com/IlikeBB/SGD-Net/main/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/IlikeBB/SGD-Net/main/Toward Explainable Semantic Segmentation Guided Detector for Segmentation and Classification of Diffusion-Weighted MRI of Acute Ischemic Stroke</h1>\n<h2>Abstract</h2>\n<h4>Background and Purpose</h4>\n<blockquote>\n<p>Neuroimaging is valuable for clinical decision support in acute ischemic stroke (AIS). Diffusion-weighted imaging (DWI) is the representative MRI sequence to timely, sensitively, and accurately reflect ischemia injuries to brain tissue. However, the complexity of MRI elevates the threshold for instantaneously precise interpretation of the images. Therefore, this work leverage machine learning to segment and classify the AIS lesions on DWI images. We focused on model development, performance comparisons, and utilization for decision making.</p>\n</blockquote>\n<h4>Methods</h4>\n<blockquote>\n<p>We enrolled brain MRI images of AIS during 2017-2020 in a tertiary teaching hospital. DWI were analyzed by the network for semantic segmentation guided detector (SGD-Net), composed of a U-shaped stage 1 (S1) model for segmentation and a stage 2 (S2) model for classification. An image review board labeled images to provide ground truth for model training and testing. The binary classes in S2 were AIS lesion size (lacune vs. non-lacune) and circulatory territory of lesion location (anterior vs. posterior circulation). We compared different backbones of SGD-Net and contrasted them with one-stage classifiers.</p>\n</blockquote>\n<h4>Conclusions</h4>\n<blockquote>\n<p>The SGD-Net precisely segmented AIS lesions on DWI and accurately classified lesion size and location. Based on the two-stage design, combinations of different backbones for S1 U-Net and S2 classifier performed superiorly to the one-stage 3D-ResNet and 3D-CNNs. The U-shaped architecture of S1 was considered crucial for satisfactory model performance. In the future, the deployment of SGD-Net to the emergency health care system would improve AIS patient care. </p>\n</blockquote>\n<h2>Experiment Environment</h2>\n<p><code>OS: Ubuntu 16.04\nCUDA: 10.1\nGPU: Nvidia GTX 1080Ti x 1</code></p>\n<h2>Build Virtual Environment (Using Conda)</h2>\n<p>```\n!conda env create -f SGD.yml</p>\n<p>!conda activate SGD\n```</p>\n<h2>Model Architecture</h2>\n<p><img src='https://github.com/IlikeBB/F3DD/blob/main/plot_results/%E6%9E%B6%E6%A7%8B%E5%9C%96.jpg'></p>\n<h2>Data Preparing</h2>\n<p><code>!pip install nibabel\n!pip install scikit-image</code></p>\n<blockquote>\n<ul>\n<li>Loading nii or nii.gz data and transformation to numpy data array.</li>\n<li>Please refer to <code>00.nii data loading.ipynb</code> build your dataset array or build random data array.\n<code>example:\n ./data_set/...\n     1| 00001.nii -&gt; 00001.npy\n     2| 00002.nii -&gt; 00002.npy\n     3| 00003.nii -&gt; 00003.npy\n                  .\n                  .\n     n|     n.nii -&gt;     n.npy</code>\n<code>concate data array-&gt; [Sample Number, depth, width, height] ([140,32,384,384])</code></li>\n</ul>\n</blockquote>\n<h2>Training</h2>\n<p><code>!pip install git+https://github.com/mjkvaak/ImageDataAugmentor</code></p>\n<h3>Training S1 Semantic Segmentation Network</h3>\n<p><code>!python 01.S1_Training.py</code></p>\n<blockquote>\n<ul>\n<li>Edit env parameter value in <code>/utils/model_config_S1.yam</code>.</li>\n</ul>\n</blockquote>\n<h3>Training S2 3D Classification Network</h3>\n<p><code>!python 02.S2_AP_Training.py\n!python 02.S2_NL_Training.py</code></p>\n<blockquote>\n<ul>\n<li>Edit env parameter value in <code>/utils/model_config_NL or AP.yaml</code>.</li>\n</ul>\n</blockquote>\n<h2>Testing</h2>\n<p><code>!pip install -U scikit-learn</code></p>\n<blockquote>\n<ul>\n<li>Please refer to <code>03.evaluate.ipynb</code></li>\n<li>Edit env parameter value in <code>/utils/model_config.yaml</code>.</li>\n</ul>\n</blockquote>\n<h2>Perfromace Plot</h2>\n<p><img src='https://github.com/IlikeBB/F3DD/blob/main/plot_results/fig4-5%20revise%20table.001.png'>\n<img src='https://github.com/IlikeBB/F3DD/blob/main/plot_results/fig4-5%20revise%20table.002.png'></p>\n<h2>Visual Results</h2>\n<p><img src='https://github.com/IlikeBB/F3DD/blob/main/plot_results/is0302.gif'></p>\n<img src='https://github.com/IlikeBB/F3DD/blob/main/plot_results/is0323.gif'></p>\n<img src='https://github.com/IlikeBB/F3DD/blob/main/plot_results/is0319.gif'></p>\n<img src='https://github.com/IlikeBB/F3DD/blob/main/plot_results/is0337.gif'></p></p>\n<h2>Reference</h2>\n<h4>Data Augmentation reference from<a href='https://github.com/albumentations-team/albumentations'> Albumentations</a>, <a href='https://github.com/mjkvaak/ImageDataAugmentor'> ImageDataAugmentor</a>.</h4>\n<h4>The code is heavily adapted from<a href='https://github.com/JihongJu/keras-resnet3d'> 3D ResNet</a>, <a href='https://github.com/qubvel/segmentation_models'> Segmentation Models</a>.</h4"
      },
      "source": "https://raw.githubusercontent.com/IlikeBB/SGD-Net/main/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/IlikeBB/SGD-Net/main/Toward Explainable Semantic Segmentation Guided Detector for Segmentation and Classification of Diffusion-Weighted MRI of Acute Ischemic Stroke</h1>\n<h2>Abstract</h2>\n<h4>Background and Purpose</h4>\n<blockquote>\n<p>Neuroimaging is valuable for clinical decision support in acute ischemic stroke (AIS). Diffusion-weighted imaging (DWI) is the representative MRI sequence to timely, sensitively, and accurately reflect ischemia injuries to brain tissue. However, the complexity of MRI elevates the threshold for instantaneously precise interpretation of the images. Therefore, this work leverage machine learning to segment and classify the AIS lesions on DWI images. We focused on model development, performance comparisons, and utilization for decision making.</p>\n</blockquote>\n<h4>Methods</h4>\n<blockquote>\n<p>We enrolled brain MRI images of AIS during 2017-2020 in a tertiary teaching hospital. DWI were analyzed by the network for semantic segmentation guided detector (SGD-Net), composed of a U-shaped stage 1 (S1) model for segmentation and a stage 2 (S2) model for classification. An image review board labeled images to provide ground truth for model training and testing. The binary classes in S2 were AIS lesion size (lacune vs. non-lacune) and circulatory territory of lesion location (anterior vs. posterior circulation). We compared different backbones of SGD-Net and contrasted them with one-stage classifiers.</p>\n</blockquote>\n<h4>Conclusions</h4>\n<blockquote>\n<p>The SGD-Net precisely segmented AIS lesions on DWI and accurately classified lesion size and location. Based on the two-stage design, combinations of different backbones for S1 U-Net and S2 classifier performed superiorly to the one-stage 3D-ResNet and 3D-CNNs. The U-shaped architecture of S1 was considered crucial for satisfactory model performance. In the future, the deployment of SGD-Net to the emergency health care system would improve AIS patient care. </p>\n</blockquote>\n<h2>Experiment Environment</h2>\n<p><code>OS: Ubuntu 16.04\nCUDA: 10.1\nGPU: Nvidia GTX 1080Ti x 1</code></p>\n<h2>Build Virtual Environment (Using Conda)</h2>\n<p>```\n!conda env create -f SGD.yml</p>\n<p>!conda activate SGD\n```</p>\n<h2>Model Architecture</h2>\n<p><img src='https://github.com/IlikeBB/F3DD/blob/main/plot_results/%E6%9E%B6%E6%A7%8B%E5%9C%96.jpg'></p>\n<h2>Data Preparing</h2>\n<p><code>!pip install nibabel\n!pip install scikit-image</code></p>\n<blockquote>\n<ul>\n<li>Loading nii or nii.gz data and transformation to numpy data array.</li>\n<li>Please refer to <code>00.nii data loading.ipynb</code> build your dataset array or build random data array.\n<code>example:\n ./data_set/...\n     1| 00001.nii -&gt; 00001.npy\n     2| 00002.nii -&gt; 00002.npy\n     3| 00003.nii -&gt; 00003.npy\n                  .\n                  .\n     n|     n.nii -&gt;     n.npy</code>\n<code>concate data array-&gt; [Sample Number, depth, width, height] ([140,32,384,384])</code></li>\n</ul>\n</blockquote>\n<h2>Training</h2>\n<p><code>!pip install git+https://github.com/mjkvaak/ImageDataAugmentor</code></p>\n<h3>Training S1 Semantic Segmentation Network</h3>\n<p><code>!python 01.S1_Training.py</code></p>\n<blockquote>\n<ul>\n<li>Edit env parameter value in <code>/utils/model_config_S1.yam</code>.</li>\n</ul>\n</blockquote>\n<h3>Training S2 3D Classification Network</h3>\n<p><code>!python 02.S2_AP_Training.py\n!python 02.S2_NL_Training.py</code></p>\n<blockquote>\n<ul>\n<li>Edit env parameter value in <code>/utils/model_config_NL or AP.yaml</code>.</li>\n</ul>\n</blockquote>\n<h2>Testing</h2>\n<p><code>!pip install -U scikit-learn</code></p>\n<blockquote>\n<ul>\n<li>Please refer to <code>03.evaluate.ipynb</code></li>\n<li>Edit env parameter value in <code>/utils/model_config.yaml</code>.</li>\n</ul>\n</blockquote>\n<h2>Perfromace Plot</h2>\n<p><img src='https://github.com/IlikeBB/F3DD/blob/main/plot_results/fig4-5%20revise%20table.001.png'>\n<img src='https://github.com/IlikeBB/F3DD/blob/main/plot_results/fig4-5%20revise%20table.002.png'></p>\n<h2>Visual Results</h2>\n<p><img src='https://github.com/IlikeBB/F3DD/blob/main/plot_results/is0302.gif'></p>\n<img src='https://github.com/IlikeBB/F3DD/blob/main/plot_results/is0323.gif'></p>\n<img src='https://github.com/IlikeBB/F3DD/blob/main/plot_results/is0319.gif'></p>\n<img src='https://github.com/IlikeBB/F3DD/blob/main/plot_results/is0337.gif'></p></p>\n<h2>Reference</h2>\n<h4>Data Augmentation reference from<a href='https://github.com/albumentations-team/albumentations'> Albumentations</a>, <a href='https://github.com/mjkvaak/ImageDataAugmentor'> ImageDataAugmentor</a>.</h4>\n<h4>The code is heavily adapted from<a href='https://github.com/JihongJu/keras-resnet3d'> 3D ResNet</a>, <a href='https://github.com/qubvel/segmentation_models'> Segmentation Models</a>.</h4"
      },
      "source": "https://raw.githubusercontent.com/IlikeBB/SGD-Net/main/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/IlikeBB/SGD-Net/main/Toward Explainable Semantic Segmentation Guided Detector for Segmentation and Classification of Diffusion-Weighted MRI of Acute Ischemic Stroke</h1>\n<h2>Abstract</h2>\n<h4>Background and Purpose</h4>\n<blockquote>\n<p>Neuroimaging is valuable for clinical decision support in acute ischemic stroke (AIS). Diffusion-weighted imaging (DWI) is the representative MRI sequence to timely, sensitively, and accurately reflect ischemia injuries to brain tissue. However, the complexity of MRI elevates the threshold for instantaneously precise interpretation of the images. Therefore, this work leverage machine learning to segment and classify the AIS lesions on DWI images. We focused on model development, performance comparisons, and utilization for decision making.</p>\n</blockquote>\n<h4>Methods</h4>\n<blockquote>\n<p>We enrolled brain MRI images of AIS during 2017-2020 in a tertiary teaching hospital. DWI were analyzed by the network for semantic segmentation guided detector (SGD-Net), composed of a U-shaped stage 1 (S1) model for segmentation and a stage 2 (S2) model for classification. An image review board labeled images to provide ground truth for model training and testing. The binary classes in S2 were AIS lesion size (lacune vs. non-lacune) and circulatory territory of lesion location (anterior vs. posterior circulation). We compared different backbones of SGD-Net and contrasted them with one-stage classifiers.</p>\n</blockquote>\n<h4>Conclusions</h4>\n<blockquote>\n<p>The SGD-Net precisely segmented AIS lesions on DWI and accurately classified lesion size and location. Based on the two-stage design, combinations of different backbones for S1 U-Net and S2 classifier performed superiorly to the one-stage 3D-ResNet and 3D-CNNs. The U-shaped architecture of S1 was considered crucial for satisfactory model performance. In the future, the deployment of SGD-Net to the emergency health care system would improve AIS patient care. </p>\n</blockquote>\n<h2>Experiment Environment</h2>\n<p><code>OS: Ubuntu 16.04\nCUDA: 10.1\nGPU: Nvidia GTX 1080Ti x 1</code></p>\n<h2>Build Virtual Environment (Using Conda)</h2>\n<p>```\n!conda env create -f SGD.yml</p>\n<p>!conda activate SGD\n```</p>\n<h2>Model Architecture</h2>\n<p><img src='https://github.com/IlikeBB/F3DD/blob/main/plot_results/%E6%9E%B6%E6%A7%8B%E5%9C%96.jpg'></p>\n<h2>Data Preparing</h2>\n<p><code>!pip install nibabel\n!pip install scikit-image</code></p>\n<blockquote>\n<ul>\n<li>Loading nii or nii.gz data and transformation to numpy data array.</li>\n<li>Please refer to <code>00.nii data loading.ipynb</code> build your dataset array or build random data array.\n<code>example:\n ./data_set/...\n     1| 00001.nii -&gt; 00001.npy\n     2| 00002.nii -&gt; 00002.npy\n     3| 00003.nii -&gt; 00003.npy\n                  .\n                  .\n     n|     n.nii -&gt;     n.npy</code>\n<code>concate data array-&gt; [Sample Number, depth, width, height] ([140,32,384,384])</code></li>\n</ul>\n</blockquote>\n<h2>Training</h2>\n<p><code>!pip install git+https://github.com/mjkvaak/ImageDataAugmentor</code></p>\n<h3>Training S1 Semantic Segmentation Network</h3>\n<p><code>!python 01.S1_Training.py</code></p>\n<blockquote>\n<ul>\n<li>Edit env parameter value in <code>/utils/model_config_S1.yam</code>.</li>\n</ul>\n</blockquote>\n<h3>Training S2 3D Classification Network</h3>\n<p><code>!python 02.S2_AP_Training.py\n!python 02.S2_NL_Training.py</code></p>\n<blockquote>\n<ul>\n<li>Edit env parameter value in <code>/utils/model_config_NL or AP.yaml</code>.</li>\n</ul>\n</blockquote>\n<h2>Testing</h2>\n<p><code>!pip install -U scikit-learn</code></p>\n<blockquote>\n<ul>\n<li>Please refer to <code>03.evaluate.ipynb</code></li>\n<li>Edit env parameter value in <code>/utils/model_config.yaml</code>.</li>\n</ul>\n</blockquote>\n<h2>Perfromace Plot</h2>\n<p><img src='https://github.com/IlikeBB/F3DD/blob/main/plot_results/fig4-5%20revise%20table.001.png'>\n<img src='https://github.com/IlikeBB/F3DD/blob/main/plot_results/fig4-5%20revise%20table.002.png'></p>\n<h2>Visual Results</h2>\n<p><img src='https://github.com/IlikeBB/F3DD/blob/main/plot_results/is0302.gif'></p>\n<img src='https://github.com/IlikeBB/F3DD/blob/main/plot_results/is0323.gif'></p>\n<img src='https://github.com/IlikeBB/F3DD/blob/main/plot_results/is0319.gif'></p>\n<img src='https://github.com/IlikeBB/F3DD/blob/main/plot_results/is0337.gif'></p></p>\n<h2>Reference</h2>\n<h4>Data Augmentation reference from<a href='https://github.com/albumentations-team/albumentations'> Albumentations</a>, <a href='https://github.com/mjkvaak/ImageDataAugmentor'> ImageDataAugmentor</a>.</h4>\n<h4>The code is heavily adapted from<a href='https://github.com/JihongJu/keras-resnet3d'> 3D ResNet</a>, <a href='https://github.com/qubvel/segmentation_models'> Segmentation Models</a>.</h4"
      },
      "source": "https://raw.githubusercontent.com/IlikeBB/SGD-Net/main/README.md",
      "technique": "regular_expression"
    }
  ],
  "installation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Background and Purpose",
        "parent_header": [
          "Toward Explainable Semantic Segmentation Guided Detector for Segmentation and Classification of Diffusion-Weighted MRI of Acute Ischemic Stroke",
          "Abstract"
        ],
        "type": "Text_excerpt",
        "value": "> Neuroimaging is valuable for clinical decision support in acute ischemic stroke (AIS). Diffusion-weighted imaging (DWI) is the representative MRI sequence to timely, sensitively, and accurately reflect ischemia injuries to brain tissue. However, the complexity of MRI elevates the threshold for instantaneously precise interpretation of the images. Therefore, this work leverage machine learning to segment and classify the AIS lesions on DWI images. We focused on model development, performance comparisons, and utilization for decision making."
      },
      "source": "https://raw.githubusercontent.com/IlikeBB/SGD-Net/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Methods",
        "parent_header": [
          "Toward Explainable Semantic Segmentation Guided Detector for Segmentation and Classification of Diffusion-Weighted MRI of Acute Ischemic Stroke",
          "Abstract"
        ],
        "type": "Text_excerpt",
        "value": "> We enrolled brain MRI images of AIS during 2017-2020 in a tertiary teaching hospital. DWI were analyzed by the network for semantic segmentation guided detector (SGD-Net), composed of a U-shaped stage 1 (S1) model for segmentation and a stage 2 (S2) model for classification. An image review board labeled images to provide ground truth for model training and testing. The binary classes in S2 were AIS lesion size (lacune vs. non-lacune) and circulatory territory of lesion location (anterior vs. posterior circulation). We compared different backbones of SGD-Net and contrasted them with one-stage classifiers."
      },
      "source": "https://raw.githubusercontent.com/IlikeBB/SGD-Net/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Conclusions",
        "parent_header": [
          "Toward Explainable Semantic Segmentation Guided Detector for Segmentation and Classification of Diffusion-Weighted MRI of Acute Ischemic Stroke",
          "Abstract"
        ],
        "type": "Text_excerpt",
        "value": "> The SGD-Net precisely segmented AIS lesions on DWI and accurately classified lesion size and location. Based on the two-stage design, combinations of different backbones for S1 U-Net and S2 classifier performed superiorly to the one-stage 3D-ResNet and 3D-CNNs. The U-shaped architecture of S1 was considered crucial for satisfactory model performance. In the future, the deployment of SGD-Net to the emergency health care system would improve AIS patient care. \n"
      },
      "source": "https://raw.githubusercontent.com/IlikeBB/SGD-Net/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Experiment Environment",
        "parent_header": [
          "Toward Explainable Semantic Segmentation Guided Detector for Segmentation and Classification of Diffusion-Weighted MRI of Acute Ischemic Stroke"
        ],
        "type": "Text_excerpt",
        "value": "```\nOS: Ubuntu 16.04\nCUDA: 10.1\nGPU: Nvidia GTX 1080Ti x 1\n```"
      },
      "source": "https://raw.githubusercontent.com/IlikeBB/SGD-Net/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Build Virtual Environment (Using Conda)",
        "parent_header": [
          "Toward Explainable Semantic Segmentation Guided Detector for Segmentation and Classification of Diffusion-Weighted MRI of Acute Ischemic Stroke"
        ],
        "type": "Text_excerpt",
        "value": "```\n!conda env create -f SGD.yml\n\n!conda activate SGD\n```"
      },
      "source": "https://raw.githubusercontent.com/IlikeBB/SGD-Net/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Model Architecture",
        "parent_header": [
          "Toward Explainable Semantic Segmentation Guided Detector for Segmentation and Classification of Diffusion-Weighted MRI of Acute Ischemic Stroke"
        ],
        "type": "Text_excerpt",
        "value": "<img src='https://github.com/IlikeBB/F3DD/blob/main/plot_results/%E6%9E%B6%E6%A7%8B%E5%9C%96.jpg'>\n"
      },
      "source": "https://raw.githubusercontent.com/IlikeBB/SGD-Net/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Data Preparing",
        "parent_header": [
          "Toward Explainable Semantic Segmentation Guided Detector for Segmentation and Classification of Diffusion-Weighted MRI of Acute Ischemic Stroke"
        ],
        "type": "Text_excerpt",
        "value": "```\n!pip install nibabel\n!pip install scikit-image\n```\n> * Loading nii or nii.gz data and transformation to numpy data array.\n> * Please refer to `00.nii data loading.ipynb` build your dataset array or build random data array.\n```\n example:\n ./data_set/...\n     1| 00001.nii -> 00001.npy\n     2| 00002.nii -> 00002.npy\n     3| 00003.nii -> 00003.npy\n                  .\n                  .\n     n|     n.nii ->     n.npy\n```\n```\nconcate data array-> [Sample Number, depth, width, height] ([140,32,384,384])\n```\n"
      },
      "source": "https://raw.githubusercontent.com/IlikeBB/SGD-Net/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Training",
        "parent_header": [
          "Toward Explainable Semantic Segmentation Guided Detector for Segmentation and Classification of Diffusion-Weighted MRI of Acute Ischemic Stroke"
        ],
        "type": "Text_excerpt",
        "value": "```\n!pip install git+https://github.com/mjkvaak/ImageDataAugmentor\n```"
      },
      "source": "https://raw.githubusercontent.com/IlikeBB/SGD-Net/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Training S1 Semantic Segmentation Network",
        "parent_header": [
          "Toward Explainable Semantic Segmentation Guided Detector for Segmentation and Classification of Diffusion-Weighted MRI of Acute Ischemic Stroke",
          "Training"
        ],
        "type": "Text_excerpt",
        "value": "```\n!python 01.S1_Training.py\n```\n> * Edit env parameter value in `/utils/model_config_S1.yam`.\n"
      },
      "source": "https://raw.githubusercontent.com/IlikeBB/SGD-Net/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Training S2 3D Classification Network",
        "parent_header": [
          "Toward Explainable Semantic Segmentation Guided Detector for Segmentation and Classification of Diffusion-Weighted MRI of Acute Ischemic Stroke",
          "Training"
        ],
        "type": "Text_excerpt",
        "value": "```\n!python 02.S2_AP_Training.py\n!python 02.S2_NL_Training.py\n```\n> * Edit env parameter value in `/utils/model_config_NL or AP.yaml`.\n"
      },
      "source": "https://raw.githubusercontent.com/IlikeBB/SGD-Net/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Testing",
        "parent_header": [
          "Toward Explainable Semantic Segmentation Guided Detector for Segmentation and Classification of Diffusion-Weighted MRI of Acute Ischemic Stroke"
        ],
        "type": "Text_excerpt",
        "value": "```\n!pip install -U scikit-learn\n```\n> * Please refer to `03.evaluate.ipynb`\n> * Edit env parameter value in `/utils/model_config.yaml`.\n"
      },
      "source": "https://raw.githubusercontent.com/IlikeBB/SGD-Net/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Perfromace Plot",
        "parent_header": [
          "Toward Explainable Semantic Segmentation Guided Detector for Segmentation and Classification of Diffusion-Weighted MRI of Acute Ischemic Stroke"
        ],
        "type": "Text_excerpt",
        "value": "<img src='https://github.com/IlikeBB/F3DD/blob/main/plot_results/fig4-5%20revise%20table.001.png'>\n<img src='https://github.com/IlikeBB/F3DD/blob/main/plot_results/fig4-5%20revise%20table.002.png'>\n"
      },
      "source": "https://raw.githubusercontent.com/IlikeBB/SGD-Net/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Visual Results",
        "parent_header": [
          "Toward Explainable Semantic Segmentation Guided Detector for Segmentation and Classification of Diffusion-Weighted MRI of Acute Ischemic Stroke"
        ],
        "type": "Text_excerpt",
        "value": "<img src='https://github.com/IlikeBB/F3DD/blob/main/plot_results/is0302.gif'></p>\n<img src='https://github.com/IlikeBB/F3DD/blob/main/plot_results/is0323.gif'></p>\n<img src='https://github.com/IlikeBB/F3DD/blob/main/plot_results/is0319.gif'></p>\n<img src='https://github.com/IlikeBB/F3DD/blob/main/plot_results/is0337.gif'></p>\n"
      },
      "source": "https://raw.githubusercontent.com/IlikeBB/SGD-Net/main/README.md",
      "technique": "header_analysis"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/IlikeBB/SGD-Net/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ""
      },
      "technique": "GitHub_API"
    }
  ],
  "license": [
    {
      "confidence": 1,
      "result": {
        "type": "File_dump",
        "value": "MIT License\n\nCopyright (c) 2019 ryanhuynh\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
      },
      "source": "https://raw.githubusercontent.com/IlikeBB/SGD-Net/main/utils/augmented/LICENSE",
      "technique": "file_exploration"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "SGD-Net"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "User",
        "value": "IlikeBB"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Jupyter Notebook",
        "size": 494277,
        "type": "Programming_language",
        "value": "Jupyter Notebook"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "HTML",
        "size": 444842,
        "type": "Programming_language",
        "value": "HTML"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 143612,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Shell",
        "size": 4902,
        "type": "Programming_language",
        "value": "Shell"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/IlikeBB/SGD-Net/main/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "somef_missing_categories": [
    "citation",
    "acknowledgement",
    "run",
    "download",
    "requirements",
    "contact",
    "description",
    "contributors",
    "documentation",
    "usage",
    "faq",
    "support",
    "identifier",
    "has_build_file"
  ],
  "somef_provenance": {
    "date": "2024-10-05 23:36:26",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 1
      },
      "technique": "GitHub_API"
    }
  ]
}