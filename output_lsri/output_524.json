{
  "application_domain": [
    {
      "confidence": 50.33,
      "result": {
        "type": "String",
        "value": "Computer Vision"
      },
      "technique": "supervised_classification"
    }
  ],
  "citation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Citation",
        "parent_header": [
          "MobileSal",
          "Others"
        ],
        "type": "Text_excerpt",
        "value": "If you are using the code/model/data provided here in a publication, please consider citing our work:\n\n````\n@ARTICLE{wu2021mobilesal,\n  author={Wu, Yu-Huan and Liu, Yun and Xu, Jun and Bian, Jia-Wang and Gu, Yu-Chao and Cheng, Ming-Ming},\n  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, \n  title={MobileSal: Extremely Efficient RGB-D Salient Object Detection}, \n  year={2022},\n  volume={44},\n  number={12},\n  pages={10261--10269},\n  doi={10.1109/TPAMI.2021.3134684}\n}\n````\n\n"
      },
      "source": "https://raw.githubusercontent.com/yuhuan-wu/mobilesal/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "author": "Wu, Yu-Huan and Liu, Yun and Xu, Jun and Bian, Jia-Wang and Gu, Yu-Chao and Cheng, Ming-Ming",
        "doi": "10.1109/TPAMI.2021.3134684",
        "format": "bibtex",
        "title": "MobileSal: Extremely Efficient RGB-D Salient Object Detection",
        "type": "Text_excerpt",
        "value": "@article{wu2021mobilesal,\n    doi = {10.1109/TPAMI.2021.3134684},\n    pages = {10261--10269},\n    number = {12},\n    volume = {44},\n    year = {2022},\n    title = {MobileSal: Extremely Efficient RGB-D Salient Object Detection},\n    journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},\n    author = {Wu, Yu-Huan and Liu, Yun and Xu, Jun and Bian, Jia-Wang and Gu, Yu-Chao and Cheng, Ming-Ming},\n}"
      },
      "source": "https://raw.githubusercontent.com/yuhuan-wu/mobilesal/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/yuhuan-wu/MobileSal"
      },
      "technique": "GitHub_API"
    }
  ],
  "contact": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Contact",
        "parent_header": [
          "MobileSal",
          "Others"
        ],
        "type": "Text_excerpt",
        "value": "* I encourage everyone to contact me via my e-mail. My e-mail is: wuyuhuan @ mail.nankai (dot) edu.cn\n"
      },
      "source": "https://raw.githubusercontent.com/yuhuan-wu/mobilesal/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2021-07-07T03:18:51Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2024-06-25T07:53:58Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "[IEEE TPAMI22] MobileSal: Extremely Efficient RGB-D Salient Object Detection [PyTorch & Jittor]"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 0.9692444430848173,
      "result": {
        "original_header": "MobileSal",
        "type": "Text_excerpt",
        "value": "This repository contains full training & testing code, and pretrained saliency maps. We have achieved competitive performance on the RGB-D salient object detection task with a speed of 450fps. \nIf you run into any problems or feel any difficulties to run this code, do not hesitate to leave issues in this repository. \nThis repository contains: \n- [x] Full code, data, pretrained models for `training` and `testing`\n- [x] MobileSal deployment, achieving 420FPS (fp32) and 800FPS (fp16) with `batch size 1` on a single RTX 2080Ti. \n"
      },
      "source": "https://raw.githubusercontent.com/yuhuan-wu/mobilesal/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9007662971606437,
      "result": {
        "original_header": "Pretrained Models",
        "type": "Text_excerpt",
        "value": "As in our paper, we train our model on the NJU2K_NLPR training set, and test our model on NJU2K_test, NLPR_test, STEREO, SIP, and SSD datasets. For DUTLF-D, we train our model on DUTLF-D training set and evaluate on its testing test. \n"
      },
      "source": "https://raw.githubusercontent.com/yuhuan-wu/mobilesal/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9540963640171002,
      "result": {
        "original_header": "Generate Saliency Maps",
        "type": "Text_excerpt",
        "value": "The deployment largely speeds up MobileSal with batch size of 1.\nAn example script is located at: `tools/test_trt.sh`. Run:\n```\nbash ./tools/test_trt.sh\n```\nThis script will automatically convert PyTorch MobileSal to TensorRT-based MobileSal. Then it will generate saliency maps via the TensorRT-based MobileSal.\nOn deployment for real-world applications, you can load the converted TensorRT MobileSal for inference:\n```\nfrom torch2trt import torch2trt, TRTModule\nmodel = TRTModule(); trt_model_path = \"pretrained/mobilesal_trt.pth\"\nmodel.load_state_dict(torch.load(trt_model_path))\nresult = model(image, depth) # get result with [torch.Tensor] input\n```\n \n"
      },
      "source": "https://raw.githubusercontent.com/yuhuan-wu/mobilesal/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9047231027073884,
      "result": {
        "original_header": "Speed Test",
        "type": "Text_excerpt",
        "value": "The speed result on a single RTX 2080Ti is as below: \n"
      },
      "source": "https://raw.githubusercontent.com/yuhuan-wu/mobilesal/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9388729207534459,
      "result": {
        "original_header": "Pretrained Saliency maps",
        "type": "Text_excerpt",
        "value": "For covenience, we provide the pretrained saliency maps on several datasets as below: \n"
      },
      "source": "https://raw.githubusercontent.com/yuhuan-wu/mobilesal/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9841873119670065,
      "result": {
        "original_header": "Acknowlogdement",
        "type": "Text_excerpt",
        "value": "This repository is built under the help of the following five projects for academic use only: \n"
      },
      "source": "https://raw.githubusercontent.com/yuhuan-wu/mobilesal/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/yuhuan-wu/mobilesal/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 14
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/yuhuan-wu/MobileSal/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "yuhuan-wu/MobileSal"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "MobileSal"
      },
      "source": "https://raw.githubusercontent.com/yuhuan-wu/mobilesal/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "has_script_file": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/yuhuan-wu/mobilesal/master/tools/train.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/yuhuan-wu/mobilesal/master/tools/test.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/yuhuan-wu/mobilesal/master/tools/test_dut.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/yuhuan-wu/mobilesal/master/tools/test_trt.sh"
      },
      "technique": "file_exploration"
    }
  ],
  "installation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Data Preparing",
        "parent_header": [
          "MobileSal"
        ],
        "type": "Text_excerpt",
        "value": "Before training/testing our network, please download the training data: \n\n* Preprocessed data of 6 datasets: [[Google Drive]](https://drive.google.com/file/d/1czlZyW9_6k3ueS--TDAZK6M7Uv6FpUfO/view?usp=sharing), [[Baidu Pan, 9nxi]](https://pan.baidu.com/s/1a71BlcvX0MTBuP_GGd84WA)\n\n\nNote: if you are blocked by Google and Baidu services, you can contact me via e-mail and I will send you a copy of data and model weights.\n\nWe have processed the data well so you can use them without any preprocessing steps. \nAfter completion of downloading, extract the data and put them to `./data/` folder.\nThen, the `./datasets/` folder should contain six folders: `NJU2K/, NLPR/, STERE/, SSD/, SIP/, DUT-RGBD/`, representing `NJU2K, NLPR, STEREO, SSD, SIP, DUTLF-D` datasets, respectively.\n\n"
      },
      "source": "https://raw.githubusercontent.com/yuhuan-wu/mobilesal/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 0.993291081371737,
      "result": {
        "original_header": "MobileSal",
        "type": "Text_excerpt",
        "value": "If you run into any problems or feel any difficulties to run this code, do not hesitate to leave issues in this repository. \n"
      },
      "source": "https://raw.githubusercontent.com/yuhuan-wu/mobilesal/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9999999999999716,
      "result": {
        "original_header": "Deployment",
        "type": "Text_excerpt",
        "value": "For Jittor users, we create a branch `jittor`. So please run the following command first:\n````\ngit checkout jittor\n````\nTo install MobileSal, please run:\n````\npip install -r envs/requirements.txt\n````\n \n"
      },
      "source": "https://raw.githubusercontent.com/yuhuan-wu/mobilesal/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9510155007360841,
      "result": {
        "original_header": "Speed Test",
        "type": "Text_excerpt",
        "value": "We provide a speed test script on MobileSal:\n```\npython speed_test.py\n```\n \n"
      },
      "source": "https://raw.githubusercontent.com/yuhuan-wu/mobilesal/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "invocation": [
    {
      "confidence": 0.889171784165028,
      "result": {
        "original_header": "Generate Saliency Maps",
        "type": "Text_excerpt",
        "value": "The deployment largely speeds up MobileSal with batch size of 1.\nAn example script is located at: `tools/test_trt.sh`. Run:\n```\nbash ./tools/test_trt.sh\n```\nThis script will automatically convert PyTorch MobileSal to TensorRT-based MobileSal. Then it will generate saliency maps via the TensorRT-based MobileSal.\nOn deployment for real-world applications, you can load the converted TensorRT MobileSal for inference:\n```\nfrom torch2trt import torch2trt, TRTModule\nmodel = TRTModule(); trt_model_path = \"pretrained/mobilesal_trt.pth\"\nmodel.load_state_dict(torch.load(trt_model_path))\nresult = model(image, depth) # get result with [torch.Tensor] input\n```\n \n"
      },
      "source": "https://raw.githubusercontent.com/yuhuan-wu/mobilesal/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9036433119056397,
      "result": {
        "original_header": "Speed Test",
        "type": "Text_excerpt",
        "value": "We provide a speed test script on MobileSal:\n```\npython speed_test.py\n```\n \n"
      },
      "source": "https://raw.githubusercontent.com/yuhuan-wu/mobilesal/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/yuhuan-wu/MobileSal/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ""
      },
      "technique": "GitHub_API"
    }
  ],
  "license": [
    {
      "confidence": 1,
      "result": {
        "original_header": "License",
        "parent_header": [
          "MobileSal",
          "Others"
        ],
        "type": "Text_excerpt",
        "value": "The code is released under the [Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International Public License](https://creativecommons.org/licenses/by-nc-sa/4.0/legalcode) for NonCommercial use only.\n\n"
      },
      "source": "https://raw.githubusercontent.com/yuhuan-wu/mobilesal/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "MobileSal"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "User",
        "value": "yuhuan-wu"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 72884,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Shell",
        "size": 1624,
        "type": "Programming_language",
        "value": "Shell"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/yuhuan-wu/mobilesal/master/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "related_papers": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://arxiv.org/abs/2106.12011"
      },
      "source": "https://raw.githubusercontent.com/yuhuan-wu/mobilesal/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "requirements": [
    {
      "confidence": 1,
      "result": {
        "original_header": "PyTorch",
        "parent_header": [
          "MobileSal",
          "Requirements"
        ],
        "type": "Text_excerpt",
        "value": "* Python 3.6+\n* PyTorch >=0.4.1, OpenCV-Python\n* Tested on PyTorch 1.7.1\n"
      },
      "source": "https://raw.githubusercontent.com/yuhuan-wu/mobilesal/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Jittor",
        "parent_header": [
          "MobileSal",
          "Requirements"
        ],
        "type": "Text_excerpt",
        "value": "* Python 3.7+\n* Jittor, OpenCV-Python\n* Tested on Jittor 1.3.1\n"
      },
      "source": "https://raw.githubusercontent.com/yuhuan-wu/mobilesal/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "somef_missing_categories": [
    "acknowledgement",
    "run",
    "download",
    "contributors",
    "documentation",
    "usage",
    "faq",
    "support",
    "identifier",
    "has_build_file",
    "executable_example"
  ],
  "somef_provenance": {
    "date": "2024-10-06 01:17:15",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 63
      },
      "technique": "GitHub_API"
    }
  ]
}