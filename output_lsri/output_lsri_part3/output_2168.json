{
  "application_domain": [
    {
      "confidence": 24.4,
      "result": {
        "type": "String",
        "value": "Computer Vision"
      },
      "technique": "supervised_classification"
    }
  ],
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/DiltheyLab/MetaMaps"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2018-06-19T10:10:16Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2024-08-18T06:47:46Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "Long-read metagenomic analysis"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 0.9522721098933433,
      "result": {
        "original_header": "MetaMaps",
        "type": "Text_excerpt",
        "value": "MetaMaps is tool specifically developed for the analysis of long-read (PacBio/Oxford Nanopore) metagenomic datasets. \nIt simultaenously carries out read assignment and sample composition estimation. \nIt is faster than classical exact alignment-based approaches, and its output is more information-rich than that of kmer-spectra-based methods. For example, each MetaMaps alignment comes with an approximate alignment location, an estimated alignment identity and a mapping quality. \nThe approximate mapping algorithm employed by MetaMaps is based on [MashMap](https://github.com/marbl/MashMap). MetaMaps adds a mapping quality model and EM-based estimation of sample composition.\n \n"
      },
      "source": "https://raw.githubusercontent.com/DiltheyLab/MetaMaps/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9509125774918429,
      "result": {
        "original_header": "Output",
        "type": "Text_excerpt",
        "value": "1. `classification_results.EM.WIMP`: Sample composition at different taxonomic levels (WIMP = \"What's in my pot\"). The level \"definedGenomes\" represents strain-level resolution (i.e., the defined genomes in the classification database). The EM algorithm is carried out at this level.\n   \n   Output columns: `Absolute` specifies the number of reads assigned (by their maximum likelihood mapping estimate) to the taxonomic entity; `EMFrequency` specifies the estimated frequency of the taxonomic entity prior to taking into account unmapped reads; `PotFrequency` specifies the estimated final frequency of the taxonomic entity (i.e. after correcting for unmapped reads). \n2. `classification_results.EM.reads2Taxon`: One line per read, and each line consists of the read ID and the taxon ID of the genome that the read was assigned to. Taxon IDs beginning with an 'x' represent MetaMaps-internal taxon IDs that disambiguate between source genomes attached to the same 'species' node. These can be interpreted using the extended database taxonomy (sub-directory `taxonomy` in the directory of the utilized database). \n3. `classification_results.EM.reads2Taxon.krona`: Like `classification_results.EM.reads2Taxon`, but in [Krona](https://github.com/marbl/Krona/wiki) format. Each line has an additional quality value, and only taxon IDs from the standard NCBI taxonomy are used. \n4. `classification_results.EM.contigCoverage`: Read coverage for contigs that appear in the final set of maximum-likelihood mappings. Contigs are split into windows of 1000 base pairs. Each line represents one window and specifies the MetaMaps taxonID of the contig (`taxonID`), a species/strain label (`equalCoverageUnitLabel`), the ID of the contig in the classification database FASTA file (`contigID`), start and stop coordinates of the window (`start` and `stop`), the number of read bases overlapping the window (`nBases`), and the number of read bases overlapping the window divided by window length, i.e. coverage (`readCoverage`). \n5. `classification_results.EM.lengthAndIdentitiesPerMappingUnit`: Read length and estimated identity for all reads, sorted by the contig they are mapped to. Each line represents one read and has the fields `AnalysisLevel`, which is always equal to `EqualCoverageUnit`; `ID`, which is the ID of the contig in the classification database FASTA file; `readI`, which is a simple numerical read ID; `Identity`, which is the estimated alignment identity; and `Length`, specifying the length of the read. \n5. `classification_results.EM`: The final and complete set of approximate read mappings. Each line represents one mapping in a simple space-delimited format. Fields: read ID, read length, beginning of the mapping in the read, end of the mapping in the read, strand, contig ID, contig length, beginning of the mapping in the contig, end of the mapping in the contig, estimated alignment identity using a Poisson model, MinHash intersection size, MinHash union size, estimated alignment identity using a binomial approximation, mapping quality. The mapping qualities of all mappings for one read sum up to 1. \n6. `classification_results.EM.evidenceUnknownSpecies`: Various statistics on read identities and zero-coverage regions of identified genomes. These are not particularly useful in their current state; visual inspection of coverage and identity patterns should take precedence. \n"
      },
      "source": "https://raw.githubusercontent.com/DiltheyLab/MetaMaps/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9267618452966808,
      "result": {
        "original_header": "Databases",
        "type": "Text_excerpt",
        "value": "The 'miniSeq+H' database is a good place to start. It contains >12000 microbial genomes and the human reference genome. We provide miniSeq+H as a download (see above for the link). \nYou can also download and construct your own reference databases. For example, this is how to construct the miniSeq+H database: \n1. Download the genomes you want to include. The easiest way to do this is by copying the RefSeq/Genbank directory structure of the taxonomic branches you're interested in. This can be done with the `downloadRefSeq.pl` script, which is easily customizable (e.g., `--targetBranches archaea,bacteria,fungi` to download these three branches). Example: \n2. We need to make sure that each contig ID is annotated with a correct and unique taxon ID and we want the whole database as one file. `annotateRefSeqSequencesWithUniqueTaxonIDs.pl` can help: \n    ```\n    perl buildDB.pl --DB databases/myDB --FASTAs download/refseq,hg38.primary.fna.with9606 --taxonomy download/taxonomy_uniqueIDs\n    ```\n\t\n    The NCBI taxonomy changes on a regular basis, and you might not want to repeat the complete database construction process every time that happens. You can update the utilized taxonomy as part of `buildDB.pl`, by specifying the \"old\" taxonomy (used for `addTaxonIDToFasta.pl`), `--updateTaxonomy 1`, and the path to a download of the new taxonomy (e.g. [ftp://ftp.ncbi.nlm.nih.gov/pub/taxonomy/taxdump.tar.gz](ftp://ftp.ncbi.nlm.nih.gov/pub/taxonomy/taxdump.tar.gz)). Example: \n"
      },
      "source": "https://raw.githubusercontent.com/DiltheyLab/MetaMaps/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9381723553664135,
      "result": {
        "original_header": "Advanced features",
        "type": "Text_excerpt",
        "value": "### Plotting spatial genome coverage and alignment identities \n"
      },
      "source": "https://raw.githubusercontent.com/DiltheyLab/MetaMaps/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8955062441737012,
      "result": {
        "original_header": "Plotting spatial genome coverage and alignment identities",
        "type": "Text_excerpt",
        "value": "MetaMaps comes with a small R script (`plotIdentities_EM.R`) that helps visalize spatial genome coverage and alignment identity per genome. You can assess these metrics to identify mismatches between the sample and the database. \nParameters: the classification prefix (i.e. whatever input your provided to `metamaps --classify`) of the output. \n"
      },
      "source": "https://raw.githubusercontent.com/DiltheyLab/MetaMaps/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9845385039454922,
      "result": {
        "original_header": "Filtering out WIMP entries with low median identity",
        "type": "Text_excerpt",
        "value": "If you suspect that your sample contains many genomes not represented in the database (one way to adjudicate this is to examine the identity histograms of the maximum likelihood alignments, e.g. with `plotIdentities_EM.R`), the produced WIMP files may contain many false-positive hits. \n"
      },
      "source": "https://raw.githubusercontent.com/DiltheyLab/MetaMaps/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9513065800069269,
      "result": {
        "original_header": "COG group analysis",
        "type": "Text_excerpt",
        "value": "You can use MetaMaps to carry out a COG group analysis of your metagenomic sample. Whenever a read overlaps with an annotated gene location, it is counted towards the COG groups (and other annotations) associated with the corresponding gene. Note that a single read can overlap with multiple genes, and that a single gene can be associated with multiple COG groups (or other annotations). Gene locations and amino acid sequences come from GenBank/Refseq, and the annotations are produced with [eggnog-mapper](https://github.com/jhcepas/eggnog-mapper). \n\n    To carry out this type of analysis, you need an \"annotated\" database that contains, in addition to the reference FASTA files, the locations and amino acid sequences of encoded genes, as well as a (gene) -> (annotation) mapping file. The [refseq_with_annotations](https://www.dropbox.com/s/36nz876g1hjh01r/refseq_with_annotations.tar.gz?dl=0) database (18.4 GB compressed) is a good place to start. You can untar this file from the main MetaMaps directory. Afterwards, you should see a `databases/refseq_with_annotations` directory. \n2. Carry out mapping and classification. \n3. Carry out the gene- and annotation-level analysis. \n    A gene- and annotation-level analysis is carried out with the script `geneLevelAnalysis.pl`. Example: \n    This command will produce the following files:\n    - `classification_results.EM.geneLevelAnalysis`: This file contains the names and (for some genes) protein IDs of genes hit by overlapping reads from the input dataset. It also contains the number of overlapping reads and their median identity. \n    - `classification_results.EM.proteins.*`: Like `classification_results.EM.geneLevelAnalysis`, but agglomerated according to eggnog-mapper-produced gene annotations. For example, `classification_results.EM.proteins.COG` will contain a COG-level analysis of the input data. Note that features are not mutually exclusive, i.e. a single read can overlap with multiple genes, and a single gene can carry multiple annotations. \n"
      },
      "source": "https://raw.githubusercontent.com/DiltheyLab/MetaMaps/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "documentation": [
    {
      "confidence": 1,
      "result": {
        "format": "wiki",
        "type": "Url",
        "value": "https://github.com/marbl/Krona/wiki"
      },
      "source": "https://raw.githubusercontent.com/DiltheyLab/MetaMaps/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/DiltheyLab/MetaMaps/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 23
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/DiltheyLab/MetaMaps/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "DiltheyLab/MetaMaps"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "MetaMaps"
      },
      "source": "https://raw.githubusercontent.com/DiltheyLab/MetaMaps/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "has_script_file": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/DiltheyLab/MetaMaps/master/bootstrap.sh"
      },
      "technique": "file_exploration"
    }
  ],
  "installation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Installation",
        "parent_header": [
          "MetaMaps"
        ],
        "type": "Text_excerpt",
        "value": "Then download a database, e.g. [miniSeq+H](https://www.dropbox.com/s/6p9o42yufx2vkae/miniSeq%2BH.tar.gz?dl=0) (~8G compressed, microbial genomes and the human reference genome). Extract the downloaded database into the `databases/` directory.\n"
      },
      "source": "https://raw.githubusercontent.com/DiltheyLab/MetaMaps/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 0.9003660180326855,
      "result": {
        "original_header": "Output",
        "type": "Text_excerpt",
        "value": "You can download [example output files](https://github.com/DiltheyLab/MetaMaps/blob/master/MetaMaps_example_output.zip).\n \n"
      },
      "source": "https://raw.githubusercontent.com/DiltheyLab/MetaMaps/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9708390876863646,
      "result": {
        "original_header": "Databases",
        "type": "Text_excerpt",
        "value": "1. Download the genomes you want to include. The easiest way to do this is by copying the RefSeq/Genbank directory structure of the taxonomic branches you're interested in. This can be done with the `downloadRefSeq.pl` script, which is easily customizable (e.g., `--targetBranches archaea,bacteria,fungi` to download these three branches). Example: \n    ```\n    mkdir download\n\tperl downloadRefSeq.pl --seqencesOutDirectory download/refseq --taxonomyOutDirectory download/taxonomy\n    ``` \n    ```\n    perl annotateRefSeqSequencesWithUniqueTaxonIDs.pl --refSeqDirectory download/refseq --taxonomyInDirectory download/taxonomy --taxonomyOutDirectory download/taxonomy_uniqueIDs\n    ```\n    \n    By default this script will only process complete (finished) assemblies - if you want to modify this behaviour, uncomment the line `next unless($assembly_level eq 'Complete Genome');`.\n    \n3. We might also manually want to include additional genomes, for example the human reference genome. Obtain the genome in one file (e.g. `hg38.primary.fna`) and add taxon IDs: \n    ```\n    perl util/addTaxonIDToFasta.pl --inputFA hg38.primary.fna --outputFA hg38.primary.fna.with9606 --taxonID 9606\n    ```\n4. If the `databases` directory does not exist, create it: `mkdir -p databases`. \n    ```\n    perl buildDB.pl --DB databases/myDB --FASTAs download/refseq/ref.fa,hg38.primary.fna.with9606 --taxonomy download/new_taxonomy --oldTaxonomy download/taxonomy_uniqueIDs --updateTaxonomy 1\n    ``` \n"
      },
      "source": "https://raw.githubusercontent.com/DiltheyLab/MetaMaps/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9672707946516969,
      "result": {
        "original_header": "Filtering out WIMP entries with low median identity",
        "type": "Text_excerpt",
        "value": "You can filter your WIMP output with the script `filterLowIdentityEntities.pl`. \n"
      },
      "source": "https://raw.githubusercontent.com/DiltheyLab/MetaMaps/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "invocation": [
    {
      "confidence": 0.8188723102352211,
      "result": {
        "original_header": "Databases",
        "type": "Text_excerpt",
        "value": "    ```\n    mkdir download\n\tperl downloadRefSeq.pl --seqencesOutDirectory download/refseq --taxonomyOutDirectory download/taxonomy\n    ``` \n    ```\n    perl buildDB.pl --DB databases/myDB --FASTAs download/refseq/ref.fa,hg38.primary.fna.with9606 --taxonomy download/new_taxonomy --oldTaxonomy download/taxonomy_uniqueIDs --updateTaxonomy 1\n    ``` \n"
      },
      "source": "https://raw.githubusercontent.com/DiltheyLab/MetaMaps/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8677982509526866,
      "result": {
        "original_header": "Plotting spatial genome coverage and alignment identities",
        "type": "Text_excerpt",
        "value": "Example:\n```\nRscript plotIdentities_EM.R classification_results\n```\n \n"
      },
      "source": "https://raw.githubusercontent.com/DiltheyLab/MetaMaps/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8003745384114032,
      "result": {
        "original_header": "Filtering out WIMP entries with low median identity",
        "type": "Text_excerpt",
        "value": "Example:\n```\nperl filterLowIdentityEntities.pl --DB miniSeq+H --mappings classification_results --identityThreshold 0.8\n```\n \n"
      },
      "source": "https://raw.githubusercontent.com/DiltheyLab/MetaMaps/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8677982509526866,
      "result": {
        "original_header": "COG group analysis",
        "type": "Text_excerpt",
        "value": "    Example: \n"
      },
      "source": "https://raw.githubusercontent.com/DiltheyLab/MetaMaps/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/DiltheyLab/MetaMaps/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ""
      },
      "technique": "GitHub_API"
    }
  ],
  "license": [
    {
      "confidence": 1,
      "result": {
        "name": "Other",
        "spdx_id": "NOASSERTION",
        "type": "License",
        "url": null,
        "value": null
      },
      "technique": "GitHub_API"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "MetaMaps"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "Organization",
        "value": "DiltheyLab"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Perl",
        "size": 577450,
        "type": "Programming_language",
        "value": "Perl"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "C++",
        "size": 324260,
        "type": "Programming_language",
        "value": "C++"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "R",
        "size": 96952,
        "type": "Programming_language",
        "value": "R"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "C",
        "size": 19559,
        "type": "Programming_language",
        "value": "C"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Makefile",
        "size": 1760,
        "type": "Programming_language",
        "value": "Makefile"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "M4",
        "size": 1546,
        "type": "Programming_language",
        "value": "M4"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Shell",
        "size": 8,
        "type": "Programming_language",
        "value": "Shell"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/DiltheyLab/MetaMaps/master/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "somef_missing_categories": [
    "citation",
    "acknowledgement",
    "run",
    "download",
    "requirements",
    "contact",
    "contributors",
    "faq",
    "support",
    "identifier",
    "has_build_file",
    "executable_example"
  ],
  "somef_provenance": {
    "date": "2024-10-06 07:57:00",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 98
      },
      "technique": "GitHub_API"
    }
  ],
  "usage": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Usage",
        "parent_header": [
          "MetaMaps"
        ],
        "type": "Text_excerpt",
        "value": "Analysis of a dataset with MetaMaps consists of two steps: mapping and classification:\n\n```\n./metamaps mapDirectly --all -r databases/miniSeq+H/DB.fa -q input.fastq -o classification_results\n./metamaps classify --mappings classification_results --DB databases/miniSeq+H\n```\n"
      },
      "source": "https://raw.githubusercontent.com/DiltheyLab/MetaMaps/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Memory-efficient mapping",
        "parent_header": [
          "MetaMaps",
          "Usage"
        ],
        "type": "Text_excerpt",
        "value": "You can use the '--maxmemory' parameter to specify a target for maximum memory consumption (in gigabytes). Note that this feature is implemented heuristically; actual memory usage will fluctuate and execeed the target. We recommend using around 70% of the available memory as a target amount (for example, 20G when you have a 32G machine).\n\nExample:\n\n```\n./metamaps mapDirectly --all -r databases/miniSeq+H/DB.fa -q input.fastq -o classification_results --maxmemory 20\n./metamaps classify --mappings classification_results --DB databases/miniSeq+H\n```\n"
      },
      "source": "https://raw.githubusercontent.com/DiltheyLab/MetaMaps/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Multithreading",
        "parent_header": [
          "MetaMaps",
          "Usage"
        ],
        "type": "Text_excerpt",
        "value": "You can use the parameter `-t` to speed up mapping and classification.\n\nExample:\n\n```\n./metamaps mapDirectly -t 5 --all -r databases/miniSeq+H/DB.fa -q input.fastq -o classification_results\n./metamaps classify -t 5 --mappings classification_results --DB databases/miniSeq+H\n```\n\nImportant: if you encounter problems with multithreading efficiency, try `unset MALLOC_ARENA_MAX` immediately before calling MetaMaps.\n"
      },
      "source": "https://raw.githubusercontent.com/DiltheyLab/MetaMaps/master/README.md",
      "technique": "header_analysis"
    }
  ]
}