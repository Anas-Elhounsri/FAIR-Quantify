{
  "application_domain": [
    {
      "confidence": 22.02,
      "result": {
        "type": "String",
        "value": "Natural Language Processing"
      },
      "technique": "supervised_classification"
    }
  ],
  "citation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Cite",
        "parent_header": [
          "ACEP"
        ],
        "type": "Text_excerpt",
        "value": "If these codes are helpful to you, please cite our paper:\n\nFu, H., Cao, Z., Li, M. et al. ACEP: improving antimicrobial peptides recognition through automatic feature fusion and amino acid embedding. BMC Genomics 21, 597 (2020). https://doi.org/10.1186/s12864-020-06978-0\n\nhttps://bmcgenomics.biomedcentral.com/articles/10.1186/s12864-020-06978-0\n\n\n\n\n"
      },
      "source": "https://raw.githubusercontent.com/Fuhaoyi/ACEP/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/Fuhaoyi/ACEP"
      },
      "technique": "GitHub_API"
    }
  ],
  "contact": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Contact Us",
        "parent_header": [
          "ACEP"
        ],
        "type": "Text_excerpt",
        "value": "If you have any problems, please contact fhy11235813@gmail.com\n\nHaoyi Fu\n\nSchool of Information Science and Engineering, Yunnan University\n"
      },
      "source": "https://raw.githubusercontent.com/Fuhaoyi/ACEP/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2019-12-26T14:29:04Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2024-06-06T17:58:44Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "Open source software and datasets for the ACEP algorithm"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "1.1 Description",
        "parent_header": [
          "ACEP",
          "1.Making predictions for sequences"
        ],
        "type": "Text_excerpt",
        "value": "ACEP is a deep learning model for high-throughput antibacterial peptide recognition. By loading a pre-trained model, the software can be deployed on a common computer to perform antimicrobial peptide recognition, important motif discovery, and visualization analysis.\nBoth the peptide sequences and PSSM profiles need to be input the model.\n"
      },
      "source": "https://raw.githubusercontent.com/Fuhaoyi/ACEP/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 0.8855496731318283,
      "result": {
        "original_header": "ACEP",
        "type": "Text_excerpt",
        "value": "Open source software and datasets for the ACEP algorithm\n \n"
      },
      "source": "https://raw.githubusercontent.com/Fuhaoyi/ACEP/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9541475081390559,
      "result": {
        "original_header": "2.Architecture of the ACEP modle.",
        "type": "Text_excerpt",
        "value": "We use convolutional layer, pooling layer, LSTM layer, fully connected layer and attention mechanism to build the model.\nThe yellow module, the blue module and the red module are used to generate features. The green module is used to fuse features; the purple module corresponds to sigmoid node that outputs the prediction results. \n"
      },
      "source": "https://raw.githubusercontent.com/Fuhaoyi/ACEP/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9158920672512951,
      "result": {
        "original_header": "3.2 Experimental comparison",
        "type": "Text_excerpt",
        "value": "You can view the performance of the model by running ACEP_model_performance.py. And it can also be compared with other state-of-the-art antimicrobial peptides recognition methods by running ACEP_comparison_test.py and ACEP_ROC.py. In addition, run ACEP_R1_xxx.py to understand the role of different functional modules. And evaluate model performance using cross validation on all datasets by running ACEP_model_CV.py\n \n"
      },
      "source": "https://raw.githubusercontent.com/Fuhaoyi/ACEP/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8287591563507622,
      "result": {
        "original_header": "3.3 Experimental analysis and visualization",
        "type": "Text_excerpt",
        "value": "Observe amino acid clustering by running ACEP_cluster.py. Observe attention scores and motifs by running ACEP_attention_scores.py and ACEP_attention_motif.py. Observe the distribution of fusion features in space by running ACEP_fusion_feature.py.\n \n"
      },
      "source": "https://raw.githubusercontent.com/Fuhaoyi/ACEP/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/Fuhaoyi/ACEP/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 0
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/Fuhaoyi/ACEP/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "Fuhaoyi/ACEP"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "ACEP"
      },
      "source": "https://raw.githubusercontent.com/Fuhaoyi/ACEP/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "images": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Fuhaoyi/ACEP/master/model_structure.png"
      },
      "source": "https://raw.githubusercontent.com/Fuhaoyi/ACEP/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "installation": [
    {
      "confidence": 0.9970217248763156,
      "result": {
        "original_header": "2.Architecture of the ACEP modle.",
        "type": "Text_excerpt",
        "value": "<div align=center><img width=\"50%\" height=\"50%\" alt=\"Model_Structure\" src=\"https://raw.githubusercontent.com/Fuhaoyi/ACEP/master/model_structure.png\"/></div> \n"
      },
      "source": "https://raw.githubusercontent.com/Fuhaoyi/ACEP/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "invocation": [
    {
      "confidence": 0.8360929697496311,
      "result": {
        "original_header": "3.1 Training model",
        "type": "Text_excerpt",
        "value": "You can train a new model by running ACEP_model_train.py files. And the code for the amino acid embedding tensor can be found in the EmbeddingRST.py file. The training data is placed in the AMPs_Experiment_Dataset / AMPs_Experiment_Dataset.zip file. This file needs to be decompressed before training the model. In addition, you can observe the training history by running the ACEP_training_history.py file.\n \n"
      },
      "source": "https://raw.githubusercontent.com/Fuhaoyi/ACEP/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8655149375205736,
      "result": {
        "original_header": "3.4 Others",
        "type": "Text_excerpt",
        "value": "If your sequence is a '.fasta' file, you can call the function in Data_pre_processing.py to convert the fasta file to a '.csv' file so that it can be imported into the model.\nIf you want to see false negative sequences, you can run ACEP_false_negtive.py file.\n \n"
      },
      "source": "https://raw.githubusercontent.com/Fuhaoyi/ACEP/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/Fuhaoyi/ACEP/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ""
      },
      "technique": "GitHub_API"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "ACEP"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "User",
        "value": "Fuhaoyi"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 156066,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Fuhaoyi/ACEP/master/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "requirements": [
    {
      "confidence": 1,
      "result": {
        "original_header": "1.3 Requirements",
        "parent_header": [
          "ACEP",
          "1.Making predictions for sequences"
        ],
        "type": "Text_excerpt",
        "value": "Python3\nPython packages: Tensorfollow(vr.1.6.0), Keras(vr.2.15), Matplotlib, scikit-learn, numpy, pandas and senborn(The senborn package is used for visualization).\n\nWe recommend using a GPU to speed up the calculations; if you use GPU acceleration, you also need to install cuda and cudnn.\n"
      },
      "source": "https://raw.githubusercontent.com/Fuhaoyi/ACEP/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "somef_missing_categories": [
    "acknowledgement",
    "run",
    "download",
    "contributors",
    "documentation",
    "license",
    "faq",
    "support",
    "identifier",
    "has_build_file",
    "executable_example"
  ],
  "somef_provenance": {
    "date": "2024-10-06 16:56:14",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 7
      },
      "technique": "GitHub_API"
    }
  ],
  "type": [
    {
      "confidence": 0.82,
      "result": {
        "type": "String",
        "value": "commandline-application"
      },
      "technique": "software_type_heuristics"
    }
  ],
  "usage": [
    {
      "confidence": 1,
      "result": {
        "original_header": "1.2 Getting PSSM profiles",
        "parent_header": [
          "ACEP",
          "1.Making predictions for sequences"
        ],
        "type": "Text_excerpt",
        "value": "There are two ways to obtain PSSMs, a web servers or a standalone BLAST program. If your computer's memory is large enough (about 64GB), then you can run the standalone BLAST as described in section 1.2.2, otherwise we recommend to use an online server to obtain PSSMs.\n"
      },
      "source": "https://raw.githubusercontent.com/Fuhaoyi/ACEP/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "1.2.1 Getting PSSM through online server",
        "parent_header": [
          "ACEP",
          "1.Making predictions for sequences"
        ],
        "type": "Text_excerpt",
        "value": "PSSM profiles of sequences can be obtained through POSSUM website (http://possum.erc.monash.edu/). \n\nOn POSSUM server page, the parameters of descriptors are all set to 'off' and the parameters for BLAST are set to defaults. After submitting sequences, wait for the server to finish calculation and download original PSSM profiles. \n\nNote: if you want to use POSSUM online service, you have to fill the short sequence less than 50AA to more than 50AA in length by repeatedly copying the sequence, due to server restrictions on sequence length. (Or splicing signal peptide and propeptide to sequences to extend them.)\n"
      },
      "source": "https://raw.githubusercontent.com/Fuhaoyi/ACEP/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "1.2.2 Getting PSSM through standalone BLAST program",
        "parent_header": [
          "ACEP",
          "1.Making predictions for sequences"
        ],
        "type": "Text_excerpt",
        "value": "* **Step 1.** Go to the NCBI website to download the BLAST program (ncbi-blast-2.10.1+-win64.exe, https://ftp.ncbi.nlm.nih.gov/blast/executables/LATEST/). <br />\n    Go to UniProt's website to download protein sequences (UniRef90 or UniRef50, fasta format, https://www.uniprot.org/downloads).<br />\n    Unzip uniref90.fasta.gz to the bin folder of the ncbi-blast-2.10.1+-win64 installation directory (eg. E:\\blast-2.9.0+\\bin\\).\n\n* **Step 2.** Use command line to enter the E:\\blast-2.9.0\\bin folder, run the following command to establish a local BLAST database.\n\n            makeblastdb -in uniref90.fasta -out uniref90.db -dbtype prot\n\n* **Step 3.** Put a single sequence into the queryseq.fasta file, run the following command to generate a single PSSM 0001.pssm.\n\n            psiblast -db uniref90.db -query queryseq.fasta -out result1.out -out_ascii_pssm 0001.pssm -num_iterations 3 -evalue 1e-3\n\n* **Step 4.** If you need to generate PSSM profiles for a large number of sequences, you can store all the sequences in the queryseq.fasta file, and then execute ACEP/ACME_codes/localBLASTgetPSSMs/localBLASTgetPSSMs.py.\n\n    Three parameters need to be set in the localBLASTgetPSSMs.py program.<br />\n    path0: the path of psiblast program (eg. path0 ='E:/blast-2.9.0/bin/psiblast').<br />\n    path1: the path of BLAST database (eg. path1 ='E:/blast-2.9.0 /bin/uniref90.db').<br />\n    path2: the path where the localBLASTgetPSSMs.py program is located (eg. path2 ='E:/ACEP/ACME_codes/localBLASTgetPSSMs/').\n\n"
      },
      "source": "https://raw.githubusercontent.com/Fuhaoyi/ACEP/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "1.4 Starting a prediction",
        "parent_header": [
          "ACEP",
          "1.Making predictions for sequences"
        ],
        "type": "Text_excerpt",
        "value": "* **Step 1.** Download all the files in ACME_codes folder. \n\n* **Step 2.** Enter sequences into the 'AMP_prediction/inputs/sequences.csv' file and put the PSSM files into the 'AMP_prediction/inputs/PSSM_files/' directory.\n\n   Note: In order to increase the speed of high-throughput sequence prediction without generating additional errors, the PSSM files placed in the directory can only be named using numbers, such as 00001.pssm, 00002.pssm, 00003.pssm ..., and the order of these files that are sorted by file names must be the same as the order of sequences in the sequences.csv file. The refun() function in Data_pre_processing.py file will help to do this.\n\n* **Step 3.** Run ACEP_prediction.py.\n\n* **Step 4.** View predicted results in 'AMP_prediction/outputs/outputs.csv' file. And sequences with probability greater than or equal to 0.5 are identified as AMPs, and sequences with probability less than 0.5 are identified as non-AMPs.\n"
      },
      "source": "https://raw.githubusercontent.com/Fuhaoyi/ACEP/master/README.md",
      "technique": "header_analysis"
    }
  ]
}