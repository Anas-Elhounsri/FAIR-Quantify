{
  "acknowledgement": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Acknowledgments",
        "type": "Text_excerpt",
        "value": "* This code is inspired by [CycleGAN and pix2pix in PyTorch](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix).\n"
      },
      "source": "https://raw.githubusercontent.com/nadeemlab/DeepLIIF/main/README.md",
      "technique": "header_analysis"
    }
  ],
  "application_domain": [
    {
      "confidence": 35.02,
      "result": {
        "type": "String",
        "value": "Computer Vision"
      },
      "technique": "supervised_classification"
    }
  ],
  "citation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Reference",
        "type": "Text_excerpt",
        "value": "If you find our work useful in your research or if you use parts of this code or our released dataset, please cite the following papers:\n```\n@article{ghahremani2022deep,\n  title={Deep learning-inferred multiplex immunofluorescence for immunohistochemical image quantification},\n  author={Ghahremani, Parmida and Li, Yanyun and Kaufman, Arie and Vanguri, Rami and Greenwald, Noah and Angelo, Michael and Hollmann, Travis J and Nadeem, Saad},\n  journal={Nature Machine Intelligence},\n  volume={4},\n  number={4},\n  pages={401--412},\n  year={2022},\n  publisher={Nature Publishing Group}\n}\n\n@article{ghahremani2022deepliifui,\n  title={DeepLIIF: An Online Platform for Quantification of Clinical Pathology Slides},\n  author={Ghahremani, Parmida and Marino, Joseph and Dodds, Ricardo and Nadeem, Saad},\n  journal={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},\n  pages={21399--21405},\n  year={2022}\n}\n\n@article{ghahremani2023deepliifdataset,\n  title={An AI-Ready Multiplex Staining Dataset for Reproducible and Accurate Characterization of Tumor Immune Microenvironment},\n  author={Ghahremani, Parmida and Marino, Joseph and Hernandez-Prera, Juan and V. de la Iglesia, Janis and JC Slebos, Robbert and H. Chung, Christine and Nadeem, Saad},\n  journal={International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI)},\n  year={2023}\n}\n\n@article{nadeem2023ki67validationMTC,\n  author = {Nadeem, Saad and Hanna, Matthew G and Viswanathan, Kartik and Marino, Joseph and Ahadi, Mahsa and Alzumaili, Bayan and Bani, Mohamed-Amine and Chiarucci, Federico and Chou, Angela and De Leo, Antonio and Fuchs, Talia L and Lubin, Daniel J and Luxford, Catherine and Magliocca, Kelly and Martinez, Germ\u00e1n and Shi, Qiuying and Sidhu, Stan and Al Ghuzlan, Abir and Gill, Anthony J and Tallini, Giovanni and Ghossein, Ronald and Xu, Bin},\n  title = {Ki67 proliferation index in medullary thyroid carcinoma: a comparative study of multiple counting methods and validation of image analysis and deep learning platforms},\n  journal = {Histopathology},\n  year = {2023},\n  doi = {https://doi.org/10.1111/his.15048}\n}\n\n@article{zehra2024deepliifstitch,\nauthor = {Zehra, Talat and Marino, Joseph and Wang, Wendy and Frantsuzov, Grigoriy and Nadeem, Saad},\ntitle = {Rethinking Histology Slide Digitization Workflows for Low-Resource Settings},\njournal = {International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI)},\nyear = {2024}\n}\n```\n"
      },
      "source": "https://raw.githubusercontent.com/nadeemlab/DeepLIIF/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "author": "Ghahremani, Parmida and Li, Yanyun and Kaufman, Arie and Vanguri, Rami and Greenwald, Noah and Angelo, Michael and Hollmann, Travis J and Nadeem, Saad",
        "format": "bibtex",
        "title": "Deep learning-inferred multiplex immunofluorescence for immunohistochemical image quantification",
        "type": "Text_excerpt",
        "value": "@article{ghahremani2022deep,\n    publisher = {Nature Publishing Group},\n    year = {2022},\n    pages = {401--412},\n    number = {4},\n    volume = {4},\n    journal = {Nature Machine Intelligence},\n    author = {Ghahremani, Parmida and Li, Yanyun and Kaufman, Arie and Vanguri, Rami and Greenwald, Noah and Angelo, Michael and Hollmann, Travis J and Nadeem, Saad},\n    title = {Deep learning-inferred multiplex immunofluorescence for immunohistochemical image quantification},\n}"
      },
      "source": "https://raw.githubusercontent.com/nadeemlab/DeepLIIF/main/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "author": "Ghahremani, Parmida and Marino, Joseph and Dodds, Ricardo and Nadeem, Saad",
        "format": "bibtex",
        "title": "DeepLIIF: An Online Platform for Quantification of Clinical Pathology Slides",
        "type": "Text_excerpt",
        "value": "@article{ghahremani2022deepliifui,\n    year = {2022},\n    pages = {21399--21405},\n    journal = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},\n    author = {Ghahremani, Parmida and Marino, Joseph and Dodds, Ricardo and Nadeem, Saad},\n    title = {DeepLIIF: An Online Platform for Quantification of Clinical Pathology Slides},\n}"
      },
      "source": "https://raw.githubusercontent.com/nadeemlab/DeepLIIF/main/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "author": "Ghahremani, Parmida and Marino, Joseph and Hernandez-Prera, Juan and V. de la Iglesia, Janis and JC Slebos, Robbert and H. Chung, Christine and Nadeem, Saad",
        "format": "bibtex",
        "title": "An AI-Ready Multiplex Staining Dataset for Reproducible and Accurate Characterization of Tumor Immune Microenvironment",
        "type": "Text_excerpt",
        "value": "@article{ghahremani2023deepliifdataset,\n    year = {2023},\n    journal = {International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI)},\n    author = {Ghahremani, Parmida and Marino, Joseph and Hernandez-Prera, Juan and V. de la Iglesia, Janis and JC Slebos, Robbert and H. Chung, Christine and Nadeem, Saad},\n    title = {An AI-Ready Multiplex Staining Dataset for Reproducible and Accurate Characterization of Tumor Immune Microenvironment},\n}"
      },
      "source": "https://raw.githubusercontent.com/nadeemlab/DeepLIIF/main/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "author": "Nadeem, Saad and Hanna, Matthew G and Viswanathan, Kartik and Marino, Joseph and Ahadi, Mahsa and Alzumaili, Bayan and Bani, Mohamed-Amine and Chiarucci, Federico and Chou, Angela and De Leo, Antonio and Fuchs, Talia L and Lubin, Daniel J and Luxford, Catherine and Magliocca, Kelly and Martinez, Germ\u00e1n and Shi, Qiuying and Sidhu, Stan and Al Ghuzlan, Abir and Gill, Anthony J and Tallini, Giovanni and Ghossein, Ronald and Xu, Bin",
        "doi": "https://doi.org/10.1111/his.15048",
        "format": "bibtex",
        "title": "Ki67 proliferation index in medullary thyroid carcinoma: a comparative study of multiple counting methods and validation of image analysis and deep learning platforms",
        "type": "Text_excerpt",
        "value": "@article{nadeem2023ki67validationMTC,\n    doi = {https://doi.org/10.1111/his.15048},\n    year = {2023},\n    journal = {Histopathology},\n    title = {Ki67 proliferation index in medullary thyroid carcinoma: a comparative study of multiple counting methods and validation of image analysis and deep learning platforms},\n    author = {Nadeem, Saad and Hanna, Matthew G and Viswanathan, Kartik and Marino, Joseph and Ahadi, Mahsa and Alzumaili, Bayan and Bani, Mohamed-Amine and Chiarucci, Federico and Chou, Angela and De Leo, Antonio and Fuchs, Talia L and Lubin, Daniel J and Luxford, Catherine and Magliocca, Kelly and Martinez, Germ\u00e1n and Shi, Qiuying and Sidhu, Stan and Al Ghuzlan, Abir and Gill, Anthony J and Tallini, Giovanni and Ghossein, Ronald and Xu, Bin},\n}"
      },
      "source": "https://raw.githubusercontent.com/nadeemlab/DeepLIIF/main/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "author": "Zehra, Talat and Marino, Joseph and Wang, Wendy and Frantsuzov, Grigoriy and Nadeem, Saad",
        "format": "bibtex",
        "title": "Rethinking Histology Slide Digitization Workflows for Low-Resource Settings",
        "type": "Text_excerpt",
        "value": "@article{zehra2024deepliifstitch,\n    year = {2024},\n    journal = {International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI)},\n    title = {Rethinking Histology Slide Digitization Workflows for Low-Resource Settings},\n    author = {Zehra, Talat and Marino, Joseph and Wang, Wendy and Frantsuzov, Grigoriy and Nadeem, Saad},\n}"
      },
      "source": "https://raw.githubusercontent.com/nadeemlab/DeepLIIF/main/README.md",
      "technique": "regular_expression"
    }
  ],
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/nadeemlab/DeepLIIF"
      },
      "technique": "GitHub_API"
    }
  ],
  "contributing_guidelines": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Contributing Training Data",
        "type": "Text_excerpt",
        "value": "To train DeepLIIF, we used a dataset of lung and bladder tissues containing IHC, hematoxylin, mpIF DAPI, mpIF Lap2, and \nmpIF Ki67 of the same tissue scanned using ZEISS Axioscan. These images were scaled and co-registered with the fixed IHC \nimages using affine transformations, resulting in 1264 co-registered sets of IHC and corresponding multiplex images of \nsize 512x512. We randomly selected 575 sets for training, 91 sets for validation, and 598 sets for testing the model. \nWe also randomly selected and manually segmented 41 images of size 640x640 from recently released [BCDataset](https://sites.google.com/view/bcdataset) \nwhich contains Ki67 stained sections of breast carcinoma with Ki67+ and Ki67- cell centroid annotations (for cell \ndetection rather than cell instance segmentation task). We split these tiles into 164 images of size 512x512; the test \nset varies widely in the density of tumor cells and the Ki67 index. You can find this dataset [here](https://zenodo.org/record/4751737#.YKRTS0NKhH4).\n\nWe are also creating a self-configurable version of DeepLIIF which will take as input any co-registered H&E/IHC and \nmultiplex images and produce the optimal output. If you are generating or have generated H&E/IHC and multiplex staining \nfor the same slide (de novo staining) and would like to contribute that data for DeepLIIF, we can perform \nco-registration, whole-cell multiplex segmentation via [ImPartial](https://github.com/nadeemlab/ImPartial), train the \nDeepLIIF model and release back to the community with full credit to the contributors.\n\n- [x] **Memorial Sloan Kettering Cancer Center** [AI-ready immunohistochemistry and multiplex immunofluorescence dataset](https://zenodo.org/record/4751737#.YKRTS0NKhH4) for breast, lung, and bladder cancers (**Nature Machine Intelligence'22**)\n- [x] **Moffitt Cancer Center** [AI-ready multiplex immunofluorescence and multiplex immunohistochemistry dataset](https://wiki.cancerimagingarchive.net/pages/viewpage.action?pageId=70226184) for head-and-neck squamous cell carcinoma (**MICCAI'23**)   \n"
      },
      "source": "https://raw.githubusercontent.com/nadeemlab/DeepLIIF/main/README.md",
      "technique": "header_analysis"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2021-04-15T03:21:18Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2024-10-04T01:03:02Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "Deep Learning Inferred Multiplex ImmunoFluorescence for IHC Image Quantification (https://deepliif.org) [Nature Machine Intelligence'22, CVPR'22, MICCAI'23, Histopathology'23, MICCAI'24]"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 0.9918316079968075,
      "result": {
        "original_header": "Training Dataset",
        "type": "Text_excerpt",
        "value": "For training, all image sets must be 512x512 and combined together in 3072x512 images (six images of size 512x512 stitched \n"
      },
      "source": "https://raw.githubusercontent.com/nadeemlab/DeepLIIF/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9258265848036573,
      "result": {
        "original_header": "Training",
        "type": "Text_excerpt",
        "value": "For training, all image sets must be 512x512 and combined together in 3072x512 images (six images of size 512x512 stitched\ntogether horizontally).\nThe data need to be arranged in the following order:\n```\nXXX_Dataset \n    \u251c\u2500\u2500 train\n    \u2514\u2500\u2500 val\n```\nWe have provided a simple function in the CLI for preparing data for training. \n* To view training losses and results, open the URL http://localhost:8097. For cloud servers replace localhost with your IP.\n* Epoch-wise intermediate training results are in `DeepLIIF/checkpoints/Model_Name/web/index.html`.\n* Trained models will be by default be saved in `DeepLIIF/checkpoints/Model_Name`.\n* Training datasets can be downloaded [here](https://zenodo.org/record/4751737#.YKRTS0NKhH4). \n**DP**: To train a model you can use DP. DP is single-process. It means that **all the GPUs you want to use must be on the same machine** so that they can be included in the same process - you cannot distribute the training across multiple GPU machines, unless you write your own code to handle inter-node (node = machine) communication.\nTo split and manage the workload for multiple GPUs within the same process, DP uses multi-threading. \nYou can find more information on DP [here](https://github.com/nadeemlab/DeepLIIF/blob/main/Multi-GPU%20Training.md). \nTo train a model with DP (Example with 2 GPUs (on 1 machine)):\n```\ndeepliif train --dataroot <data_dir> --batch-size 6 --gpu-ids 0 --gpu-ids 1\n```\nNote that `batch-size` is defined per process. Since DP is a single-process method, the `batch-size` you set is the **effective** batch size. \n**DDP**: To train a model you can use DDP. DDP usually spawns multiple processes. \n**DeepLIIF's code follows the PyTorch recommendation to spawn 1 process per GPU** ([doc](https://github.com/pytorch/examples/blob/master/distributed/ddp/README.md#application-process-topologies)). If you want to assign multiple GPUs to each process, you will need to make modifications to DeepLIIF's code (see [doc](https://pytorch.org/tutorials/intermediate/ddp_tutorial.html#combine-ddp-with-model-parallelism)).\nDespite all the benefits of DDP, one drawback is the extra GPU memory needed for dedicated CUDA buffer for communication. See a short discussion [here](https://discuss.pytorch.org/t/do-dataparallel-and-distributeddataparallel-affect-the-batch-size-and-gpu-memory-consumption/97194/2). In the context of DeepLIIF, this means that there might be situations where you could use a *bigger batch size with DP* as compared to DDP, which may actually train faster than using DDP with a smaller batch size.\nYou can find more information on DDP [here](https://github.com/nadeemlab/DeepLIIF/blob/main/Multi-GPU%20Training.md). \nTo launch training using DDP on a local machine, use `deepliif trainlaunch`. Example with 2 GPUs (on 1 machine):\n```\ndeepliif trainlaunch --dataroot <data_dir> --batch-size 3 --gpu-ids 0 --gpu-ids 1 --use-torchrun \"--nproc_per_node 2\"\n```\nNote that\n1. `batch-size` is defined per process. Since DDP is a single-process method, the `batch-size` you set is the batch size for each process, and the **effective** batch size will be `batch-size` multiplied by the number of processes you started. In the above example, it will be 3 * 2 = 6.\n2. You still need to provide **all GPU ids to use** to the training command. Internally, in each process DeepLIIF picks the device using `gpu_ids[local_rank]`. If you provide `--gpu-ids 2 --gpu-ids 3`, the process with local rank 0 will use gpu id 2 and that with local rank 1 will use gpu id 3. \n3. `-t 3 --log_dir <log_dir>` is not required, but is a useful setting in `torchrun` that saves the log from each process to your target log directory. For example:\nBASH7*\n4. If your PyTorch is older than 1.10, DeepLIIF calls `torch.distributed.launch` in the backend. Otherwise, DeepLIIF calls `torchrun`.\n \n"
      },
      "source": "https://raw.githubusercontent.com/nadeemlab/DeepLIIF/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9159599281328092,
      "result": {
        "original_header": "Testing",
        "type": "Text_excerpt",
        "value": "To test the model:\n```\ndeepliif test --input-dir /path/to/input/images\n              --output-dir /path/to/output/images\n              --model-dir /path/to/the/serialized/model\n              --tile-size 512\n```\nor\nBASH2*\n* The latest version of the pretrained models can be downloaded [here](https://zenodo.org/record/4751737#.YKRTS0NKhH4).\n* Before running test on images, the model files must be serialized as described above.\n* The serialized model files are expected to be located in `DeepLIIF/model-server/DeepLIIF_Latest_Model`.\n* The test results will be saved to the specified output directory, which defaults to the input directory.\n* The tile size must be specified and is used to split the image into tiles for processing.  The tile size is based on the resolution (scan magnification) of the input image, and the recommended values are a tile size of 512 for 40x images, 256 for 20x, and 128 for 10x.  Note that the smaller the tile size, the longer inference will take.\n* Testing datasets can be downloaded [here](https://zenodo.org/record/4751737#.YKRTS0NKhH4). \nIf you prefer, it is possible to run the models using Torchserve.\nPlease see [the documentation](https://nadeemlab.github.io/DeepLIIF/deployment/#deploying-deepliif-with-torchserve)\non how to deploy the model with Torchserve and for an example of how to run the inference.\n \n"
      },
      "source": "https://raw.githubusercontent.com/nadeemlab/DeepLIIF/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8646515132283111,
      "result": {
        "original_header": "ImageJ Plugin",
        "type": "Text_excerpt",
        "value": "If you don't have access to GPU or appropriate hardware and just want to use ImageJ to run inference, we have also created an [ImageJ plugin](https://github.com/nadeemlab/DeepLIIF/tree/main/ImageJ_Plugin) for your convenience. \n"
      },
      "source": "https://raw.githubusercontent.com/nadeemlab/DeepLIIF/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8925920126477228,
      "result": {
        "original_header": "Cloud Deployment",
        "type": "Text_excerpt",
        "value": "Our deployment at [deepliif.org](https://deepliif.org) also provides virtual slide digitization to generate a single stitched image from a 10x video acquired with a microscope and camera.  The video should be captured with the following guidelines to achieve the best results:\n* Brief but complete pauses at every section of the sample to avoid motion artifacts.\n* Significant overlap between pauses so that there is sufficient context for stitching frames together.\n* Methodical and consistent movement over the sample.  For example, start at the top left corner, then go all the way to the right, then down one step, then all the way to the left, down one step, etc., until the end of the sample is reached.  Again, brief overlapping pauses throughout will allow the best quality images to be generated. \n"
      },
      "source": "https://raw.githubusercontent.com/nadeemlab/DeepLIIF/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9862536786156192,
      "result": {
        "original_header": "Cloud API Endpoints",
        "type": "Text_excerpt",
        "value": "DeepLIIF can also be accessed programmatically through an endpoint by posting a multipart-encoded request containing the original image file, along with optional parameters including postprocessing thresholds:\n```\nPOST /api/infer\n\nFile Parameter:\n\n  img (required)\n    Image on which to run DeepLIIF.\n\nQuery String Parameters:\n\n  resolution\n    Resolution used to scan the slide (10x, 20x, 40x). Default is 40x.\n\n  pil\n    If present, use Pillow to load the image instead of Bio-Formats. Pillow is\n    faster, but works only on common image types (png, jpeg, etc.).\n\n  slim\n    If present, return only the refined segmentation result image.\n\n  nopost\n    If present, do not perform postprocessing (returns only inferred images).\n\n  prob_thresh\n    Probability threshold used in postprocessing the inferred segmentation map\n    image. The segmentation map value must be above this value in order for a\n    pixel to be included in the final cell segmentation. Valid values are an\n    integer in the range 0-254. Default is 150.\n\n  size_thresh\n    Lower threshold for size gating the cells in postprocessing. Segmented\n    cells must have more pixels than this value in order to be included in the\n    final cell segmentation. Valid values are 0, a positive integer, or 'auto'.\n    'Auto' will try to automatically determine this lower bound for size gating\n    based on the distribution of detected cell sizes. Default is 'auto'.\n\n  size_thresh_upper\n    Upper threshold for size gating the cells in postprocessing.  Segmented\n    cells must have less pixels that this value in order to be included in the\n    final cell segmentation. Valid values are a positive integer or 'none'.\n    'None' will use no upper threshold in size gating. Default is 'none'.\n\n  marker_thresh\n    Threshold for the effect that the inferred marker image will have on the\n    postprocessing classification of cells as positive.  If any corresponding\n    pixel in the marker image for a cell is above this threshold, the cell will\n    be classified as being positive regardless of the values from the inferred\n    segmentation image. Valid values are an integer in the range 0-255, 'none',\n    or 'auto'. 'None' will not use the marker image during classification.\n    'Auto' will automatically determine a threshold from the marker image.\n    Default is 'auto'.\n```\nFor example, in Python:\n```python\nimport os\nimport json\nimport base64\nfrom io import BytesIO\n\nimport requests\nfrom PIL import Image\n\n# Use the sample images from the main DeepLIIF repo\nimages_dir = './Sample_Large_Tissues'\nfilename = 'ROI_1.png'\n\nroot = os.path.splitext(filename)[0]\n\nres = requests.post(\n    url='https://deepliif.org/api/infer',\n    files={\n        'img': open(f'{images_dir}/{filename}', 'rb'),\n    },\n    params={\n        'resolution': '40x',\n    },\n)\n\ndata = res.json()\n\ndef b64_to_pil(b):\n    return Image.open(BytesIO(base64.b64decode(b.encode())))\n\nfor name, img in data['images'].items():\n    with open(f'{images_dir}/{root}_{name}.png', 'wb') as f:\n        b64_to_pil(img).save(f, format='PNG')\n\nwith open(f'{images_dir}/{root}_scoring.json', 'w') as f:\n    json.dump(data['scoring'], f, indent=2)\nprint(json.dumps(data['scoring'], indent=2))\n```\nIf you have previously run DeepLIIF on an image and want to postprocess it with different thresholds, the postprocessing routine can be called directly using the previously inferred results:\n```\nPOST /api/postprocess\n\nFile Parameters:\n\n  img (required)\n    Image on which DeepLIIF was run.\n\n  seg_img (required)\n    Inferred segmentation image previously generated by DeepLIIF.\n\n  marker_img (optional)\n    Inferred marker image previously generated by DeepLIIF.  If this is\n    omitted, then the marker image will not be used in classification.\n\nQuery String Parameters:\n\n  resolution\n    Resolution used to scan the slide (10x, 20x, 40x). Default is 40x.\n\n  pil\n    If present, use Pillow to load the original image instead of Bio-Formats.\n    Pillow is faster, but works only on common image types (png, jpeg, etc.).\n    Pillow is always used to open the seg_img and marker_img files.\n\n  prob_thresh\n    Probability threshold used in postprocessing the inferred segmentation map\n    image. The segmentation map value must be above this value in order for a\n    pixel to be included in the final cell segmentation. Valid values are an\n    integer in the range 0-254. Default is 150.\n\n  size_thresh\n    Lower threshold for size gating the cells in postprocessing. Segmented\n    cells must have more pixels than this value in order to be included in the\n    final cell segmentation. Valid values are 0, a positive integer, or 'auto'.\n    'Auto' will try to automatically determine this lower bound for size gating\n    based on the distribution of detected cell sizes. Default is 'auto'.\n\n  size_thresh_upper\n    Upper threshold for size gating the cells in postprocessing.  Segmented\n    cells must have less pixels that this value in order to be included in the\n    final cell segmentation. Valid values are a positive integer or 'none'.\n    'None' will use no upper threshold in size gating. Default is 'none'.\n\n  marker_thresh\n    Threshold for the effect that the inferred marker image will have on the\n    postprocessing classification of cells as positive.  If any corresponding\n    pixel in the marker image for a cell is above this threshold, the cell will\n    be classified as being positive regardless of the values from the inferred\n    segmentation image. Valid values are an integer in the range 0-255, 'none',\n    or 'auto'. 'None' will not use the marker image during classification.\n    'Auto' will automatically determine a threshold from the marker image.\n    Default is 'auto'. (If marker_img is not supplied, this has no effect.)\n```\nFor example, in Python:\n```python\nimport os\nimport json\nimport base64\nfrom io import BytesIO\n\nimport requests\nfrom PIL import Image\n\n# Use the sample images from the main DeepLIIF repo\nimages_dir = './Sample_Large_Tissues'\nfilename = 'ROI_1.png'\n\nroot = os.path.splitext(filename)[0]\n\nres = requests.post(\n    url='https://deepliif.org/api/infer',\n    files={\n        'img': open(f'{images_dir}/{filename}', 'rb'),\n        'seg_img': open(f'{images_dir}/{root}_Seg.png', 'rb'),\n        'marker_img': open(f'{images_dir}/{root}_Marker.png', 'rb'),\n    },\n    params={\n        'resolution': '40x',\n        'pil': True,\n        'size_thresh': 250,\n    },\n)\n\ndata = res.json()\n\ndef b64_to_pil(b):\n    return Image.open(BytesIO(base64.b64decode(b.encode())))\n\nfor name, img in data['images'].items():\n    with open(f'{images_dir}/{root}_{name}.png', 'wb') as f:\n        b64_to_pil(img).save(f, format='PNG')\n\nwith open(f'{images_dir}/{root}_scoring.json', 'w') as f:\n    json.dump(data['scoring'], f, indent=2)\nprint(json.dumps(data['scoring'], indent=2))\n```\n \n"
      },
      "source": "https://raw.githubusercontent.com/nadeemlab/DeepLIIF/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9464567220841034,
      "result": {
        "original_header": "Synthetic Data Generation",
        "type": "Text_excerpt",
        "value": "The first version of DeepLIIF model suffered from its inability to separate IHC positive cells in some large clusters,\nresulting from the absence of clustered positive cells in our training data. To infuse more information about the\nclustered positive cells into our model, we present a novel approach for the synthetic generation of IHC images using\nco-registered data. \nWe design a GAN-based model that receives the Hematoxylin channel, the mpIF DAPI image, and the segmentation mask and\ngenerates the corresponding IHC image. The model converts the Hematoxylin channel to gray-scale to infer more helpful\ninformation such as the texture and discard unnecessary information such as color. The Hematoxylin image guides the\nnetwork to synthesize the background of the IHC image by preserving the shape and texture of the cells and artifacts in\nthe background. The DAPI image assists the network in identifying the location, shape, and texture of the cells to\nbetter isolate the cells from the background. The segmentation mask helps the network specify the color of cells based \non the type of the cell (positive cell: a brown hue, negative: a blue hue). \nIn the next step, we generate synthetic IHC images with more clustered positive cells. To do so, we change the \nsegmentation mask by choosing a percentage of random negative cells in the segmentation mask (called as Neg-to-Pos) and \nconverting them into positive cells. Some samples of the synthesized IHC images along with the original IHC image are \nshown below. \n![IHC_Gen_image](docs/training/images/IHC_Gen.jpg)*Overview of synthetic IHC image generation. (a) A training sample \nof the IHC-generator model. (b) Some samples of synthesized IHC images using the trained IHC-Generator model. The \nNeg-to-Pos shows the percentage of the negative cells in the segmentation mask converted to positive cells.* \nWe created a new dataset using the original IHC images and synthetic IHC images. We synthesize each image in the dataset \ntwo times by setting the Neg-to-Pos parameter to %50 and %70. We re-trained our network with the new dataset. You can \nfind the new trained model [here](https://zenodo.org/record/4751737/files/DeepLIIF_Latest_Model.zip?download=1).\n \n"
      },
      "source": "https://raw.githubusercontent.com/nadeemlab/DeepLIIF/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8614482804264422,
      "result": {
        "original_header": "Registration",
        "type": "Text_excerpt",
        "value": "To register the de novo stained mpIF and IHC images, you can use the registration framework in the 'Registration' \ndirectory. Please refer to the README file provided in the same directory for more details.\n \n"
      },
      "source": "https://raw.githubusercontent.com/nadeemlab/DeepLIIF/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9742547113257259,
      "result": {
        "type": "Text_excerpt",
        "value": "\n*Reporting biomarkers assessed by routine immunohistochemical (IHC) staining of tissue is broadly used in diagnostic \npathology laboratories for patient care. To date, clinical reporting is predominantly qualitative or semi-quantitative. \nBy creating a multitask deep learning framework referred to as DeepLIIF, we present a single-step solution to stain \ndeconvolution/separation, cell segmentation, and quantitative single-cell IHC scoring. Leveraging a unique de novo \ndataset of co-registered IHC and multiplex immunofluorescence (mpIF) staining of the same slides, we segment and \ntranslate low-cost and prevalent IHC slides to more expensive-yet-informative mpIF images, while simultaneously \nproviding the essential ground truth for the superimposed brightfield IHC channels. Moreover, a new nuclear-envelop \nstain, LAP2beta, with high (>95%) cell coverage is introduced to improve cell delineation/segmentation and protein \nexpression quantification on IHC slides. By simultaneously translating input IHC images to clean/separated mpIF channels \nand performing cell segmentation/classification, we show that our model trained on clean IHC Ki67 data can generalize to \nmore noisy and artifact-ridden images as well as other nuclear and non-nuclear markers such as CD3, CD8, BCL2, BCL6, \nMYC, MUM1, CD10, and TP53. We thoroughly evaluate our method on publicly available benchmark datasets as well as against \npathologists' semi-quantitative scoring. Trained on IHC, DeepLIIF generalizes well to H&E images for out-of-the-box nuclear \nsegmentation.* \n**DeepLIIF** is deployed as a free publicly available cloud-native platform (https://deepliif.org) with Bioformats (more than 150 input formats supported) and MLOps pipeline. We also release **DeepLIIF** implementations for single/multi-GPU training, Torchserve/Dask+Torchscript deployment, and auto-scaling via Pulumi (1000s of concurrent connections supported); details can be found in our . **DeepLIIF** can be run locally (GPU required) by  and using the deepliif CLI command. **DeepLIIF** can be used remotely (no GPU required) through the https://deepliif.org website, calling the , or via the ; details for the free cloud-native platform can be found in our . \n\u00a9 This code is made available for non-commercial academic purposes. \n\n*Overview of DeepLIIF pipeline and sample input IHCs (different \nbrown/DAB markers -- BCL2, BCL6, CD10, CD3/CD8, Ki67) with corresponding DeepLIIF-generated hematoxylin/mpIF modalities \nand classified (positive (red) and negative (blue) cell) segmentation masks. (a) Overview of DeepLIIF. Given an IHC \ninput, our multitask deep learning framework simultaneously infers corresponding Hematoxylin channel, mpIF DAPI, mpIF \nprotein expression (Ki67, CD3, CD8, etc.), and the positive/negative protein cell segmentation, baking explainability \nand interpretability into the model itself rather than relying on coarse activation/attention maps. In the segmentation \nmask, the red cells denote cells with positive protein expression (brown/DAB cells in the input IHC), whereas blue cells \nrepresent negative cells (blue cells in the input IHC). (b) Example DeepLIIF-generated hematoxylin/mpIF modalities and \nsegmentation masks for different IHC markers. DeepLIIF, trained on clean IHC Ki67 nuclear marker images, can generalize \nto noisier as well as other IHC nuclear/cytoplasmic marker images.* \n"
      },
      "source": "https://raw.githubusercontent.com/nadeemlab/DeepLIIF/main/README.md",
      "technique": "supervised_classification"
    }
  ],
  "documentation": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/nadeemlab/DeepLIIF/tree/main/docs"
      },
      "technique": "file_exploration"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/nadeemlab/DeepLIIF/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 61
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/nadeemlab/DeepLIIF/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "nadeemlab/DeepLIIF"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ""
      },
      "source": "https://raw.githubusercontent.com/nadeemlab/DeepLIIF/main/README.md",
      "technique": "regular_expression"
    }
  ],
  "has_build_file": [
    {
      "confidence": 1,
      "result": {
        "format": "dockerfile",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/nadeemlab/DeepLIIF/main/Dockerfile"
      },
      "source": "https://raw.githubusercontent.com/nadeemlab/DeepLIIF/main/Dockerfile",
      "technique": "file_exploration"
    }
  ],
  "has_script_file": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/nadeemlab/DeepLIIF/main/Scripts/download_training_sets.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/nadeemlab/DeepLIIF/main/Scripts/download_pre_trained_model.sh"
      },
      "technique": "file_exploration"
    }
  ],
  "images": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://static.pepy.tech/personalized-badge/deepliif?period=total&amp;units=international_system&amp;left_color=grey&amp;right_color=blue&amp;left_text=total%20downloads"
      },
      "source": "https://raw.githubusercontent.com/nadeemlab/DeepLIIF/main/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/nadeemlab/DeepLIIF/main/./images/overview.png"
      },
      "source": "https://raw.githubusercontent.com/nadeemlab/DeepLIIF/main/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/nadeemlab/DeepLIIF/main/images/deepliif-imagej-demo.gif"
      },
      "source": "https://raw.githubusercontent.com/nadeemlab/DeepLIIF/main/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/nadeemlab/DeepLIIF/main/images/deepliif-imagej-roi-demo.gif"
      },
      "source": "https://raw.githubusercontent.com/nadeemlab/DeepLIIF/main/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/nadeemlab/DeepLIIF/main/images/deepliif-website-demo-04.gif"
      },
      "source": "https://raw.githubusercontent.com/nadeemlab/DeepLIIF/main/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/nadeemlab/DeepLIIF/main/images/deepliif-stitch-demo-01.gif"
      },
      "source": "https://raw.githubusercontent.com/nadeemlab/DeepLIIF/main/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/nadeemlab/DeepLIIF/main/docs/training/images/IHC_Gen.jpg"
      },
      "source": "https://raw.githubusercontent.com/nadeemlab/DeepLIIF/main/README.md",
      "technique": "regular_expression"
    }
  ],
  "installation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Installing `deepliif`",
        "type": "Text_excerpt",
        "value": "DeepLIIF can be `pip` installed:\n```shell\n$ conda create --name deepliif_env python=3.8\n$ conda activate deepliif_env\n(deepliif_env) $ conda install -c conda-forge openjdk\n(deepliif_env) $ pip install deepliif\n```\n\nThe package is composed of two parts:\n1. A library that implements the core functions used to train and test DeepLIIF models. \n2. A CLI to run common batch operations including training, batch testing and Torchscipt models serialization.\n\nYou can list all available commands:\n\n```\n(venv) $ deepliif --help\nUsage: deepliif [OPTIONS] COMMAND [ARGS]...\n\nOptions:\n  --help  Show this message and exit.\n\nCommands:\n  prepare-testing-data   Preparing data for testing\n  serialize              Serialize DeepLIIF models using Torchscript\n  test                   Test trained models\n  train                  General-purpose training script for multi-task...\n```\n\n**Note:** You might need to install a version of PyTorch that is compatible with your CUDA version. \nOtherwise, only the CPU will be used. \nVisit the [PyTorch website](https://pytorch.org/) for details. \nYou can confirm if your installation will run on the GPU by checking if the following returns `True`:\n\n```\nimport torch\ntorch.cuda.is_available()\n```\n"
      },
      "source": "https://raw.githubusercontent.com/nadeemlab/DeepLIIF/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 0.9904111647023229,
      "result": {
        "original_header": "Training",
        "type": "Text_excerpt",
        "value": "**DDP**: To train a model you can use DDP. DDP usually spawns multiple processes. \n**DeepLIIF's code follows the PyTorch recommendation to spawn 1 process per GPU** ([doc](https://github.com/pytorch/examples/blob/master/distributed/ddp/README.md#application-process-topologies)). If you want to assign multiple GPUs to each process, you will need to make modifications to DeepLIIF's code (see [doc](https://pytorch.org/tutorials/intermediate/ddp_tutorial.html#combine-ddp-with-model-parallelism)).\nDespite all the benefits of DDP, one drawback is the extra GPU memory needed for dedicated CUDA buffer for communication. See a short discussion [here](https://discuss.pytorch.org/t/do-dataparallel-and-distributeddataparallel-affect-the-batch-size-and-gpu-memory-consumption/97194/2). In the context of DeepLIIF, this means that there might be situations where you could use a *bigger batch size with DP* as compared to DDP, which may actually train faster than using DDP with a smaller batch size.\nYou can find more information on DDP [here](https://github.com/nadeemlab/DeepLIIF/blob/main/Multi-GPU%20Training.md). \n"
      },
      "source": "https://raw.githubusercontent.com/nadeemlab/DeepLIIF/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9570805502155691,
      "result": {
        "original_header": "ImageJ Plugin",
        "type": "Text_excerpt",
        "value": "If you don't have access to GPU or appropriate hardware and just want to use ImageJ to run inference, we have also created an [ImageJ plugin](https://github.com/nadeemlab/DeepLIIF/tree/main/ImageJ_Plugin) for your convenience. \nThe plugin also supports submitting multiple ROIs at once: \n"
      },
      "source": "https://raw.githubusercontent.com/nadeemlab/DeepLIIF/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9997738827143782,
      "result": {
        "original_header": "Cloud Deployment",
        "type": "Text_excerpt",
        "value": "If you don't have access to GPU or appropriate hardware and don't want to install ImageJ, we have also created a [cloud-native DeepLIIF deployment](https://deepliif.org) with a user-friendly interface to upload images, visualize, interact, and download the final results. \n"
      },
      "source": "https://raw.githubusercontent.com/nadeemlab/DeepLIIF/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9313338499747478,
      "result": {
        "type": "Text_excerpt",
        "value": "**DeepLIIF** is deployed as a free publicly available cloud-native platform (https://deepliif.org) with Bioformats (more than 150 input formats supported) and MLOps pipeline. We also release **DeepLIIF** implementations for single/multi-GPU training, Torchserve/Dask+Torchscript deployment, and auto-scaling via Pulumi (1000s of concurrent connections supported); details can be found in our . **DeepLIIF** can be run locally (GPU required) by  and using the deepliif CLI command. **DeepLIIF** can be used remotely (no GPU required) through the https://deepliif.org website, calling the , or via the ; details for the free cloud-native platform can be found in our . \n"
      },
      "source": "https://raw.githubusercontent.com/nadeemlab/DeepLIIF/main/README.md",
      "technique": "supervised_classification"
    }
  ],
  "invocation": [
    {
      "confidence": 0.8545503269163179,
      "result": {
        "original_header": "Training",
        "type": "Text_excerpt",
        "value": "## Training\nTo train a model:\n```\ndeepliif train --dataroot /path/to/input/images \n               --name Model_Name \n```\nor\nBASH4* \n* To view training losses and results, open the URL http://localhost:8097. For cloud servers replace localhost with your IP.\n* Epoch-wise intermediate training results are in `DeepLIIF/checkpoints/Model_Name/web/index.html`.\n* Trained models will be by default be saved in `DeepLIIF/checkpoints/Model_Name`.\n* Training datasets can be downloaded [here](https://zenodo.org/record/4751737#.YKRTS0NKhH4). \n"
      },
      "source": "https://raw.githubusercontent.com/nadeemlab/DeepLIIF/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8105368999139201,
      "result": {
        "original_header": "Serialize Model",
        "type": "Text_excerpt",
        "value": "The installed `deepliif` uses Dask to perform inference on the input IHC images.\nBefore running the `test` command, the model files must be serialized using Torchscript.\nTo serialize the model files:\n```\ndeepliif serialize --model-dir /path/to/input/model/files\n                   --output-dir /path/to/output/model/files\n```\n* By default, the model files are expected to be located in `DeepLIIF/model-server/DeepLIIF_Latest_Model`.\n* By default, the serialized files will be saved to the same directory as the input model files.\n \n"
      },
      "source": "https://raw.githubusercontent.com/nadeemlab/DeepLIIF/main/README.md",
      "technique": "supervised_classification"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/nadeemlab/DeepLIIF/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "ai-ready, cell-biology, cell-segmentation, cloud-native-applications, datasets, deep-learning, digital-pathology, image-segmentation, immunohistochemical-images, immunohistochemistry, multiplex, multitask-learning, pathology, pathology-gan, pathology-image, pytorch, segmentation, stitching, super-resolution, whole-slide-imaging"
      },
      "technique": "GitHub_API"
    }
  ],
  "license": [
    {
      "confidence": 1,
      "result": {
        "name": "Other",
        "spdx_id": "NOASSERTION",
        "type": "License",
        "url": null,
        "value": null
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "type": "File_dump",
        "value": "\u201cCommons Clause\u201d License Condition v1.0\n\nThe Software is provided to you by the Licensor under the License, as defined below, subject to the following condition.\n\nWithout limiting other conditions in the License, the grant of rights under the License will not include, and the License does not grant to you, the right to Sell the Software.\n\nFor purposes of the foregoing, \u201cSell\u201d means practicing any or all of the rights granted to you under the License to provide to third parties, for a fee or other consideration (including without limitation fees for hosting or consulting/ support services related to the Software), a product or service whose value derives, entirely or substantially, from the functionality of the Software. Any license notice or attribution required by the License must also include this Commons Clause License Condition notice.\n\nSoftware: DeepLIIF\n\nLicense: Apache 2.0 with Commons Clause\n\nLicensor: Nadeem Lab\n"
      },
      "source": "https://raw.githubusercontent.com/nadeemlab/DeepLIIF/main/LICENSE.md",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "License",
        "type": "Text_excerpt",
        "value": "\u00a9 [Nadeem Lab](https://nadeemlab.org/) - DeepLIIF code is distributed under **Apache 2.0 with Commons Clause** license, \nand is available for non-commercial academic purposes. \n"
      },
      "source": "https://raw.githubusercontent.com/nadeemlab/DeepLIIF/main/README.md",
      "technique": "header_analysis"
    }
  ],
  "logo": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/nadeemlab/DeepLIIF/main/./images/DeepLIIF_logo.png"
      },
      "source": "https://raw.githubusercontent.com/nadeemlab/DeepLIIF/main/README.md",
      "technique": "regular_expression"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "DeepLIIF"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "Organization",
        "value": "nadeemlab"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 501924,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Java",
        "size": 49591,
        "type": "Programming_language",
        "value": "Java"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Shell",
        "size": 2128,
        "type": "Programming_language",
        "value": "Shell"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Dockerfile",
        "size": 468,
        "type": "Programming_language",
        "value": "Dockerfile"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/nadeemlab/DeepLIIF/main/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "related_papers": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://arxiv.org/pdf/2204.04494.pdf"
      },
      "source": "https://raw.githubusercontent.com/nadeemlab/DeepLIIF/main/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://arxiv.org/abs/2305.16465\">MICCAI'23</a>\n    |\n    <a href=\"https://onlinelibrary.wiley.com/share/author/4AEBAGEHSZE9GDP3H8MN?target=10.1111/his.15048\">Histopathology'23</a>\n    |\n    <a href=\"https://arxiv.org/abs/2405.08169\">MICCAI'24</a>\n    |\n    <a href=\"https://deepliif.org/\">Cloud Deployment</a>\n    |\n    <a href=\"https://nadeemlab.github.io/DeepLIIF/\">Documentation</a>\n    |\n    <a href=\"#support\">Support</a>\n  </p>\n</p>\n\n*Reporting biomarkers assessed by routine immunohistochemical (IHC"
      },
      "source": "https://raw.githubusercontent.com/nadeemlab/DeepLIIF/main/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://arxiv.org/abs/2405.08169\">MICCAI'24</a>\n    |\n    <a href=\"https://deepliif.org/\">Cloud Deployment</a>\n    |\n    <a href=\"https://nadeemlab.github.io/DeepLIIF/\">Documentation</a>\n    |\n    <a href=\"#support\">Support</a>\n  </p>\n</p>\n\n*Reporting biomarkers assessed by routine immunohistochemical (IHC"
      },
      "source": "https://raw.githubusercontent.com/nadeemlab/DeepLIIF/main/README.md",
      "technique": "regular_expression"
    }
  ],
  "releases": [
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "jommarin",
          "type": "User"
        },
        "date_created": "2024-06-25T15:59:54Z",
        "date_published": "2024-06-25T16:03:20Z",
        "description": "- Update tiling method for inference on large images",
        "html_url": "https://github.com/nadeemlab/DeepLIIF/releases/tag/V1.1.11",
        "name": "DeepLIIF 1.1.11",
        "release_id": 162340368,
        "tag": "V1.1.11",
        "tarball_url": "https://api.github.com/repos/nadeemlab/DeepLIIF/tarball/V1.1.11",
        "type": "Release",
        "url": "https://api.github.com/repos/nadeemlab/DeepLIIF/releases/162340368",
        "value": "https://api.github.com/repos/nadeemlab/DeepLIIF/releases/162340368",
        "zipball_url": "https://api.github.com/repos/nadeemlab/DeepLIIF/zipball/V1.1.11"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "jommarin",
          "type": "User"
        },
        "date_created": "2024-04-23T21:16:26Z",
        "date_published": "2024-04-23T21:20:16Z",
        "description": "- Modify segmentation map weights\r\n- Update empty tile detection method",
        "html_url": "https://github.com/nadeemlab/DeepLIIF/releases/tag/V1.1.10",
        "name": "DeepLIIF 1.1.10",
        "release_id": 152484347,
        "tag": "V1.1.10",
        "tarball_url": "https://api.github.com/repos/nadeemlab/DeepLIIF/tarball/V1.1.10",
        "type": "Release",
        "url": "https://api.github.com/repos/nadeemlab/DeepLIIF/releases/152484347",
        "value": "https://api.github.com/repos/nadeemlab/DeepLIIF/releases/152484347",
        "zipball_url": "https://api.github.com/repos/nadeemlab/DeepLIIF/zipball/V1.1.10"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "jommarin",
          "type": "User"
        },
        "date_created": "2024-01-29T21:29:39Z",
        "date_published": "2024-01-29T21:31:54Z",
        "description": "- Output postprocessing settings (thresholds) in scoring results\r\n- Allow marker image to be omitted from postprocessing\r\n- Use all GPUs by default for inference if unspecified",
        "html_url": "https://github.com/nadeemlab/DeepLIIF/releases/tag/V1.1.9",
        "name": "DeepLIIF 1.1.9",
        "release_id": 139014091,
        "tag": "V1.1.9",
        "tarball_url": "https://api.github.com/repos/nadeemlab/DeepLIIF/tarball/V1.1.9",
        "type": "Release",
        "url": "https://api.github.com/repos/nadeemlab/DeepLIIF/releases/139014091",
        "value": "https://api.github.com/repos/nadeemlab/DeepLIIF/releases/139014091",
        "zipball_url": "https://api.github.com/repos/nadeemlab/DeepLIIF/zipball/V1.1.9"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "jommarin",
          "type": "User"
        },
        "date_created": "2024-01-19T16:59:43Z",
        "date_published": "2024-01-19T17:09:31Z",
        "description": "- Updated postprocessing algorithm\r\n- Addition of DeepLIIFExt model class",
        "html_url": "https://github.com/nadeemlab/DeepLIIF/releases/tag/V1.1.8",
        "name": "DeepLIIF 1.1.8",
        "release_id": 137772636,
        "tag": "V1.1.8",
        "tarball_url": "https://api.github.com/repos/nadeemlab/DeepLIIF/tarball/V1.1.8",
        "type": "Release",
        "url": "https://api.github.com/repos/nadeemlab/DeepLIIF/releases/137772636",
        "value": "https://api.github.com/repos/nadeemlab/DeepLIIF/releases/137772636",
        "zipball_url": "https://api.github.com/repos/nadeemlab/DeepLIIF/zipball/V1.1.8"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "jommarin",
          "type": "User"
        },
        "date_created": "2023-07-21T03:51:52Z",
        "date_published": "2023-07-21T03:53:49Z",
        "description": "- Ignore empty tiles during inference.",
        "html_url": "https://github.com/nadeemlab/DeepLIIF/releases/tag/V1.1.7",
        "name": "DeepLIIF 1.1.7",
        "release_id": 113058473,
        "tag": "V1.1.7",
        "tarball_url": "https://api.github.com/repos/nadeemlab/DeepLIIF/tarball/V1.1.7",
        "type": "Release",
        "url": "https://api.github.com/repos/nadeemlab/DeepLIIF/releases/113058473",
        "value": "https://api.github.com/repos/nadeemlab/DeepLIIF/releases/113058473",
        "zipball_url": "https://api.github.com/repos/nadeemlab/DeepLIIF/zipball/V1.1.7"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "jommarin",
          "type": "User"
        },
        "date_created": "2023-03-20T20:30:41Z",
        "date_published": "2023-03-22T17:08:18Z",
        "description": "- Stable model serialization and inference between runs\r\n- Memory efficient inference function\r\n- Option to pseudo-color marker and DAPI inferred images\r\n- Use training options in test script",
        "html_url": "https://github.com/nadeemlab/DeepLIIF/releases/tag/V1.1.6",
        "name": "DeepLIIF 1.1.6",
        "release_id": 96525521,
        "tag": "V1.1.6",
        "tarball_url": "https://api.github.com/repos/nadeemlab/DeepLIIF/tarball/V1.1.6",
        "type": "Release",
        "url": "https://api.github.com/repos/nadeemlab/DeepLIIF/releases/96525521",
        "value": "https://api.github.com/repos/nadeemlab/DeepLIIF/releases/96525521",
        "zipball_url": "https://api.github.com/repos/nadeemlab/DeepLIIF/zipball/V1.1.6"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "Parmida93",
          "type": "User"
        },
        "date_created": "2022-04-26T15:21:54Z",
        "date_published": "2022-04-26T15:26:25Z",
        "description": "- VGG loss added to the translation task.\r\n- Automatically reading the model parameters to create the model for inference.\r\n- GPU ids configuration updated.\r\n- Converting the images to 'RGB', fixing the issue of reading grayscale or 'RGBA' images.\r\n- Saving model parameters in training mode added to the cli.py file.",
        "html_url": "https://github.com/nadeemlab/DeepLIIF/releases/tag/V1.1.2",
        "name": "DeepLIIF 1.1.2",
        "release_id": 65366848,
        "tag": "V1.1.2",
        "tarball_url": "https://api.github.com/repos/nadeemlab/DeepLIIF/tarball/V1.1.2",
        "type": "Release",
        "url": "https://api.github.com/repos/nadeemlab/DeepLIIF/releases/65366848",
        "value": "https://api.github.com/repos/nadeemlab/DeepLIIF/releases/65366848",
        "zipball_url": "https://api.github.com/repos/nadeemlab/DeepLIIF/zipball/V1.1.2"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "Parmida93",
          "type": "User"
        },
        "date_created": "2022-03-28T21:44:59Z",
        "date_published": "2022-03-30T14:06:54Z",
        "description": "Added features:\r\n- Pip installation\r\n- Client commands\r\n- Multi-GPU training (DP and DDP)\r\n- Model Serialization\r\n- Deployment with Torchserve\r\n- ImageJ Plugin",
        "html_url": "https://github.com/nadeemlab/DeepLIIF/releases/tag/V1.1.0",
        "name": "DeepLIIF 1.1.0",
        "release_id": 63158707,
        "tag": "V1.1.0",
        "tarball_url": "https://api.github.com/repos/nadeemlab/DeepLIIF/tarball/V1.1.0",
        "type": "Release",
        "url": "https://api.github.com/repos/nadeemlab/DeepLIIF/releases/63158707",
        "value": "https://api.github.com/repos/nadeemlab/DeepLIIF/releases/63158707",
        "zipball_url": "https://api.github.com/repos/nadeemlab/DeepLIIF/zipball/V1.1.0"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "Parmida93",
          "type": "User"
        },
        "date_created": "2021-10-06T16:48:53Z",
        "date_published": "2021-10-06T19:24:37Z",
        "html_url": "https://github.com/nadeemlab/DeepLIIF/releases/tag/V1.0.0",
        "name": "First Release of DeepLIIF",
        "release_id": 50915815,
        "tag": "V1.0.0",
        "tarball_url": "https://api.github.com/repos/nadeemlab/DeepLIIF/tarball/V1.0.0",
        "type": "Release",
        "url": "https://api.github.com/repos/nadeemlab/DeepLIIF/releases/50915815",
        "value": "https://api.github.com/repos/nadeemlab/DeepLIIF/releases/50915815",
        "zipball_url": "https://api.github.com/repos/nadeemlab/DeepLIIF/zipball/V1.0.0"
      },
      "technique": "GitHub_API"
    }
  ],
  "requirements": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Prerequisites",
        "type": "Text_excerpt",
        "value": "1. Python 3.8\n2. Docker\n"
      },
      "source": "https://raw.githubusercontent.com/nadeemlab/DeepLIIF/main/README.md",
      "technique": "header_analysis"
    }
  ],
  "somef_missing_categories": [
    "run",
    "download",
    "contact",
    "contributors",
    "usage",
    "faq",
    "identifier",
    "executable_example"
  ],
  "somef_provenance": {
    "date": "2024-10-06 07:20:33",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 166
      },
      "technique": "GitHub_API"
    }
  ],
  "support": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Support",
        "type": "Text_excerpt",
        "value": "Please use the [Image.sc Forum](https://forum.image.sc/tag/deepliif) for discussion and questions related to DeepLIIF.\n\nBugs can be reported in the [GitHub Issues](https://github.com/nadeemlab/DeepLIIF/issues) tab.\n"
      },
      "source": "https://raw.githubusercontent.com/nadeemlab/DeepLIIF/main/README.md",
      "technique": "header_analysis"
    }
  ]
}