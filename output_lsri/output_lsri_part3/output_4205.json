{
  "application_domain": [
    {
      "confidence": 14.82,
      "result": {
        "type": "String",
        "value": "Computer Vision"
      },
      "technique": "supervised_classification"
    }
  ],
  "citation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Citing PyCurv",
        "type": "Text_excerpt",
        "value": "If you have used PyCurv for a scientific work, please cite the publication\n\"Reliable estimation of membrane curvature for cryo-electron tomography\"\n(\\ `Salfer et al. 2020, PLoS Computational biology <https://doi.org/10.1371/journal.pcbi.1007962>`_\\ ).\n"
      },
      "source": "https://raw.githubusercontent.com/kalemaria/pycurv/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/kalemaria/pycurv"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2019-08-28T07:10:39Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2024-05-29T15:03:33Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "Reliable estimation of membrane curvature for cryo-electron tomography"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 0.9631081643288099,
      "result": {
        "original_header": "PyCurv",
        "type": "Text_excerpt",
        "value": "This Python-based software was developed mainly to analyse curvature of\nmembranes in 3D originating from high-resolution, noisy cryo-electron tomograms.\nAdditionally, the software was also applied to other volumetric data with\nsegmented structures or directly surface data, e.g. brain or organs from MRI and\ncells from confocal light microscopy.\nAccepted image data formats are: MRC, EM, VTI, NII.\nAccepted surface data formats are: VTP, VTK, STL, PLY. \nMoreover, the software can be used to calculate distances between two adjacent\nmembranes and thicknesses of a membrane organelle. \nFurthermore, the software enables to calculate density distribution of\nparticles mapped on a membrane, e.g. membrane-bound ribosomes. \nThe software output is mostly in VTP format (triangle-mesh surfaces with\nnumerical properties like curvatures, distances or densities), which can be\nvisualized and further analysed in 3D using an external tool,\n`ParaView <https://www.paraview.org/>`_.\nAlso CSV table files for plotting the results are produced and many plotting\nfunctions are included.\n \n"
      },
      "source": "https://raw.githubusercontent.com/kalemaria/pycurv/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9781644321796656,
      "result": {
        "original_header": "`pycurv` package",
        "type": "Text_excerpt",
        "value": "This is the main Python package containing modules, classes and functions used\nfor the following analyses: \n\n* \n  Estimation of membrane curvature using our several tensor voting-based methods\n  based on (Page et al. 2002, Graphical Models) and (Tong and Tang 2005, IEEE\n  Transactions on Pattern Analysis and Machine Intelligence), details available\n  in (\\ `Salfer et al. 2020, PLoS Computational biology <https://doi.org/10.1371/journal.pcbi.1007962>`_\\ ).\n  The workflow consists of the following main steps: \n\n  #. signed surface generation from a segmentation\n  #. surface graph generation and surface cleaning\n  #. estimation of normal vectors of the true surface per triangle\n  #. principle directions and curvatures estimation per triangle. \n  The main parameter of our methods, ``radius_hit`` (borrowed from Tong and Tang\n  2005 ) should be set to the radius of the smallest feature of interest on the\n  input surface (in the target units, e.g. nanometers). It is used to define a\n  geodesic neighborhood of triangles for each central triangle. \n  Our method of choice is AVV (augmented vector voting), because it proved to be\n  the most robust to noisy and irregularly triangulated surface and to variable\n  feature size. \n* \n  Calculation of distances between two adjacent membranes and thicknesses of a\n  membrane organelle, using the membrane surfaces and outgoing normal vectors\n  (estimated as in step iii. in the curvature estimation workflow) from the\n  first, flat membrane surface. \n* \n  Calculation of ribosome density on ER and vesicle membranes using a mask with\n  ribosome coordinates on the membranes and the membrane mask.\n \n"
      },
      "source": "https://raw.githubusercontent.com/kalemaria/pycurv/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8628688525094023,
      "result": {
        "original_header": "`pycurv_scripts` package",
        "type": "Text_excerpt",
        "value": "This package contains Python scripts applying the PyCurv package and\ncombining different functions into the workflows described above, the main are: \n"
      },
      "source": "https://raw.githubusercontent.com/kalemaria/pycurv/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8166676842872148,
      "result": {
        "original_header": "`scripts_running_mindboggle_and_freesurfer` folder",
        "type": "Text_excerpt",
        "value": "Python and bash scripts running Mindboggle (Klein et al. 2017, PLoS Computational\nBiology) and FreeSurfer (Pienaar et al. 2008, International Journal of Imaging\nSystems and Technology) curvature estimation functions and extracting the values\nto CSV files.\n \n"
      },
      "source": "https://raw.githubusercontent.com/kalemaria/pycurv/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9875613258823559,
      "result": {
        "original_header": "`pycurv_testing` package",
        "type": "Text_excerpt",
        "value": "This package was used for testing our and external curvature estimation\nalgorithms from VTK (Schroeder et al., 2006, Kitware), FreeSurfer and\nMindboggle. It contains: \n\n* code used to generate synthetic surfaces\n* error calculation module\n* scripts getting FreeSurfer's and Mindboggle's curvatures and calculating\n  errors from their output VTK files.\n* integration and unit tests for the main PyCurv workflows and functions\n* a collection of plotting functions.\n* folders with output of curvature tests, e.g. ``test_vector_voting_output``\\ ),\n  and the test surfaces, e.g. ``torus/noise0/torus_rr25_csr10.surface.vtp``.\n \n"
      },
      "source": "https://raw.githubusercontent.com/kalemaria/pycurv/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9746883603713616,
      "result": {
        "original_header": "`experimental_data_sets` folder",
        "type": "Text_excerpt",
        "value": "\n* vesicle: membrane segmentation of a vesicle from a cryo-electron tomogram\n  (B\u00e4uerlein et al. 2017)\n* ER: compartment segmentation of a cortical ER membrane from a\n  cryo-electron tomogram (Collado et al. 2019), deposited in EM Data Bank\n  (EMD-10765)\n* Golgi and vesicles: compartment segmentations of the Golgi apparatus and\n  Golgi-derived vesicles from a cryo-electron tomogram, deposited in EM Data\n  Bank (EMD-10766)\n* embryo: surfaces of C. elegans embryo cells imaged by confocal light\n  microscopy and segmented by LimeSeg (Machado et al., BMC Bioinformatics 2019)\n* brain: cortical pial surfaces of both human brain hemispheres imaged by MRI\n  and segmented by FreeSurfer, taken from\n  `Mindboggle example data <https://osf.io/8cf5z/>`_. \nOutput of the following curvature algorithms is included for experimental data\n(AVV and SSVV output also includes minimum and maximum principal curvatures\ncalculated by VTK): \n\n* vesicle: AVV\n* ER: AVV, SSVV and Mindboggle\n* Golgi and vesicles: AVV\n* embryo: AVV\n* brain: AVV, Mindboggle, FreeSurfer\n \n"
      },
      "source": "https://raw.githubusercontent.com/kalemaria/pycurv/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8494226192251777,
      "result": {
        "original_header": ".",
        "type": "Text_excerpt",
        "value": "   In order that your conda python is found every time you open a new\n   bash shell, add it to PATH by adding the following line to your ``~/.bashrc``\\ : \n   You should be able to import ``pycurv``\\ , ``pycurv_testing`` and ``pycurv_scripts``\n   from a ``python`` or ``ipython`` shell.\n \n"
      },
      "source": "https://raw.githubusercontent.com/kalemaria/pycurv/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9758607777472955,
      "result": {
        "original_header": "Applying PyCurv",
        "type": "Text_excerpt",
        "value": "To test your PyCurv installation, you can run tests on synthetic surfaces or\nworkflow scripts on the provided experimental data sets, as explained in the\nnext subsections.\nThen, you can build your own PyCurv curvature estimation workflow, as explained\nstep-by-step in the \"User manual\" subsection.\nFor the full documentation of all modules and functions, please consult\n``<path_to_installation>/pycurv/docs/_build/html/py-modindex.html)``.\n \n"
      },
      "source": "https://raw.githubusercontent.com/kalemaria/pycurv/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/kalemaria/pycurv/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "executable_example": [
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/kalemaria/pycurv/master/experimental_data_sets/plotting_organelles_curvature/Curvature_of_organelles.ipynb"
      },
      "source": "https://raw.githubusercontent.com/kalemaria/pycurv/master/experimental_data_sets/plotting_organelles_curvature/Curvature_of_organelles.ipynb",
      "technique": "file_exploration"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 6
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/kalemaria/pycurv/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "kalemaria/pycurv"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "PyCurv"
      },
      "source": "https://raw.githubusercontent.com/kalemaria/pycurv/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "has_script_file": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/kalemaria/pycurv/master/readme_md2rst.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/kalemaria/pycurv/master/scripts_running_mindboggle_and_freesurfer/run_freesurfer_curvature.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/kalemaria/pycurv/master/scripts_running_mindboggle_and_freesurfer/run_freesurfer_curvature_brain.sh"
      },
      "technique": "file_exploration"
    }
  ],
  "installation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Installing PyCurv",
        "type": "Text_excerpt",
        "value": "Please note that PyCurv depends on a publicly available Python package,\nPyto (Lu\u010di\u0107 et al., 2016, PMID: 27742578, DOI: 10.1016/j.jsb.2016.10.004), it\ncan be found `here <https://github.com/vladanl/Pyto>`_.\n"
      },
      "source": "https://raw.githubusercontent.com/kalemaria/pycurv/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Installation instructions with conda",
        "parent_header": [
          "Installing PyCurv"
        ],
        "type": "Text_excerpt",
        "value": "The following instruction were tested on SUSE Linux Enterprise Server 12, but\nthey should work on other Linux-based systems.\n\n"
      },
      "source": "https://raw.githubusercontent.com/kalemaria/pycurv/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Installation instructions without conda",
        "parent_header": [
          "."
        ],
        "type": "Text_excerpt",
        "value": "The following instruction were tested on Ubuntu 18.04, but the process should be\nequivalent for other Ubuntu versions. Ubuntu can be installed for free, also in\na virtual machine on other operating systems (Windows or Mac).\nUbuntu 18.04 has ``python3`` version 3.6.7 preinstalled.\n\n\n#. \n   Install `graph-tool <https://graph-tool.skewed.de/>`_ (Peixoto, 2014)\n   for Ubuntu according to `instructions <https://git.skewed.de/count0/\n   graph-tool/wikis/installation-instructions#debian-ubuntu>`_\\ ,\n   ``DISTRIBUTION=bionic``\\ , but before running ``apt-get update`` add the public key:\n\n   .. code-block::\n\n      apt-key adv --keyserver pgp.skewed.de --recv-key 612DEFB798507F25\n\n   Unfortunately, this installation of the graph-tool package does not work with\n   conda python.\n\n#. \n   Add the path to the `Pyto <https://github.com/vladanl/Pyto>`_ package to PYTHONPATH in bashrc.\n\n#. \n   Install `pip3 <https://linuxize.com/post/how-to-install-pip-on-ubuntu-18.04/>`_\n   (includes setuptools), `venv <https://docs.python.org/3/library/venv.html>`_\n   (from Python version 3.3 on, recommended from version 3.5 on) in e.g.\n   ``~/workspace``\\ :\n\n   .. code-block::\n\n      python3 -m venv ./venv \u2013system-site-packages\n\n   and activate:\n\n   .. code-block::\n\n      source venv/bin/activate\n\n   ``ipython3`` should be present and you should be able to import ``graph_tool``\\ :\n\n   .. code-block:: python\n\n      from graph_tool.all import *\n\n#. \n   To download the PyCurv package, run from a bash shell:\n\n   .. code-block::\n\n      cd <path_to_installation>  # your destination folder\n      git clone https://github.com/kalemaria/pycurv.git\n\n   The folder ``pycurv`` should be created, containing the modules and folders\n   listed here.\n\n#. \n   Install dependencies from the ``setup.py``\\ :\n\n   .. code-block::\n\n      cd <path_to_installation>/pycurv\n      python setup.py install\n\n   You should be able to import ``pycurv``\\ , ``pycurv_testing`` and ``pycurv_scripts``\n   from a ``python`` or ``ipython`` shell.\n\n#. \n   To re-create the environment on another computer or after\n   re-installation, freeze the current state of the environment packages:\n\n   .. code-block::\n\n      pip freeze > requirements_pycurv.txt\n\n   To re-create the environment:\n\n   .. code-block::\n\n      pip install -r requirements_pycurv.txt\n"
      },
      "source": "https://raw.githubusercontent.com/kalemaria/pycurv/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Running the experimental data sets",
        "parent_header": [
          "Applying PyCurv"
        ],
        "type": "Text_excerpt",
        "value": "To run the curvature estimation workflow on the vesicle and ER segmentation in\nthe ``experimental_data_sets`` folder, just run in a bash shell:\n\n.. code-block::\n\n   cd <path_to_installation>/pycurv/pycurv_scripts\n   python curvature_calculation.py\n\nThe output will be generated in the respective subfolders of the input,\n``vesicle`` and ``ER``.\nYou can change the parameters and find more workflow examples in the script.\n"
      },
      "source": "https://raw.githubusercontent.com/kalemaria/pycurv/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "User manual",
        "parent_header": [
          "Applying PyCurv"
        ],
        "type": "Text_excerpt",
        "value": "If the tests and the examples above worked for you, now you can learn how to\nbuild your own PyCurv curvature estimation workflow.  \n\n\n.. image:: images/Workflow.png\n   :target: images/Workflow.png\n   :alt: Workflow\n\n\nImports\n^^^^^^^\n\nFist, import the following:\n\n.. code-block:: python\n\n   from pycurv import pycurv_io as io\n   from pycurv import run_gen_surface, THRESH_SIGMA1, TriangleGraph, MAX_DIST_SURF\n   import numpy as np\n   from scipy import ndimage\n   from graph_tool import load_graph\n\nParameters\n^^^^^^^^^^\n\nInitialize the following parameters for your run:\n\n.. code-block:: python\n\n   fold = <your_path_to_input>  # output will be also written there\n   base_filename = <prefix_for_your_output_files>\n   pixel_size = <nanometers>  # pixel size of the (underlying) segmentation\n   radius_hit = <nm>  # radius of the smallest feature of interest (neighborhood)\n\n   # alternative or optional:\n   # for step 1.:\n   #   for segmentation input:\n   seg_file = <your_segmentation_file>  # MRC in this example\n   label = <membrane_label>\n   cube_size = <pixels>  # try 3 or 5\n   filled_label = <lumen_label>  # if compartment segmentation\n   #   for surface input:\n   surf_file = <your_surface_file>  # VTP in this example\n   # for step 2.:\n   # to remove small disconnected surface components within this size (default 100)\n   min_component = <number_triangles>\n   # for step 3.:\n   methods = [\"VV\", \"SSVV\"]  # list of algorithms to run (default \"VV\")\n   area2 = <True_or_False>  # if method \"VV\": True for AVV (default), False for RVV\n   cores = <cores>  # number of cores to run VV in parallel (default 6)\n\nBuilding your workflow\n^^^^^^^^^^^^^^^^^^^^^^\n\n\n#. \n   Generate or load the surface.\n\n\n   #. \n      If the input is a segmentation (here MRC), load it first:\n\n      .. code-block:: python\n\n         seg = io.load_tomo(fold + seg_file)\n         data_type = seg.dtype\n\n\n      #. \n         If the segmentation is not filled (contains only membrane label),\n         generate the surface using the *membrane segmentation* algorithm.\n         First, get the membrane segmentation:\n\n         .. code-block:: python\n\n            binary_seg = (seg == label).astype(data_type)\n\n         Then, generate surface delineating the membrane segmentation:\n\n         .. code-block:: python\n\n            surf = run_gen_surface(binary_seg, fold + base_filename, lbl=1)\n\n         However, the surface is not always oriented properly, especially if\n         there are holes in the segmentation. To close small holes (fitting in\n         the given cube) in the segmentation, run before ``run_gen_surface``\\ :\n\n         .. code-block:: python\n\n            cube = np.ones((cube_size, cube_size, cube_size))\n            binary_seg = ndimage.binary_closing(\n                binary_seg, structure=cube, iterations=1).astype(data_type)\n\n      #. \n         If the segmentation is filled, generate the surface using the\n         *compartment segmentation* algorithm. This is the preferred approach,\n         because the surface is always properly oriented. As in the previous\n         case, first, get the membrane segmentation:\n\n         .. code-block:: python\n\n            binary_seg = (seg == label).astype(data_type)\n\n         Second, combine the membrane segmentation with the lumen segmentation\n         into compartment (filled) segmentation:\n\n         .. code-block:: python\n\n            filled_binary_seg = np.logical_or(\n                seg == label, seg == filled_label).astype(data_type)\n\n         Then, generate isosurface around the slightly smoothed compartment\n         segmentation and apply the mask of membrane segmentation:\n\n         .. code-block:: python\n\n            surf = run_gen_surface(\n                filled_binary_seg, fold + base_filename, lbl=1,\n                other_mask=binary_seg, isosurface=True, sg=1, thr=THRESH_SIGMA1)\n\n      In both above cases, the surface is saved to a VTP file named\n      ``fold + base_filename + \".surface.vtp\"``.\n\n   #. \n      If the input is a surface (here VTP), omit the above steps and load it:\n\n      .. code-block:: python\n\n         surf = io.load_poly(fold + surf_file)\n\n#. \n   From the surface, generate a \"triangle\" graph, with vertices at triangle\n   centers and edges between neighboring triangles:\n\n   .. code-block:: python\n\n      tg = TriangleGraph()\n      scale = (pixel_size, pixel_size, pixel_size)\n      tg.build_graph_from_vtk_surface(surf, scale)\n\n   If the surface has borders, they have grown a bit during the surface\n   generation (in order to bridge upon small holes) and should be removed:\n\n   .. code-block:: python\n\n      tg.find_vertices_near_border(MAX_DIST_SURF * pixel_size, purge=True)\n\n   You may filter out possibly occurring small disconnected fragments:\n\n   .. code-block:: python\n\n      tg.find_small_connected_components(\n          threshold=min_component, purge=True, verbose=True)\n\n   You can check the number of graph vertices and edges before / after each\n   step:\n\n   .. code-block:: python\n\n      print('The graph has {} vertices and {} edges'.format(\n          tg.graph.num_vertices(), tg.graph.num_edges()))\n\n   It might be a good idea to save the graph and the clean surface into files:\n\n   .. code-block:: python\n\n      clean_graph_file = '{}.scaled_cleaned.gt'.format(base_filename)\n      clean_surf_file = '{}.scaled_cleaned.vtp'.format(base_filename)\n      tg.graph.save(fold + clean_graph_file)\n      surf_clean = tg.graph_to_triangle_poly()\n      io.save_vtp(surf_clean, fold + clean_surf_file)\n\n   This way, you can load the graph and the surface to continue later:\n\n   .. code-block:: python\n\n      surf_clean = io.load_poly(fold + clean_surf_file)\n      tg = TriangleGraph()\n      tg.graph = load_graph(fold + clean_graph_file)\n\n#. \n   Then, you can estimate surface normals at each triangle center using a\n   geodesic neighborhood of triangles, and finally, estimate principle\n   directions and curvatures as well as calculate different combined indices\n   using one of the tensor voting-based algorithms: RVV, AVV (default) or SSVV:\n\n   .. code-block:: python\n\n      method_tg_surf_dict = normals_directions_and_curvature_estimation(\n          tg, radius_hit, methods=methods, area2=area2, cores=cores,\n          poly_surf=surf_clean)  # required only for SSVV\n\n   Save the output (graph and surface objects) for later filtering or inspection\n   in ParaView:\n\n   .. code-block:: python\n\n      for method in list(method_tg_surf_dict.keys()):\n          (tg, surf) = method_tg_surf_dict[method]\n          if method == 'VV':\n              if area2 is False:\n                  method = 'RVV'\n              else:\n                  method = 'AVV'\n          gt_file = '{}{}.{}_rh{}.gt'.format(\n              fold, base_filename, method, radius_hit)\n          tg.graph.save(gt_file)\n          surf_file = '{}{}.{}_rh{}.vtp'.format(\n              fold, base_filename, method, radius_hit)\n          io.save_vtp(surf, surf_file)\n\nAnalyzing the output\n^^^^^^^^^^^^^^^^^^^^\n\nThe output VTP file is a surface with all the calculated values stored as\ntriangle properties, which can be visualized in\n`ParaView <https://www.paraview.org/>`_.\n\n\n.. image:: images/ParaView.png\n   :target: images/ParaView.png\n   :alt: ParaView visualization\n\n\n\n* normal: original triangle normal\n* area: triangle are in the input units (e.g. nm)\n\nThe following properties are estimated using each of our algorithms:\n\n\n* ``N_v``\\ : estimates triangle normal\n* ``T_1``\\ : maximal principal direction\n* ``T_2``\\ : minimal principal direction\n* ``kappa1``\\ : maximal principle curvature\n* ``kappa2``\\ : minimal principle curvature\n* ``mean_curvature_VV``\\ : mean curvature\n* ``gauss_curvature_VV``\\ : Gauss curvature\n* ``curvedness_VV``\\ : curvedness\n* ``shape_index_VV``\\ : Shape Index\n\nThe following properties are calculated using VTK per triangle vertex using\nonly 1-ring neighbors, 3 triangle values are averaged per triangle:\n\n\n* ``max_curvature``\\ : maximal principle curvature\n* ``mean_curvature``\\ : minimal principle curvature\n* ``mean_curvature``\\ : mean curvature\n* ``gauss_curvature``\\ : Gauss curvature\n\nTo extract the curvatures into a CSV file, run:\n\n.. code-block:: python\n\n   extract_curvatures_after_new_workflow(\n       fold, base_filename, radius_hit, methods=['VV'], exclude_borders=1\n\nBecause of the last option, two files will be output: with all values and\nexcluding those within 1 nm to the surface border.\n\nFinally, you can plot your results in the CSV file, using for example\n``<path_to_installation>/pycurv/pycurv_testing/plotting.py``.\n"
      },
      "source": "https://raw.githubusercontent.com/kalemaria/pycurv/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 0.997524405511035,
      "result": {
        "original_header": ".",
        "type": "Text_excerpt",
        "value": "      targetFold=<your_conda_path>\n      wget https://repo.anaconda.com/miniconda/Miniconda3-4.7.10-Linux-x86_64.sh \n      bash Miniconda3-4.7.10-Linux-x86_64.sh -b -p $targetFold \n      export PATH=$targetFold/bin:$PATH \n      conda config --set allow_conda_downgrades true \n      conda install conda=4.6.14 \n      conda config --set allow_conda_downgrades true\n      conda config --add channels pkgw-forge\n      conda config --add channels conda-forge \n      conda install -c pkgw-forge gtk3\n      conda install -c conda-forge pygobject\n      conda install -c conda-forge matplotlib\n      conda install -c conda-forge/label/cf202003 graph-tool \n   From the same bash shell, ``which python`` should output\n   ``<your_conda_path>/bin/python``. \n   In order that your conda python is found every time you open a new\n   bash shell, add it to PATH by adding the following line to your ``~/.bashrc``\\ : \n      export PATH=<your_conda_path>/bin:$PATH \n#. \n   Add the path to the `Pyto <https://github.com/vladanl/Pyto>`_ package to PYTHONPATH in your ``~/.bashrc``\n   (See https://stackoverflow.com/questions/19917492/how-to-use-pythonpath and\n   https://docs.python.org/3.6/tutorial/modules.html): \n      export PYTHONPATH=<your_path_to_pyto>:$PYTHONPATH \n#. \n   To download the PyCurv package, run from a bash shell: \n      cd <path_to_installation>  # your destination folder\n      git clone https://github.com/kalemaria/pycurv.git \n#. \n   Install dependencies from the ``setup.py``\\ : \n      cd <path_to_installation>/pycurv\n      python setup.py install \n"
      },
      "source": "https://raw.githubusercontent.com/kalemaria/pycurv/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.999911087004865,
      "result": {
        "original_header": "Applying PyCurv",
        "type": "Text_excerpt",
        "value": "To test your PyCurv installation, you can run tests on synthetic surfaces or\nworkflow scripts on the provided experimental data sets, as explained in the\nnext subsections.\nThen, you can build your own PyCurv curvature estimation workflow, as explained\nstep-by-step in the \"User manual\" subsection.\nFor the full documentation of all modules and functions, please consult\n``<path_to_installation>/pycurv/docs/_build/html/py-modindex.html)``.\n \n"
      },
      "source": "https://raw.githubusercontent.com/kalemaria/pycurv/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9979707599771593,
      "result": {
        "original_header": "Reporting bugs",
        "type": "Text_excerpt",
        "value": "If you have found a bug or have an issue with the software, please open an issue\n`here <https://github.com/kalemaria/pycurv/issues>`_.\n \n"
      },
      "source": "https://raw.githubusercontent.com/kalemaria/pycurv/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "invocation": [
    {
      "confidence": 0.8149907036316164,
      "result": {
        "original_header": ".",
        "type": "Text_excerpt",
        "value": "   From the same bash shell, ``which python`` should output\n   ``<your_conda_path>/bin/python``. \n      from graph_tool.all import * \n"
      },
      "source": "https://raw.githubusercontent.com/kalemaria/pycurv/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/kalemaria/pycurv/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ""
      },
      "technique": "GitHub_API"
    }
  ],
  "license": [
    {
      "confidence": 1,
      "result": {
        "name": "GNU Lesser General Public License v3.0",
        "spdx_id": "LGPL-3.0",
        "type": "License",
        "url": "https://api.github.com/licenses/lgpl-3.0",
        "value": "https://api.github.com/licenses/lgpl-3.0"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "type": "File_dump",
        "value": "                   GNU LESSER GENERAL PUBLIC LICENSE\n                       Version 3, 29 June 2007\n\n Copyright (C) 2007 Free Software Foundation, Inc. <https://fsf.org/>\n Everyone is permitted to copy and distribute verbatim copies\n of this license document, but changing it is not allowed.\n\n\n  This version of the GNU Lesser General Public License incorporates\nthe terms and conditions of version 3 of the GNU General Public\nLicense, supplemented by the additional permissions listed below.\n\n  0. Additional Definitions.\n\n  As used herein, \"this License\" refers to version 3 of the GNU Lesser\nGeneral Public License, and the \"GNU GPL\" refers to version 3 of the GNU\nGeneral Public License.\n\n  \"The Library\" refers to a covered work governed by this License,\nother than an Application or a Combined Work as defined below.\n\n  An \"Application\" is any work that makes use of an interface provided\nby the Library, but which is not otherwise based on the Library.\nDefining a subclass of a class defined by the Library is deemed a mode\nof using an interface provided by the Library.\n\n  A \"Combined Work\" is a work produced by combining or linking an\nApplication with the Library.  The particular version of the Library\nwith which the Combined Work was made is also called the \"Linked\nVersion\".\n\n  The \"Minimal Corresponding Source\" for a Combined Work means the\nCorresponding Source for the Combined Work, excluding any source code\nfor portions of the Combined Work that, considered in isolation, are\nbased on the Application, and not on the Linked Version.\n\n  The \"Corresponding Application Code\" for a Combined Work means the\nobject code and/or source code for the Application, including any data\nand utility programs needed for reproducing the Combined Work from the\nApplication, but excluding the System Libraries of the Combined Work.\n\n  1. Exception to Section 3 of the GNU GPL.\n\n  You may convey a covered work under sections 3 and 4 of this License\nwithout being bound by section 3 of the GNU GPL.\n\n  2. Conveying Modified Versions.\n\n  If you modify a copy of the Library, and, in your modifications, a\nfacility refers to a function or data to be supplied by an Application\nthat uses the facility (other than as an argument passed when the\nfacility is invoked), then you may convey a copy of the modified\nversion:\n\n   a) under this License, provided that you make a good faith effort to\n   ensure that, in the event an Application does not supply the\n   function or data, the facility still operates, and performs\n   whatever part of its purpose remains meaningful, or\n\n   b) under the GNU GPL, with none of the additional permissions of\n   this License applicable to that copy.\n\n  3. Object Code Incorporating Material from Library Header Files.\n\n  The object code form of an Application may incorporate material from\na header file that is part of the Library.  You may convey such object\ncode under terms of your choice, provided that, if the incorporated\nmaterial is not limited to numerical parameters, data structure\nlayouts and accessors, or small macros, inline functions and templates\n(ten or fewer lines in length), you do both of the following:\n\n   a) Give prominent notice with each copy of the object code that the\n   Library is used in it and that the Library and its use are\n   covered by this License.\n\n   b) Accompany the object code with a copy of the GNU GPL and this license\n   document.\n\n  4. Combined Works.\n\n  You may convey a Combined Work under terms of your choice that,\ntaken together, effectively do not restrict modification of the\nportions of the Library contained in the Combined Work and reverse\nengineering for debugging such modifications, if you also do each of\nthe following:\n\n   a) Give prominent notice with each copy of the Combined Work that\n   the Library is used in it and that the Library and its use are\n   covered by this License.\n\n   b) Accompany the Combined Work with a copy of the GNU GPL and this license\n   document.\n\n   c) For a Combined Work that displays copyright notices during\n   execution, include the copyright notice for the Library among\n   these notices, as well as a reference directing the user to the\n   copies of the GNU GPL and this license document.\n\n   d) Do one of the following:\n\n       0) Convey the Minimal Corresponding Source under the terms of this\n       License, and the Corresponding Application Code in a form\n       suitable for, and under terms that permit, the user to\n       recombine or relink the Application with a modified version of\n       the Linked Version to produce a modified Combined Work, in the\n       manner specified by section 6 of the GNU GPL for conveying\n       Corresponding Source.\n\n       1) Use a suitable shared library mechanism for linking with the\n       Library.  A suitable mechanism is one that (a) uses at run time\n       a copy of the Library already present on the user's computer\n       system, and (b) will operate properly with a modified version\n       of the Library that is interface-compatible with the Linked\n       Version.\n\n   e) Provide Installation Information, but only if you would otherwise\n   be required to provide such information under section 6 of the\n   GNU GPL, and only to the extent that such information is\n   necessary to install and execute a modified version of the\n   Combined Work produced by recombining or relinking the\n   Application with a modified version of the Linked Version. (If\n   you use option 4d0, the Installation Information must accompany\n   the Minimal Corresponding Source and Corresponding Application\n   Code. If you use option 4d1, you must provide the Installation\n   Information in the manner specified by section 6 of the GNU GPL\n   for conveying Corresponding Source.)\n\n  5. Combined Libraries.\n\n  You may place library facilities that are a work based on the\nLibrary side by side in a single library together with other library\nfacilities that are not Applications and are not covered by this\nLicense, and convey such a combined library under terms of your\nchoice, if you do both of the following:\n\n   a) Accompany the combined library with a copy of the same work based\n   on the Library, uncombined with any other library facilities,\n   conveyed under the terms of this License.\n\n   b) Give prominent notice with the combined library that part of it\n   is a work based on the Library, and explaining where to find the\n   accompanying uncombined form of the same work.\n\n  6. Revised Versions of the GNU Lesser General Public License.\n\n  The Free Software Foundation may publish revised and/or new versions\nof the GNU Lesser General Public License from time to time. Such new\nversions will be similar in spirit to the present version, but may\ndiffer in detail to address new problems or concerns.\n\n  Each version is given a distinguishing version number. If the\nLibrary as you received it specifies that a certain numbered version\nof the GNU Lesser General Public License \"or any later version\"\napplies to it, you have the option of following the terms and\nconditions either of that published version or of any later version\npublished by the Free Software Foundation. If the Library as you\nreceived it does not specify a version number of the GNU Lesser\nGeneral Public License, you may choose any version of the GNU Lesser\nGeneral Public License ever published by the Free Software Foundation.\n\n  If the Library as you received it specifies that a proxy can decide\nwhether future versions of the GNU Lesser General Public License shall\napply, that proxy's public statement of acceptance of any version is\npermanent authorization for you to choose that version for the\nLibrary.\n"
      },
      "source": "https://raw.githubusercontent.com/kalemaria/pycurv/master/LICENSE",
      "technique": "file_exploration"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "pycurv"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "User",
        "value": "kalemaria"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 655978,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Jupyter Notebook",
        "size": 126434,
        "type": "Programming_language",
        "value": "Jupyter Notebook"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Shell",
        "size": 3302,
        "type": "Programming_language",
        "value": "Shell"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/kalemaria/pycurv/master/README.md"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/kalemaria/pycurv/master/README.rst"
      },
      "technique": "file_exploration"
    }
  ],
  "run": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Running the tests",
        "parent_header": [
          "Applying PyCurv"
        ],
        "type": "Text_excerpt",
        "value": "To run the integration tests of the curvature workflow on synthetic surfaces,\nexecute from a bash shell:\n\n.. code-block::\n\n   pytest -q --disable-pytest-warnings <path_to_installation>/pycurv/pycurv_testing/\n   test_vector_voting.py\n\nTo run a specific test, for example ``test_sphere_curvatures``\\ , run:\n\n.. code-block::\n\n   pytest -q --disable-pytest-warnings <path_to_installation>/pycurv/pycurv_testing/\n   test_vector_voting.py::test_sphere_curvatures\n\nIf it does not work, try to replace ``pytest -q`` by ``python -m pytest``.\n\nA folder ``test_vector_voting_output`` containing the test results will be created\ninside the current directory.\n\nIn the same manner, you can run:\n\n\n* the integration tests of the distances and thicknesses workflow\n  (\\ ``test_distances_calculation.py``\\ )\n* the unit test of histogram area calculation\n  (\\ ``test_histogram_area_calculation.py``\\ )\n* the unit test for some linear algebra functions (\\ ``test_linalg.py``\\ )\n"
      },
      "source": "https://raw.githubusercontent.com/kalemaria/pycurv/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Running the experimental data sets",
        "parent_header": [
          "Applying PyCurv"
        ],
        "type": "Text_excerpt",
        "value": "To run the curvature estimation workflow on the vesicle and ER segmentation in\nthe ``experimental_data_sets`` folder, just run in a bash shell:\n\n.. code-block::\n\n   cd <path_to_installation>/pycurv/pycurv_scripts\n   python curvature_calculation.py\n\nThe output will be generated in the respective subfolders of the input,\n``vesicle`` and ``ER``.\nYou can change the parameters and find more workflow examples in the script.\n"
      },
      "source": "https://raw.githubusercontent.com/kalemaria/pycurv/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "somef_missing_categories": [
    "acknowledgement",
    "download",
    "requirements",
    "contact",
    "contributors",
    "documentation",
    "usage",
    "faq",
    "support",
    "identifier",
    "has_build_file"
  ],
  "somef_provenance": {
    "date": "2024-10-06 15:35:00",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 16
      },
      "technique": "GitHub_API"
    }
  ]
}