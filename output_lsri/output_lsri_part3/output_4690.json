{
  "citation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Citation",
        "parent_header": [
          "RNN-IMP"
        ],
        "type": "Text_excerpt",
        "value": "If you find RNN-IMP or any of the scripts in this repository useful for your research, please cite:\n\n> Kojima, K., Tadaka, S., Okamura, Y. & Kinoshita, K. (2024).\n> Two-stage strategy using denoising autoencoders for robust reference-free genotype imputation with missing input genotypes.\n> *Journal of Human Genetics*.\n> https://doi.org/10.1038/s10038-024-01261-6\n\n> Kojima, K., Tadaka, S., Katsuoka, F., Tamiya, G., Yamamoto, M. & Kinoshita, K. (2020).\n> A genotype imputation method for de-identified haplotype reference information by using recurrent neural network.\n> *PLoS Computational Biology*, **16**(10): e1008207.\n> https://doi.org/10.1371/journal.pcbi.1008207\n"
      },
      "source": "https://raw.githubusercontent.com/kanamekojima/rnnimp/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/kanamekojima/rnnimp"
      },
      "technique": "GitHub_API"
    }
  ],
  "contact": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Contact",
        "parent_header": [
          "RNN-IMP"
        ],
        "type": "Text_excerpt",
        "value": "Developer: Kaname Kojima, Ph.D.\n\nE-mail: kojima [AT] megabank [DOT] tohoku [DOT] ac [DOT] jp or kengo [AT] ecei [DOT] tohoku [DOT] ac [DOT] jp\n"
      },
      "source": "https://raw.githubusercontent.com/kanamekojima/rnnimp/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2019-09-17T18:48:29Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2024-08-08T14:15:19Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 0.9771745134315744,
      "result": {
        "original_header": "RNN-IMP",
        "type": "Text_excerpt",
        "value": "RNN-IMP is a Python program for reference-free genotype imputation using recurrent neural networks (RNNs).\nRNN-IMP takes phased genotypes in HAPSLEGEND format as input and outputs imputation results in either VCF or Oxford GEN format.\n \n"
      },
      "source": "https://raw.githubusercontent.com/kanamekojima/rnnimp/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9575014880653911,
      "result": {
        "original_header": "Options for `scripts/train/train.py`",
        "type": "Text_excerpt",
        "value": "| Option | Default Value | Summary |\n|:-------|:-------------:|:-------|\n| --data-list STRING_VALUE | - | Input data list file |\n| --output-prefix STRING_VALUE | - | Output file name prefix |\n| --rnn-cell-type STRING_VALUE | GRU | RNN cell type. Available options: GRU / LSTM |\n| --num-units INT_VALUE | 40 | Vector size in RNN cells |\n| --num-layers-higher INT_VALUE | 4 | RNN layer size for the higher MAF model |\n| --num-layers-lower INT_VALUE | 4 | RNN layer size for the lower MAF model |\n| --feature-size INT_VALUE | 40 | Input feature vector size |\n| --gamma1 FLOAT_VALUE | 0.75 | Loss weight parameter for the higher MAF model |\n| --gamma2 FLOAT_VALUE | 0.75 | Loss weight parameter for the lower MAF model |\n| --batch-size INT_VALUE | 500 | Training batch size |\n| --max-iteration-count INT_VALUE | 100000 | Maximum iteration count |\n| --validation-sample-size INT_VALUE | 100 | Validation sample size |\n| --num-threads INT_VALUE | 1 | Number of threads in TensorFlow |\n| --slurm | False | Enables the use of Slurm for distributed computation (this option is only effective in environments where Slurm is available) |\n| --job-name-prefix STRING_VALUE | train | Job name prefix for Slurm jobs |\n| --memory-size STRING_VALUE | 20GB | Memory size limit for Slurm jobs |\n| --python3-bin STRING_VALUE | python3 | Path to the Python3 binary |\n \n"
      },
      "source": "https://raw.githubusercontent.com/kanamekojima/rnnimp/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/kanamekojima/rnnimp/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 2
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/kanamekojima/rnnimp/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "kanamekojima/rnnimp"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "RNN-IMP"
      },
      "source": "https://raw.githubusercontent.com/kanamekojima/rnnimp/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "installation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Installation",
        "parent_header": [
          "RNN-IMP"
        ],
        "type": "Text_excerpt",
        "value": "Requirements: Python versions 3.5 to 3.10 (ensure python3 is in your path)\n\n```sh\ngit clone https://github.com/kanamekojima/rnnimp.git\ncd rnnimp\npython3 -m pip install -r requirements.txt\n```\n"
      },
      "source": "https://raw.githubusercontent.com/kanamekojima/rnnimp/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Preparation of Example Dataset",
        "parent_header": [
          "RNN-IMP",
          "Example Usage"
        ],
        "type": "Text_excerpt",
        "value": "To prepare the example dataset, the following files are required:\n\n- A VCF file from the 1000 Genomes Project (1KGP) phase 3 dataset for chromosome 22 (`ALL.chr22.phase3_shapeit2_mvncall_integrated_v5b.20130502.genotypes.vcf.gz`):\n  - Download the VCF file from the following website and place it in the `org_data` directory:\n    - [https://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502](https://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502)\n- A manifest file for the Infinium Omni2.5-8 BeadChip (`InfiniumOmni2-5-8v1-4_A1.csv`):\n  - Download `infinium-omni-2-5-8v1-4-a1-manifest-file-csv.zip` from the following website:\n    - [https://support.illumina.com/array/array_kits/humanomni2_5-8_beadchip_kit/downloads.html](https://support.illumina.com/array/array_kits/humanomni2_5-8_beadchip_kit/downloads.html)\n    - Unzip the file and place `InfiniumOmni2-5-8v1-4_A1.csv` in the `org_data` directory.\n- An Hg19 fasta file (hg19.fa):\n  - Download `hg19.fa.gz` from the following website:\n    - [https://hgdownload.soe.ucsc.edu/goldenPath/hg19/bigZips/](https://hgdownload.soe.ucsc.edu/goldenPath/hg19/bigZips/)\n    - Unzip the file and place `hg19.fa` in the `org_data` directory.\n\nAfter preparing the above files, execute the following command in the `rnnimp` directory:\n\n```sh\npython3 scripts/test_data_preparation.py\n```\n\nThis process generates the example dataset, including:\n\n- `example_data/test/chr22_true.[hap.gz/legend.gz]`: Phased genotype data for 100 individuals from `org_data/test_samples.txt` for chromosome 22 in HAPSLEGEND format, derived from the 1KGP phase 3 dataset. These individuals are randomly selected from the 2,504 individuals in the 1KGP phase 3 dataset.\n- `example_data/test/chr22.[hap.gz/legend.gz]`: Phased genotype data extracted from `example_data/test/chr22_true.[hap.gz/legend.gz]` for marker sites designed for the Infinium Omni2.5-8 BeadChip. This dataset simulates input data from the Omni2.5 array.\n- `example_data/train/chr22.[hap.gz/legend.gz]`: Phased genotype data for the remaining 2,404 individuals not included in `org_data/test_samples.txt` for chromosome 22, obtained from the 1KGP phase 3 dataset in HAPSLEGEND format. This dataset is used for training RNN-IMP.\n"
      },
      "source": "https://raw.githubusercontent.com/kanamekojima/rnnimp/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 0.9999988123796246,
      "result": {
        "original_header": "Options for `scripts/inference/imputation.py`",
        "type": "Text_excerpt",
        "value": "| Option | Default Value | Summary |\n|:-------|:-------------:|:-------|\n| --hap STRING_VALUE | - | Input hap file |\n| --legend STRING_VALUE | - | Input legend file |\n| --sample STRING_VALUE | None | Input sample file (optional) |\n| --chromosome | None | Chromosome name. Required for VCF output format. |\n| --model-prefix STRING_VALUE | - | Model name prefix |\n| --output-prefix STRING_VALUE | - | Output file name prefix |\n| --output-format STRING_VALUE | gen | Output format [gen / vcf] |\n| --python3-bin STRING_VALUE | python3 | Path to the Python3 binary |\n \n"
      },
      "source": "https://raw.githubusercontent.com/kanamekojima/rnnimp/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "invocation": [
    {
      "confidence": 0.9040287292675392,
      "result": {
        "original_header": "Options for `scripts/inference/imputation.py`",
        "type": "Text_excerpt",
        "value": "| Option | Default Value | Summary |\n|:-------|:-------------:|:-------|\n| --hap STRING_VALUE | - | Input hap file |\n| --legend STRING_VALUE | - | Input legend file |\n| --sample STRING_VALUE | None | Input sample file (optional) |\n| --chromosome | None | Chromosome name. Required for VCF output format. |\n| --model-prefix STRING_VALUE | - | Model name prefix |\n| --output-prefix STRING_VALUE | - | Output file name prefix |\n| --output-format STRING_VALUE | gen | Output format [gen / vcf] |\n| --python3-bin STRING_VALUE | python3 | Path to the Python3 binary |\n \n"
      },
      "source": "https://raw.githubusercontent.com/kanamekojima/rnnimp/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/kanamekojima/rnnimp/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ""
      },
      "technique": "GitHub_API"
    }
  ],
  "license": [
    {
      "confidence": 1,
      "result": {
        "name": "MIT License",
        "spdx_id": "MIT",
        "type": "License",
        "url": "https://api.github.com/licenses/mit",
        "value": "https://api.github.com/licenses/mit"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "type": "File_dump",
        "value": "MIT License\n\nCopyright (c) 2020 Kaname Kojima\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
      },
      "source": "https://raw.githubusercontent.com/kanamekojima/rnnimp/master/LICENSE.md",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "License",
        "parent_header": [
          "RNN-IMP"
        ],
        "type": "Text_excerpt",
        "value": "The scripts in this repository are available under the MIT License.\nFor more details, see the [LICENSE.md](LICENSE.md) file.\n"
      },
      "source": "https://raw.githubusercontent.com/kanamekojima/rnnimp/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "rnnimp"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "User",
        "value": "kanamekojima"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 131246,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/kanamekojima/rnnimp/master/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "somef_missing_categories": [
    "acknowledgement",
    "run",
    "download",
    "requirements",
    "contributors",
    "documentation",
    "faq",
    "support",
    "identifier",
    "has_build_file",
    "executable_example"
  ],
  "somef_provenance": {
    "date": "2024-10-06 17:21:36",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 10
      },
      "technique": "GitHub_API"
    }
  ],
  "usage": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Preparation of Example Dataset",
        "parent_header": [
          "RNN-IMP",
          "Example Usage"
        ],
        "type": "Text_excerpt",
        "value": "To prepare the example dataset, the following files are required:\n\n- A VCF file from the 1000 Genomes Project (1KGP) phase 3 dataset for chromosome 22 (`ALL.chr22.phase3_shapeit2_mvncall_integrated_v5b.20130502.genotypes.vcf.gz`):\n  - Download the VCF file from the following website and place it in the `org_data` directory:\n    - [https://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502](https://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502)\n- A manifest file for the Infinium Omni2.5-8 BeadChip (`InfiniumOmni2-5-8v1-4_A1.csv`):\n  - Download `infinium-omni-2-5-8v1-4-a1-manifest-file-csv.zip` from the following website:\n    - [https://support.illumina.com/array/array_kits/humanomni2_5-8_beadchip_kit/downloads.html](https://support.illumina.com/array/array_kits/humanomni2_5-8_beadchip_kit/downloads.html)\n    - Unzip the file and place `InfiniumOmni2-5-8v1-4_A1.csv` in the `org_data` directory.\n- An Hg19 fasta file (hg19.fa):\n  - Download `hg19.fa.gz` from the following website:\n    - [https://hgdownload.soe.ucsc.edu/goldenPath/hg19/bigZips/](https://hgdownload.soe.ucsc.edu/goldenPath/hg19/bigZips/)\n    - Unzip the file and place `hg19.fa` in the `org_data` directory.\n\nAfter preparing the above files, execute the following command in the `rnnimp` directory:\n\n```sh\npython3 scripts/test_data_preparation.py\n```\n\nThis process generates the example dataset, including:\n\n- `example_data/test/chr22_true.[hap.gz/legend.gz]`: Phased genotype data for 100 individuals from `org_data/test_samples.txt` for chromosome 22 in HAPSLEGEND format, derived from the 1KGP phase 3 dataset. These individuals are randomly selected from the 2,504 individuals in the 1KGP phase 3 dataset.\n- `example_data/test/chr22.[hap.gz/legend.gz]`: Phased genotype data extracted from `example_data/test/chr22_true.[hap.gz/legend.gz]` for marker sites designed for the Infinium Omni2.5-8 BeadChip. This dataset simulates input data from the Omni2.5 array.\n- `example_data/train/chr22.[hap.gz/legend.gz]`: Phased genotype data for the remaining 2,404 individuals not included in `org_data/test_samples.txt` for chromosome 22, obtained from the 1KGP phase 3 dataset in HAPSLEGEND format. This dataset is used for training RNN-IMP.\n"
      },
      "source": "https://raw.githubusercontent.com/kanamekojima/rnnimp/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Imputation for the Example Dataset",
        "parent_header": [
          "RNN-IMP",
          "Example Usage"
        ],
        "type": "Text_excerpt",
        "value": "RNN-IMP performs imputation on small regions separately and combines these results to produce an imputation result for an entire chromosome in VCF format or Oxford GEN format.\nFor each small region, specific RNN model structures and their parameters, stored in ONNX Runtime (ORT) format, along with target information in legend format, are required.\n\nLegend files from the example training data are located in the `results/train/models` directory, and ORT files can be obtained with the following commands in the `rnnimp` directory:\n\n```sh\nwget https://github.com/kanamekojima/rnnimp/raw/master/results/train/models/chr22_onnx_files.tbz -P org_data\ntar jxf org_data/chr22_onnx_files.tbz -C results/train/models\n\nfor onnx_file in $(ls results/train/models/chr22*.onnx)\ndo\n  python3 -m onnxruntime.tools.convert_onnx_models_to_ort $onnx_file\ndone\n```\n\nThese files can also be generated through the training process, as described in the subsequent section.\nTo perform imputation on `example_data/test/chr22.[hap.gz/legend.gz]` using these model information files, execute the following command in the `rnnimp` directory:\n\n```sh\npython3 scripts/inference/imputation.py \\\n    --hap example_data/test/chr22.hap.gz \\\n    --legend example_data/test/chr22.legend.gz \\\n    --model-prefix results/train/models/chr22 \\\n    --output-prefix results/imputation/chr22\n```\n\nThis command generates the imputation result for `example_data/test/chr22.[hap.gz/legend.gz]` as `results/imputation/chr22.gen`.\nTo produce the results in VCF format, use the `--output-format vcf` option.\n"
      },
      "source": "https://raw.githubusercontent.com/kanamekojima/rnnimp/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Training RNN Models for the Example Dataset",
        "parent_header": [
          "RNN-IMP",
          "Example Usage"
        ],
        "type": "Text_excerpt",
        "value": "In RNN-IMP, the whole chromosome is divided into small regions, and RNN models are trained separately for each region.\nTo begin, divide the training data, `example_data/train/chr22.[hap.gz/legend.gz]`, into smaller segments using the following commands in the `rnnimp` directory:\n\n```sh\nwget https://raw.githubusercontent.com/stephenslab/ldshrink/main/inst/test_gdsf/fourier_ls-all.bed -P org_data\nhead -n 1 org_data/fourier_ls-all.bed > org_data/fourier_ls-chr22.bed\ngrep \"^chr22 \" org_data/fourier_ls-all.bed >> org_data/fourier_ls-chr22.bed\npython3 scripts/train/train_data_splitter.py \\\n    --hap example_data/train/chr22.hap.gz \\\n    --legend example_data/train/chr22.legend.gz \\\n    --output-prefix example_data/train/split/chr22 \\\n    --body-marker-count-limit 200 \\\n    --flanking-marker-count-limit 50 \\\n    --imp-site-count-limit 1000 \\\n    --partition org_data/fourier_ls-chr22.bed\n```\n\nThe `--partition` option specifies a file containing a list of regions into which the chromosome is divided, facilitating segmentation based on these predefined regions.\nFor this example, a list of regions segmented at high recombination rate points is used.\nThis list is available on the Stephens lab GitHub page as a file named `fourier_ls-all.bed`:\n[https://github.com/stephenslab/ldshrink](https://github.com/stephenslab/ldshrink)\n\nBased on the specified criteria, these segmented regions are further divided in the above commands, resulting in the generation of training data files for 225 divided regions in this example.\nThe prefixes for these files are listed in `example_data/train/split/chr22.list`.\n\nTo train RNN models for these regions using the segmented training data, execute the following command in the `rnnimp` directory:\n\n```sh\npython3 scripts/train/train.py \\\n    --data-list example_data/train/split/chr22.list \\\n    --rnn-cell-type GRU \\\n    --num-layers-higher 4 \\\n    --num-layers-lower 4 \\\n    --num-units 40 \\\n    --gamma1 0.75 \\\n    --gamma2 -0.75 \\\n    --feature-size 40 \\\n    --output-prefix results/train/chr22\n```\n\n**Warning:** Running the training command as described may require over six months to complete on a single thread, even using high-end CPUs.\nTo significantly reduce computation time, the use of supercomputing resources, which allow for parallel processing, is strongly recommended.\nThe `--slurm` option facilitates the parallel training of RNN models across different regions by leveraging supercomputing resources managed with Slurm.\nDue to the variability in Slurm configurations, please refer to the `scripts/train/slurm.py` script for usage details and make necessary adjustments to fit your computing environment.\nFor computing environments using job schedulers other than Slurm, modifications to the `scripts/train/train.py` script will be required to enable parallel processing.\n"
      },
      "source": "https://raw.githubusercontent.com/kanamekojima/rnnimp/master/README.md",
      "technique": "header_analysis"
    }
  ]
}