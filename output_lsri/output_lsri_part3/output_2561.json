{
  "application_domain": [
    {
      "confidence": 55.16,
      "result": {
        "type": "String",
        "value": "Computer Vision"
      },
      "technique": "supervised_classification"
    }
  ],
  "citation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Citation",
        "parent_header": [
          "COVID-CS dataset and JCS model"
        ],
        "type": "Text_excerpt",
        "value": "```\n@article{wu2021jcs,\n  title={{JCS}: An explainable {COVID}-19 diagnosis system by joint classification and segmentation},\n  author={Wu, Yu-Huan and Gao, Shang-Hua and Mei, Jie and Xu, Jun and Fan, Deng-Ping and Zhang, Rong-Guo and Cheng, Ming-Ming},\n  journal={IEEE Transactions on Image Processing},\n  volume={30},\n  pages={3113--3126},\n  year={2021},\n  publisher={IEEE}\n}\n```\n\n"
      },
      "source": "https://raw.githubusercontent.com/yuhuan-wu/JCS/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "author": "Wu, Yu-Huan and Gao, Shang-Hua and Mei, Jie and Xu, Jun and Fan, Deng-Ping and Zhang, Rong-Guo and Cheng, Ming-Ming",
        "format": "bibtex",
        "title": "{JCS}: An explainable {COVID}-19 diagnosis system by joint classification and segmentation",
        "type": "Text_excerpt",
        "value": "@article{wu2021jcs,\n    publisher = {IEEE},\n    year = {2021},\n    pages = {3113--3126},\n    volume = {30},\n    journal = {IEEE Transactions on Image Processing},\n    author = {Wu, Yu-Huan and Gao, Shang-Hua and Mei, Jie and Xu, Jun and Fan, Deng-Ping and Zhang, Rong-Guo and Cheng, Ming-Ming},\n    title = {{JCS}: An explainable {COVID}-19 diagnosis system by joint classification and segmentation},\n}"
      },
      "source": "https://raw.githubusercontent.com/yuhuan-wu/JCS/main/README.md",
      "technique": "regular_expression"
    }
  ],
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/yuhuan-wu/JCS"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2020-10-22T11:21:36Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2024-06-25T17:57:58Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "[IEEE TIP 2021] COVID-CS Dataset and Code of JCS: An explainable COVID-19 diagnosis system by joint classification and segmentation"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 0.9726005593859494,
      "result": {
        "original_header": "COVID-CS dataset and JCS model",
        "type": "Text_excerpt",
        "value": "Official repository of the paper: JCS: An explainable COVID-19 diagnosis system by joint classification and segmentation,\nIEEE Transactions on Image Processing (TIP) 2021. \nThis repository contains: \n- [x] Available COVID-CS classification and segmentation data, including demos, annotations, and ResNet stage-1 features.\n- [x] **Training** and testing code of our JCS model. \nThis paper has been accepted and published in [IEEE Transactions on Image Processing (TIP) 2021](https://ieeexplore.ieee.org/document/9357961). \n\nIf you need any (special) help for the code and data, do not hesitate to leave issues in this repository. \n"
      },
      "source": "https://raw.githubusercontent.com/yuhuan-wu/JCS/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9614082358668338,
      "result": {
        "original_header": "Testing",
        "type": "Text_excerpt",
        "value": "We provide a demo that generates **explainable attention maps** of CT images, as shown in our paper. \n* First, please download the model weights:  `res2net_cls.pth` which only is trained with image labels and `res2net_segloss.pth` which is trained with pixel-level annotations. \nDownloading urls are  [res2net_cls.pth](https://drive.google.com/file/d/1rhLLZoeCBYQ7XWpEppywdL3mODlsJn9k/view?usp=sharing) and [res2net_segloss.pth](https://drive.google.com/file/d/1B431SuffibX9tBueSeVVoOL9TThmvjIz/view?usp=sharing), respectively. Put the weights into `model_zoo/` folder.\n* Second, run `PYTHONPATH=$(pwd):$PYTHONPATH python tools/gen_results.py`, results will be generated in the `results_pos` folder. You should get same result with the illustrated figure in our paper.\n \n"
      },
      "source": "https://raw.githubusercontent.com/yuhuan-wu/JCS/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9072645637132227,
      "result": {
        "original_header": "Training",
        "type": "Text_excerpt",
        "value": "Where `train/1.jpg` is the CT image filename and `train/1.png` is the name of the corresponding annotation image.\nEach line includes one CT image with a corresponding annotation image. \nIf you do not have data, you can train with provided examples as described below. \nWe provide a training script with training examples which are located in the `data` folder. \nBefore training our model, please make sure that your GPU memory is higher than `4GB` for a batchsize of 1 or `6GB` for a batchsize of 2. \nYou can also prepare your data following the format of the data in the `./data/` folder.  \nNote: The pure source segmentation data of our COVID-CS dataset can not be released so far according to some policies. Therefore, we utilize COVID-19-CT100 dataset to show how to train our model simply. \n"
      },
      "source": "https://raw.githubusercontent.com/yuhuan-wu/JCS/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9863663660998002,
      "result": {
        "original_header": "COVID-CS Dataset",
        "type": "Text_excerpt",
        "value": "\nDue to our confidential agreement with the data provider, we cannot share the source CT images. \nTherefore, we provide **CNN features of CT images**. Currently, we provide the intermediate features. \nWe generate intermediate features with the JCS model or ImageNet-pretrained model.\nMore specifically, only features at the first stage are restored.\nTo save space, we quantize the features into uint8 format.\nTaking the VGG-16-based backbone as the example:\n```python\n x = vgg16.conv1_1(ct_images)\n features = vgg16.conv1_2(x) # We record features conv1_2 of VGG-16\n features = (features.cpu().numpy() * 20).astype(numpy.uint8) # To save space, we save features as the uint8 format.\n ### A coefficient 20 is to more effeciently utilize the space of uint8 variables\n \n save(features, save_path) # Saveing features\n```\n \nAs JCS has two backbones, we save vgg_features and res2net_features for each CT image.\n \n"
      },
      "source": "https://raw.githubusercontent.com/yuhuan-wu/JCS/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9113515434997376,
      "result": {
        "original_header": "COVID-CS Data for Segmentation",
        "type": "Text_excerpt",
        "value": "Only features are provided. To train or test your model, you should skip the first stage of the backbone.\nThen you can load our provided features and finish the inference of other stages:\n```python\n$NAME.mat, which contains two variables: vgg_feats, res2net_feats\nimport scipy.io as sio\nimport torch\nfeats = sio.load_mat('$NAME.mat')\nvgg_feats = torch.from_numpy(feats[\"vgg_feats\"]).float() / 20 # get vgg_feats conv1_2 (of VGG-16)\nres2net_feats = torch.from_numpy(feats[\"res2net_feats\"]).float() / 20 # get res2net_feats conv1 (of Res2Net-101-v1b)\noutput = model(vgg_feats, res2net_feats) or model(vgg_feats) or model(res2net_feats) # model inference\n```\n \nAs default, the CT images are of `512 * 512` size. So vgg_feats and res2net_feats are of `1 * 64 * 512 * 512` and `1 * 64 * 256 * 256` size, respectively. To save disk space, we also provide the half size version (`256 * 256` CT image input size). \n* Segmentation annotation data, including train/test split txt files: [Google Drive](https://drive.google.com/file/d/1U489DgHNqlwLJ9VZa6qssf65SV9F45jc/view?usp=sharing)\n* JCS pretrained features: [OneDrive, 21.7GB](https://mailnankaieducn-my.sharepoint.com/:u:/g/personal/wuyuhuan_mail_nankai_edu_cn/EfiCUqJ0oABAjQs5aHC-IScBmTIIaur_qV8Ldt2366JXPA?e=tvFhDV)\n* JCS pretrained features (half feature size): [OneDrive, 5.7GB](https://mailnankaieducn-my.sharepoint.com/:u:/g/personal/wuyuhuan_mail_nankai_edu_cn/EXjDhKvCRdZKjutnjSujHWcB6Fkjx329ZJI6wesnQ07Tog?e=GNkXZf)\n* ImageNet pretrained features: [OneDrive, 19.8GB](https://mailnankaieducn-my.sharepoint.com/:u:/g/personal/wuyuhuan_mail_nankai_edu_cn/EY01kub68GJPmzJmht97EaYBvX03anlgGgIJSeSAtitSWw?e=U0Totb)\n* ImageNet pretrained features (half feature size): [OneDrive, 5.5GB](https://mailnankaieducn-my.sharepoint.com/:u:/g/personal/wuyuhuan_mail_nankai_edu_cn/Ebux1iLP1rxPvQTD66Ssi0ABg3bJYae9gGZc2q-j7gmB-A?e=irzXFy)\n \n"
      },
      "source": "https://raw.githubusercontent.com/yuhuan-wu/JCS/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9685041921476745,
      "result": {
        "original_header": "COVID-CS Data for Classification",
        "type": "Text_excerpt",
        "value": "We provide what we used for training classification model of JCS.  \nEach .mat file is size 64\u00d7112\u00d7112 feature of the first stage resnet, from a CT Image. We use same CT images for training the classification model for JCS, which also achieves Good result. So the above data will be enough for you to train a new model.  \nHow to use these features for training?\nPlease read the README.md of the [data](https://drive.google.com/file/d/1jfvNF2Kv14kTQ1jts5eYaerI1_WbAHTi/view?usp=sharing) first.\nIf you only use these features, I recommend to remove the first stage of resnet and directly pass the features to the next stage.\n \n"
      },
      "source": "https://raw.githubusercontent.com/yuhuan-wu/JCS/main/README.md",
      "technique": "supervised_classification"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/yuhuan-wu/JCS/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 13
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/yuhuan-wu/JCS/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "yuhuan-wu/JCS"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ""
      },
      "source": "https://raw.githubusercontent.com/yuhuan-wu/JCS/main/README.md",
      "technique": "regular_expression"
    }
  ],
  "has_script_file": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/yuhuan-wu/JCS/main/tools/test_joint.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/yuhuan-wu/JCS/main/tools/train.sh"
      },
      "technique": "file_exploration"
    }
  ],
  "installation": [
    {
      "confidence": 0.8521426406920645,
      "result": {
        "original_header": "COVID-CS dataset and JCS model",
        "type": "Text_excerpt",
        "value": "\nIf you need any (special) help for the code and data, do not hesitate to leave issues in this repository. \n"
      },
      "source": "https://raw.githubusercontent.com/yuhuan-wu/JCS/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9434993260372937,
      "result": {
        "original_header": "Testing",
        "type": "Text_excerpt",
        "value": "After finishing the above steps, `tools/test_joint.sh` can be directly used to compute the final covid-19 results, like this:\n```\nbash ./tools/test_joint.sh\n```\n \nYou should get 66.61% mIoU computed by our CUDA-based evaluator.  \n"
      },
      "source": "https://raw.githubusercontent.com/yuhuan-wu/JCS/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9478862518180728,
      "result": {
        "original_header": "Training",
        "type": "Text_excerpt",
        "value": "Please place your full data folder (e.g. `COVID-Dataset`) under the `./data` folder.\nThen, create `train.txt` and `test.txt` following this format:\n````\ntrain/1.jpg train/1.png \ntrain/2.jpg train/2.png \n````\n \nEdit `./tools/train.sh`, replace `--data_dir ./data/xxxxx` with `--data_dir ./data/COVID-Dataset`. \nIf you do not have data, you can train with provided examples as described below. \n`CUDA_VISIBLE_DEVICES=0 ./tools/train.sh` \n"
      },
      "source": "https://raw.githubusercontent.com/yuhuan-wu/JCS/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9901042942056969,
      "result": {
        "original_header": "Others",
        "type": "Text_excerpt",
        "value": "If you need special help, please leave issues or directly contact me via e-mail. Thanks!\n \n"
      },
      "source": "https://raw.githubusercontent.com/yuhuan-wu/JCS/main/README.md",
      "technique": "supervised_classification"
    }
  ],
  "invocation": [
    {
      "confidence": 0.8090033378152253,
      "result": {
        "original_header": "Testing",
        "type": "Text_excerpt",
        "value": "* **Segmentation Test** \nPlease download the computed intermediate features at first: [OneDrive](https://mailnankaieducn-my.sharepoint.com/:u:/g/personal/wuyuhuan_mail_nankai_edu_cn/EfiCUqJ0oABAjQs5aHC-IScBmTIIaur_qV8Ldt2366JXPA?e=tvFhDV). Download the annotation files: [Google Drive](https://drive.google.com/file/d/1U489DgHNqlwLJ9VZa6qssf65SV9F45jc/view?usp=sharing).\nExtract them into `./data/COVID-CS/` folder. Put features under `data/COVID-CS/feats_joint_pretrained` directory.\nDownload [the annotation files](https://drive.google.com/file/d/1U489DgHNqlwLJ9VZa6qssf65SV9F45jc/view?usp=sharing), and put them under the `./data/COVID-CS/` folder. \n* First, please download the model weights:  `res2net_cls.pth` which only is trained with image labels and `res2net_segloss.pth` which is trained with pixel-level annotations. \nDownloading urls are  [res2net_cls.pth](https://drive.google.com/file/d/1rhLLZoeCBYQ7XWpEppywdL3mODlsJn9k/view?usp=sharing) and [res2net_segloss.pth](https://drive.google.com/file/d/1B431SuffibX9tBueSeVVoOL9TThmvjIz/view?usp=sharing), respectively. Put the weights into `model_zoo/` folder.\n* Second, run `PYTHONPATH=$(pwd):$PYTHONPATH python tools/gen_results.py`, results will be generated in the `results_pos` folder. You should get same result with the illustrated figure in our paper.\n \n"
      },
      "source": "https://raw.githubusercontent.com/yuhuan-wu/JCS/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8576889299458607,
      "result": {
        "original_header": "Training",
        "type": "Text_excerpt",
        "value": "Please place your full data folder (e.g. `COVID-Dataset`) under the `./data` folder.\nThen, create `train.txt` and `test.txt` following this format:\n````\ntrain/1.jpg train/1.png \ntrain/2.jpg train/2.png \n````\n \nEdit `./tools/train.sh`, replace `--data_dir ./data/xxxxx` with `--data_dir ./data/COVID-Dataset`. \n* Training Segmentation Model: An Example \nWe provide a training script with training examples which are located in the `data` folder. \nThen, please download the ImageNet-pretrained VGG-16 model [5stages_vgg16_bn-6c64b313.pth](https://drive.google.com/file/d/1zgO9vMCDpj2J50EExa28S3nWDNGQe5WC/view?usp=sharing) and put the model weights under the `model_zoo/` folder.\nAfter the above preparation, you can simply run the following command to train our model:  \n`CUDA_VISIBLE_DEVICES=0 ./tools/train.sh` \n"
      },
      "source": "https://raw.githubusercontent.com/yuhuan-wu/JCS/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.813704203548952,
      "result": {
        "original_header": "Pretrained Models",
        "type": "Text_excerpt",
        "value": "* Segmentation:\n* Joint pretrained model (cls + seg): [Google Drive](https://drive.google.com/file/d/1V1EKXL4gFAH6ZtFRcmUv9-aI0sc5e9Ga/view).\n* Single pretrained model (seg only): [Google Drive](https://drive.google.com/file/d/1iXD9n1LSR7_pyyU8xQd0kZVn0IAat3Aq/view).\n* Classification:\n* Pretrained model (trained only with image labels): [Google Drive](https://drive.google.com/file/d/1rhLLZoeCBYQ7XWpEppywdL3mODlsJn9k/view?usp=sharing).\n* Pretrained model (trained with pixel-level annotation): [Google Drive](https://drive.google.com/file/d/1B431SuffibX9tBueSeVVoOL9TThmvjIz/view?usp=sharing).\n \n"
      },
      "source": "https://raw.githubusercontent.com/yuhuan-wu/JCS/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8543600602630111,
      "result": {
        "original_header": "COVID-CS Data for Classification",
        "type": "Text_excerpt",
        "value": "Data Download: \n* [Google Drive](https://drive.google.com/file/d/1jfvNF2Kv14kTQ1jts5eYaerI1_WbAHTi/view?usp=sharing) \n"
      },
      "source": "https://raw.githubusercontent.com/yuhuan-wu/JCS/main/README.md",
      "technique": "supervised_classification"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/yuhuan-wu/JCS/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ""
      },
      "technique": "GitHub_API"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "JCS"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "User",
        "value": "yuhuan-wu"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 82215,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Shell",
        "size": 1238,
        "type": "Programming_language",
        "value": "Shell"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/yuhuan-wu/JCS/main/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "requirements": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Requirements",
        "parent_header": [
          "COVID-CS dataset and JCS model",
          "Method"
        ],
        "type": "Text_excerpt",
        "value": "A computer that should have **PyTorch >= 0.4.1 and CUDA**\n\nIt should have no big differences running on PyTorch 0.4.1 ~ 1.7.\n"
      },
      "source": "https://raw.githubusercontent.com/yuhuan-wu/JCS/main/README.md",
      "technique": "header_analysis"
    }
  ],
  "somef_missing_categories": [
    "acknowledgement",
    "run",
    "download",
    "contact",
    "contributors",
    "documentation",
    "license",
    "usage",
    "faq",
    "support",
    "identifier",
    "has_build_file",
    "executable_example"
  ],
  "somef_provenance": {
    "date": "2024-10-06 09:22:30",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 48
      },
      "technique": "GitHub_API"
    }
  ]
}