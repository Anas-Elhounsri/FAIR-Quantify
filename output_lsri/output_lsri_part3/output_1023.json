{
  "application_domain": [
    {
      "confidence": 14.76,
      "result": {
        "type": "String",
        "value": "Computer Vision"
      },
      "technique": "supervised_classification"
    }
  ],
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/MeHelmy/princess"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2019-04-07T15:41:52Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2024-05-06T13:48:08Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 0.9507358255854118,
      "result": {
        "original_header": "What is new?",
        "type": "Text_excerpt",
        "value": "- Clair3 for calling single nucleotide polymorphisms (SNPs) and insertions/deletions (Indels)\n  - Ability to use different models than the default one that comes with Clair3, which can be helpful in cases where there is new kit/training dataset or when working with data other than the human genome.\n- Sniffles2 for detecting structural variants (SVs)\n- Generation of a gVCF file for cohort analysis\n- Generation of an SNF file for cohort structural variant analysis\n- The pipeline has been fully tested on both PBS and Slurm systems with easy configuration\n- The main conda environment has been updated for improved granularity.\n--- \nPrincess is a fast and scalable framework to detect and report haplotype resolved Single Nucleotide Variants (SNV) and Structural Variations (SVs) at scale. It can leverage your cluster environment to speed up the detection which starts with one or many fasta or fastq files.\nPublication: https://genomebiology.biomedcentral.com/articles/10.1186/s13059-021-02486-w    \n* __Mapping__:   Minimap2 or NGMLR\n* __SNVs__: Clair3 \n* __SVs__: Sniffles2\n* __Phasing SNVs__: WhatsHap\n* __Phasing SVs__: Sniffles2\n* __Extend Phasing__: PRINCESS-subtool\n* __Phased Methylation__: Nanopolish + PRINCESS-subtool\n* __QC Statistics__ for each step \n"
      },
      "source": "https://raw.githubusercontent.com/MeHelmy/princess/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9784059364476212,
      "result": {
        "original_header": "Test case",
        "type": "Text_excerpt",
        "value": "We uploaded a HiFi compressed data file from the publicly available HG002 data set.\nThe complete data set (High-fidelity 15kb long-read dataset of HG002, Ashkenazim Son.) is available [Here](https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/AshkenazimTrio/HG002_NA24385_son/PacBio_CCS_15kb/) \n"
      },
      "source": "https://raw.githubusercontent.com/MeHelmy/princess/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.927708640679904,
      "result": {
        "original_header": "Converting from PBS to Slurm",
        "type": "Text_excerpt",
        "value": "1- Please ensure that you modify the `cluster/cluster_config.yaml` to specify the appropriate long-running node. For example, you can set the long queue system as follows:\n    `long: &long_queue long_queue` \n    Where long_queue is the queue system that can run for a long time. Similarly, you can set the short queue in the following way:\n    `short: &short_queue short_queue`, . Please refer to your cluster system administrator for more details.  \n2- Please, ensure that you changed `cluster/config.yaml` from `cluster-status: \"pbs_status.py\"` to `cluster-status: \"slurm_status.py\"`  \n3- In the `cluster/key_mapping.yaml` file. Please, change `system: \"pbs\"` to `system: \"slurm\"`  \n4- Finally, in the `cluster/cluster_config.yaml` file, I set CPU and memory to each job to suit my cluster.  \nE.g.\n```\nminimap2:\n  queue: *long_queue\n  time: \"72:00:00\"\n  nCPUs: \"12\"\n  mem: 20G\n```\nHere, I am using 12 CPUs, 20G memory, and the job running time is \"72:00:00\" maximum (three days.). You may need to use a different configuration based on the resources availability in your cluster. Please, refer to your system administrator for more details. \n"
      },
      "source": "https://raw.githubusercontent.com/MeHelmy/princess/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "documentation": [
    {
      "confidence": 1,
      "result": {
        "format": "wiki",
        "type": "Url",
        "value": "https://github.com/MeHelmy/princess/wiki"
      },
      "source": "https://raw.githubusercontent.com/MeHelmy/princess/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/MeHelmy/princess/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 9
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/MeHelmy/princess/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "MeHelmy/princess"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "Princess"
      },
      "source": "https://raw.githubusercontent.com/MeHelmy/princess/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "installation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Installation",
        "parent_header": [
          "Princess"
        ],
        "type": "Text_excerpt",
        "value": "Princess was tested on CentOS release 6.7, Conda version 4.7.12 is installed:\nfor more information about [Installing Conda press here](https://bioconda.github.io/user/install.html#install-conda, \"Install Conda\")\nTo download same Conda version [here](https://repo.continuum.io/miniconda/Miniconda3-4.7.12-Linux-x86_64.sh \"Conda 4.7.12\")*\n\n1. After conda is installed. Snakemake should be installed and yaml\n~~~\nconda install snakemake=5.7.1\nconda install pyyaml\n~~~\n2. Downloading PRINCESS  \n~~~\ngit clone https://github.com/MeHelmy/princess.git\n~~~\n\n---\n"
      },
      "source": "https://raw.githubusercontent.com/MeHelmy/princess/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 0.9999999965237976,
      "result": {
        "original_header": "Test case",
        "type": "Text_excerpt",
        "value": "To download the test data run the following command:\n```\nwget https://bcm.box.com/shared/static/sdml5d7csxprgu3cl5cve0lgv5jnrrlv --output-document  HiFi.fastq.gz\n```\nAfter download is finished you shall have a HiFi fastq file called `HiFi.fastq.gz`, to run the analysis test run the following command:\nBASH2*\nall:           The command to run full analysis for other options please run `princess -h`  \n---directory:  The out put directory it could be any name, use the full path, in my case the output is  same place.  \n--ReadType:    Read type, the supported read types are clr, ccs, and ont.  \n--ref:         Path to the reference please use samtools faidx with refernce before running Princess.  \n--jobs:        Number of running jobs on cluster.  \n--sampleFiles: Sample fastq file we downloaded, it could be more than one either compressed or not.  \n--latency-wait 200 -p:  These are additional Snakemake option to wait 200 seconds before collecting output.   \n"
      },
      "source": "https://raw.githubusercontent.com/MeHelmy/princess/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9753422970053989,
      "result": {
        "original_header": "Collect benchmark Statistics",
        "type": "Text_excerpt",
        "value": "```\ncd benchmark  # There is a directory benchmark contains all the analyses that were done by PRINCESS\nfind \"$PWD\" -type f | grep -v \"myBenchMark.txt\" > myBenchMark.txt\nwhile read -r line; do n=$(echo  $line | awk  -v FS=/ '{print $(NF-1)\"-\"$(NF)}');  awk -v f=$line -v o=$n 'NR!=1 {print o\"\\t\"$(NF)}' $line  ;done < myBenchMark.txt\n```  \n- meth    contains methylation info (if user choose to run methylation)  \n"
      },
      "source": "https://raw.githubusercontent.com/MeHelmy/princess/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8675416209599439,
      "result": {
        "original_header": "Converting from PBS to Slurm",
        "type": "Text_excerpt",
        "value": "1- Please ensure that you modify the `cluster/cluster_config.yaml` to specify the appropriate long-running node. For example, you can set the long queue system as follows:\n    `long: &long_queue long_queue` \n    Where long_queue is the queue system that can run for a long time. Similarly, you can set the short queue in the following way:\n    `short: &short_queue short_queue`, . Please refer to your cluster system administrator for more details.  \n2- Please, ensure that you changed `cluster/config.yaml` from `cluster-status: \"pbs_status.py\"` to `cluster-status: \"slurm_status.py\"`  \n3- In the `cluster/key_mapping.yaml` file. Please, change `system: \"pbs\"` to `system: \"slurm\"`  \n4- Finally, in the `cluster/cluster_config.yaml` file, I set CPU and memory to each job to suit my cluster.  \nE.g.\n```\nminimap2:\n  queue: *long_queue\n  time: \"72:00:00\"\n  nCPUs: \"12\"\n  mem: 20G\n```\nHere, I am using 12 CPUs, 20G memory, and the job running time is \"72:00:00\" maximum (three days.). You may need to use a different configuration based on the resources availability in your cluster. Please, refer to your system administrator for more details. \n"
      },
      "source": "https://raw.githubusercontent.com/MeHelmy/princess/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "invocation": [
    {
      "confidence": 0.8352067320489036,
      "result": {
        "original_header": "Test case",
        "type": "Text_excerpt",
        "value": "To download the test data run the following command:\n```\nwget https://bcm.box.com/shared/static/sdml5d7csxprgu3cl5cve0lgv5jnrrlv --output-document  HiFi.fastq.gz\n```\nAfter download is finished you shall have a HiFi fastq file called `HiFi.fastq.gz`, to run the analysis test run the following command:\nBASH2*\nall:           The command to run full analysis for other options please run `princess -h`  \n---directory:  The out put directory it could be any name, use the full path, in my case the output is  same place.  \n--ReadType:    Read type, the supported read types are clr, ccs, and ont.  \n--ref:         Path to the reference please use samtools faidx with refernce before running Princess.  \n--jobs:        Number of running jobs on cluster.  \n--sampleFiles: Sample fastq file we downloaded, it could be more than one either compressed or not.  \n--latency-wait 200 -p:  These are additional Snakemake option to wait 200 seconds before collecting output.   \n"
      },
      "source": "https://raw.githubusercontent.com/MeHelmy/princess/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8581191125585247,
      "result": {
        "original_header": "Collect benchmark Statistics",
        "type": "Text_excerpt",
        "value": "```\ncd benchmark  # There is a directory benchmark contains all the analyses that were done by PRINCESS\nfind \"$PWD\" -type f | grep -v \"myBenchMark.txt\" > myBenchMark.txt\nwhile read -r line; do n=$(echo  $line | awk  -v FS=/ '{print $(NF-1)\"-\"$(NF)}');  awk -v f=$line -v o=$n 'NR!=1 {print o\"\\t\"$(NF)}' $line  ;done < myBenchMark.txt\n```  \n- meth    contains methylation info (if user choose to run methylation)  \n"
      },
      "source": "https://raw.githubusercontent.com/MeHelmy/princess/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/MeHelmy/princess/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "long-reads, methylation, phasing, single-nucleotide-variation, structural-variation"
      },
      "technique": "GitHub_API"
    }
  ],
  "license": [
    {
      "confidence": 1,
      "result": {
        "name": "MIT License",
        "spdx_id": "MIT",
        "type": "License",
        "url": "https://api.github.com/licenses/mit",
        "value": "https://api.github.com/licenses/mit"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "type": "File_dump",
        "value": "MIT License\n\nCopyright (c) 2022 Medhat\n=======\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
      },
      "source": "https://raw.githubusercontent.com/MeHelmy/princess/master/LICENSE",
      "technique": "file_exploration"
    }
  ],
  "logo": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/MeHelmy/princess/master/./pictures/leia.jpg"
      },
      "source": "https://raw.githubusercontent.com/MeHelmy/princess/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "princess"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "User",
        "value": "MeHelmy"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 148287,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/MeHelmy/princess/master/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "releases": [
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "MeHelmy",
          "type": "User"
        },
        "date_created": "2021-07-12T17:17:25Z",
        "date_published": "2021-08-26T18:03:29Z",
        "description": "PRINCESS is a structured workflow that takes raw sequence reads and generates a fully phased SNV, SV, and methylation call set within a few hours. PRINCESS achieves high accuracy and long phasing even on low coverage datasets and can resolve repetitive, complex medical relevant genes that often escape detection. ",
        "html_url": "https://github.com/MeHelmy/princess/releases/tag/v1.0",
        "name": "v1.0",
        "release_id": 48520618,
        "tag": "v1.0",
        "tarball_url": "https://api.github.com/repos/MeHelmy/princess/tarball/v1.0",
        "type": "Release",
        "url": "https://api.github.com/repos/MeHelmy/princess/releases/48520618",
        "value": "https://api.github.com/repos/MeHelmy/princess/releases/48520618",
        "zipball_url": "https://api.github.com/repos/MeHelmy/princess/zipball/v1.0"
      },
      "technique": "GitHub_API"
    }
  ],
  "somef_missing_categories": [
    "citation",
    "acknowledgement",
    "run",
    "download",
    "requirements",
    "contact",
    "contributors",
    "faq",
    "support",
    "identifier",
    "has_build_file",
    "executable_example"
  ],
  "somef_provenance": {
    "date": "2024-10-06 03:13:13",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 79
      },
      "technique": "GitHub_API"
    }
  ],
  "type": [
    {
      "confidence": 0.82,
      "result": {
        "type": "String",
        "value": "commandline-application"
      },
      "technique": "software_type_heuristics"
    }
  ],
  "usage": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Tutorial",
        "parent_header": [
          "Princess"
        ],
        "type": "Text_excerpt",
        "value": "To have an overview about princess write command `princess -h`.\nYou will have the following list of commands that we can use in princess.\n\n~~~\nusage: princess [-h] {all,align,sv,snv,variant,phase,overview} ...\n\nPrincess A framework for long-reads analysis.\n\noptional arguments:\n  -h, --help            show this help message and exit\n\nSub-commands:\n  Valid sub-commands\n\n  {all,align,sv,snv,variant,phase,overview}\n    all                 This command will run the following: Align the reads.\n                        Identify SVs Identify SNVs Phase both SNVs and SVs\n    align               This command will use the input sequence files and\n                        align them against the reference using either Minimap2\n                        or NGMLR use -a to choose aligner otherwise Minimap2\n                        will be used by default.\n    sv                  This command will use bam file to identify SV using\n                        Sniffles.\n    snv                 This command will use bam file to identify SNVs using\n                        Clair3.\n    variant             This command will use bam file to identify SVs and\n                        SNVs.\n    phase               This command will use use reads to identify SNVs by\n                        Clair and Phase them.\n    overview            This command will show what steps will run.\n\nprincess version 0.01. use command -h for info.\n~~~\n\n\nAssume that we want only to run `snv` command, to know more about its option:\n\n`princess snv -h`\n\n\n~~~\nusage: princess snv [-h] [-v] -d Working directory -r {ont,clr,ccs} [-l] [-u]\n                    [-e] [-a {minimap,ngmlr}]\n                    [-s sampleFiles [sampleFiles ...]] -f REF [-j JOBS]\n                    [-g LOG_FILE] [-c CHRS [CHRS ...]] [-t]\n\noptional arguments:\n  -h, --help            show this help message and exit\n  -v, --version         show program's version number and exit\n  -d Working directory, --directory Working directory\n                        Working directory.\n  -r {ont,clr,ccs}, --ReadType {ont,clr,ccs}\n                        Read technology (Note: clr is not supported anymore by clair3)\n  -l, --removeFiles     remove princess source script after running default:\n                        False)\n  -u, --UseConda        Use conda for running default: True)\n  -e, --Cluster         Use cluster while running default: True)\n  -a {minimap,ngmlr}, --Aligner {minimap,ngmlr}\n                        In case if you want to choose specific aligner\n                        otherwise default will be used default: minimap)\n  -s sampleFiles [sampleFiles ...], --sampleFiles sampleFiles [sampleFiles ...]\n                        list of fatsa, fastq, or gz files.\n  -f REF, --ref REF     The reference file will be used to align reads to.\n  -j JOBS, --jobs JOBS  Number of running jobs default: 200 )\n  -g LOG_FILE, --log LOG_FILE\n                        Log file: PrincessLog.txt )\n  -c CHRS [CHRS ...], --chr CHRS [CHRS ...]\n                        Chromosomes list, if not specified we will use all\n                        Chromosomes.\n  -t, --filter          Filter identified SNVs using Princess algorithm\n                        default: True)\n~~~\n\n\n~~~\nprincess all  -d ./princess_all -r ont -s reads.split00.fastq.gz reads.split01.fastq.gz  -f hs37d5_mainchr.fa\n~~~\n\n`-r` defines the reads type.  \n`-s` samples that we would like to analyze.  \n`-f` **full path** to the reference.  \n\n*__Note__*  \nI am assuming that the reference file is indexed, if not please use the following command.  \n`samtools faidx hs37d5_mainchr.fa` as a result you will have `hs37d5_mainchr.fa.fai`.\n\nDone!!\n"
      },
      "source": "https://raw.githubusercontent.com/MeHelmy/princess/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "For methylation calling.",
        "parent_header": [
          "Princess",
          "Tutorial"
        ],
        "type": "Text_excerpt",
        "value": "Methylation calling is a part from the `all` option.\n\n```\noptional arguments:\n  -h, --help            show this help message and exit\n  -v, --version         show program's version number and exit\n  -d Working directory, --directory Working directory\n                        Working directory.\n  -r {ont,clr,ccs}, --ReadType {ont,clr,ccs}\n                        Read technology\n  -l, --removeFiles     remove princess source script after running default: False)\n  -u, --UseConda        Use conda for running default: True)\n  -e, --Cluster         Use cluster while running default: True)\n  -a {minimap,ngmlr}, --Aligner {minimap,ngmlr}\n                        In case if you want to choose specific aligner otherwise default will be used default: minimap)\n  -s sampleFiles [sampleFiles ...], --sampleFiles sampleFiles [sampleFiles ...]\n                        list of fatsa, fastq, or gz files.\n  -f REF, --ref REF     The reference file will be used to align reads to.\n  -j JOBS, --jobs JOBS  Number of running jobs default: 200 )\n  -g LOG_FILE, --log LOG_FILE\n                        Log file: PrincessLog.txt )\n  -c CHRS [CHRS ...], --chr CHRS [CHRS ...]\n                        Chromosomes list, if not specified we will use all Chromosomes.\n  -t, --filter          Filter identified SNVs using Princess algorithm default: True)\n  -m, --methylation     Identify methylation, mutually inclusive with -md default: False)\n  -md Fast5 Directory, --methylationDirectory Fast5 Directory\n                        Fast5 directory will be used to identify methylation mutually inclusive with option -m default: False)\n```\nBy choosing the flag __`--methylation`__, Princess will call the methylation on the input data (ONT data), this option is inclusive with the option __`--methylationDirectory`__ which requires the fasta5 directory.\n"
      },
      "source": "https://raw.githubusercontent.com/MeHelmy/princess/master/README.md",
      "technique": "header_analysis"
    }
  ]
}