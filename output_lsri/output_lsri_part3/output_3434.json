{
  "citation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Citation",
        "parent_header": [
          "MetaBCC-LR: Metagenomics Binning by Coverage and Composition for Long Reads"
        ],
        "type": "Text_excerpt",
        "value": "```bibtex\n@article{10.1093/bioinformatics/btaa441,\n    author = {Wickramarachchi, Anuradha and Mallawaarachchi, Vijini and Rajan, Vaibhav and Lin, Yu},\n    title = \"{MetaBCC-LR: metagenomics binning by coverage and composition for long reads}\",\n    journal = {Bioinformatics},\n    volume = {36},\n    number = {Supplement_1},\n    pages = {i3-i11},\n    year = {2020},\n    month = {07},\n    abstract = \"{Metagenomics studies have provided key insights into the composition and structure of microbial communities found in different environments. Among the techniques used to analyse metagenomic data, binning is considered a crucial step to characterize the different species of micro-organisms present. The use of short-read data in most binning tools poses several limitations, such as insufficient species-specific signal, and the emergence of long-read sequencing technologies offers us opportunities to surmount them. However, most current metagenomic binning tools have been developed for short reads. The few tools that can process long reads either do not scale with increasing input size or require a database with reference genomes that are often unknown. In this article, we present MetaBCC-LR, a scalable reference-free binning method which clusters long reads directly based on their k-mer coverage histograms and oligonucleotide composition.We evaluate MetaBCC-LR on multiple simulated and real metagenomic long-read datasets with varying coverages and error rates. Our experiments demonstrate that MetaBCC-LR substantially outperforms state-of-the-art reference-free binning tools, achieving \u223c13\\\\% improvement in F1-score and \u223c30\\\\% improvement in ARI compared to the best previous tools. Moreover, we show that using MetaBCC-LR before long-read assembly helps to enhance the assembly quality while significantly reducing the assembly cost in terms of time and memory usage. The efficiency and accuracy of MetaBCC-LR pave the way for more effective long-read-based metagenomics analyses to support a wide range of applications.The source code is freely available at: https://github.com/anuradhawick/MetaBCC-LR.Supplementary data are available at Bioinformatics online.}\",\n    issn = {1367-4803},\n    doi = {10.1093/bioinformatics/btaa441},\n    url = {https://doi.org/10.1093/bioinformatics/btaa441},\n    eprint = {https://academic.oup.com/bioinformatics/article-pdf/36/Supplement\\_1/i3/33488763/btaa441.pdf},\n}\n```\n"
      },
      "source": "https://raw.githubusercontent.com/anuradhawick/MetaBCC-LR/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "author": "Wickramarachchi, Anuradha and Mallawaarachchi, Vijini and Rajan, Vaibhav and Lin, Yu",
        "doi": "10.1093/bioinformatics/btaa441",
        "format": "bibtex",
        "title": "{MetaBCC-LR: metagenomics binning by coverage and composition for long reads}",
        "type": "Text_excerpt",
        "url": "https://doi.org/10.1093/bioinformatics/btaa441",
        "value": "@article{10.1093/bioinformatics/btaa441,\n    eprint = {https://academic.oup.com/bioinformatics/article-pdf/36/Supplement\\_1/i3/33488763/btaa441.pdf},\n    url = {https://doi.org/10.1093/bioinformatics/btaa441},\n    doi = {10.1093/bioinformatics/btaa441},\n    issn = {1367-4803},\n    abstract = {{Metagenomics studies have provided key insights into the composition and structure of microbial communities found in different environments. Among the techniques used to analyse metagenomic data, binning is considered a crucial step to characterize the different species of micro-organisms present. The use of short-read data in most binning tools poses several limitations, such as insufficient species-specific signal, and the emergence of long-read sequencing technologies offers us opportunities to surmount them. However, most current metagenomic binning tools have been developed for short reads. The few tools that can process long reads either do not scale with increasing input size or require a database with reference genomes that are often unknown. In this article, we present MetaBCC-LR, a scalable reference-free binning method which clusters long reads directly based on their k-mer coverage histograms and oligonucleotide composition.We evaluate MetaBCC-LR on multiple simulated and real metagenomic long-read datasets with varying coverages and error rates. Our experiments demonstrate that MetaBCC-LR substantially outperforms state-of-the-art reference-free binning tools, achieving \u223c13\\\\% improvement in F1-score and \u223c30\\\\% improvement in ARI compared to the best previous tools. Moreover, we show that using MetaBCC-LR before long-read assembly helps to enhance the assembly quality while significantly reducing the assembly cost in terms of time and memory usage. The efficiency and accuracy of MetaBCC-LR pave the way for more effective long-read-based metagenomics analyses to support a wide range of applications.The source code is freely available at: https://github.com/anuradhawick/MetaBCC-LR.Supplementary data are available at Bioinformatics online.}},\n    month = {07},\n    year = {2020},\n    pages = {i3-i11},\n    number = {Supplement_1},\n    volume = {36},\n    journal = {Bioinformatics},\n    title = {{MetaBCC-LR: metagenomics binning by coverage and composition for long reads}},\n    author = {Wickramarachchi, Anuradha and Mallawaarachchi, Vijini and Rajan, Vaibhav and Lin, Yu},\n}"
      },
      "source": "https://raw.githubusercontent.com/anuradhawick/MetaBCC-LR/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/anuradhawick/MetaBCC-LR"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2019-10-21T04:11:29Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2024-09-10T02:17:38Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "Reference-free Binning of Metagenomics Long Reads using Coverage and Composition"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 0.9814474010172147,
      "result": {
        "original_header": "New in v-2.X",
        "type": "Text_excerpt",
        "value": "* No need to have DSK, we have implemented a consice k-mer counting strategy using compare and swap (CAS).\n* Supports UMAP and SONG embeddings. Please note that UMAP and SONG are still being improved. Needs more work from our side. But usable!\n* Supports any input format **fasta, fastq** or **gzipped** formats of either. (Thanks for Klib by Attractive Chaos [blog](http://attractivechaos.github.io/klib/))\n \n"
      },
      "source": "https://raw.githubusercontent.com/anuradhawick/MetaBCC-LR/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "download": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Downloading MetaBCC-LR",
        "parent_header": [
          "MetaBCC-LR: Metagenomics Binning by Coverage and Composition for Long Reads"
        ],
        "type": "Text_excerpt",
        "value": "To download MetaBCC-LR, you have to clone the MetaBCC-LR repository to your machine.\n\n```\ngit clone https://github.com/anuradhawick/MetaBCC-LR.git\n```\n"
      },
      "source": "https://raw.githubusercontent.com/anuradhawick/MetaBCC-LR/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/anuradhawick/MetaBCC-LR/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 0
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/anuradhawick/MetaBCC-LR/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "anuradhawick/MetaBCC-LR"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "MetaBCC-LR: Metagenomics Binning by Coverage and Composition for Long Reads"
      },
      "source": "https://raw.githubusercontent.com/anuradhawick/MetaBCC-LR/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "has_script_file": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/anuradhawick/MetaBCC-LR/master/build.sh"
      },
      "technique": "file_exploration"
    }
  ],
  "installation": [
    {
      "confidence": 0.9999999997560849,
      "result": {
        "original_header": "Update",
        "type": "Text_excerpt",
        "value": "Program can be built and installed with `sh build` and `pip install .` \nWe recommend using `sh build` and using the program without installing. Thus making it easier to fetch future upadates and run.\n \n"
      },
      "source": "https://raw.githubusercontent.com/anuradhawick/MetaBCC-LR/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/anuradhawick/MetaBCC-LR/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "binning, c-plus-plus, genomics, long-reads, metagenomics, python"
      },
      "technique": "GitHub_API"
    }
  ],
  "license": [
    {
      "confidence": 1,
      "result": {
        "name": "MIT License",
        "spdx_id": "MIT",
        "type": "License",
        "url": "https://api.github.com/licenses/mit",
        "value": "https://api.github.com/licenses/mit"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "type": "File_dump",
        "value": "MIT License\n\nCopyright (c) 2022 Anuradha Wickramarachchi\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
      },
      "source": "https://raw.githubusercontent.com/anuradhawick/MetaBCC-LR/master/LICENSE",
      "technique": "file_exploration"
    }
  ],
  "logo": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/anuradhawick/MetaBCC-LR/master/MetaBCC-LR_logo.png"
      },
      "source": "https://raw.githubusercontent.com/anuradhawick/MetaBCC-LR/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "MetaBCC-LR"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "User",
        "value": "anuradhawick"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 33876,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "C++",
        "size": 29659,
        "type": "Programming_language",
        "value": "C++"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "C",
        "size": 9118,
        "type": "Programming_language",
        "value": "C"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Shell",
        "size": 1912,
        "type": "Programming_language",
        "value": "Shell"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/anuradhawick/MetaBCC-LR/master/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "releases": [
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "anuradhawick",
          "type": "User"
        },
        "date_created": "2021-05-23T07:36:36Z",
        "date_published": "2021-05-23T07:42:17Z",
        "description": "Updates\r\n* Supports all read input types FASTA, FASTQ, GZIPPED, etc using klib/kseq.h\r\n* Supports TSNE, UMAP and SONG embeddings for faster clustering\r\n* Script to separate reads to bins available.\r\nBug fixes\r\n* Fixed not creation of sub folders when restarted\r\n* Improved resume capability\r\n",
        "html_url": "https://github.com/anuradhawick/MetaBCC-LR/releases/tag/v2.0.0",
        "name": "Major update! New embeddings and faster!",
        "release_id": 43423644,
        "tag": "v2.0.0",
        "tarball_url": "https://api.github.com/repos/anuradhawick/MetaBCC-LR/tarball/v2.0.0",
        "type": "Release",
        "url": "https://api.github.com/repos/anuradhawick/MetaBCC-LR/releases/43423644",
        "value": "https://api.github.com/repos/anuradhawick/MetaBCC-LR/releases/43423644",
        "zipball_url": "https://api.github.com/repos/anuradhawick/MetaBCC-LR/zipball/v2.0.0"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "anuradhawick",
          "type": "User"
        },
        "date_created": "2020-08-24T08:43:15Z",
        "date_published": "2020-08-24T08:44:51Z",
        "description": "This is the first official release of the program\r\n* Please raise issues at anuradha.wickramarachchi@anu.edu.au OR in the Issues section",
        "html_url": "https://github.com/anuradhawick/MetaBCC-LR/releases/tag/v1.0.0",
        "name": "MetaBCC-LR v-1.0.0",
        "release_id": 30042675,
        "tag": "v1.0.0",
        "tarball_url": "https://api.github.com/repos/anuradhawick/MetaBCC-LR/tarball/v1.0.0",
        "type": "Release",
        "url": "https://api.github.com/repos/anuradhawick/MetaBCC-LR/releases/30042675",
        "value": "https://api.github.com/repos/anuradhawick/MetaBCC-LR/releases/30042675",
        "zipball_url": "https://api.github.com/repos/anuradhawick/MetaBCC-LR/zipball/v1.0.0"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "anuradhawick",
          "type": "User"
        },
        "date_created": "2020-02-19T06:22:17Z",
        "date_published": "2020-02-19T06:33:20Z",
        "description": "## Resume Capabilities\r\n\r\nPreviously users had to re-run the tool from the beginning if they had to change sampled count or the sensitivity. I consumes a significant time thus it is cumbersome. With the latest update resuming can be done with a different number of sampled reads. This makes the analysis much easier.\r\n\r\n## Other improvements\r\n\r\n* Sensitivity figure is now labelled from 1 - 10 as 1 being the lowest and 10 being the highest. Previously it was the other way around. Now it is straight forward.\r\n* No bins will be discarded no matter how small they are. This enables the recovery of smaller bins for downstream analysis.\r\n\r\n*Please note that this is a pre-release. Thank you!*\r\n\r\nSuggestions and bug reports are welcome. Cheers!",
        "html_url": "https://github.com/anuradhawick/MetaBCC-LR/releases/tag/v-0.2",
        "name": "Resume capabilities",
        "release_id": 23792335,
        "tag": "v-0.2",
        "tarball_url": "https://api.github.com/repos/anuradhawick/MetaBCC-LR/tarball/v-0.2",
        "type": "Release",
        "url": "https://api.github.com/repos/anuradhawick/MetaBCC-LR/releases/23792335",
        "value": "https://api.github.com/repos/anuradhawick/MetaBCC-LR/releases/23792335",
        "zipball_url": "https://api.github.com/repos/anuradhawick/MetaBCC-LR/zipball/v-0.2"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "anuradhawick",
          "type": "User"
        },
        "date_created": "2020-01-09T01:03:34Z",
        "date_published": "2020-01-09T01:05:37Z",
        "description": "Preliminary release",
        "html_url": "https://github.com/anuradhawick/MetaBCC-LR/releases/tag/v-0.1",
        "name": "MetaBCC-LR-v-0.1",
        "release_id": 22696761,
        "tag": "v-0.1",
        "tarball_url": "https://api.github.com/repos/anuradhawick/MetaBCC-LR/tarball/v-0.1",
        "type": "Release",
        "url": "https://api.github.com/repos/anuradhawick/MetaBCC-LR/releases/22696761",
        "value": "https://api.github.com/repos/anuradhawick/MetaBCC-LR/releases/22696761",
        "zipball_url": "https://api.github.com/repos/anuradhawick/MetaBCC-LR/zipball/v-0.1"
      },
      "technique": "GitHub_API"
    }
  ],
  "requirements": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Dependencies",
        "parent_header": [
          "MetaBCC-LR: Metagenomics Binning by Coverage and Composition for Long Reads"
        ],
        "type": "Text_excerpt",
        "value": "MetaBCC-LR is coded purely using C++ (v9) and Python 3.6. To run MetaBCC-LR, you will need to install the following python and C++ modules.\n"
      },
      "source": "https://raw.githubusercontent.com/anuradhawick/MetaBCC-LR/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Python dependencies",
        "parent_header": [
          "MetaBCC-LR: Metagenomics Binning by Coverage and Composition for Long Reads",
          "Dependencies"
        ],
        "type": "Text_excerpt",
        "value": "* numpy 1.16.4 \n* scipy 1.3.0 \n* kneed 0.4.2\n* seaborn 0.9.0\n* h5py 2.9.0\n* tabulate 0.8.7\n* umap-learn 0.5.1\n* song-vis (latest version from github)\n"
      },
      "source": "https://raw.githubusercontent.com/anuradhawick/MetaBCC-LR/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "C++ requirements",
        "parent_header": [
          "MetaBCC-LR: Metagenomics Binning by Coverage and Composition for Long Reads",
          "Dependencies"
        ],
        "type": "Text_excerpt",
        "value": "* GCC version 9.1.0\n* OpenMP 4.5 for multi processing\n* PThreads (any version should work)\n\n\n"
      },
      "source": "https://raw.githubusercontent.com/anuradhawick/MetaBCC-LR/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "run": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Test run data",
        "parent_header": [
          "MetaBCC-LR: Metagenomics Binning by Coverage and Composition for Long Reads",
          "Running the MetaBCC-LR"
        ],
        "type": "Text_excerpt",
        "value": "Extract test data from [here](https://anu365-my.sharepoint.com/:f:/g/personal/u6776114_anu_edu_au/EnV-rUq01pRHl1lH4Y8SaSwBwVVMKNAptbA6YW8RWX6Pqw?e=tDgy9v);\n\nIn order to run MetaBCC-LR you are required to provide the reads in FASTQ or FASTA format.\n\n```\npython mbcclr --resume -r test_data/data/reads.fasta -g test_data/data/ids.txt -o test_output -e umap -c 25000 -bs 10 -bc 10 -k 4\n```\n"
      },
      "source": "https://raw.githubusercontent.com/anuradhawick/MetaBCC-LR/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Separate reads into Bins",
        "parent_header": [
          "MetaBCC-LR: Metagenomics Binning by Coverage and Composition for Long Reads",
          "Running the MetaBCC-LR"
        ],
        "type": "Text_excerpt",
        "value": "You can use the script `reads2bins.py` to separate reads into bins. This is included in a separate script as you might want to play around with clustering sensitivity and sampling reads count to get a good final binning. You can look into images generated in `Output/images` directory to see if you have a good clustering of reads. Finally you can use the script `reads2bins.py` to separate reads.\n\nInputs:\n* -r path to reads file used for binning\n* -b output/final.txt (the file containing bin of each read)\n* -o a destination directory to place final fasta files\n\n```\nusage: reads2bins.py [-h] --reads READS --bins BINS --output OUTPUT\n\nSeparate reads in to bins.\n\noptional arguments:\n  -h, --help            show this help message and exit\n  --reads READS, -r READS\n  --bins BINS, -b BINS\n  --output OUTPUT, -o OUTPUT\n```\n"
      },
      "source": "https://raw.githubusercontent.com/anuradhawick/MetaBCC-LR/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "somef_missing_categories": [
    "acknowledgement",
    "contact",
    "contributors",
    "documentation",
    "faq",
    "identifier",
    "has_build_file",
    "executable_example"
  ],
  "somef_provenance": {
    "date": "2024-10-06 12:45:41",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 19
      },
      "technique": "GitHub_API"
    }
  ],
  "support": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Usage and Help",
        "parent_header": [
          "MetaBCC-LR: Metagenomics Binning by Coverage and Composition for Long Reads",
          "Running the MetaBCC-LR"
        ],
        "type": "Text_excerpt",
        "value": "```\ncd MetaBCC-LR\n./mbcclr -h\n\nusage: mbcclr [-h] --reads-path READS_PATH [--embedding {tsne,umap,song}]\n              [--k-size {3,4,5,6,7}] [--sample-count SAMPLE_COUNT]\n              [--sensitivity SENSITIVITY] [--bin-size BIN_SIZE]\n              [--bin-count BIN_COUNT] [--threads THREADS]\n              [--ground-truth GROUND_TRUTH] [--resume] --output OUTPUT\n              [--version]\n\nMetaBCC-LR Help. A tool developed for binning of metagenomics long reads\n(PacBio/ONT). Tool utilizes composition and coverage profiles of reads based\non k-mer frequencies to perform dimension reduction. dimension reduced reads\nare then clustered using DB-SCAN. Minimum RAM requirement is 9GB.\n\noptional arguments:\n  -h, --help            show this help message and exit\n  --reads-path READS_PATH, -r READS_PATH\n                        Reads path for binning\n  --embedding {tsne,umap,song}, -e {tsne,umap,song}\n                        Embedding tool to be used for clustering\n  --k-size {3,4,5,6,7}, -k {3,4,5,6,7}\n                        Choice of k-mer for oligonucleotide frequency vector.\n  --sample-count SAMPLE_COUNT, -c SAMPLE_COUNT\n                        Number of reads to sample in order to determine the\n                        number of bins. Set to 1% of reads by default.\n                        Changing this parameter will affect whether low\n                        coverage species are separated or not.\n  --sensitivity SENSITIVITY, -s SENSITIVITY\n                        Value between 1 and 10, Higher helps recovering low\n                        abundant species (No. of species > 100)\n  --bin-size BIN_SIZE, -bs BIN_SIZE\n                        Size of each bin in coverage histogram.\n  --bin-count BIN_COUNT, -bc BIN_COUNT\n                        Number of bins in the coverage histogram.\n  --threads THREADS, -t THREADS\n                        Thread count for computation\n  --ground-truth GROUND_TRUTH, -g GROUND_TRUTH\n                        Ground truth of reads for dry runs and sensitivity\n                        tuning\n  --resume              Continue from the last step or the binning step (which\n                        ever comes first). Can save time needed to run DSK and\n                        obtain k-mers. Ideal for sensitivity tuning\n  --output OUTPUT, -o OUTPUT\n                        Output directory\n  --version, -v         Show version.\n```\n\n* Output path is the foldername that you wish the results to be in.\n* Specify the number of threads\n* The program requires a minimum of 5GB to run. This is because we have optimized the coverage histogram generation process to accommodate all 15mers in RAM for faster lookup of counts.\n"
      },
      "source": "https://raw.githubusercontent.com/anuradhawick/MetaBCC-LR/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "type": [
    {
      "confidence": 0.82,
      "result": {
        "type": "String",
        "value": "commandline-application"
      },
      "technique": "software_type_heuristics"
    }
  ],
  "usage": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Usage and Help",
        "parent_header": [
          "MetaBCC-LR: Metagenomics Binning by Coverage and Composition for Long Reads",
          "Running the MetaBCC-LR"
        ],
        "type": "Text_excerpt",
        "value": "```\ncd MetaBCC-LR\n./mbcclr -h\n\nusage: mbcclr [-h] --reads-path READS_PATH [--embedding {tsne,umap,song}]\n              [--k-size {3,4,5,6,7}] [--sample-count SAMPLE_COUNT]\n              [--sensitivity SENSITIVITY] [--bin-size BIN_SIZE]\n              [--bin-count BIN_COUNT] [--threads THREADS]\n              [--ground-truth GROUND_TRUTH] [--resume] --output OUTPUT\n              [--version]\n\nMetaBCC-LR Help. A tool developed for binning of metagenomics long reads\n(PacBio/ONT). Tool utilizes composition and coverage profiles of reads based\non k-mer frequencies to perform dimension reduction. dimension reduced reads\nare then clustered using DB-SCAN. Minimum RAM requirement is 9GB.\n\noptional arguments:\n  -h, --help            show this help message and exit\n  --reads-path READS_PATH, -r READS_PATH\n                        Reads path for binning\n  --embedding {tsne,umap,song}, -e {tsne,umap,song}\n                        Embedding tool to be used for clustering\n  --k-size {3,4,5,6,7}, -k {3,4,5,6,7}\n                        Choice of k-mer for oligonucleotide frequency vector.\n  --sample-count SAMPLE_COUNT, -c SAMPLE_COUNT\n                        Number of reads to sample in order to determine the\n                        number of bins. Set to 1% of reads by default.\n                        Changing this parameter will affect whether low\n                        coverage species are separated or not.\n  --sensitivity SENSITIVITY, -s SENSITIVITY\n                        Value between 1 and 10, Higher helps recovering low\n                        abundant species (No. of species > 100)\n  --bin-size BIN_SIZE, -bs BIN_SIZE\n                        Size of each bin in coverage histogram.\n  --bin-count BIN_COUNT, -bc BIN_COUNT\n                        Number of bins in the coverage histogram.\n  --threads THREADS, -t THREADS\n                        Thread count for computation\n  --ground-truth GROUND_TRUTH, -g GROUND_TRUTH\n                        Ground truth of reads for dry runs and sensitivity\n                        tuning\n  --resume              Continue from the last step or the binning step (which\n                        ever comes first). Can save time needed to run DSK and\n                        obtain k-mers. Ideal for sensitivity tuning\n  --output OUTPUT, -o OUTPUT\n                        Output directory\n  --version, -v         Show version.\n```\n\n* Output path is the foldername that you wish the results to be in.\n* Specify the number of threads\n* The program requires a minimum of 5GB to run. This is because we have optimized the coverage histogram generation process to accommodate all 15mers in RAM for faster lookup of counts.\n"
      },
      "source": "https://raw.githubusercontent.com/anuradhawick/MetaBCC-LR/master/README.md",
      "technique": "header_analysis"
    }
  ]
}