{
  "application_domain": [
    {
      "confidence": 55.96,
      "result": {
        "type": "String",
        "value": "Reinforcement Learning"
      },
      "technique": "supervised_classification"
    }
  ],
  "citation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "References",
        "parent_header": [
          "FiMDP - Fuel in Markov Decision Processes"
        ],
        "type": "Text_excerpt",
        "value": "<a id=\"1\">[1]</a> \nBlahoudek F., Br\u00e1zdil T., Novotn\u00fd P., Ornik M., Thangeda P., Topcu U. (2020) **Qualitative Controller Synthesis for Consumption Markov Decision Processes.** In proceeding of CAV 2020. Lecture Notes in Computer Science, vol 12225. Springer. https://doi.org/10.1007/978-3-030-53291-8_22\n\n\n[FiMDP-Evaluation]: https://github.com/FiMDP/FiMDP-Evaluation\n[FiMDP readthedocs]: https://fimdp.readthedocs.io/\n[FiMDPEnv]: https://github.com/FiMDP/FiMDPEnv\n[Graphviz]: https://graphviz.org/\n[Storm]: https://www.stormchecker.org/index.html\n[Stormpy]: https://moves-rwth.github.io/stormpy/\n[Spot]: https://spot.lrde.epita.fr/\n"
      },
      "source": "https://raw.githubusercontent.com/FiMDP/FiMDP/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/FiMDP/FiMDP"
      },
      "technique": "GitHub_API"
    }
  ],
  "contact": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Contact",
        "parent_header": [
          "FiMDP - Fuel in Markov Decision Processes"
        ],
        "type": "Text_excerpt",
        "value": "If you have any trouble with the installation, or have any questions, raise an issue or email [Franti\u0161ek (Fanda) Blahoudek](fandikb+dev@gmail.com) or [Pranay Thangeda](contact@prny.me).\n"
      },
      "source": "https://raw.githubusercontent.com/FiMDP/FiMDP/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2019-10-08T16:33:59Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2024-04-17T03:32:46Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 0.9421227664115116,
      "result": {
        "original_header": "FiMDP - Fuel in Markov Decision Processes",
        "type": "Text_excerpt",
        "value": "**Python Package with Algorithms for Controller Synthesis in Resource-constrained Markov Decision Processes** \n**FiMDP** is a Python package for analysis and controller synthesis of Consumption Markov Decision Processes (ConsMDPs) \u2014 MDPs with resource constraints. The model of ConsMDPs and the basic algorithms implemented in FiMDP are described in our paper presented at CAV2020 [[1]](#1). \nOur related project called **[FiMDPEnv]** is a set of environments that work with FiMDP and can create animations like this one.\n<p align=\"center\">\n<img src=\"https://github.com/FiMDP/FiMDP/blob/master/docs/source/images/demoanimation.gif\" alt=\"Multiple agents following energy-aware policy in grid-world.\" align=\"center\" height=\"250\" width=\"350\" >\n<br>\n<em>Multiple agents following energy-aware policies in UUVEnv from <a href=\"https://github.com/FiMDP/FiMDPEnv\">FiMDPEnv</a>.  </em>\n</p>\n \n"
      },
      "source": "https://raw.githubusercontent.com/FiMDP/FiMDP/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9301754985502405,
      "result": {
        "original_header": "Evaluations",
        "type": "Text_excerpt",
        "value": "Notebooks evaluationg performance of FiMDP are stored in a separate repository \n[FiMDP-Evaluation]. \n"
      },
      "source": "https://raw.githubusercontent.com/FiMDP/FiMDP/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "documentation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Usage and documentation (work in progress)",
        "parent_header": [
          "FiMDP - Fuel in Markov Decision Processes"
        ],
        "type": "Text_excerpt",
        "value": "The directory [tut](tut/README.md) contains several notebooks that explain how to use FiMDP. The notebook [Basics.ipynb](tut/Basics.ipynb) is a good starting point.\n\nFor a complete overview of the tool, installation options, source code documentation, and interactive examples refer to [FiMDP readthedocs].\n\n"
      },
      "source": "https://raw.githubusercontent.com/FiMDP/FiMDP/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "format": "readthedocs",
        "type": "Url",
        "value": "https://fimdp.readthedocs.io/"
      },
      "source": "https://raw.githubusercontent.com/FiMDP/FiMDP/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/FiMDP/FiMDP/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "executable_example": [
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/FiMDP/FiMDP/master/tut/Solvers.ipynb"
      },
      "source": "https://raw.githubusercontent.com/FiMDP/FiMDP/master/tut/Solvers.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/FiMDP/FiMDP/master/tut/Basics.ipynb"
      },
      "source": "https://raw.githubusercontent.com/FiMDP/FiMDP/master/tut/Basics.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/FiMDP/FiMDP/master/tut/Strategies.ipynb"
      },
      "source": "https://raw.githubusercontent.com/FiMDP/FiMDP/master/tut/Strategies.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/FiMDP/FiMDP/master/tut/Labeled.ipynb"
      },
      "source": "https://raw.githubusercontent.com/FiMDP/FiMDP/master/tut/Labeled.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/FiMDP/FiMDP/master/tut/ExplicitEnergy.ipynb"
      },
      "source": "https://raw.githubusercontent.com/FiMDP/FiMDP/master/tut/ExplicitEnergy.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/FiMDP/FiMDP/master/tut/StormAndPrism.ipynb"
      },
      "source": "https://raw.githubusercontent.com/FiMDP/FiMDP/master/tut/StormAndPrism.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/FiMDP/FiMDP/master/examples/LowerBoundOnIterations.ipynb"
      },
      "source": "https://raw.githubusercontent.com/FiMDP/FiMDP/master/examples/LowerBoundOnIterations.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/FiMDP/FiMDP/master/examples/IncorrectBoundOnLeastFixpoint.ipynb"
      },
      "source": "https://raw.githubusercontent.com/FiMDP/FiMDP/master/examples/IncorrectBoundOnLeastFixpoint.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/FiMDP/FiMDP/master/examples/reach_buchi.ipynb"
      },
      "source": "https://raw.githubusercontent.com/FiMDP/FiMDP/master/examples/reach_buchi.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/FiMDP/FiMDP/master/examples/SafeByLeastFixpoint.ipynb"
      },
      "source": "https://raw.githubusercontent.com/FiMDP/FiMDP/master/examples/SafeByLeastFixpoint.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://mybinder.org/v2/gh/xblahoud/FiMDP/master?urlpath=lab"
      },
      "source": "https://raw.githubusercontent.com/FiMDP/FiMDP/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 7
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/FiMDP/FiMDP/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "FiMDP/FiMDP"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "FiMDP - Fuel in Markov Decision Processes"
      },
      "source": "https://raw.githubusercontent.com/FiMDP/FiMDP/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "images": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/FiMDP/FiMDP/master/docs/source/images/demoanimation.gif"
      },
      "source": "https://raw.githubusercontent.com/FiMDP/FiMDP/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "installation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Installation",
        "parent_header": [
          "FiMDP - Fuel in Markov Decision Processes"
        ],
        "type": "Text_excerpt",
        "value": "FiMDP can be installed using pip from PyPI\n```\npip install -U fimdp\n```\nWhile the baseline package has minimal dependencies, FiMDP depends on several other tools for extended functionality. Some of the recommended dependencies are:\n\n* [Graphviz]: for visualizations in Jupyter notebooks,\n* [Storm] and [Stormpy]: for reading PRSIM, JANI, and Storm models,\n* [Spot](https://spot.lrde.epita.fr/): for support of labeled ConsMDPs and specifications given as deterministic B\u00fcchi automata or the recurrence fragment of Linear-time Temporal Logic (LTL).\n"
      },
      "source": "https://raw.githubusercontent.com/FiMDP/FiMDP/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 0.9996093492729174,
      "result": {
        "original_header": "FiMDP - Fuel in Markov Decision Processes",
        "type": "Text_excerpt",
        "value": "Our related project called **[FiMDPEnv]** is a set of environments that work with FiMDP and can create animations like this one.\n<p align=\"center\">\n<img src=\"https://github.com/FiMDP/FiMDP/blob/master/docs/source/images/demoanimation.gif\" alt=\"Multiple agents following energy-aware policy in grid-world.\" align=\"center\" height=\"250\" width=\"350\" >\n<br>\n<em>Multiple agents following energy-aware policies in UUVEnv from <a href=\"https://github.com/FiMDP/FiMDPEnv\">FiMDPEnv</a>.  </em>\n</p>\n \n"
      },
      "source": "https://raw.githubusercontent.com/FiMDP/FiMDP/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/FiMDP/FiMDP/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ""
      },
      "technique": "GitHub_API"
    }
  ],
  "license": [
    {
      "confidence": 1,
      "result": {
        "name": "MIT License",
        "spdx_id": "MIT",
        "type": "License",
        "url": "https://api.github.com/licenses/mit",
        "value": "https://api.github.com/licenses/mit"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "type": "File_dump",
        "value": "MIT License\n\nCopyright (c) 2019, 2020 UT Austin and UIUC\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
      },
      "source": "https://raw.githubusercontent.com/FiMDP/FiMDP/master/LICENSE",
      "technique": "file_exploration"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "FiMDP"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "Organization",
        "value": "FiMDP"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Jupyter Notebook",
        "size": 1987198,
        "type": "Programming_language",
        "value": "Jupyter Notebook"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 202551,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Shell",
        "size": 603,
        "type": "Programming_language",
        "value": "Shell"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/FiMDP/FiMDP/master/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "releases": [
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "xblahoud",
          "type": "User"
        },
        "date_created": "2020-10-23T17:45:59Z",
        "date_published": "2020-10-23T17:57:15Z",
        "description": "Version 2 brings a new interface and a lot of new functionalities, including new solvers, integration with Storm(py), strategies and simulator, and more.\r\n\r\n### Added\r\n * Solvers that use heuristics for strategies usable in control. This is implemented in class\r\n   `GoalLeaningES` of the `energy_solver.py` module. See [tut/Solvers](tut/Solvers.ipynb)\r\n   notebook for more details. Use [nbviewer] for the rendered notebook if you don't want\r\n   to run the notebook locally; it renders the animations correctly.\r\n * Support for full-featured strategies that resolve the next action to play based on the history. See `Strategy`\r\n   for the interface. See [tut/Strategies](tut/Strategies.ipynb) for more details.\r\n     - `CounterStrategy` implements strategies with a limited memory. The class only\r\n     maintains the energy level of the play and can use it for the selection of next\r\n     actions. The class only implements the memory and relies on `selector` objects\r\n     to choose the next action. Any object implementing `select_action(state, energy)`\r\n     can be used as selector.\r\n     - `CounterSelector` is an enriched variant of what was called \"strategy\" in\r\n     versions up to 1.2. This is the class intended to be used by the\r\n     `CounterStrategy` instances.\r\n     - `SelectionRule` is a helper class that stores the selection rules for one\r\n     state. It is basically a `dict` enriched with `select_action` (and `update`)\r\n     function. The keys in this `dict` are lower bounds of intervals that are\r\n     mapped to the corresponding values. `select_action` takes care of the\r\n     translation of lower bounds to intervals.\r\n * Integration with Stormpy for reading PRISM and Storm models into FiMDP and for\r\n   translation of FiMDP models into equivalent models in Stormpy. See \r\n   [tut/Storm_and_prism](tut/StormAndPrism.ipynb) for more details.\r\n * Ability to reason about Consumption MDPs with state labeled by sets of atomic propositions. \r\n   This is implemented in the module `labeled.py`. The labeled ConsMDPs can be checked against\r\n   specifications given by deterministic DBAs or the recurrence fragment of LTL. This requires\r\n   [Spot] to be installed. See [tut/Labeled](tut/Labeled.ipynb) for more details.\r\n * Binary search for detection of minimal capacity needed for a task\r\n   (function `mincap_solvers.bin_search`).\r\n * `fimdp.setup()` configures FiMDP to create nicer pictures of ConsMDPs.\r\n * Solvers can now be visualized. Legend for the semantics of the minimal levels can be \r\n   requested by calling `solver.show(.l)`\r\n * Show now takes `<N` option where the integer `N` marks the maximal number of states that\r\n   should be drawn. It can be also specified by `max_states=N`.\r\n * `ConsMDP.show` takes `targets` argument which enables to highlight the given\r\n   set of targets. Alternatively, targets can be specified using the option\r\n   string `\".T{t\u2081,t\u2082,...}\"`. This cannot be used for solvers.\r\n \r\n### Changed\r\n\r\nThe package underwent a massive refactoring. There is a completely new interface for\r\nenergy solvers, part of the ConsMDP interface was removed (in favor of solvers), and\r\nmost of the codes was moved to new (or renamed) modules. The changes are listed below\r\nand split into backward-incompatible and -compatible. \r\n\r\n#### Backward incompatible changes\r\n * `ConsMDP` class does no longer have functions `get_buchi` and similar. Instead,\r\n   solvers must be used explicitly. Moreover, they have no solver associated anymore\r\n   and when visualized, they never show minimal levels for objectives (visualize solver\r\n   instead). \r\n   See [tut/Basics][Basics] for more details.\r\n * Solvers have new interface. See the corresponding \r\n   [issue #29](https://github.com/xblahoud/FiMDP/issues/29) or the [Basics] notebook\r\n   for more details.\r\n * **moved between modules:**\r\n   - The class `ConsMDP` and its helper classes (`ActionData` and iterators) are moved\r\n     from `consMDP.py` module to `core.py`.\r\n   - Code regarding explicit encoding of energy to state-space was moved to `explicit.py`\r\n   - Fixpoints-related code was moved to `energy_solvers.py`\r\n   - Objectives definitions (BUCHI, etc.) moved to `objectives.py`\r\n * `energy_solver.py` renamed to `energy_solvers.py`\r\n * The update function of energy solvers now stores pointer to the whole ActionData object instead of\r\n   just label. Add `.label` to every access to actions stored in the current representations\r\n   of strategies.\r\n\r\n#### Backward compatible changes\r\n * `EnergySolvers.get_strategy` returns `CounterSelector` objects instead of `list` of `dict`s\r\n * `ActionData.__repr__` now prints full information about the action (source state, consumption, label, and successor distribution).\r\n * Visualization uses various shapes where appropriate.\r\n",
        "html_url": "https://github.com/FiMDP/FiMDP/releases/tag/v2.0.0",
        "name": "Version 2",
        "release_id": 32991656,
        "tag": "v2.0.0",
        "tarball_url": "https://api.github.com/repos/FiMDP/FiMDP/tarball/v2.0.0",
        "type": "Release",
        "url": "https://api.github.com/repos/FiMDP/FiMDP/releases/32991656",
        "value": "https://api.github.com/repos/FiMDP/FiMDP/releases/32991656",
        "zipball_url": "https://api.github.com/repos/FiMDP/FiMDP/zipball/v2.0.0"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "xblahoud",
          "type": "User"
        },
        "date_created": "2020-06-22T23:09:58Z",
        "date_published": "2020-06-22T23:17:16Z",
        "description": "* Data structures for consumption Markov Decision Processes (CMDP)\r\n* Solvers for strategy synthesis (and solving underlying decision problems) for Survival, Positive reachability (of given target set `T`), almost-sure reachability of `T`, and almsot-sure B\u00fcchi objective on `T`\r\n* Algorithm for explicit representation of energy + MEC decomposition of this explicit MDP\r\n* Example notebooks",
        "html_url": "https://github.com/FiMDP/FiMDP/releases/tag/v1.0.2",
        "name": "Version 1.0.2: First version with basic functionality for PyPI",
        "release_id": 27807082,
        "tag": "v1.0.2",
        "tarball_url": "https://api.github.com/repos/FiMDP/FiMDP/tarball/v1.0.2",
        "type": "Release",
        "url": "https://api.github.com/repos/FiMDP/FiMDP/releases/27807082",
        "value": "https://api.github.com/repos/FiMDP/FiMDP/releases/27807082",
        "zipball_url": "https://api.github.com/repos/FiMDP/FiMDP/zipball/v1.0.2"
      },
      "technique": "GitHub_API"
    }
  ],
  "somef_missing_categories": [
    "acknowledgement",
    "run",
    "download",
    "requirements",
    "contributors",
    "faq",
    "support",
    "identifier",
    "has_build_file"
  ],
  "somef_provenance": {
    "date": "2024-10-06 00:42:09",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 4
      },
      "technique": "GitHub_API"
    }
  ],
  "usage": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Usage and documentation (work in progress)",
        "parent_header": [
          "FiMDP - Fuel in Markov Decision Processes"
        ],
        "type": "Text_excerpt",
        "value": "The directory [tut](tut/README.md) contains several notebooks that explain how to use FiMDP. The notebook [Basics.ipynb](tut/Basics.ipynb) is a good starting point.\n\nFor a complete overview of the tool, installation options, source code documentation, and interactive examples refer to [FiMDP readthedocs].\n\n"
      },
      "source": "https://raw.githubusercontent.com/FiMDP/FiMDP/master/README.md",
      "technique": "header_analysis"
    }
  ]
}