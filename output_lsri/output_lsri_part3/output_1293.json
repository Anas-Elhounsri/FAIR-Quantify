{
  "application_domain": [
    {
      "confidence": 35.05,
      "result": {
        "type": "String",
        "value": "Computer Vision"
      },
      "technique": "supervised_classification"
    }
  ],
  "citation": [
    {
      "confidence": 1,
      "result": {
        "original_header": ":page_with_curl: Citation",
        "parent_header": [
          ":notebook_with_decorative_cover: Table of Contents"
        ],
        "type": "Text_excerpt",
        "value": "If you use this GitHub repository (or any modules associated with it), please cite our [paper](https://www.frontiersin.org/articles/10.3389/fninf.2021.679838/full) for the initial version of `thingsvision` as follows:\n\n```latex\n@article{Muttenthaler_2021,\n\tauthor = {Muttenthaler, Lukas and Hebart, Martin N.},\n\ttitle = {THINGSvision: A Python Toolbox for Streamlining the Extraction of Activations From Deep Neural Networks},\n\tjournal ={Frontiers in Neuroinformatics},\n\tvolume = {15},\n\tpages = {45},\n\tyear = {2021},\n\turl = {https://www.frontiersin.org/article/10.3389/fninf.2021.679838},\n\tdoi = {10.3389/fninf.2021.679838},\n\tissn = {1662-5196},\n}\n```\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>\n\n\n"
      },
      "source": "https://raw.githubusercontent.com/ViCCo-Group/THINGSvision/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "author": "Muttenthaler, Lukas and Hebart, Martin N.",
        "doi": "10.3389/fninf.2021.679838",
        "format": "bibtex",
        "title": "THINGSvision: A Python Toolbox for Streamlining the Extraction of Activations From Deep Neural Networks",
        "type": "Text_excerpt",
        "url": "https://www.frontiersin.org/article/10.3389/fninf.2021.679838",
        "value": "@article{Muttenthaler_2021,\n    issn = {1662-5196},\n    doi = {10.3389/fninf.2021.679838},\n    url = {https://www.frontiersin.org/article/10.3389/fninf.2021.679838},\n    year = {2021},\n    pages = {45},\n    volume = {15},\n    journal = {Frontiers in Neuroinformatics},\n    title = {THINGSvision: A Python Toolbox for Streamlining the Extraction of Activations From Deep Neural Networks},\n    author = {Muttenthaler, Lukas and Hebart, Martin N.},\n}"
      },
      "source": "https://raw.githubusercontent.com/ViCCo-Group/THINGSvision/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/ViCCo-Group/thingsvision"
      },
      "technique": "GitHub_API"
    }
  ],
  "contributing_guidelines": [
    {
      "confidence": 1,
      "result": {
        "original_header": ":wave: How to contribute",
        "parent_header": [
          ":notebook_with_decorative_cover: Table of Contents"
        ],
        "type": "Text_excerpt",
        "value": "If you come across problems or have suggestions please submit an issue!\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>\n\n\n"
      },
      "source": "https://raw.githubusercontent.com/ViCCo-Group/THINGSvision/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2020-11-02T14:14:18Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2024-09-12T14:24:14Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "Python package for extracting representations from state-of-the-art computer vision models"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 0.9694740097306485,
      "result": {
        "original_header": ":star2: About the Project",
        "type": "Text_excerpt",
        "value": "`thingsvision` is a Python package for extracting (image) representations from many state-of-the-art computer vision models. Essentially, you provide `thingsvision` with a directory of images and specify the neural network you're interested in. Subsequently, `thingsvision` returns the representation of the selected neural network for each image, resulting in one feature map (vector or matrix, depending on the layer) per image. These features, used interchangeably with _image representations_, can then be used for further analyses. \n:rotating_light: NOTE: some function calls mentioned in the original [paper](https://www.frontiersin.org/articles/10.3389/fninf.2021.679838/full) have been deprecated. To use this package successfully, exclusively follow this `README` and the [documentation](https://vicco-group.github.io/thingsvision/)! :rotating_light: \n"
      },
      "source": "https://raw.githubusercontent.com/ViCCo-Group/THINGSvision/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9895421202816542,
      "result": {
        "original_header": ":mechanical_arm: Functionality",
        "type": "Text_excerpt",
        "value": "With `thingsvision`, you can:\n- extract features for any imageset from many popular networks.\n- extract features for any imageset from your custom networks.\n- extract features for >26,000 images from the [THINGS image database](https://osf.io/jum2f/).\n- [align](https://vicco-group.github.io/thingsvision/Alignment.html) the extracted features with human object perception (e.g., using [gLocal](https://proceedings.neurips.cc/paper_files/paper/2023/hash/9febda1c8344cc5f2d51713964864e93-Abstract-Conference.html)).\n- extract features from [HDF5 datasets](https://vicco-group.github.io/thingsvision/LoadingYourData.html#using-the-hdf5dataset-class) directly (e.g., [NSD stimuli](https://naturalscenesdataset.org/))\n- conduct basic [Representational Similarity Analysis (RSA)](https://vicco-group.github.io/thingsvision/RSA.html#representational-similarity-analysis-rsa) after feature extraction.\n- perform efficient [Centered Kernel Alignment (CKA)](https://vicco-group.github.io/thingsvision/RSA.html#centered-kernel-alignment-cka) to compare image features across model-module combinations.\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p> \n"
      },
      "source": "https://raw.githubusercontent.com/ViCCo-Group/THINGSvision/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9542184381381076,
      "result": {
        "original_header": ":file_cabinet: Model collection",
        "type": "Text_excerpt",
        "value": "Neural networks come from different sources. With `thingsvision`, you can extract image representations of all models from:\n- [torchvision](https://pytorch.org/vision/0.8/models.html)\n- [Keras](https://www.tensorflow.org/api_docs/python/tf/keras/applications)\n- [timm](https://github.com/rwightman/pytorch-image-models)\n- `ssl` (self-supervised learning models)\n  - `simclr-rn50`, `mocov2-rn50`, `barlowtwins-rn50`, `pirl-rn50`\n  - `jigsaw-rn50`, `rotnet-rn50`, `swav-rn50`, `vicreg-rn50`\n  - `dino-rn50`, `dino-xcit-{small/medium}-{12/24}-p{8/16}`\n  - `dino-vit-{tiny/small/base}-p{8/16}`\n  - `dinov2-vit-{small/base/large/giant}-p14`\n  - `mae-vit-{base/large}-p16`, `mae-vit-huge-p14`<br>\n- [OpenCLIP](https://github.com/mlfoundations/open_clip) models (CLIP trained on LAION-{400M/2B/5B})\n- [CLIP](https://github.com/openai/CLIP) models (CLIP trained on WiT)\n- a few custom models (Alexnet, VGG-16, Resnet50, and Inception_v3) trained on [Ecoset](https://www.pnas.org/doi/10.1073/pnas.2011417118) rather than ImageNet and one Alexnet model pretrained on ImageNet and fine-tuned on [SalObjSub](https://cs-people.bu.edu/jmzhang/sos.html)<br>\n- each of the many [CORnet](https://github.com/dicarlolab/CORnet) versions (recurrent vision models)\n- [Harmonization](https://arxiv.org/abs/2211.04533) models (see [Harmonization repo](https://github.com/serre-lab/harmonization)). The default variant is `ViT_B16`. Other available models are `ResNet50`, `VGG16`, `EfficientNetB0`, `tiny_ConvNeXT`, `tiny_MaxViT`, and `LeViT_small`<br> \n- [DreamSim](https://dreamsim-nights.github.io/) models  (see [DreamSim repo](https://github.com/ssundaram21/dreamsim)). The default variant is `open_clip_vitb32`. Other available models are `clip_vitb32`, `dino_vitb16`, and an `ensemble`. See the [docs](https://vicco-group.github.io/thingsvision/AvailableModels.html#dreamsim) for more information\n- FAIR's [Segment Anything (SAM)](https://vicco-group.github.io/thingsvision/AvailableModels.html#align-model) model\n- Kakaobrain's [ALIGN](https://vicco-group.github.io/thingsvision/AvailableModels.html#align-model) implementation \n"
      },
      "source": "https://raw.githubusercontent.com/ViCCo-Group/THINGSvision/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9942756000338722,
      "result": {
        "original_header": ":gem: Contributions",
        "type": "Text_excerpt",
        "value": "This is a joint open-source project between the [Max Planck Institute for Human Cognitive and Brain Sciences](https://www.cbs.mpg.de/en), Leipzig, and the [Machine Learning Group](https://web.ml.tu-berlin.de/) at Technische Universtit\u00e4t Berlin. Correspondence and requests for contributing should be adressed to [Lukas Muttenthaler](https://lukasmut.github.io/). Feel free to contact us if you want to become a contributor or have any suggestions/feedback. For the latter, you could also just post an issue or engange in discussions. We'll try to respond as fast as we can. \n"
      },
      "source": "https://raw.githubusercontent.com/ViCCo-Group/THINGSvision/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "documentation": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/ViCCo-Group/THINGSvision/tree/master/docs"
      },
      "technique": "file_exploration"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/ViCCo-Group/THINGSvision/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "executable_example": [
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/ViCCo-Group/THINGSvision/master/notebooks/tensorflow.ipynb"
      },
      "source": "https://raw.githubusercontent.com/ViCCo-Group/THINGSvision/master/notebooks/tensorflow.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/ViCCo-Group/THINGSvision/master/notebooks/pytorch.ipynb"
      },
      "source": "https://raw.githubusercontent.com/ViCCo-Group/THINGSvision/master/notebooks/pytorch.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/ViCCo-Group/THINGSvision/master/notebooks/.ipynb_checkpoints/pytorch-checkpoint.ipynb"
      },
      "source": "https://raw.githubusercontent.com/ViCCo-Group/THINGSvision/master/notebooks/.ipynb_checkpoints/pytorch-checkpoint.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/ViCCo-Group/THINGSvision/master/notebooks/.ipynb_checkpoints/tensorflow-checkpoint.ipynb"
      },
      "source": "https://raw.githubusercontent.com/ViCCo-Group/THINGSvision/master/notebooks/.ipynb_checkpoints/tensorflow-checkpoint.ipynb",
      "technique": "file_exploration"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 19
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/ViCCo-Group/thingsvision/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "ViCCo-Group/thingsvision"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ":notebook_with_decorative_cover: Table of Contents"
      },
      "source": "https://raw.githubusercontent.com/ViCCo-Group/THINGSvision/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "has_script_file": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/ViCCo-Group/THINGSvision/master/get_files.sh"
      },
      "technique": "file_exploration"
    }
  ],
  "images": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://colab.research.google.com/assets/colab-badge.svg"
      },
      "source": "https://raw.githubusercontent.com/ViCCo-Group/THINGSvision/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "installation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Working locally",
        "parent_header": [
          ":notebook_with_decorative_cover: Table of Contents",
          ":running: Getting Started",
          ":computer: Setting up your environment"
        ],
        "type": "Text_excerpt",
        "value": "First, create a new `conda environment` with Python version 3.8, 3.9, or 3.10 e.g. by using `conda`:\n\n```bash\n$ conda create -n thingsvision python=3.9\n$ conda activate thingsvision\n```\n\nThen, activate the environment and simply install `thingsvision` via running the following `pip` command in your terminal.\n\n```bash\n$ pip install --upgrade thingsvision\n$ pip install git+https://github.com/openai/CLIP.git\n```\n\nIf you want to extract features for [harmonized models](https://vicco-group.github.io/thingsvision/AvailableModels.html#harmonization) from the [Harmonization repo](https://github.com/serre-lab/harmonization), you have to additionally run the following `pip` command in your `thingsvision` environment (FYI: as of now, this seems to be working smoothly on Ubuntu only but not on macOS),\n\n```bash\n$ pip install git+https://github.com/serre-lab/Harmonization.git\n$ pip install keras-cv-attention-models>=1.3.5\n```\n\nIf you want to extract features for [DreamSim](https://dreamsim-nights.github.io/) from the [DreamSim repo](https://github.com/ssundaram21/dreamsim), you have to additionally run the following `pip` command in your `thingsvision` environment,\n\n```bash\n$ pip install dreamsim==0.1.2\n```\n\nSee the [docs](https://vicco-group.github.io/thingsvision/AvailableModels.html#dreamsim) for which `DreamSim` models are available in `thingsvision`.\n"
      },
      "source": "https://raw.githubusercontent.com/ViCCo-Group/THINGSvision/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Google Colab",
        "parent_header": [
          ":notebook_with_decorative_cover: Table of Contents",
          ":running: Getting Started",
          ":computer: Setting up your environment"
        ],
        "type": "Text_excerpt",
        "value": "Alternatively, you can use Google Colab to play around with `thingsvision` by uploading your image data to Google Drive (via directory mounting).\nYou can find the jupyter notebook using `PyTorch` [here](https://colab.research.google.com/github/ViCCo-Group/thingsvision/blob/master/notebooks/pytorch.ipynb) and the `TensorFlow` example [here](https://colab.research.google.com/github/ViCCo-Group/thingsvision/blob/master/notebooks/tensorflow.ipynb).\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>\n\n\n"
      },
      "source": "https://raw.githubusercontent.com/ViCCo-Group/THINGSvision/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 0.8100676048219208,
      "result": {
        "original_header": ":star2: About the Project",
        "type": "Text_excerpt",
        "value": ":rotating_light: NOTE: some function calls mentioned in the original [paper](https://www.frontiersin.org/articles/10.3389/fninf.2021.679838/full) have been deprecated. To use this package successfully, exclusively follow this `README` and the [documentation](https://vicco-group.github.io/thingsvision/)! :rotating_light: \n"
      },
      "source": "https://raw.githubusercontent.com/ViCCo-Group/THINGSvision/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/ViCCo-Group/thingsvision/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "alignment, cognitive-science, computer-vision, deep-learning, neural-networks, pytorch, representations, tensorflow"
      },
      "technique": "GitHub_API"
    }
  ],
  "license": [
    {
      "confidence": 1,
      "result": {
        "name": "MIT License",
        "spdx_id": "MIT",
        "type": "License",
        "url": "https://api.github.com/licenses/mit",
        "value": "https://api.github.com/licenses/mit"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "type": "File_dump",
        "value": "MIT License\n\nCopyright (c) 2021 Vision and Computational Cognition Group\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
      },
      "source": "https://raw.githubusercontent.com/ViCCo-Group/THINGSvision/master/LICENSE",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": ":warning: License",
        "parent_header": [
          ":notebook_with_decorative_cover: Table of Contents"
        ],
        "type": "Text_excerpt",
        "value": "This GitHub repository is licensed under the MIT License - see the [LICENSE.md](LICENSE.md) file for details.\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>\n\n\n"
      },
      "source": "https://raw.githubusercontent.com/ViCCo-Group/THINGSvision/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "thingsvision"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "Organization",
        "value": "ViCCo-Group"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 206054,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Jupyter Notebook",
        "size": 46819,
        "type": "Programming_language",
        "value": "Jupyter Notebook"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Shell",
        "size": 957,
        "type": "Programming_language",
        "value": "Shell"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/ViCCo-Group/THINGSvision/master/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "related_papers": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://arxiv.org/abs/2211.04533"
      },
      "source": "https://raw.githubusercontent.com/ViCCo-Group/THINGSvision/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "releases": [
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "LukasMut",
          "type": "User"
        },
        "date_created": "2024-09-11T15:04:20Z",
        "date_published": "2024-09-11T15:08:54Z",
        "description": "- Bug fixes regarding the SSL models and torch hub",
        "html_url": "https://github.com/ViCCo-Group/thingsvision/releases/tag/v2.6.10",
        "name": "Bug fixes",
        "release_id": 174580468,
        "tag": "v2.6.10",
        "tarball_url": "https://api.github.com/repos/ViCCo-Group/thingsvision/tarball/v2.6.10",
        "type": "Release",
        "url": "https://api.github.com/repos/ViCCo-Group/thingsvision/releases/174580468",
        "value": "https://api.github.com/repos/ViCCo-Group/thingsvision/releases/174580468",
        "zipball_url": "https://api.github.com/repos/ViCCo-Group/thingsvision/zipball/v2.6.10"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "LukasMut",
          "type": "User"
        },
        "date_created": "2024-06-18T15:17:26Z",
        "date_published": "2024-07-25T13:11:36Z",
        "description": "- bug fixes",
        "html_url": "https://github.com/ViCCo-Group/thingsvision/releases/tag/v2.6.8",
        "name": "New models: SAM and ALIGN",
        "release_id": 167130435,
        "tag": "v2.6.8",
        "tarball_url": "https://api.github.com/repos/ViCCo-Group/thingsvision/tarball/v2.6.8",
        "type": "Release",
        "url": "https://api.github.com/repos/ViCCo-Group/thingsvision/releases/167130435",
        "value": "https://api.github.com/repos/ViCCo-Group/thingsvision/releases/167130435",
        "zipball_url": "https://api.github.com/repos/ViCCo-Group/thingsvision/zipball/v2.6.8"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "LukasMut",
          "type": "User"
        },
        "date_created": "2024-05-19T16:43:24Z",
        "date_published": "2024-05-27T08:38:27Z",
        "description": "- Enabled feature extraction for new models: [SAM](https://vicco-group.github.io/thingsvision/AvailableModels.html#segment-anything) and Kakaobrain's [ALIGN](https://vicco-group.github.io/thingsvision/AvailableModels.html#segment-anything) implementation\r\n- Fixed small bugs in rbf kernel of CKA class",
        "html_url": "https://github.com/ViCCo-Group/thingsvision/releases/tag/v2.6.7",
        "name": "New models: SAM and ALIGN",
        "release_id": 157585090,
        "tag": "v2.6.7",
        "tarball_url": "https://api.github.com/repos/ViCCo-Group/thingsvision/tarball/v2.6.7",
        "type": "Release",
        "url": "https://api.github.com/repos/ViCCo-Group/thingsvision/releases/157585090",
        "value": "https://api.github.com/repos/ViCCo-Group/thingsvision/releases/157585090",
        "zipball_url": "https://api.github.com/repos/ViCCo-Group/thingsvision/zipball/v2.6.7"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "LukasMut",
          "type": "User"
        },
        "date_created": "2024-04-22T08:55:15Z",
        "date_published": "2024-04-22T09:43:37Z",
        "description": "- added support for `torch>=2.0.0` and `torchvision=0.15.*` (fixes issue #165)\r\n- implemented CKA in both NumPy and PyTorch (PyTorch runs 2x faster than NumPy)\r\n- added CUDA support for CKA in PyTorch (100x faster than CKA in NumPy)\r\n- added new function called `get_cka` where the user can set the `backend` (`torch` or `numpy`); function returns the CKA object\r\n- added an unbiased CKA variant (from [here](https://github.com/google-research/google-research/blob/master/representation_similarity/Demo.ipynb)) in addition to vanilla CKA",
        "html_url": "https://github.com/ViCCo-Group/thingsvision/releases/tag/v2.6.0",
        "name": "PyTorch 2.0 support and CKA speedups + improvements",
        "release_id": 152163833,
        "tag": "v2.6.0",
        "tarball_url": "https://api.github.com/repos/ViCCo-Group/thingsvision/tarball/v2.6.0",
        "type": "Release",
        "url": "https://api.github.com/repos/ViCCo-Group/thingsvision/releases/152163833",
        "value": "https://api.github.com/repos/ViCCo-Group/thingsvision/releases/152163833",
        "zipball_url": "https://api.github.com/repos/ViCCo-Group/thingsvision/zipball/v2.6.0"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "LukasMut",
          "type": "User"
        },
        "date_created": "2024-04-08T11:02:21Z",
        "date_published": "2024-04-08T11:22:00Z",
        "description": "- improved the efficiency of batch-wise feature extraction (with custom data pipeline)\r\n- added pretrained MAEs to the `thingsvision` model collection",
        "html_url": "https://github.com/ViCCo-Group/thingsvision/releases/tag/v2.5.3",
        "name": "Efficient batch-wise feature extraction + MAEs",
        "release_id": 150196810,
        "tag": "v2.5.3",
        "tarball_url": "https://api.github.com/repos/ViCCo-Group/thingsvision/tarball/v2.5.3",
        "type": "Release",
        "url": "https://api.github.com/repos/ViCCo-Group/thingsvision/releases/150196810",
        "value": "https://api.github.com/repos/ViCCo-Group/thingsvision/releases/150196810",
        "zipball_url": "https://api.github.com/repos/ViCCo-Group/thingsvision/zipball/v2.5.3"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "LukasMut",
          "type": "User"
        },
        "date_created": "2024-04-05T10:00:22Z",
        "date_published": "2024-04-05T13:16:46Z",
        "description": "- efficient batch-wise feature extraction (using a `with` statement for PyTorch models) for custom data pipeline",
        "html_url": "https://github.com/ViCCo-Group/thingsvision/releases/tag/v2.5.2",
        "name": "Efficient batch-wise feature extraction",
        "release_id": 149947797,
        "tag": "v2.5.2",
        "tarball_url": "https://api.github.com/repos/ViCCo-Group/thingsvision/tarball/v2.5.2",
        "type": "Release",
        "url": "https://api.github.com/repos/ViCCo-Group/thingsvision/releases/149947797",
        "value": "https://api.github.com/repos/ViCCo-Group/thingsvision/releases/149947797",
        "zipball_url": "https://api.github.com/repos/ViCCo-Group/thingsvision/zipball/v2.5.2"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "LukasMut",
          "type": "User"
        },
        "date_created": "2024-04-04T09:37:58Z",
        "date_published": "2024-04-04T09:46:14Z",
        "description": " - added a public batch-wise extraction method to the feature extractor (for custom dataset and data loader classes)\r\n - updated README and docs with explanations about how and when to use the mini-batch extraction method\r\n - small bug fixes and refactorings",
        "html_url": "https://github.com/ViCCo-Group/thingsvision/releases/tag/v2.5.1",
        "name": "Batch-wise feature extraction and human alignment",
        "release_id": 149736020,
        "tag": "v2.5.1",
        "tarball_url": "https://api.github.com/repos/ViCCo-Group/thingsvision/tarball/v2.5.1",
        "type": "Release",
        "url": "https://api.github.com/repos/ViCCo-Group/thingsvision/releases/149736020",
        "value": "https://api.github.com/repos/ViCCo-Group/thingsvision/releases/149736020",
        "zipball_url": "https://api.github.com/repos/ViCCo-Group/thingsvision/zipball/v2.5.1"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "LukasMut",
          "type": "User"
        },
        "date_created": "2024-03-28T18:01:59Z",
        "date_published": "2024-03-28T18:05:20Z",
        "description": "- added method to extractor class for aligning representations using [gLocal](https://proceedings.neurips.cc/paper_files/paper/2023/hash/9febda1c8344cc5f2d51713964864e93-Abstract-Conference.html)\r\n- small bug fixes and refactoring",
        "html_url": "https://github.com/ViCCo-Group/thingsvision/releases/tag/v2.5.0",
        "name": "v2.5.0",
        "release_id": 148921551,
        "tag": "v2.5.0",
        "tarball_url": "https://api.github.com/repos/ViCCo-Group/thingsvision/tarball/v2.5.0",
        "type": "Release",
        "url": "https://api.github.com/repos/ViCCo-Group/thingsvision/releases/148921551",
        "value": "https://api.github.com/repos/ViCCo-Group/thingsvision/releases/148921551",
        "zipball_url": "https://api.github.com/repos/ViCCo-Group/thingsvision/zipball/v2.5.0"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "LukasMut",
          "type": "User"
        },
        "date_created": "2024-03-19T09:47:13Z",
        "date_published": "2024-03-19T10:02:26Z",
        "description": "- new DreamSim models\r\n- support for CLS token extraction for supervised ViTs",
        "html_url": "https://github.com/ViCCo-Group/thingsvision/releases/tag/v2.4.2",
        "release_id": 147203369,
        "tag": "v2.4.2",
        "tarball_url": "https://api.github.com/repos/ViCCo-Group/thingsvision/tarball/v2.4.2",
        "type": "Release",
        "url": "https://api.github.com/repos/ViCCo-Group/thingsvision/releases/147203369",
        "value": "https://api.github.com/repos/ViCCo-Group/thingsvision/releases/147203369",
        "zipball_url": "https://api.github.com/repos/ViCCo-Group/thingsvision/zipball/v2.4.2"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "LukasMut",
          "type": "User"
        },
        "date_created": "2023-08-09T09:10:30Z",
        "date_published": "2023-08-09T09:12:08Z",
        "description": "- fixed import issues with DINO models\r\n- improved unittests\r\n- enhanced modularity of codebase",
        "html_url": "https://github.com/ViCCo-Group/thingsvision/releases/tag/v2.4.1",
        "name": "v2.4.1",
        "release_id": 115729606,
        "tag": "v2.4.1",
        "tarball_url": "https://api.github.com/repos/ViCCo-Group/thingsvision/tarball/v2.4.1",
        "type": "Release",
        "url": "https://api.github.com/repos/ViCCo-Group/thingsvision/releases/115729606",
        "value": "https://api.github.com/repos/ViCCo-Group/thingsvision/releases/115729606",
        "zipball_url": "https://api.github.com/repos/ViCCo-Group/thingsvision/zipball/v2.4.1"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "LukasMut",
          "type": "User"
        },
        "date_created": "2023-07-26T10:10:14Z",
        "date_published": "2023-07-26T10:11:55Z",
        "description": "- integrated DreamSim models into `thingsvision`\r\n- small changes to the codebase (more modularity)\r\n- minor refactors",
        "html_url": "https://github.com/ViCCo-Group/thingsvision/releases/tag/v2.3.18",
        "name": "v2.3.18",
        "release_id": 113642514,
        "tag": "v2.3.18",
        "tarball_url": "https://api.github.com/repos/ViCCo-Group/thingsvision/tarball/v2.3.18",
        "type": "Release",
        "url": "https://api.github.com/repos/ViCCo-Group/thingsvision/releases/113642514",
        "value": "https://api.github.com/repos/ViCCo-Group/thingsvision/releases/113642514",
        "zipball_url": "https://api.github.com/repos/ViCCo-Group/thingsvision/zipball/v2.3.18"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "LukasMut",
          "type": "User"
        },
        "date_created": "2023-07-11T09:50:52Z",
        "date_published": "2023-07-12T08:25:08Z",
        "description": "- memory fixes",
        "html_url": "https://github.com/ViCCo-Group/thingsvision/releases/tag/v2.3.17",
        "name": "v2.3.17",
        "release_id": 111911339,
        "tag": "v2.3.17",
        "tarball_url": "https://api.github.com/repos/ViCCo-Group/thingsvision/tarball/v2.3.17",
        "type": "Release",
        "url": "https://api.github.com/repos/ViCCo-Group/thingsvision/releases/111911339",
        "value": "https://api.github.com/repos/ViCCo-Group/thingsvision/releases/111911339",
        "zipball_url": "https://api.github.com/repos/ViCCo-Group/thingsvision/zipball/v2.3.17"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "LukasMut",
          "type": "User"
        },
        "date_created": "2023-04-30T10:18:22Z",
        "date_published": "2023-04-30T10:36:10Z",
        "description": "- adapted Command Line Interface (CLI) to the most recent changes in the library (see v2.3)\r\n- added automatic device checks",
        "html_url": "https://github.com/ViCCo-Group/thingsvision/releases/tag/v2.3.14",
        "name": "v2.3.14",
        "release_id": 101401871,
        "tag": "v2.3.14",
        "tarball_url": "https://api.github.com/repos/ViCCo-Group/thingsvision/tarball/v2.3.14",
        "type": "Release",
        "url": "https://api.github.com/repos/ViCCo-Group/thingsvision/releases/101401871",
        "value": "https://api.github.com/repos/ViCCo-Group/thingsvision/releases/101401871",
        "zipball_url": "https://api.github.com/repos/ViCCo-Group/thingsvision/zipball/v2.3.14"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "LukasMut",
          "type": "User"
        },
        "date_created": "2023-03-06T11:31:43Z",
        "date_published": "2023-03-06T12:26:46Z",
        "description": "- added possibility to easily extract features from [harmonized models](https://vicco-group.github.io/thingsvision/AvailableModels.html#harmonization) from the [Harmonization repo](https://github.com/serre-lab/harmonization)\r\n- added various DINO models to the available [`ssl`](https://vicco-group.github.io/thingsvision/AvailableModels.html#ssl) models\r\n- fixed dependency issues for custom models",
        "html_url": "https://github.com/ViCCo-Group/thingsvision/releases/tag/v2.3",
        "name": "v2.3",
        "release_id": 94626704,
        "tag": "v2.3",
        "tarball_url": "https://api.github.com/repos/ViCCo-Group/thingsvision/tarball/v2.3",
        "type": "Release",
        "url": "https://api.github.com/repos/ViCCo-Group/thingsvision/releases/94626704",
        "value": "https://api.github.com/repos/ViCCo-Group/thingsvision/releases/94626704",
        "zipball_url": "https://api.github.com/repos/ViCCo-Group/thingsvision/zipball/v2.3"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "LukasMut",
          "type": "User"
        },
        "date_created": "2023-02-24T09:49:03Z",
        "date_published": "2023-02-24T09:51:05Z",
        "description": "- added tests for custom model extractor and refactored torch and tensorflow extractor classes",
        "html_url": "https://github.com/ViCCo-Group/thingsvision/releases/tag/v2.2.24",
        "name": "v2.2.24",
        "release_id": 93551372,
        "tag": "v2.2.24",
        "tarball_url": "https://api.github.com/repos/ViCCo-Group/thingsvision/tarball/v2.2.24",
        "type": "Release",
        "url": "https://api.github.com/repos/ViCCo-Group/thingsvision/releases/93551372",
        "value": "https://api.github.com/repos/ViCCo-Group/thingsvision/releases/93551372",
        "zipball_url": "https://api.github.com/repos/ViCCo-Group/thingsvision/zipball/v2.2.24"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "LukasMut",
          "type": "User"
        },
        "date_created": "2023-02-19T20:53:39Z",
        "date_published": "2023-02-22T10:03:49Z",
        "description": "- added various [DINO](https://vicco-group.github.io/thingsvision/AvailableModels.html#ssl) SSL models to `thingsvision` (weights retrieved from [torch.hub](https://pytorch.org/hub/))\r\n",
        "html_url": "https://github.com/ViCCo-Group/thingsvision/releases/tag/v2.2.23",
        "name": "v2.2.23",
        "release_id": 93270555,
        "tag": "v2.2.23",
        "tarball_url": "https://api.github.com/repos/ViCCo-Group/thingsvision/tarball/v2.2.23",
        "type": "Release",
        "url": "https://api.github.com/repos/ViCCo-Group/thingsvision/releases/93270555",
        "value": "https://api.github.com/repos/ViCCo-Group/thingsvision/releases/93270555",
        "zipball_url": "https://api.github.com/repos/ViCCo-Group/thingsvision/zipball/v2.2.23"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "LukasMut",
          "type": "User"
        },
        "date_created": "2023-02-17T14:04:50Z",
        "date_published": "2023-02-17T14:35:53Z",
        "description": "- added `output_type` option for choosing between `torch.Tensor` and `np.ndarray` for type of returned features in `extractor.extract_features(...)` for substantial speed-ups during the extraction process (moving tensors to CPU is costly which is why we want to avoid it wherever possible)\r\n- note that the above is only possible for `backend=\"pt\"` (not for `backend=\"tf\"`)",
        "html_url": "https://github.com/ViCCo-Group/thingsvision/releases/tag/v2.2.22",
        "name": "v2.2.22",
        "release_id": 92845758,
        "tag": "v2.2.22",
        "tarball_url": "https://api.github.com/repos/ViCCo-Group/thingsvision/tarball/v2.2.22",
        "type": "Release",
        "url": "https://api.github.com/repos/ViCCo-Group/thingsvision/releases/92845758",
        "value": "https://api.github.com/repos/ViCCo-Group/thingsvision/releases/92845758",
        "zipball_url": "https://api.github.com/repos/ViCCo-Group/thingsvision/zipball/v2.2.22"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "LukasMut",
          "type": "User"
        },
        "date_created": "2023-02-15T09:59:40Z",
        "date_published": "2023-02-15T10:02:24Z",
        "description": "- added `output_type` option for choosing between `torch.Tensor` and `np.ndarray` for type of returned features in `extractor.extract_features(...)` for substantial speed-ups during the extraction process (moving tensors to CPU is costly which is why we want to avoid it wherever possible)\r\n- note that the above is only possible for `backend=\"pt\"`",
        "html_url": "https://github.com/ViCCo-Group/thingsvision/releases/tag/v2.2.21",
        "name": "v2.2.21",
        "release_id": 92526845,
        "tag": "v2.2.21",
        "tarball_url": "https://api.github.com/repos/ViCCo-Group/thingsvision/tarball/v2.2.21",
        "type": "Release",
        "url": "https://api.github.com/repos/ViCCo-Group/thingsvision/releases/92526845",
        "value": "https://api.github.com/repos/ViCCo-Group/thingsvision/releases/92526845",
        "zipball_url": "https://api.github.com/repos/ViCCo-Group/thingsvision/zipball/v2.2.21"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "LukasMut",
          "type": "User"
        },
        "date_created": "2023-01-18T14:03:30Z",
        "date_published": "2023-01-18T14:05:01Z",
        "description": "- memory issue fixes\r\n- abstract base class\r\n- removed mixin classes",
        "html_url": "https://github.com/ViCCo-Group/thingsvision/releases/tag/v2.2.18",
        "name": "v2.2.18",
        "release_id": 89404366,
        "tag": "v2.2.18",
        "tarball_url": "https://api.github.com/repos/ViCCo-Group/thingsvision/tarball/v2.2.18",
        "type": "Release",
        "url": "https://api.github.com/repos/ViCCo-Group/thingsvision/releases/89404366",
        "value": "https://api.github.com/repos/ViCCo-Group/thingsvision/releases/89404366",
        "zipball_url": "https://api.github.com/repos/ViCCo-Group/thingsvision/zipball/v2.2.18"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "LukasMut",
          "type": "User"
        },
        "date_created": "2023-01-01T15:12:50Z",
        "date_published": "2023-01-01T19:01:14Z",
        "description": "- incorporated `torchtyping` for better data type and shape annotations",
        "html_url": "https://github.com/ViCCo-Group/thingsvision/releases/tag/v2.2.17",
        "name": "v2.2.17",
        "release_id": 87662361,
        "tag": "v2.2.17",
        "tarball_url": "https://api.github.com/repos/ViCCo-Group/thingsvision/tarball/v2.2.17",
        "type": "Release",
        "url": "https://api.github.com/repos/ViCCo-Group/thingsvision/releases/87662361",
        "value": "https://api.github.com/repos/ViCCo-Group/thingsvision/releases/87662361",
        "zipball_url": "https://api.github.com/repos/ViCCo-Group/thingsvision/zipball/v2.2.17"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "LukasMut",
          "type": "User"
        },
        "date_created": "2022-12-20T15:12:54Z",
        "date_published": "2022-12-20T15:17:42Z",
        "description": " - fix for custom model",
        "html_url": "https://github.com/ViCCo-Group/thingsvision/releases/tag/v2.2.16",
        "name": "v2.2.16",
        "release_id": 86664144,
        "tag": "v2.2.16",
        "tarball_url": "https://api.github.com/repos/ViCCo-Group/thingsvision/tarball/v2.2.16",
        "type": "Release",
        "url": "https://api.github.com/repos/ViCCo-Group/thingsvision/releases/86664144",
        "value": "https://api.github.com/repos/ViCCo-Group/thingsvision/releases/86664144",
        "zipball_url": "https://api.github.com/repos/ViCCo-Group/thingsvision/zipball/v2.2.16"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "LukasMut",
          "type": "User"
        },
        "date_created": "2022-12-20T12:41:54Z",
        "date_published": "2022-12-20T12:44:01Z",
        "description": "- file name fix for custom model",
        "html_url": "https://github.com/ViCCo-Group/thingsvision/releases/tag/v2.2.15",
        "name": "v2.2.15",
        "release_id": 86647191,
        "tag": "v2.2.15",
        "tarball_url": "https://api.github.com/repos/ViCCo-Group/thingsvision/tarball/v2.2.15",
        "type": "Release",
        "url": "https://api.github.com/repos/ViCCo-Group/thingsvision/releases/86647191",
        "value": "https://api.github.com/repos/ViCCo-Group/thingsvision/releases/86647191",
        "zipball_url": "https://api.github.com/repos/ViCCo-Group/thingsvision/zipball/v2.2.15"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "LukasMut",
          "type": "User"
        },
        "date_created": "2022-12-20T11:29:59Z",
        "date_published": "2022-12-20T11:32:37Z",
        "description": " - new custom model",
        "html_url": "https://github.com/ViCCo-Group/thingsvision/releases/tag/v2.2.14",
        "name": "v2.2.14",
        "release_id": 86640491,
        "tag": "v2.2.14",
        "tarball_url": "https://api.github.com/repos/ViCCo-Group/thingsvision/tarball/v2.2.14",
        "type": "Release",
        "url": "https://api.github.com/repos/ViCCo-Group/thingsvision/releases/86640491",
        "value": "https://api.github.com/repos/ViCCo-Group/thingsvision/releases/86640491",
        "zipball_url": "https://api.github.com/repos/ViCCo-Group/thingsvision/zipball/v2.2.14"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "LukasMut",
          "type": "User"
        },
        "date_created": "2022-12-13T13:52:25Z",
        "date_published": "2022-12-13T13:53:54Z",
        "description": " - CLI fixes",
        "html_url": "https://github.com/ViCCo-Group/thingsvision/releases/tag/v2.2.13",
        "name": "v2.2.13",
        "release_id": 85869899,
        "tag": "v2.2.13",
        "tarball_url": "https://api.github.com/repos/ViCCo-Group/thingsvision/tarball/v2.2.13",
        "type": "Release",
        "url": "https://api.github.com/repos/ViCCo-Group/thingsvision/releases/85869899",
        "value": "https://api.github.com/repos/ViCCo-Group/thingsvision/releases/85869899",
        "zipball_url": "https://api.github.com/repos/ViCCo-Group/thingsvision/zipball/v2.2.13"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "LukasMut",
          "type": "User"
        },
        "date_created": "2022-12-12T10:59:24Z",
        "date_published": "2022-12-12T11:01:24Z",
        "description": "- merged all self-supervised learning models into a single extractor (`custom` and `vissl` -> `ssl`)\r\n- renamed `VisslExtractor(...)` to `SSLExtractor(...)`",
        "html_url": "https://github.com/ViCCo-Group/thingsvision/releases/tag/v2.2.12",
        "name": "v2.2.12",
        "release_id": 85717051,
        "tag": "v2.2.12",
        "tarball_url": "https://api.github.com/repos/ViCCo-Group/thingsvision/tarball/v2.2.12",
        "type": "Release",
        "url": "https://api.github.com/repos/ViCCo-Group/thingsvision/releases/85717051",
        "value": "https://api.github.com/repos/ViCCo-Group/thingsvision/releases/85717051",
        "zipball_url": "https://api.github.com/repos/ViCCo-Group/thingsvision/zipball/v2.2.12"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "LukasMut",
          "type": "User"
        },
        "date_created": "2022-12-06T13:37:13Z",
        "date_published": "2022-12-06T13:57:19Z",
        "description": "- Command-line interface (CLI)\r\n- README and docs overhaul",
        "html_url": "https://github.com/ViCCo-Group/thingsvision/releases/tag/v2.2.11",
        "name": "v2.2.11",
        "release_id": 85148818,
        "tag": "v2.2.11",
        "tarball_url": "https://api.github.com/repos/ViCCo-Group/thingsvision/tarball/v2.2.11",
        "type": "Release",
        "url": "https://api.github.com/repos/ViCCo-Group/thingsvision/releases/85148818",
        "value": "https://api.github.com/repos/ViCCo-Group/thingsvision/releases/85148818",
        "zipball_url": "https://api.github.com/repos/ViCCo-Group/thingsvision/zipball/v2.2.11"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "LukasMut",
          "type": "User"
        },
        "date_created": "2022-11-17T16:57:58Z",
        "date_published": "2022-11-18T08:39:45Z",
        "description": "- renamed custom SSL models to include a suffix that denotes the architecture (`svaw.py` -> `swav_rn50.py`)\r\n- added `Vicreg` to custom SSL models ",
        "html_url": "https://github.com/ViCCo-Group/thingsvision/releases/tag/v2.2.10",
        "name": "v2.2.10",
        "release_id": 83506461,
        "tag": "v2.2.10",
        "tarball_url": "https://api.github.com/repos/ViCCo-Group/thingsvision/tarball/v2.2.10",
        "type": "Release",
        "url": "https://api.github.com/repos/ViCCo-Group/thingsvision/releases/83506461",
        "value": "https://api.github.com/repos/ViCCo-Group/thingsvision/releases/83506461",
        "zipball_url": "https://api.github.com/repos/ViCCo-Group/thingsvision/zipball/v2.2.10"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "LukasMut",
          "type": "User"
        },
        "date_created": "2022-11-16T14:13:13Z",
        "date_published": "2022-11-16T14:15:22Z",
        "description": "- a few bug fixes and refactorings",
        "html_url": "https://github.com/ViCCo-Group/thingsvision/releases/tag/v2.2.8",
        "name": "v2.2.8",
        "release_id": 83265631,
        "tag": "v2.2.8",
        "tarball_url": "https://api.github.com/repos/ViCCo-Group/thingsvision/tarball/v2.2.8",
        "type": "Release",
        "url": "https://api.github.com/repos/ViCCo-Group/thingsvision/releases/83265631",
        "value": "https://api.github.com/repos/ViCCo-Group/thingsvision/releases/83265631",
        "zipball_url": "https://api.github.com/repos/ViCCo-Group/thingsvision/zipball/v2.2.8"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "LukasMut",
          "type": "User"
        },
        "date_created": "2022-11-11T12:19:34Z",
        "date_published": "2022-11-11T12:33:40Z",
        "description": "- [vissl](https://vissl.ai/) models are now available",
        "html_url": "https://github.com/ViCCo-Group/thingsvision/releases/tag/v2.2.5",
        "name": "v2.2.5",
        "release_id": 82790905,
        "tag": "v2.2.5",
        "tarball_url": "https://api.github.com/repos/ViCCo-Group/thingsvision/tarball/v2.2.5",
        "type": "Release",
        "url": "https://api.github.com/repos/ViCCo-Group/thingsvision/releases/82790905",
        "value": "https://api.github.com/repos/ViCCo-Group/thingsvision/releases/82790905",
        "zipball_url": "https://api.github.com/repos/ViCCo-Group/thingsvision/zipball/v2.2.5"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "LukasMut",
          "type": "User"
        },
        "date_created": "2022-11-09T17:00:25Z",
        "date_published": "2022-11-09T17:03:06Z",
        "description": " - major `README` overhaul \r\n - enabled `thingsvision.__version__` for automatic versioning ",
        "html_url": "https://github.com/ViCCo-Group/thingsvision/releases/tag/v2.2.4",
        "name": "v2.2.4",
        "release_id": 82581634,
        "tag": "v2.2.4",
        "tarball_url": "https://api.github.com/repos/ViCCo-Group/thingsvision/tarball/v2.2.4",
        "type": "Release",
        "url": "https://api.github.com/repos/ViCCo-Group/thingsvision/releases/82581634",
        "value": "https://api.github.com/repos/ViCCo-Group/thingsvision/releases/82581634",
        "zipball_url": "https://api.github.com/repos/ViCCo-Group/thingsvision/zipball/v2.2.4"
      },
      "technique": "GitHub_API"
    }
  ],
  "run": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Working locally",
        "parent_header": [
          ":notebook_with_decorative_cover: Table of Contents",
          ":running: Getting Started",
          ":computer: Setting up your environment"
        ],
        "type": "Text_excerpt",
        "value": "First, create a new `conda environment` with Python version 3.8, 3.9, or 3.10 e.g. by using `conda`:\n\n```bash\n$ conda create -n thingsvision python=3.9\n$ conda activate thingsvision\n```\n\nThen, activate the environment and simply install `thingsvision` via running the following `pip` command in your terminal.\n\n```bash\n$ pip install --upgrade thingsvision\n$ pip install git+https://github.com/openai/CLIP.git\n```\n\nIf you want to extract features for [harmonized models](https://vicco-group.github.io/thingsvision/AvailableModels.html#harmonization) from the [Harmonization repo](https://github.com/serre-lab/harmonization), you have to additionally run the following `pip` command in your `thingsvision` environment (FYI: as of now, this seems to be working smoothly on Ubuntu only but not on macOS),\n\n```bash\n$ pip install git+https://github.com/serre-lab/Harmonization.git\n$ pip install keras-cv-attention-models>=1.3.5\n```\n\nIf you want to extract features for [DreamSim](https://dreamsim-nights.github.io/) from the [DreamSim repo](https://github.com/ssundaram21/dreamsim), you have to additionally run the following `pip` command in your `thingsvision` environment,\n\n```bash\n$ pip install dreamsim==0.1.2\n```\n\nSee the [docs](https://vicco-group.github.io/thingsvision/AvailableModels.html#dreamsim) for which `DreamSim` models are available in `thingsvision`.\n"
      },
      "source": "https://raw.githubusercontent.com/ViCCo-Group/THINGSvision/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Google Colab",
        "parent_header": [
          ":notebook_with_decorative_cover: Table of Contents",
          ":running: Getting Started",
          ":computer: Setting up your environment"
        ],
        "type": "Text_excerpt",
        "value": "Alternatively, you can use Google Colab to play around with `thingsvision` by uploading your image data to Google Drive (via directory mounting).\nYou can find the jupyter notebook using `PyTorch` [here](https://colab.research.google.com/github/ViCCo-Group/thingsvision/blob/master/notebooks/pytorch.ipynb) and the `TensorFlow` example [here](https://colab.research.google.com/github/ViCCo-Group/thingsvision/blob/master/notebooks/tensorflow.ipynb).\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>\n\n\n"
      },
      "source": "https://raw.githubusercontent.com/ViCCo-Group/THINGSvision/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Command Line Interface (CLI)",
        "parent_header": [
          ":notebook_with_decorative_cover: Table of Contents",
          ":running: Getting Started",
          ":mag: Basic usage"
        ],
        "type": "Text_excerpt",
        "value": "`thingsvision` was designed to simplify feature extraction. If you have some folder of images (e.g., `./images`) and want to extract features for each of these images without opening a Jupyter Notebook instance or writing a Python script, it's probably easiest to use our CLI. The interface includes two options,\n\n- `thingsvision show-model`\n- `thingsvision extract-features`\n\nExample calls might look as follows:\n\n```bash\nthingsvision show-model --model-name \"alexnet\" --source \"torchvision\"\nthingsvision extract-features --image-root \"./data\" --model-name \"alexnet\" --module-name \"features.10\" --batch-size 32 --device \"cuda\" --source \"torchvision\" --file-format \"npy\" --out-path \"./features\"\n```\n\nSee `thingsvision show-model -h` and `thingsvision extract-features -h` for a list of all possible arguments. Note that the CLI provides just the basic extraction functionalities but is probably enough for most users that don't want to dive too deep into various models and modules. If you need more fine-grained control over the extraction itself, we recommend to use the python package directly and write your own Python script.\n"
      },
      "source": "https://raw.githubusercontent.com/ViCCo-Group/THINGSvision/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Python commands",
        "parent_header": [
          ":notebook_with_decorative_cover: Table of Contents",
          ":running: Getting Started",
          ":mag: Basic usage"
        ],
        "type": "Text_excerpt",
        "value": "To do this start by importing all the necessary components and instantiating a `thingsvision` extractor. Here we're using `CLIP` from the official clip repo as the model to extract features from and also load the model to GPU for faster inference,\n\n```python\nimport torch\nfrom thingsvision import get_extractor\nfrom thingsvision.utils.storing import save_features\nfrom thingsvision.utils.data import ImageDataset, DataLoader\n\nmodel_name = 'clip'\nsource = 'custom'\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nmodel_parameters = {\n    'variant': 'ViT-L/14'\n}\n\nextractor = get_extractor(\n  model_name=model_name,\n  source=source,\n  device=device,\n  pretrained=True,\n  model_parameters=model_parameters,\n)\n```\n\nAs a next step, create both dataset and dataloader for your images. We assume that all of your images are in a single `root` directory which can contain subfolders (e.g., for individual classes). Therefore, we leverage the `ImageDataset` class. \n\n```python\nroot='path/to/your/image/directory' # (e.g., './images/)\nbatch_size = 32\n\ndataset = ImageDataset(\n    root=root,\n    out_path='path/to/features',\n    backend=extractor.get_backend(), # backend framework of model\n    transforms=extractor.get_transformations(resize_dim=256, crop_dim=224) # set the input dimensionality to whichever values are required for your pretrained model\n)\n\nbatches = DataLoader(\n    dataset=dataset,\n    batch_size=batch_size,\n    backend=extractor.get_backend() # backend framework of model\n)\n```\n\nNow all that is left is to extract the image features and store them on disk! Here we're extracting features from the image encoder module of CLIP (`visual`), but if you don't know which modules are available for a given model, just call `extractor.show_model()` to print all the modules.\n\n```python\nmodule_name = 'visual'\n\nfeatures = extractor.extract_features(\n    batches=batches,\n    module_name=module_name,\n    flatten_acts=True,\n    output_type=\"ndarray\", # or \"tensor\" (only applicable to PyTorch models of which CLIP and DINO are ones!)\n)\n\nsave_features(features, out_path='path/to/features', file_format='npy') # file_format can be set to \"npy\", \"txt\", \"mat\", \"pt\", or \"hdf5\"\n```\n"
      },
      "source": "https://raw.githubusercontent.com/ViCCo-Group/THINGSvision/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "PyTorch",
        "parent_header": [
          ":notebook_with_decorative_cover: Table of Contents",
          ":running: Getting Started",
          ":mag: Basic usage",
          "Feature extraction with custom data pipeline"
        ],
        "type": "Text_excerpt",
        "value": "```python\nmodule_name = 'visual'\n\n# your custom dataset and dataloader classes come here (for example, a PyTorch data loader)\nmy_dataset = ...\nmy_dataloader = ...\n\nwith extractor.batch_extraction(module_name, output_type=\"tensor\") as e: \n  for batch in my_dataloader:\n    ... # whatever preprocessing you want to add to the batch\n    feature_batch = e.extract_batch(\n      batch=batch,\n      flatten_acts=True, # flatten 2D feature maps from an early convolutional or attention layer\n      )\n    ... # whatever post-processing you want to add to the extracted features\n```\n"
      },
      "source": "https://raw.githubusercontent.com/ViCCo-Group/THINGSvision/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "TensorFlow / Keras",
        "parent_header": [
          ":notebook_with_decorative_cover: Table of Contents",
          ":running: Getting Started",
          ":mag: Basic usage",
          "Feature extraction with custom data pipeline"
        ],
        "type": "Text_excerpt",
        "value": "```python\nmodule_name = 'visual'\n\n# your custom dataset and dataloader classes come here (for example, TFRecords files)\nmy_dataset = ...\nmy_dataloader = ...\n\nfor batch in my_dataloader:\n  ... # whatever preprocessing you want to add to the batch\n  feature_batch = extractor.extract_batch(\n    batch=batch,\n    module_name=module_name,\n    flatten_acts=True, # flatten 2D feature maps from an early convolutional or attention layer\n    )\n  ... # whatever post-processing you want to add to the extracted features\n```\n"
      },
      "source": "https://raw.githubusercontent.com/ViCCo-Group/THINGSvision/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Human alignment",
        "parent_header": [
          ":notebook_with_decorative_cover: Table of Contents",
          ":running: Getting Started",
          ":mag: Basic usage"
        ],
        "type": "Text_excerpt",
        "value": "*Human alignment*: If you want to align the extracted features with human object similarity according to the approach introduced in *[Improving neural network representations using human similiarty judgments](https://proceedings.neurips.cc/paper_files/paper/2023/hash/9febda1c8344cc5f2d51713964864e93-Abstract-Conference.html)* you can optionally `align` the extracted features using the following method:\n\n```python\naligned_features = extractor.align(\n    features=features,\n    module_name=module_name,\n    alignment_type=\"gLocal\",\n)\n```\n\nFor more information about the available alignment types and aligned models see the [docs](https://vicco-group.github.io/thingsvision/Alignment.html). \n\n\n_For more examples on the many models available in `thingsvision` and explanations of additional functionality like how to optionally turn off center cropping, how to use HDF5 datasets (e.g. NSD stimuli), how to perform RSA or CKA, or how to easily extract features for the [THINGS image database](https://osf.io/jum2f/), please refer to the [Documentation](https://vicco-group.github.io/thingsvision/)._\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>\n\n\n"
      },
      "source": "https://raw.githubusercontent.com/ViCCo-Group/THINGSvision/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "somef_missing_categories": [
    "acknowledgement",
    "download",
    "requirements",
    "contact",
    "contributors",
    "faq",
    "support",
    "identifier",
    "has_build_file"
  ],
  "somef_provenance": {
    "date": "2024-10-06 04:30:16",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 152
      },
      "technique": "GitHub_API"
    }
  ],
  "type": [
    {
      "confidence": 0.82,
      "result": {
        "type": "String",
        "value": "commandline-application"
      },
      "technique": "software_type_heuristics"
    }
  ],
  "usage": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Working locally",
        "parent_header": [
          ":notebook_with_decorative_cover: Table of Contents",
          ":running: Getting Started",
          ":computer: Setting up your environment"
        ],
        "type": "Text_excerpt",
        "value": "First, create a new `conda environment` with Python version 3.8, 3.9, or 3.10 e.g. by using `conda`:\n\n```bash\n$ conda create -n thingsvision python=3.9\n$ conda activate thingsvision\n```\n\nThen, activate the environment and simply install `thingsvision` via running the following `pip` command in your terminal.\n\n```bash\n$ pip install --upgrade thingsvision\n$ pip install git+https://github.com/openai/CLIP.git\n```\n\nIf you want to extract features for [harmonized models](https://vicco-group.github.io/thingsvision/AvailableModels.html#harmonization) from the [Harmonization repo](https://github.com/serre-lab/harmonization), you have to additionally run the following `pip` command in your `thingsvision` environment (FYI: as of now, this seems to be working smoothly on Ubuntu only but not on macOS),\n\n```bash\n$ pip install git+https://github.com/serre-lab/Harmonization.git\n$ pip install keras-cv-attention-models>=1.3.5\n```\n\nIf you want to extract features for [DreamSim](https://dreamsim-nights.github.io/) from the [DreamSim repo](https://github.com/ssundaram21/dreamsim), you have to additionally run the following `pip` command in your `thingsvision` environment,\n\n```bash\n$ pip install dreamsim==0.1.2\n```\n\nSee the [docs](https://vicco-group.github.io/thingsvision/AvailableModels.html#dreamsim) for which `DreamSim` models are available in `thingsvision`.\n"
      },
      "source": "https://raw.githubusercontent.com/ViCCo-Group/THINGSvision/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Google Colab",
        "parent_header": [
          ":notebook_with_decorative_cover: Table of Contents",
          ":running: Getting Started",
          ":computer: Setting up your environment"
        ],
        "type": "Text_excerpt",
        "value": "Alternatively, you can use Google Colab to play around with `thingsvision` by uploading your image data to Google Drive (via directory mounting).\nYou can find the jupyter notebook using `PyTorch` [here](https://colab.research.google.com/github/ViCCo-Group/thingsvision/blob/master/notebooks/pytorch.ipynb) and the `TensorFlow` example [here](https://colab.research.google.com/github/ViCCo-Group/thingsvision/blob/master/notebooks/tensorflow.ipynb).\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>\n\n\n"
      },
      "source": "https://raw.githubusercontent.com/ViCCo-Group/THINGSvision/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Command Line Interface (CLI)",
        "parent_header": [
          ":notebook_with_decorative_cover: Table of Contents",
          ":running: Getting Started",
          ":mag: Basic usage"
        ],
        "type": "Text_excerpt",
        "value": "`thingsvision` was designed to simplify feature extraction. If you have some folder of images (e.g., `./images`) and want to extract features for each of these images without opening a Jupyter Notebook instance or writing a Python script, it's probably easiest to use our CLI. The interface includes two options,\n\n- `thingsvision show-model`\n- `thingsvision extract-features`\n\nExample calls might look as follows:\n\n```bash\nthingsvision show-model --model-name \"alexnet\" --source \"torchvision\"\nthingsvision extract-features --image-root \"./data\" --model-name \"alexnet\" --module-name \"features.10\" --batch-size 32 --device \"cuda\" --source \"torchvision\" --file-format \"npy\" --out-path \"./features\"\n```\n\nSee `thingsvision show-model -h` and `thingsvision extract-features -h` for a list of all possible arguments. Note that the CLI provides just the basic extraction functionalities but is probably enough for most users that don't want to dive too deep into various models and modules. If you need more fine-grained control over the extraction itself, we recommend to use the python package directly and write your own Python script.\n"
      },
      "source": "https://raw.githubusercontent.com/ViCCo-Group/THINGSvision/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Python commands",
        "parent_header": [
          ":notebook_with_decorative_cover: Table of Contents",
          ":running: Getting Started",
          ":mag: Basic usage"
        ],
        "type": "Text_excerpt",
        "value": "To do this start by importing all the necessary components and instantiating a `thingsvision` extractor. Here we're using `CLIP` from the official clip repo as the model to extract features from and also load the model to GPU for faster inference,\n\n```python\nimport torch\nfrom thingsvision import get_extractor\nfrom thingsvision.utils.storing import save_features\nfrom thingsvision.utils.data import ImageDataset, DataLoader\n\nmodel_name = 'clip'\nsource = 'custom'\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nmodel_parameters = {\n    'variant': 'ViT-L/14'\n}\n\nextractor = get_extractor(\n  model_name=model_name,\n  source=source,\n  device=device,\n  pretrained=True,\n  model_parameters=model_parameters,\n)\n```\n\nAs a next step, create both dataset and dataloader for your images. We assume that all of your images are in a single `root` directory which can contain subfolders (e.g., for individual classes). Therefore, we leverage the `ImageDataset` class. \n\n```python\nroot='path/to/your/image/directory' # (e.g., './images/)\nbatch_size = 32\n\ndataset = ImageDataset(\n    root=root,\n    out_path='path/to/features',\n    backend=extractor.get_backend(), # backend framework of model\n    transforms=extractor.get_transformations(resize_dim=256, crop_dim=224) # set the input dimensionality to whichever values are required for your pretrained model\n)\n\nbatches = DataLoader(\n    dataset=dataset,\n    batch_size=batch_size,\n    backend=extractor.get_backend() # backend framework of model\n)\n```\n\nNow all that is left is to extract the image features and store them on disk! Here we're extracting features from the image encoder module of CLIP (`visual`), but if you don't know which modules are available for a given model, just call `extractor.show_model()` to print all the modules.\n\n```python\nmodule_name = 'visual'\n\nfeatures = extractor.extract_features(\n    batches=batches,\n    module_name=module_name,\n    flatten_acts=True,\n    output_type=\"ndarray\", # or \"tensor\" (only applicable to PyTorch models of which CLIP and DINO are ones!)\n)\n\nsave_features(features, out_path='path/to/features', file_format='npy') # file_format can be set to \"npy\", \"txt\", \"mat\", \"pt\", or \"hdf5\"\n```\n"
      },
      "source": "https://raw.githubusercontent.com/ViCCo-Group/THINGSvision/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "PyTorch",
        "parent_header": [
          ":notebook_with_decorative_cover: Table of Contents",
          ":running: Getting Started",
          ":mag: Basic usage",
          "Feature extraction with custom data pipeline"
        ],
        "type": "Text_excerpt",
        "value": "```python\nmodule_name = 'visual'\n\n# your custom dataset and dataloader classes come here (for example, a PyTorch data loader)\nmy_dataset = ...\nmy_dataloader = ...\n\nwith extractor.batch_extraction(module_name, output_type=\"tensor\") as e: \n  for batch in my_dataloader:\n    ... # whatever preprocessing you want to add to the batch\n    feature_batch = e.extract_batch(\n      batch=batch,\n      flatten_acts=True, # flatten 2D feature maps from an early convolutional or attention layer\n      )\n    ... # whatever post-processing you want to add to the extracted features\n```\n"
      },
      "source": "https://raw.githubusercontent.com/ViCCo-Group/THINGSvision/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "TensorFlow / Keras",
        "parent_header": [
          ":notebook_with_decorative_cover: Table of Contents",
          ":running: Getting Started",
          ":mag: Basic usage",
          "Feature extraction with custom data pipeline"
        ],
        "type": "Text_excerpt",
        "value": "```python\nmodule_name = 'visual'\n\n# your custom dataset and dataloader classes come here (for example, TFRecords files)\nmy_dataset = ...\nmy_dataloader = ...\n\nfor batch in my_dataloader:\n  ... # whatever preprocessing you want to add to the batch\n  feature_batch = extractor.extract_batch(\n    batch=batch,\n    module_name=module_name,\n    flatten_acts=True, # flatten 2D feature maps from an early convolutional or attention layer\n    )\n  ... # whatever post-processing you want to add to the extracted features\n```\n"
      },
      "source": "https://raw.githubusercontent.com/ViCCo-Group/THINGSvision/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Human alignment",
        "parent_header": [
          ":notebook_with_decorative_cover: Table of Contents",
          ":running: Getting Started",
          ":mag: Basic usage"
        ],
        "type": "Text_excerpt",
        "value": "*Human alignment*: If you want to align the extracted features with human object similarity according to the approach introduced in *[Improving neural network representations using human similiarty judgments](https://proceedings.neurips.cc/paper_files/paper/2023/hash/9febda1c8344cc5f2d51713964864e93-Abstract-Conference.html)* you can optionally `align` the extracted features using the following method:\n\n```python\naligned_features = extractor.align(\n    features=features,\n    module_name=module_name,\n    alignment_type=\"gLocal\",\n)\n```\n\nFor more information about the available alignment types and aligned models see the [docs](https://vicco-group.github.io/thingsvision/Alignment.html). \n\n\n_For more examples on the many models available in `thingsvision` and explanations of additional functionality like how to optionally turn off center cropping, how to use HDF5 datasets (e.g. NSD stimuli), how to perform RSA or CKA, or how to easily extract features for the [THINGS image database](https://osf.io/jum2f/), please refer to the [Documentation](https://vicco-group.github.io/thingsvision/)._\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>\n\n\n"
      },
      "source": "https://raw.githubusercontent.com/ViCCo-Group/THINGSvision/master/README.md",
      "technique": "header_analysis"
    }
  ]
}