{
  "application_domain": [
    {
      "confidence": 20.24,
      "result": {
        "type": "String",
        "value": "Computer Vision"
      },
      "technique": "supervised_classification"
    }
  ],
  "citation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Reference",
        "parent_header": [
          "netAE: network-enhanced autoencoder"
        ],
        "type": "Text_excerpt",
        "value": "[Dong, Z and Alterovitz, G (2020). netAE: Semi-supervised dimensionality reduction of single-cell RNA sequencing to facilitate cell labeling. *Bioinformatics*.](https://doi.org/10.1093/bioinformatics/btaa669)\n"
      },
      "source": "https://raw.githubusercontent.com/LeoZDong/netAE/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/LeoZDong/netAE"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2019-10-17T08:52:19Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2024-08-22T08:11:33Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "Network-enhanced autoencoder (netAE) is a semi-supervised dimensionality reduction method."
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Data description",
        "parent_header": [
          "netAE: network-enhanced autoencoder"
        ],
        "type": "Text_excerpt",
        "value": "We describe the three datasets we used in our paper. Specifically, we have\n- Cortex dataset:\n    - Zeisel, A. et al. (2015). Cell types in the mouse cortex and hippocampus revealed by single-cell rna-seq. Science, 347(6226), 1138\u20131142.\n    - 3005 samples, 19972 genes, and 7 cell classes\n- Embryo dataset:\n    - Petropoulos, S. et al. (2016). Single-cell rna-seq reveals lineage and x chromosome dynamics in human preimplantation embryos. Cell, 165(4), 1012\u20131026.\n    - 1529 samples, 24444 genes, and 5 cell classes\n- HSC dataset:\n    - Nestorowa, S. et al. (2016). A single-cell resolution map of mouse hematopoietic stem and progenitor cell differentiation. Blood, 128(8), e20\u2013e31.\n    - 1920 samples, 24557 genes, and 3 cell classes\n\nAll datasets could be downloaded from the link provided in the original paper.\n"
      },
      "source": "https://raw.githubusercontent.com/LeoZDong/netAE/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 0.9927766518686036,
      "result": {
        "original_header": "netAE: network-enhanced autoencoder",
        "type": "Text_excerpt",
        "value": "Network-enhanced autoencoder (netAE) is a semi-supervised dimensionality reduction method. It was specifically designed to facilitate cell labeling of single cell RNA-sequencing data.\n \n"
      },
      "source": "https://raw.githubusercontent.com/LeoZDong/netAE/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9139897281809917,
      "result": {
        "original_header": "Important Note",
        "type": "Text_excerpt",
        "value": "This code base is a bit old at this time, so some implementation flaws do not necessarily reflect methodology flaws. Initially it was created to run experiments on medium-sized datasets mentioned in the paper's experiments section. I have seen complaints that the code wouldn't work on super large datasets because it is requesting an unreasonably large amount of memory. This is most likely because my implementation of the modularity calculation is matrix-based for parallelization, but it is much less data-efficient. In cases where you have a large set of labeled data that needs to go through the modularity calculation, consider changing to an iteration-based implementation. Alternatively, you can also try changing the \"weighted modularity\" to \"sparsely weighted modularity\" by discarding connections that are too weak. \nAs with many neural networks, always tune hyperparameters for your particular datasets before settling on model performance. On the three datasets that I ran my experiment on, I was able to get good results without much tuning at all. But that does not mean the model could work on any dataset without tuning.  \n"
      },
      "source": "https://raw.githubusercontent.com/LeoZDong/netAE/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9284790625703593,
      "result": {
        "original_header": "Data loading",
        "type": "Text_excerpt",
        "value": "The `data.py` script handles data loading and preprocessing. For example, `dataset = Data(data_path, labeled_size=10, prep_method=\"log\")` loads the the dataset from `data_path`, randomly assigns 10 samples per class to be labeled, and preprocesses by taking the log of the raw values. Within the data folder specified by `data_path`, the numpy array `dataset_matched.npy` contains the data matrix and `gene_names.npy` contains the names of the genes (not used in training, just for reference if needed). Note that the data matrix has shape (nsamples, ngenes), so the samples are rows and the genes are columns. \nTo use the data for training, `dataset.load_all()` returns the following:\n- `expr`: preprocessed expression matrix as a numpy array\n- `lab_full`: labels of all samples\n- `labeled_idx`: indices of the randomly selected labeled set\n- `unlabeled_idx`: indices of the rest of the samples\n- `info`: additional dictionary containing information of the dataset. `info[\"cell_type\"]` is a dictionary that maps each label to the name of the cell type. `info[\"cell_id\"]` contains the cell ID in the original dataset. `info[\"gene_names\"]` contains the gene names of the dataset. \nTo load a small subset of the samples for testing, call `dataset.load_subset(p)` instead, where `p` specifies the percentage of all samples to load.\n \n"
      },
      "source": "https://raw.githubusercontent.com/LeoZDong/netAE/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/LeoZDong/netAE/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 4
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/LeoZDong/netAE/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "LeoZDong/netAE"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "netAE: network-enhanced autoencoder"
      },
      "source": "https://raw.githubusercontent.com/LeoZDong/netAE/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/LeoZDong/netAE/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ""
      },
      "technique": "GitHub_API"
    }
  ],
  "license": [
    {
      "confidence": 1,
      "result": {
        "name": "MIT License",
        "spdx_id": "MIT",
        "type": "License",
        "url": "https://api.github.com/licenses/mit",
        "value": "https://api.github.com/licenses/mit"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "type": "File_dump",
        "value": "MIT License\n\nCopyright (c) 2019 Zhengyang Dong\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
      },
      "source": "https://raw.githubusercontent.com/LeoZDong/netAE/master/LICENSE",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "License",
        "parent_header": [
          "netAE: network-enhanced autoencoder"
        ],
        "type": "Text_excerpt",
        "value": "This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details\n"
      },
      "source": "https://raw.githubusercontent.com/LeoZDong/netAE/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "netAE"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "User",
        "value": "LeoZDong"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 71451,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/LeoZDong/netAE/master/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "releases": [
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "LeoZDong",
          "type": "User"
        },
        "date_created": "2019-10-17T08:53:32Z",
        "date_published": "2020-03-02T09:09:25Z",
        "description": "Complete and functional code. Lacking proper readme and instructions.",
        "html_url": "https://github.com/LeoZDong/netAE/releases/tag/v0.1",
        "name": "Pre-release",
        "release_id": 24122769,
        "tag": "v0.1",
        "tarball_url": "https://api.github.com/repos/LeoZDong/netAE/tarball/v0.1",
        "type": "Release",
        "url": "https://api.github.com/repos/LeoZDong/netAE/releases/24122769",
        "value": "https://api.github.com/repos/LeoZDong/netAE/releases/24122769",
        "zipball_url": "https://api.github.com/repos/LeoZDong/netAE/zipball/v0.1"
      },
      "technique": "GitHub_API"
    }
  ],
  "requirements": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Prerequisites",
        "parent_header": [
          "netAE: network-enhanced autoencoder",
          "Getting Started"
        ],
        "type": "Text_excerpt",
        "value": "- pytorch 1.1\n- scikit-learn 0.22\n- numpy 1.18\n- pandas 1.0\n"
      },
      "source": "https://raw.githubusercontent.com/LeoZDong/netAE/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "somef_missing_categories": [
    "installation",
    "acknowledgement",
    "run",
    "download",
    "contact",
    "contributors",
    "documentation",
    "faq",
    "support",
    "identifier",
    "has_build_file",
    "executable_example"
  ],
  "somef_provenance": {
    "date": "2024-10-06 10:58:43",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 7
      },
      "technique": "GitHub_API"
    }
  ],
  "usage": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Getting Started",
        "parent_header": [
          "netAE: network-enhanced autoencoder"
        ],
        "type": "Text_excerpt",
        "value": "Clone the repository to your local directory.\n"
      },
      "source": "https://raw.githubusercontent.com/LeoZDong/netAE/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Training a netAE model",
        "parent_header": [
          "netAE: network-enhanced autoencoder",
          "Basic Usage"
        ],
        "type": "Text_excerpt",
        "value": "The `run.py` script handles training. Train the model using the following command and some important argument parsers:\n```\npython run.py\n## environment setup\n--data-path             # path to dataset folder\n--save-path             # path to save trained models\n--dataset               # name of dataset (used to name model when saved)\n--save_embd             # whether to save the embedded space directly along with the trained model\n\n## model hyperparameters\n--optim                 # name of optimizer\n--lr                    # learning rate\n--dim                   # dimension of the embedded space\n--gamma                 # RBF coefficient for calculating similarity matrix in modularity\n--kappa                 # KL divergence loss weight\n--lambd                 # modularity loss weight\n--phi                   # logistic regression loss weight\n\n## data\n--lab-size              # labeled set size for each cell type\n--lab-ratio             # labeled set ratio for each cell type (specify either lab-size or lab-ratio but not both)\n--seed                  # seed for randomly selecting labeled set\n```\n\nThe script handles data loading as specified above. The default is to load all data and preprocess with the `log` method. One can change the data loader parameters to load a subset or use a different preprocessing method. The default values of the hyperparameters of the model are set to be the combination used in the paper. Therefore, one can simply run `python run.py --data-path DATA_PATH --save-path SAVE_PATH --dataset DATASET` to train the model with the dataset specified in `DATA_PATH` with name `DATASET` and save the trained model in `SAVE_PATH`.\n\nAlternatively, one may call `train_netAE(all_data, labeled_data, labeled_lab, save_path, embd_save_path, args=None, params=params)` method from `netAE.py`, which directly returns the Pytorch model state dictionary of the trained model. This is easier if the trained model should be used in subsequent tasks. In this case, it is easier to pass in hyperparameters as a `params` dictionary, instead of the argument parser.\n"
      },
      "source": "https://raw.githubusercontent.com/LeoZDong/netAE/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Performing classification with trained netAE model",
        "parent_header": [
          "netAE: network-enhanced autoencoder",
          "Basic Usage"
        ],
        "type": "Text_excerpt",
        "value": "After training, one may want to use a classifier on the embedded space to test its classification accuracy. The `inference.py` script deals with comparing classification accuracy of netAE with other baseline models when using KNN and logistic regression, two simple classifiers. To start, make sure netAE, AE (the unsuperivsed counterpart), scVI, PCA, and ZIFA are trained and have their embedded spaces located in `MODEL_PATH`. Then simply pass in `--data-path`, `--model-path`, `--lab-size`, and `--dataset`. Additionally, to ensure that the labeled set used in training netAE is the same as here, make sure that you pass in the same seed `--seed` here as when training netAE.\n"
      },
      "source": "https://raw.githubusercontent.com/LeoZDong/netAE/master/README.md",
      "technique": "header_analysis"
    }
  ]
}