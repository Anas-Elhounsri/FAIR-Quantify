{
  "application_domain": [
    {
      "confidence": 21.5,
      "result": {
        "type": "String",
        "value": "Computer Vision"
      },
      "technique": "supervised_classification"
    }
  ],
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/shion-h/Umibato"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2021-01-25T09:04:47Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2023-11-23T08:11:31Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "Unsupervised learning based Microbial Interaction inference method using BAyesian esTimatiOn"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Description",
        "parent_header": [
          "Umibato"
        ],
        "type": "Text_excerpt",
        "value": "Umibato is a method for estimating time-varying microbial interactions using time-series quantitative data based on the Lotka-Volterra equation.\nDetails for this method are described in [this paper](https://www.biorxiv.org/content/10.1101/2021.01.28.428580v2).\nUmibato is implemented as a python Class.\nVariational inference for CTRHMM, the second step of Umibato, is written in C++.\nYou can also perform Umibato on UNIX shells using run_umibato.py."
      },
      "source": "https://raw.githubusercontent.com/shion-h/Umibato/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 0.9958777813442715,
      "result": {
        "original_header": "Directories",
        "type": "Text_excerpt",
        "value": "- data\n    - contains toy data for Umibato tutorials and synthetic data used in the paper\n- notebook\n    - contains the following notebooks:\n        1. conduct_experiments_on_synthetic_datasets.ipynb\n        2. make_test_case.ipynb\n        3. umibato_tutorial.ipynb\n- src\n    - contains C++ source code for estimation of CTRHMM parameters\n- testcase\n    - contains testcase data for CTRHMM implementation\n- umibato\n    - the Python library directory \n"
      },
      "source": "https://raw.githubusercontent.com/shion-h/Umibato/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8174751578153241,
      "result": {
        "original_header": "\"best_results\" directory",
        "type": "Text_excerpt",
        "value": "- ELBO.csv\n    - ELBO value at each iteration.\n- Q.csv\n    - Transition rate matrix. Rows and columns indicate source and destination microbes, respectively.\n- ViterbiPath.csv\n    - Maximum likelihood path of interaction states.\n- phi{state number}.csv\n    - gLVE parameters estimated by CTRHMM.\n- interaction_parameters{state number}.csv\n    - Corrected gLVE parameters (phi{state number}.csv) if using standardizing X.\n    - This file would not be output if not using standardizing X. \n"
      },
      "source": "https://raw.githubusercontent.com/shion-h/Umibato/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8910522309403989,
      "result": {
        "original_header": "\"figures\" directory",
        "type": "Text_excerpt",
        "value": "- gp_regression.pdf\n    - Shows the results of Gaussian process regression.\n- interaction_networks.pdf\n    - Shows the relative interaction intensities (= the interaction parameters divided by the standard deviation of growth rate across series) using Umibato (same as figure 5 in the paper).\n- max_maximized_elbo.pdf\n    - Shows the results of ELBOs (same as figure S5 in the paper).\n- maximized_elbo_boxplot.pdf\n    - Shows the distribution of ELBO values of all trials.\n- viterbi_path.pdf\n    - Shows maximum likelihood path of interaction states for each subject (same as figure 3 in the paper). \n"
      },
      "source": "https://raw.githubusercontent.com/shion-h/Umibato/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8242480474152609,
      "result": {
        "original_header": "\"processed_data\" directory",
        "type": "Text_excerpt",
        "value": "- metadata.csv\n    - Preprocessed metadata (including subject and timepoint information).\n- x.csv\n    - Preprocessed QMPs (preprocess is standardization, for example).\n- y.csv\n    - Estimated growth rate expectations.\n- yVariance.csv\n    - Estimated growth rate variances. \n"
      },
      "source": "https://raw.githubusercontent.com/shion-h/Umibato/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9491673620314759,
      "result": {
        "original_header": "KinitTrialELBO.csv",
        "type": "Text_excerpt",
        "value": "- The summary table of ELBO values for each K_init for each trial. \n"
      },
      "source": "https://raw.githubusercontent.com/shion-h/Umibato/main/README.md",
      "technique": "supervised_classification"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/shion-h/Umibato/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "executable_example": [
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/shion-h/Umibato/main/notebook/make_test_case.ipynb"
      },
      "source": "https://raw.githubusercontent.com/shion-h/Umibato/main/notebook/make_test_case.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/shion-h/Umibato/main/notebook/umibato_tutorial.ipynb"
      },
      "source": "https://raw.githubusercontent.com/shion-h/Umibato/main/notebook/umibato_tutorial.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/shion-h/Umibato/main/notebook/conduct_experiments_on_synthetic_datasets.ipynb"
      },
      "source": "https://raw.githubusercontent.com/shion-h/Umibato/main/notebook/conduct_experiments_on_synthetic_datasets.ipynb",
      "technique": "file_exploration"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 2
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/shion-h/Umibato/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "shion-h/Umibato"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "Umibato"
      },
      "source": "https://raw.githubusercontent.com/shion-h/Umibato/main/README.md",
      "technique": "regular_expression"
    }
  ],
  "has_build_file": [
    {
      "confidence": 1,
      "result": {
        "format": "dockerfile",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/shion-h/Umibato/main/Dockerfile"
      },
      "source": "https://raw.githubusercontent.com/shion-h/Umibato/main/Dockerfile",
      "technique": "file_exploration"
    }
  ],
  "has_script_file": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/shion-h/Umibato/main/src/include/eigen-eigen-323c052e1731/bench/bench_multi_compilers.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/shion-h/Umibato/main/src/include/eigen-eigen-323c052e1731/bench/perf_monitoring/gemm/run.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/shion-h/Umibato/main/src/include/eigen-eigen-323c052e1731/bench/perf_monitoring/gemm/make_plot.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/shion-h/Umibato/main/src/include/eigen-eigen-323c052e1731/bench/btl/data/mk_mean_script.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/shion-h/Umibato/main/src/include/eigen-eigen-323c052e1731/bench/btl/data/mk_gnuplot_script.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/shion-h/Umibato/main/src/include/eigen-eigen-323c052e1731/bench/btl/data/mk_new_gnuplot.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/shion-h/Umibato/main/src/include/eigen-eigen-323c052e1731/bench/btl/data/smooth_all.sh"
      },
      "technique": "file_exploration"
    }
  ],
  "installation": [
    {
      "confidence": 0.9999997976170993,
      "result": {
        "original_header": "Compilation",
        "type": "Text_excerpt",
        "value": "- After preparing the requirements, perform the following:\n```\ncmake -B umibato/bin && cmake --build umibato/bin\n```\n- Then, you can use Umibato from the root directry. \n"
      },
      "source": "https://raw.githubusercontent.com/shion-h/Umibato/main/README.md",
      "technique": "supervised_classification"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/shion-h/Umibato/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ""
      },
      "technique": "GitHub_API"
    }
  ],
  "license": [
    {
      "confidence": 1,
      "result": {
        "name": "Other",
        "spdx_id": "NOASSERTION",
        "type": "License",
        "url": null,
        "value": null
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "type": "File_dump",
        "value": "MIT License\n\nCopyright (c) 2021 Shion Hosoda\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n\nIncludes boost:\n\n          Copyright Joe Coder 2004 - 2006.\n Distributed under the Boost Software License, Version 1.0.\n    (See accompanying file LICENSE_1_0.txt or copy at\n          http://www.boost.org/LICENSE_1_0.txt)\n\nIncludes numpy:\n\nCopyright (c) 2005-2016, NumPy Developers.\nAll rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the NumPy Developers nor the names of any contributors may be used to endorse or promote products derived from this software without specific prior written permission.\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \u201cAS IS\u201d AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\nIncludes pandas:\n\npandas is distributed under a 3-clause (\"Simplified\" or \"New\") BSD\nlicense. Parts of NumPy, SciPy, numpydoc, bottleneck, which all have\nBSD-compatible licenses, are included. Their licenses follow the pandas\nlicense.\n\npandas license\n==============\n\nCopyright (c) 2011-2012, Lambda Foundry, Inc. and PyData Development Team\nAll rights reserved.\n\nCopyright (c) 2008-2011 AQR Capital Management, LLC\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are\nmet:\n\n    * Redistributions of source code must retain the above copyright\n       notice, this list of conditions and the following disclaimer.\n\n    * Redistributions in binary form must reproduce the above\n       copyright notice, this list of conditions and the following\n       disclaimer in the documentation and/or other materials provided\n       with the distribution.\n\n    * Neither the name of the copyright holder nor the names of any\n       contributors may be used to endorse or promote products derived\n       from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDER AND CONTRIBUTORS\n\"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\nLIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\nA PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\nOWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\nSPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\nLIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\nDATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\nTHEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\nAbout the Copyright Holders\n===========================\n\nAQR Capital Management began pandas development in 2008. Development was\nled by Wes McKinney. AQR released the source under this license in 2009.\nWes is now an employee of Lambda Foundry, and remains the pandas project\nlead.\n\nThe PyData Development Team is the collection of developers of the PyData\nproject. This includes all of the PyData sub-projects, including pandas. The\ncore team that coordinates development on GitHub can be found here:\nhttp://github.com/pydata.\n\nFull credits for pandas contributors can be found in the documentation.\n\nOur Copyright Policy\n====================\n\nPyData uses a shared copyright model. Each contributor maintains copyright\nover their contributions to PyData. However, it is important to note that\nthese contributions are typically only changes to the repositories. Thus,\nthe PyData source code, in its entirety, is not the copyright of any single\nperson or institution. Instead, it is the collective copyright of the\nentire PyData Development Team. If individual contributors want to maintain\na record of what changes/contributions they have specific copyright on,\nthey should indicate their copyright in the commit message of the change\nwhen they commit the change to one of the PyData repositories.\n\nWith this in mind, the following banner should be used in any source code\nfile to indicate the copyright and license terms:\n\n#-----------------------------------------------------------------------------\n# Copyright (c) 2012, PyData Development Team\n# All rights reserved.\n#\n# Distributed under the terms of the BSD Simplified License.\n#\n# The full license is in the LICENSE file, distributed with this software.\n#-----------------------------------------------------------------------------\n\nOther licenses can be found in the LICENSES directory.\n\n\nIncludes GPy:\n\nCopyright (c) 2012, the GPy authors\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n    * Redistributions of source code must retain the above copyright\n      notice, this list of conditions and the following disclaimer.\n    * Redistributions in binary form must reproduce the above copyright\n      notice, this list of conditions and the following disclaimer in the\n      documentation and/or other materials provided with the distribution.\n    * Neither the name of the <organization> nor the\n      names of its contributors may be used to endorse or promote products\n      derived from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND\nANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\nWARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\nDISCLAIMED. IN NO EVENT SHALL <COPYRIGHT HOLDER> BE LIABLE FOR ANY\nDIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\n(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\nLOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND\nON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\nSOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\nIncludes matplotlib:\n\n1. This LICENSE AGREEMENT is between the Matplotlib Development Team (\"MDT\"), and the Individual or Organization (\"Licensee\") accessing and otherwise using matplotlib software in source or binary form and its associated documentation.\n\n2. Subject to the terms and conditions of this License Agreement, MDT hereby grants Licensee a nonexclusive, royalty-free, world-wide license to reproduce, analyze, test, perform and/or display publicly, prepare derivative works, distribute, and otherwise use matplotlib 3.1.0 alone or in any derivative version, provided, however, that MDT's License Agreement and MDT's notice of copyright, i.e., \"Copyright (c) 2012-2013 Matplotlib Development Team; All Rights Reserved\" are retained in matplotlib 3.1.0 alone or in any derivative version prepared by Licensee.\n\n3. In the event Licensee prepares a derivative work that is based on or incorporates matplotlib 3.1.0 or any part thereof, and wants to make the derivative work available to others as provided herein, then Licensee hereby agrees to include in any such work a brief summary of the changes made to matplotlib 3.1.0.\n\n4. MDT is making matplotlib 3.1.0 available to Licensee on an \"AS IS\" basis. MDT MAKES NO REPRESENTATIONS OR WARRANTIES, EXPRESS OR IMPLIED. BY WAY OF EXAMPLE, BUT NOT LIMITATION, MDT MAKES NO AND DISCLAIMS ANY REPRESENTATION OR WARRANTY OF MERCHANTABILITY OR FITNESS FOR ANY PARTICULAR PURPOSE OR THAT THE USE OF MATPLOTLIB 3.1.0 WILL NOT INFRINGE ANY THIRD PARTY RIGHTS.\n\n5. MDT SHALL NOT BE LIABLE TO LICENSEE OR ANY OTHER USERS OF MATPLOTLIB 3.1.0 FOR ANY INCIDENTAL, SPECIAL, OR CONSEQUENTIAL DAMAGES OR LOSS AS A RESULT OF MODIFYING, DISTRIBUTING, OR OTHERWISE USING MATPLOTLIB 3.1.0, OR ANY DERIVATIVE THEREOF, EVEN IF ADVISED OF THE POSSIBILITY THEREOF.\n\n6. This License Agreement will automatically terminate upon a material breach of its terms and conditions.\n\n7. Nothing in this License Agreement shall be deemed to create any relationship of agency, partnership, or joint venture between MDT and Licensee. This License Agreement does not grant permission to use MDT trademarks or trade name in a trademark sense to endorse or promote products or services of Licensee, or any third party.\n\n8. By copying, installing or otherwise using matplotlib 3.1.0, Licensee agrees to be bound by the terms and conditions of this License Agreement.\n\nIncludes seaborn:\n\nCopyright (c) 2012-2020, Michael L. Waskom\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n\n* Redistributions of source code must retain the above copyright notice, this\n  list of conditions and the following disclaimer.\n\n* Redistributions in binary form must reproduce the above copyright notice,\n  this list of conditions and the following disclaimer in the documentation\n  and/or other materials provided with the distribution.\n\n* Neither the name of the project nor the names of its\n  contributors may be used to endorse or promote products derived from\n  this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\nFOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\nSERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\nCAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\nOR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n"
      },
      "source": "https://raw.githubusercontent.com/shion-h/Umibato/main/LICENSE",
      "technique": "file_exploration"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "Umibato"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "User",
        "value": "shion-h"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "C++",
        "size": 9269427,
        "type": "Programming_language",
        "value": "C++"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Jupyter Notebook",
        "size": 3925927,
        "type": "Programming_language",
        "value": "Jupyter Notebook"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Fortran",
        "size": 1326303,
        "type": "Programming_language",
        "value": "Fortran"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "CMake",
        "size": 325288,
        "type": "Programming_language",
        "value": "CMake"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "C",
        "size": 195179,
        "type": "Programming_language",
        "value": "C"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Cuda",
        "size": 130730,
        "type": "Programming_language",
        "value": "Cuda"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 33247,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Shell",
        "size": 19541,
        "type": "Programming_language",
        "value": "Shell"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "JavaScript",
        "size": 7960,
        "type": "Programming_language",
        "value": "JavaScript"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "CSS",
        "size": 5504,
        "type": "Programming_language",
        "value": "CSS"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Dockerfile",
        "size": 441,
        "type": "Programming_language",
        "value": "Dockerfile"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Objective-C",
        "size": 85,
        "type": "Programming_language",
        "value": "Objective-C"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/shion-h/Umibato/main/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "requirements": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Requirements",
        "parent_header": [
          "Umibato"
        ],
        "type": "Text_excerpt",
        "value": "- Libraries\n    - Python (3.7.7)\n    - Python library\n        - tqdm (4.48.2)\n        - numpy (1.18.1)\n        - pandas (1.0.3)\n        - GPy (1.9.9)\n        - matplotlib (3.1.3)\n        - seaborn (0.10.1)\n    - g++ Compiler (5.4.0) or clang (12.0.0)\n    - C++ library\n        - boost (1.63.0)\n        - eigen (included in this repository)\n    - cmake (3.16.3)\n- Dataset\n    - Quantitative abundance profiles (QMPs)\n        - The rows and columns indicate microbes and samples, respectively.\n    - Metadata\n        - The rows and columns indicate samples and factors of metadata, respectively.\n        - including \"timepoint\" and \"subjectID\" columns (see an example of data/toy/metadata.tsv)."
      },
      "source": "https://raw.githubusercontent.com/shion-h/Umibato/main/README.md",
      "technique": "header_analysis"
    }
  ],
  "somef_missing_categories": [
    "citation",
    "acknowledgement",
    "run",
    "download",
    "contact",
    "contributors",
    "documentation",
    "faq",
    "support",
    "identifier"
  ],
  "somef_provenance": {
    "date": "2024-10-06 08:05:53",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 10
      },
      "technique": "GitHub_API"
    }
  ],
  "usage": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Docker tutorial",
        "parent_header": [
          "Umibato",
          "Tutorials"
        ],
        "type": "Text_excerpt",
        "value": "Here, Umibato tutorial using Docker is provided.\nWe tested this tutorial using Docker desktop version 3.2.2 on MacOS version 11.2.3. \nAfter cloning this repository, perform the following command on the root directory to build a docker image:\n```\ndocker build -t umibato:1 .\n```\n\"umibato:1\" is an arbitary name. Now, all installations and compilations were finished. Next, you constract and run a container using the following command:\n```\ndocker container run -it --name umibato-1 umibato:1 /bin/bash\n```\n\"umibato-1\" is also an arbitary name. You've been logged in the virtual Docker machine. \n**Now, you can use Umibato.** \n\nThe following shows the commands to reproduce the results.\n\nLet's download the dataset used in the paper. Perform the following commands in the docker shell:\n```\nmkdir -p ./data/bucci_et_al\ncurl -o ./data/bucci_et_al/metadata.tsv https://bitbucket.org/MDSINE/mdsine/raw/a5384a34f4c75402aee9bdb8b90db3d70052ac73/data_diet/metadata.txt\ncurl -o ./data/bucci_et_al/x.tsv https://bitbucket.org/MDSINE/mdsine/raw/a5384a34f4c75402aee9bdb8b90db3d70052ac73/data_diet/counts.txt\n```\nThis dataset is from the following paper:\n\n> Bucci, Vanni, et al. \"MDSINE: Microbial Dynamical Systems INference Engine for microbiome time-series analyses.\" Genome biology 17.1 (2016): 1-17.\n\nRename a column name of the original dataset.\n```\nsed -e 's/measurementID/timepoint/g' ./data/bucci_et_al/metadata.tsv > ./tmp.tsv\ncp ./tmp.tsv ./data/bucci_et_al/metadata.tsv\nrm ./tmp.tsv\n```\nThe following command performs Umibato with 10 CTRHMM trials and one-core CPU:\n```\npython3 run_umibato.py ./data/bucci_et_al/x.tsv ./data/bucci_et_al/metadata.tsv 1 15 --n_init 10 --n_jobs 1 --output_path ./output\n```\nAnd you can see some figures in /home/output/figures. \nThe following command performs the same experiment as the paper:\n```\npython3 run_umibato.py ./data/bucci_et_al/x.tsv ./data/bucci_et_al/metadata.tsv 1 15 --n_init 10000 --n_jobs 100 --output_path ./output\n```\nThis command takes 2-3 hours for 100 parallel. It takes 1 day or more to perform Umibato for 2 parallel."
      },
      "source": "https://raw.githubusercontent.com/shion-h/Umibato/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Notebook tutorial",
        "parent_header": [
          "Umibato",
          "Tutorials"
        ],
        "type": "Text_excerpt",
        "value": "To use the tutorial notebook, you need requirements and compilations below or using Docker. "
      },
      "source": "https://raw.githubusercontent.com/shion-h/Umibato/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Usage",
        "parent_header": [
          "Umibato"
        ],
        "type": "Text_excerpt",
        "value": "python run_umibato.py\n[-h] [-s K_STEP] [-g] [--no_gp_correction]\n[-a AUGMENTATION_SIZE] [-r] [--no_x_standardization]\n[-l Y_VAR_LOWER_BOUND] [-v] [--no_est_y_var]\n[-m MAX_ITER] [-c TOL] [-i N_INIT] [-j N_JOBS]\n[-t RA_THRESHOLD] [-o OUTPUT_PATH]\nqmps_filepath metadata_filepath k_min k_max"
      },
      "source": "https://raw.githubusercontent.com/shion-h/Umibato/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Positional arguments",
        "parent_header": [
          "Umibato",
          "Usage"
        ],
        "type": "Text_excerpt",
        "value": "- **qmps_filepath**\n    - Quantitative microbiota profiles file path.\n- **metadata_filepath**\n    - Metadata file (including \"subjectID\" and \"timepoint\" columns) path.\n- **k_min**\n    - The min number of states.\n- **k_max**\n    - The max number of states.\n"
      },
      "source": "https://raw.githubusercontent.com/shion-h/Umibato/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Optional arguments",
        "parent_header": [
          "Umibato",
          "Usage"
        ],
        "type": "Text_excerpt",
        "value": "- -h, --help\n    - Show the help message and exit.\n- -s K_STEP, --k_step K_STEP\n    - The step number of states (default: 1).\n- -g, --gp_correction\n    - Use of GP correction (default: False).\n        - GP correction replace abundances (variable X) into exponentials of prediction values of GPR (e^E[f]).\n    - --no_gp_correction\n        - No use of GP correction.\n- -a AUGMENTATION_SIZE, --augmentation_size AUGMENTATION_SIZE\n    - The number of data augmented by Gaussian process regression (default: 0).\n- -r, --x_standardization\n    - Standardize x (default: True).\n    - --no_x_standardization\n        - Not standardize x.\n- -l Y_VAR_LOWER_BOUND, --y_var_lower_bound Y_VAR_LOWER_BOUND\n    - The lower bound of y variances (default: 1.0e-4) when using estimation of y variances. \n- -v, --est_y_var\n    - Use estimation of y variances by GPR for each observation point (default: True).\n    - --no_est_y_var\n        - Not use estimation of y variances.\n- -m MAX_ITER, --max_iter MAX_ITER\n    - The max number of iterations (default: 100).\n- -c TOL, --tol TOL\n    - Convergence threshold (default: 1.0e-4).\n- -i N_INIT, --n_init N_INIT\n    - The number of trials (default: 1.0e-4).\n- -j N_JOBS, --n_jobs N_JOBS\n    - The number of jobs (default: 1).\n- -t RA_THRESHOLD, --ra_threshold RA_THRESHOLD\n    - Threshold of relative abundance (default: 0.0).\n- -o OUTPUT_PATH, --output_path OUTPUT_PATH\n    - Path to an output directory (default: '.').\n"
      },
      "source": "https://raw.githubusercontent.com/shion-h/Umibato/main/README.md",
      "technique": "header_analysis"
    }
  ]
}