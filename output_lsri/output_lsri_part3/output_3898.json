{
  "application_domain": [
    {
      "confidence": 0.9734621602064637,
      "result": {
        "type": "String",
        "value": "Graphs"
      },
      "technique": "supervised_classification"
    },
    {
      "confidence": 25.42,
      "result": {
        "type": "String",
        "value": "Natural Language Processing"
      },
      "technique": "supervised_classification"
    },
    {
      "confidence": 4.62,
      "result": {
        "type": "String",
        "value": "Audio"
      },
      "technique": "supervised_classification"
    }
  ],
  "citation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Citation",
        "parent_header": [
          "CellVGAE"
        ],
        "type": "Text_excerpt",
        "value": "```\n@article{10.1093/bioinformatics/btab804,\n    author = {Buterez, David and Bica, Ioana and Tariq, Ifrah and Andr\u00e9s-Terr\u00e9, Helena and Li\u00f2, Pietro},\n    title = \"{CellVGAE: an unsupervised scRNA-seq analysis workflow with graph attention networks}\",\n    journal = {Bioinformatics},\n    volume = {38},\n    number = {5},\n    pages = {1277-1286},\n    year = {2021},\n    month = {12},\n    abstract = \"{Single-cell RNA sequencing allows high-resolution views of individual cells for libraries of up to millions of samples, thus motivating the use of deep learning for analysis. In this study, we introduce the use of graph neural networks for the unsupervised exploration of scRNA-seq data by developing a variational graph autoencoder architecture with graph attention layers that operates directly on the connectivity between cells, focusing on dimensionality reduction and clustering. With the help of several case studies, we show that our model, named CellVGAE, can be effectively used for exploratory analysis even on challenging datasets, by extracting meaningful features from the data and providing the means to visualize and interpret different aspects of the model.We show that CellVGAE is more interpretable than existing scRNA-seq variational architectures by analysing the graph attention coefficients. By drawing parallels with other scRNA-seq studies on interpretability, we assess the validity of the relationships modelled by attention, and furthermore, we show that CellVGAE can intrinsically capture information such as pseudotime and NF-\u0138B activation dynamics, the latter being a property that is not generally shared by existing neural alternatives. We then evaluate the dimensionality reduction and clustering performance on 9 difficult and well-annotated datasets by comparing with three leading neural and non-neural techniques, concluding that CellVGAE outperforms competing methods. Finally, we report a decrease in training times of up to \u00d7 20 on a dataset of 1.3 million cells compared to existing deep learning architectures.The CellVGAE code is available at https://github.com/davidbuterez/CellVGAE.Supplementary data are available at Bioinformatics online.}\",\n    issn = {1367-4803},\n    doi = {10.1093/bioinformatics/btab804},\n    url = {https://doi.org/10.1093/bioinformatics/btab804},\n    eprint = {https://academic.oup.com/bioinformatics/article-pdf/38/5/1277/49009403/btab804.pdf},\n}\n```\n"
      },
      "source": "https://raw.githubusercontent.com/davidbuterez/CellVGAE/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "author": "Buterez, David and Bica, Ioana and Tariq, Ifrah and Andr\u00e9s-Terr\u00e9, Helena and Li\u00f2, Pietro",
        "doi": "10.1093/bioinformatics/btab804",
        "format": "bibtex",
        "title": "{CellVGAE: an unsupervised scRNA-seq analysis workflow with graph attention networks}",
        "type": "Text_excerpt",
        "url": "https://doi.org/10.1093/bioinformatics/btab804",
        "value": "@article{10.1093/bioinformatics/btab804,\n    eprint = {https://academic.oup.com/bioinformatics/article-pdf/38/5/1277/49009403/btab804.pdf},\n    url = {https://doi.org/10.1093/bioinformatics/btab804},\n    doi = {10.1093/bioinformatics/btab804},\n    issn = {1367-4803},\n    abstract = {{Single-cell RNA sequencing allows high-resolution views of individual cells for libraries of up to millions of samples, thus motivating the use of deep learning for analysis. In this study, we introduce the use of graph neural networks for the unsupervised exploration of scRNA-seq data by developing a variational graph autoencoder architecture with graph attention layers that operates directly on the connectivity between cells, focusing on dimensionality reduction and clustering. With the help of several case studies, we show that our model, named CellVGAE, can be effectively used for exploratory analysis even on challenging datasets, by extracting meaningful features from the data and providing the means to visualize and interpret different aspects of the model.We show that CellVGAE is more interpretable than existing scRNA-seq variational architectures by analysing the graph attention coefficients. By drawing parallels with other scRNA-seq studies on interpretability, we assess the validity of the relationships modelled by attention, and furthermore, we show that CellVGAE can intrinsically capture information such as pseudotime and NF-\u0138B activation dynamics, the latter being a property that is not generally shared by existing neural alternatives. We then evaluate the dimensionality reduction and clustering performance on 9 difficult and well-annotated datasets by comparing with three leading neural and non-neural techniques, concluding that CellVGAE outperforms competing methods. Finally, we report a decrease in training times of up to \u00d7 20 on a dataset of 1.3 million cells compared to existing deep learning architectures.The CellVGAE code is available at https://github.com/davidbuterez/CellVGAE.Supplementary data are available at Bioinformatics online.}},\n    month = {12},\n    year = {2021},\n    pages = {1277-1286},\n    number = {5},\n    volume = {38},\n    journal = {Bioinformatics},\n    title = {{CellVGAE: an unsupervised scRNA-seq analysis workflow with graph attention networks}},\n    author = {Buterez, David and Bica, Ioana and Tariq, Ifrah and Andr\u00e9s-Terr\u00e9, Helena and Li\u00f2, Pietro},\n}"
      },
      "source": "https://raw.githubusercontent.com/davidbuterez/CellVGAE/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/davidbuterez/CellVGAE"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2020-11-29T14:21:09Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2024-04-30T18:40:41Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "An unsupervised scRNA-seq analysis workflow with graph attention networks"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 0.9629610433532018,
      "result": {
        "original_header": "CellVGAE",
        "type": "Text_excerpt",
        "value": "An unsupervised scRNA-seq analysis workflow with graph attention networks \nCellVGAE uses the connectivity between cells (such as *k*-nearest neighbour graphs or KNN) with gene expression values as node features to learn high-quality cell representations in a lower-dimensional space, with applications in downstream analyses like (density-based) clustering, visualisation, gene set enrichment analysis and others. CellVGAE leverages both the variational graph autoencoder and graph attention networks to offer a powerful and more interpretable machine learning approach. It is implemented in PyTorch using the PyTorch Geometric library.\n \n"
      },
      "source": "https://raw.githubusercontent.com/davidbuterez/CellVGAE/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/davidbuterez/CellVGAE/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "executable_example": [
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/davidbuterez/CellVGAE/master/adjacency_matrices_plots/adjacency_matrices_plots.ipynb"
      },
      "source": "https://raw.githubusercontent.com/davidbuterez/CellVGAE/master/adjacency_matrices_plots/adjacency_matrices_plots.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/davidbuterez/CellVGAE/master/top_genes/top_genes.ipynb"
      },
      "source": "https://raw.githubusercontent.com/davidbuterez/CellVGAE/master/top_genes/top_genes.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/davidbuterez/CellVGAE/master/preprocessing/hvg_proprocessing.ipynb"
      },
      "source": "https://raw.githubusercontent.com/davidbuterez/CellVGAE/master/preprocessing/hvg_proprocessing.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/davidbuterez/CellVGAE/master/preprocessing/generate_knn.ipynb"
      },
      "source": "https://raw.githubusercontent.com/davidbuterez/CellVGAE/master/preprocessing/generate_knn.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/davidbuterez/CellVGAE/master/misc/benchmark_sam.ipynb"
      },
      "source": "https://raw.githubusercontent.com/davidbuterez/CellVGAE/master/misc/benchmark_sam.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/davidbuterez/CellVGAE/master/misc/curate_baron.ipynb"
      },
      "source": "https://raw.githubusercontent.com/davidbuterez/CellVGAE/master/misc/curate_baron.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/davidbuterez/CellVGAE/master/misc/clean_wang.ipynb"
      },
      "source": "https://raw.githubusercontent.com/davidbuterez/CellVGAE/master/misc/clean_wang.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/davidbuterez/CellVGAE/master/misc/clean_seger.ipynb"
      },
      "source": "https://raw.githubusercontent.com/davidbuterez/CellVGAE/master/misc/clean_seger.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/davidbuterez/CellVGAE/master/platelet_knn_analysis/platelet_knn_analysis.ipynb"
      },
      "source": "https://raw.githubusercontent.com/davidbuterez/CellVGAE/master/platelet_knn_analysis/platelet_knn_analysis.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/davidbuterez/CellVGAE/master/attention_visualisation/attn_graph_darmanis_igraph.ipynb"
      },
      "source": "https://raw.githubusercontent.com/davidbuterez/CellVGAE/master/attention_visualisation/attn_graph_darmanis_igraph.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/davidbuterez/CellVGAE/master/attention_visualisation/attn_heatmap_pbmc_all_mean_heads.ipynb"
      },
      "source": "https://raw.githubusercontent.com/davidbuterez/CellVGAE/master/attention_visualisation/attn_heatmap_pbmc_all_mean_heads.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/davidbuterez/CellVGAE/master/attention_visualisation/attn_heatmap_pbmc_per_head.ipynb"
      },
      "source": "https://raw.githubusercontent.com/davidbuterez/CellVGAE/master/attention_visualisation/attn_heatmap_pbmc_per_head.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/davidbuterez/CellVGAE/master/attention_visualisation/attn_graph_pbmc_igraph.ipynb"
      },
      "source": "https://raw.githubusercontent.com/davidbuterez/CellVGAE/master/attention_visualisation/attn_graph_pbmc_igraph.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/davidbuterez/CellVGAE/master/attention_visualisation/latent_space_euclidean_distance.ipynb"
      },
      "source": "https://raw.githubusercontent.com/davidbuterez/CellVGAE/master/attention_visualisation/latent_space_euclidean_distance.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/davidbuterez/CellVGAE/master/attention_visualisation/attn_heatmap_darmanis_mean_heads.ipynb"
      },
      "source": "https://raw.githubusercontent.com/davidbuterez/CellVGAE/master/attention_visualisation/attn_heatmap_darmanis_mean_heads.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/davidbuterez/CellVGAE/master/attention_visualisation/attn_heatmap_darmanis_per_head.ipynb"
      },
      "source": "https://raw.githubusercontent.com/davidbuterez/CellVGAE/master/attention_visualisation/attn_heatmap_darmanis_per_head.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/davidbuterez/CellVGAE/master/saved_embeddings/inspect_saved.ipynb"
      },
      "source": "https://raw.githubusercontent.com/davidbuterez/CellVGAE/master/saved_embeddings/inspect_saved.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/davidbuterez/CellVGAE/master/saved_embeddings/plots_with_sam_embeddings/all_datasets_plots.ipynb"
      },
      "source": "https://raw.githubusercontent.com/davidbuterez/CellVGAE/master/saved_embeddings/plots_with_sam_embeddings/all_datasets_plots.ipynb",
      "technique": "file_exploration"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 8
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/davidbuterez/CellVGAE/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "davidbuterez/CellVGAE"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "CellVGAE"
      },
      "source": "https://raw.githubusercontent.com/davidbuterez/CellVGAE/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "images": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/davidbuterez/CellVGAE/master/figures/workflow.png"
      },
      "source": "https://raw.githubusercontent.com/davidbuterez/CellVGAE/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/davidbuterez/CellVGAE/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ""
      },
      "technique": "GitHub_API"
    }
  ],
  "license": [
    {
      "confidence": 1,
      "result": {
        "name": "MIT License",
        "spdx_id": "MIT",
        "type": "License",
        "url": "https://api.github.com/licenses/mit",
        "value": "https://api.github.com/licenses/mit"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "type": "File_dump",
        "value": "MIT License\n\nCopyright (c) 2021 David Buterez\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
      },
      "source": "https://raw.githubusercontent.com/davidbuterez/CellVGAE/master/LICENSE",
      "technique": "file_exploration"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "CellVGAE"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "User",
        "value": "davidbuterez"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Jupyter Notebook",
        "size": 29500694,
        "type": "Programming_language",
        "value": "Jupyter Notebook"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 48571,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/davidbuterez/CellVGAE/master/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "requirements": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Requirements",
        "parent_header": [
          "CellVGAE"
        ],
        "type": "Text_excerpt",
        "value": "Installing CellVGAE with pip will attempt to install PyTorch and PyTorch Geometric, however it is recommended that the appropriate GPU/CPU versions are installed manually beforehand. For Linux:\n\n1. Install PyTorch GPU: \n\n   ```conda install pytorch torchvision torchaudio cudatoolkit=11.1 -c pytorch -c nvidia```\n\n   or PyTorch CPU:  \n\n   ```conda install pytorch torchvision torchaudio cpuonly -c pytorch```\n\n   \n   \n2. Install PyTorch Geometric:  \n\n   `conda install pyg -c pyg -c conda-forge`\n   \n   \n\n3. (Optional) Install Faiss CPU:  \n\n   `conda install -c pytorch faiss-cpu`\n\n   \n\n   Faiss is only required if using the option `--graph_type \"KNN Faiss\"` .  It is a soft dependency as it is not available for some platforms (currently Apple M1). Attempting to use CellVGAE with Faiss without installing it will result in an exception.\n\n   A GPU version of Faiss for CUDA 11.1 is not yet available.\n\n   \n\n4. Install CellVGAE with pip:\n\n   `pip install cellvgae --pre`\n   \n   \n\n5. (Optional) For the attention graph visualisations of Figure 6, `igraph` is required:\n\n   `pip install python-igraph`\n\n\n\n\nIf using the R preprocessing code, we recommend installing the following:\n\n`Seurat 3`, `scran`, `SingleCellExperiment`. `scRNAseq`, `BiocSingular`, `igraph`, `dplyr` and `textshape`.\n\n\n"
      },
      "source": "https://raw.githubusercontent.com/davidbuterez/CellVGAE/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "somef_missing_categories": [
    "installation",
    "acknowledgement",
    "run",
    "download",
    "contact",
    "contributors",
    "documentation",
    "faq",
    "support",
    "identifier",
    "has_build_file"
  ],
  "somef_provenance": {
    "date": "2024-10-06 14:30:30",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 24
      },
      "technique": "GitHub_API"
    }
  ],
  "type": [
    {
      "confidence": 0.82,
      "result": {
        "type": "String",
        "value": "commandline-application"
      },
      "technique": "software_type_heuristics"
    }
  ],
  "usage": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Example use",
        "parent_header": [
          "CellVGAE"
        ],
        "type": "Text_excerpt",
        "value": "Using the example files in this repo (.h5ad file is the same as downloaded by Scanpy 1.8.1):\n\n```bash\npython -m cellvgae --input_gene_expression_path \"example_data/paul15_myeloid_scanpy.h5ad\" --graph_file_path \"example_data/paul15_Faiss_KNN_K3_KHVG2500.txt\" --graph_convolution \"GAT\" --num_hidden_layers 2 --hidden_dims 128 128 --num_heads 3 3 3 3 --dropout 0.4 0.4 0.4 0.4 --latent_dim 50 --epochs 50 --model_save_path \"model_saved_out\"\n```\n\nOther examples are available in `examples/cellvgae_example_scripts.txt`\n\n(also consult the help section below)\n\n\n"
      },
      "source": "https://raw.githubusercontent.com/davidbuterez/CellVGAE/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Usage",
        "parent_header": [
          "CellVGAE"
        ],
        "type": "Text_excerpt",
        "value": "Invoke the training script with `python -m cellvgae` with the arguments detailed below:\n\n```\nusage: train [-h] [--input_gene_expression_path INPUT_GENE_EXPRESSION_PATH] [--hvg HVG] [--khvg KHVG] [--graph_type {KNN Scanpy,KNN Faiss,PKNN}] [--k K] [--graph_n_pcs GRAPH_N_PCS]\n             [--graph_metric {euclidean,manhattan,cosine}] [--graph_distance_cutoff_num_stds GRAPH_DISTANCE_CUTOFF_NUM_STDS] [--save_graph] [--raw_counts] [--faiss_gpu]\n             [--hvg_file_path HVG_FILE_PATH] [--khvg_file_path KHVG_FILE_PATH] [--graph_file_path GRAPH_FILE_PATH] [--graph_convolution {GAT,GATv2,GCN}] [--num_hidden_layers {2,3}]\n             [--num_heads [NUM_HEADS [NUM_HEADS ...]]] [--hidden_dims [HIDDEN_DIMS [HIDDEN_DIMS ...]]] [--dropout [DROPOUT [DROPOUT ...]]] [--latent_dim LATENT_DIM] [--loss {kl,mmd}] [--lr LR]\n             [--epochs EPOCHS] [--val_split VAL_SPLIT] [--test_split TEST_SPLIT] [--transpose_input] [--use_linear_decoder] [--decoder_nn_dim1 DECODER_NN_DIM1] [--name NAME] --model_save_path MODEL_SAVE_PATH [--umap] [--hdbscan]\n\nTrain CellVGAE.\n\noptional arguments:\n  -h, --help            show this help message and exit\n  --input_gene_expression_path INPUT_GENE_EXPRESSION_PATH\n                        Input gene expression file path.\n  --hvg HVG             Number of HVGs.\n  --khvg KHVG           Number of KHVGs.\n  --graph_type {KNN Scanpy,KNN Faiss,PKNN}\n                        Type of graph.\n  --k K                 K for KNN or Pearson (PKNN) graph.\n  --graph_n_pcs GRAPH_N_PCS\n                        Use this many Principal Components for the KNN (only Scanpy).\n  --graph_metric {euclidean,manhattan,cosine}\n  --graph_distance_cutoff_num_stds GRAPH_DISTANCE_CUTOFF_NUM_STDS\n                        Number of standard deviations to add to the mean of distances/correlation values. Can be negative.\n  --save_graph          Save the generated graph to the output path specified by --model_save_path.\n  --raw_counts          Enable preprocessing recipe for raw counts.\n  --faiss_gpu           Use Faiss on the GPU (only for KNN Faiss).\n  --hvg_file_path HVG_FILE_PATH\n                        HVG file if not using command line options to generate it.\n  --khvg_file_path KHVG_FILE_PATH\n                        KHVG file if not using command line options to generate it. Can be the same file as --hvg_file_path if HVG = KHVG.\n  --graph_file_path GRAPH_FILE_PATH\n                        Graph specified as an edge list (one edge per line, nodes separated by whitespace, not comma), if not using command line options to generate it.\n  --graph_convolution {GAT,GATv2,GCN}\n  --num_hidden_layers {2,3}\n                        Number of hidden layers (must be 2 or 3).\n  --num_heads [NUM_HEADS [NUM_HEADS ...]]\n                        Number of attention heads for each layer. Input is a list that must match the total number of layers = num_hidden_layers + 2 in length.\n  --hidden_dims [HIDDEN_DIMS [HIDDEN_DIMS ...]]\n                        Output dimension for each hidden layer. Input is a list that matches --num_hidden_layers in length.\n  --dropout [DROPOUT [DROPOUT ...]]\n                        Dropout for each layer. Input is a list that must match the total number of layers = num_hidden_layers + 2 in length.\n  --latent_dim LATENT_DIM\n                        Latent dimension (output dimension for node embeddings).\n  --loss {kl,mmd}       Loss function (KL or MMD).\n  --lr LR               Learning rate for Adam.\n  --epochs EPOCHS       Number of training epochs.\n  --val_split VAL_SPLIT\n                        Validation split e.g. 0.1.\n  --test_split TEST_SPLIT\n                        Test split e.g. 0.1.\n  --transpose_input     Specify if inputs should be transposed.\n  --use_linear_decoder  Turn on a neural network decoder, similar to traditional VAEs.\n  --decoder_nn_dim1 DECODER_NN_DIM1\n                        First hidden dimenson for the neural network decoder, if specified using --use_linear_decoder.\n  --name NAME           Name used for the written output files.\n  --model_save_path MODEL_SAVE_PATH\n                        Path to save PyTorch model and output files. Will create the entire path if necessary.\n  --umap                Compute and save the 2D UMAP embeddings of the output node features.\n  --hdbscan             Compute and save different HDBSCAN clusterings.\n```\n"
      },
      "source": "https://raw.githubusercontent.com/davidbuterez/CellVGAE/master/README.md",
      "technique": "header_analysis"
    }
  ]
}