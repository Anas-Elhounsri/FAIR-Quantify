{
  "application_domain": [
    {
      "confidence": 52.38,
      "result": {
        "type": "String",
        "value": "Computer Vision"
      },
      "technique": "supervised_classification"
    }
  ],
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/lmbxmu/EPruner"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2020-02-08T04:53:22Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2024-09-23T14:40:07Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "Pytorch implementation of our paper accepted by IEEE TNNLS, 2021 -- Network Pruning using Adaptive Exemplar Filters"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 0.8376398226682028,
      "result": {
        "original_header": "Pre-trained Models",
        "type": "Text_excerpt",
        "value": "We provide the pre-trained models used in our paper.\n \n"
      },
      "source": "https://raw.githubusercontent.com/lmbxmu/EPruner/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9536066905200857,
      "result": {
        "original_header": "Result Models",
        "type": "Text_excerpt",
        "value": " We provide our pruned models in the experiments, along with their training loggers and configurations.  \n"
      },
      "source": "https://raw.githubusercontent.com/lmbxmu/EPruner/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/lmbxmu/EPruner/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 5
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/lmbxmu/EPruner/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "lmbxmu/EPruner"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "Network Pruning using Adaptive Exemplar Filters ."
      },
      "source": "https://raw.githubusercontent.com/lmbxmu/EPruner/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "images": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/lmbxmu/EPruner/master/img/framework.png"
      },
      "source": "https://raw.githubusercontent.com/lmbxmu/EPruner/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/lmbxmu/EPruner/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ""
      },
      "technique": "GitHub_API"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "EPruner"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "User",
        "value": "lmbxmu"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 74045,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/lmbxmu/EPruner/master/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "run": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Running Code",
        "type": "Text_excerpt",
        "value": "The code has been tested using Pytorch1.3 and CUDA10.0 on Ubuntu16.04.\n\nRequirements: Sklearn 0.20.1\n\n"
      },
      "source": "https://raw.githubusercontent.com/lmbxmu/EPruner/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "EPruner",
        "parent_header": [
          "Running Code"
        ],
        "type": "Text_excerpt",
        "value": "You can run the following code to search model on CIFAR-10:\n\n```shell\npython epruner_cifar.py \n--dataset cifar10 \n--data_path /data/CIFAR10/ \n--pretrain_model /data/model/resnet56.pt \n--job_dir /data/experiment/resnet56 \n--arch resnet \n--cfg resnet56 \n--init_method centroids \n--preference_beta 0.76 \n--lr 0.01 \n--lr_decay_step 50 100 \n--num_epochs 150 \n--train_batch_size 256 \n--weight_decay 5e-3 \n--gpus 0\n```\n\n You can run the following code to search model on ImageNet: \n\n```shell\npython epruner_imagenet.py \n--dataset imagenet \n--data_path /data/ImageNet/ \n--pretrain_model /data/model/resnet50.pth \n--job_dir /data/experiment/resnet50 \n--arch resnet \n--cfg resnet50 \n--init_method centroids \n--preference_beta 0.75 \n--lr 0.1 \n--lr_decay_step 30 60 \n--num_epochs 90 \n--train_batch_size 256 \n--weight_decay 1e-4 \n--gpus 0 1 2 \n```\n"
      },
      "source": "https://raw.githubusercontent.com/lmbxmu/EPruner/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Test Our Performance",
        "parent_header": [
          "Running Code"
        ],
        "type": "Text_excerpt",
        "value": "Before you testing our model, please use the following command to install the thop python package which can calculate the flops and params of model:\n\n```shell\npip install thop\n```\n\n Follow the command below to verify our pruned models: \n\n```shell\npython test_flops_params.py\n--dataset cifar10 \n--data_path /data/CIFAR10 \n--arch resnet \n--cfg resnet56\n--pruned_model /data/model/pruned_model/resnet56/model_best.pt \n--eval_batch_size 100\n--gpus 0\n```\n\n\n"
      },
      "source": "https://raw.githubusercontent.com/lmbxmu/EPruner/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Other Arguments",
        "parent_header": [
          "Running Code"
        ],
        "type": "Text_excerpt",
        "value": "```shell\noptional arguments:\n  -h, --help            show this help message and exit\n  --gpus GPUS [GPUS ...]\n                        Select gpu_id to use. default:[0]\n  --dataset DATASET     Select dataset to train. default:cifar10\n  --data_path DATA_PATH\n                        The dictionary where the input is stored.\n                        default:/home/lishaojie/data/cifar10/\n  --job_dir JOB_DIR     The directory where the summaries will be stored.\n                        default:./experiments\n  --arch ARCH           Architecture of model. default:resnet\n  --cfg CFG             Detail architecuture of model. default:resnet56\n  --num_epochs NUM_EPOCHS\n                        The num of epochs to train. default:150\n  --train_batch_size TRAIN_BATCH_SIZE\n                        Batch size for training. default:256\n  --eval_batch_size EVAL_BATCH_SIZE\n                        Batch size for validation. default:100\n  --momentum MOMENTUM   Momentum for MomentumOptimizer. default:0.9\n  --lr LR               Learning rate for train. default:1e-2\n  --lr_decay_step LR_DECAY_STEP [LR_DECAY_STEP ...]\n                        the iterval of learn rate. default:50, 100\n  --weight_decay WEIGHT_DECAY\n                        The weight decay of loss. default:5e-4\n  --pretrain_model PRETRAIN_MODEL\n                        Path to the pretrain model . default:None\n  --init_method INIT_METHOD\n                        Initital method of pruned model. default:centroids.\n                        optimal:random,centroids,random_project\n  --preference_beta PREFERENCE_BETA\n                        The coefficient of preference used in\n                        AffinityPropagation cluster. default:0.75\n```\n"
      },
      "source": "https://raw.githubusercontent.com/lmbxmu/EPruner/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "somef_missing_categories": [
    "installation",
    "citation",
    "acknowledgement",
    "download",
    "requirements",
    "contact",
    "contributors",
    "documentation",
    "license",
    "usage",
    "faq",
    "support",
    "identifier",
    "has_build_file",
    "executable_example"
  ],
  "somef_provenance": {
    "date": "2024-10-06 05:45:13",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 22
      },
      "technique": "GitHub_API"
    }
  ],
  "type": [
    {
      "confidence": 0.82,
      "result": {
        "type": "String",
        "value": "commandline-application"
      },
      "technique": "software_type_heuristics"
    }
  ]
}