{
  "application_domain": [
    {
      "confidence": 39.19,
      "result": {
        "type": "String",
        "value": "Computer Vision"
      },
      "technique": "supervised_classification"
    }
  ],
  "citation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Citation",
        "parent_header": [
          "VCRNet"
        ],
        "type": "Text_excerpt",
        "value": "If you find our paper or code useful for your research, please cite:\n\n```BibTex\n@ARTICLE{9694502,\n  author={Pan, Zhaoqing and Yuan, Feng and Lei, Jianjun and Fang, Yuming and Shao, Xiao and Kwong, Sam},\n  journal={IEEE Transactions on Image Processing}, \n  title={VCRNet: Visual Compensation Restoration Network for No-Reference Image Quality Assessment}, \n  year={2022},\n  volume={31},\n  number={},\n  pages={1613-1627},\n  doi={10.1109/TIP.2022.3144892}}\n```\n\n"
      },
      "source": "https://raw.githubusercontent.com/NUIST-Videocoding/VCRNet/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "author": "Pan, Zhaoqing and Yuan, Feng and Lei, Jianjun and Fang, Yuming and Shao, Xiao and Kwong, Sam",
        "doi": "10.1109/TIP.2022.3144892",
        "format": "bibtex",
        "title": "VCRNet: Visual Compensation Restoration Network for No-Reference Image Quality Assessment",
        "type": "Text_excerpt",
        "value": "@article{9694502,\n    doi = {10.1109/TIP.2022.3144892},\n    pages = {1613-1627},\n    number = {},\n    volume = {31},\n    year = {2022},\n    title = {VCRNet: Visual Compensation Restoration Network for No-Reference Image Quality Assessment},\n    journal = {IEEE Transactions on Image Processing},\n    author = {Pan, Zhaoqing and Yuan, Feng and Lei, Jianjun and Fang, Yuming and Shao, Xiao and Kwong, Sam},\n}"
      },
      "source": "https://raw.githubusercontent.com/NUIST-Videocoding/VCRNet/main/README.md",
      "technique": "regular_expression"
    }
  ],
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/NUIST-Videocoding/VCRNet"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2021-10-22T10:42:49Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2024-06-18T01:32:32Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "Code for VCRNet: Visual Compensation Restoration Network for No-Reference Image Quality Assessment"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 0.9765129959296424,
      "result": {
        "original_header": "VCRNet",
        "type": "Text_excerpt",
        "value": "Guided by the free-energy principle, generative adversarial networks (GAN)-based no-reference image quality assessment (NR-IQA) methods have improved the image quality\nprediction accuracy. However, the GAN cannot well handle the restoration task for the free-energy principle-guided NR-IQA\nmethods, especially for the severely destroyed images, which results in that the quality degradation relationship between the\ndistorted image and its restored image cannot be accurately built.To address this problem, a visual compensation restoration network (VCRNet)-based NR-IQA method is proposed, which\nuses a non-adversarial model to efficiently handle the distorted image restoration task. The proposed VCRNet consists of a\nvisual restoration network and a quality estimation network.\n![./image-20211022140814450](https://github.com/NUIST-Videocoding/VCRNet/blob/main/VCRNet/image-20211022140814450.png)\n \n"
      },
      "source": "https://raw.githubusercontent.com/NUIST-Videocoding/VCRNet/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8025976032569633,
      "result": {
        "original_header": "Note",
        "type": "Text_excerpt",
        "value": "- The pretrained EfficientNet-B0 is installed by:\n```bash\npip install efficientnet_pytorch\n```\n- During training process, the dataset is split into \"training_set\" and \"testing_set\", and the testing process are also been performed, and the testing results can be seen in TEST_SRCC and TEST_PLCC\n \n"
      },
      "source": "https://raw.githubusercontent.com/NUIST-Videocoding/VCRNet/main/README.md",
      "technique": "supervised_classification"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/NUIST-Videocoding/VCRNet/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 6
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/NUIST-Videocoding/VCRNet/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "NUIST-Videocoding/VCRNet"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "VCRNet"
      },
      "source": "https://raw.githubusercontent.com/NUIST-Videocoding/VCRNet/main/README.md",
      "technique": "regular_expression"
    }
  ],
  "images": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/NUIST-Videocoding/VCRNet/main/VCRNet/image-20211022140814450.png"
      },
      "source": "https://raw.githubusercontent.com/NUIST-Videocoding/VCRNet/main/README.md",
      "technique": "regular_expression"
    }
  ],
  "installation": [
    {
      "confidence": 0.9995375233098613,
      "result": {
        "original_header": "Dataset",
        "type": "Text_excerpt",
        "value": "| Dataset   | Links                                                       |\n| --------- | ----------------------------------------------------------- |\n| LIVE      | https://live.ece.utexas.edu/research/quality/index.htm      |\n| TID2013   | http://r0k.us/graphics/kodak/                               |\n| KONIQ-10K | http://database.mmsp-kn.de/koniq-10k-database.html          |\n| CSIQ      | https://pan.baidu.com/s/1XCSafnf3SlbgePJuMq5M5w  pass: w7dh |\n \n"
      },
      "source": "https://raw.githubusercontent.com/NUIST-Videocoding/VCRNet/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9397474102134743,
      "result": {
        "original_header": "Training and Testing",
        "type": "Text_excerpt",
        "value": "```bash\nCUDA_VISIBLE_DEVICES=0 python main.py --mode train --dataset live\n```\n \n"
      },
      "source": "https://raw.githubusercontent.com/NUIST-Videocoding/VCRNet/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9875853766816873,
      "result": {
        "original_header": "Note",
        "type": "Text_excerpt",
        "value": "- The pretrained EfficientNet-B0 is installed by:\n```bash\npip install efficientnet_pytorch\n```\n- During training process, the dataset is split into \"training_set\" and \"testing_set\", and the testing process are also been performed, and the testing results can be seen in TEST_SRCC and TEST_PLCC\n \n"
      },
      "source": "https://raw.githubusercontent.com/NUIST-Videocoding/VCRNet/main/README.md",
      "technique": "supervised_classification"
    }
  ],
  "invocation": [
    {
      "confidence": 0.9546130901151062,
      "result": {
        "original_header": "Training and Testing",
        "type": "Text_excerpt",
        "value": "```bash\nCUDA_VISIBLE_DEVICES=0 python main.py --mode train --dataset live\n```\n \n"
      },
      "source": "https://raw.githubusercontent.com/NUIST-Videocoding/VCRNet/main/README.md",
      "technique": "supervised_classification"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/NUIST-Videocoding/VCRNet/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ""
      },
      "technique": "GitHub_API"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "VCRNet"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "User",
        "value": "NUIST-Videocoding"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 60587,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/NUIST-Videocoding/VCRNet/main/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "requirements": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Requirements",
        "parent_header": [
          "VCRNet"
        ],
        "type": "Text_excerpt",
        "value": "- PyTorch=1.1.0\n- Torchvision=0.3.0\n- numpy=1.16.0\n- scipy=1.2.1\n- argparse=1.4.1\n- h5py=2.10.0\n- efficientnet_pytorch=0.7.1\n"
      },
      "source": "https://raw.githubusercontent.com/NUIST-Videocoding/VCRNet/main/README.md",
      "technique": "header_analysis"
    }
  ],
  "somef_missing_categories": [
    "acknowledgement",
    "run",
    "download",
    "contact",
    "contributors",
    "documentation",
    "license",
    "usage",
    "faq",
    "support",
    "identifier",
    "has_build_file",
    "executable_example"
  ],
  "somef_provenance": {
    "date": "2024-10-06 00:56:26",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 21
      },
      "technique": "GitHub_API"
    }
  ]
}