{
  "application_domain": [
    {
      "confidence": 59.98,
      "result": {
        "type": "String",
        "value": "Computer Vision"
      },
      "technique": "supervised_classification"
    }
  ],
  "citation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Cite:",
        "parent_header": [
          "HiCARN: Resolution Enhancement of Hi-C Data Using Cascading Residual Networks"
        ],
        "type": "Text_excerpt",
        "value": "Parker Hicks, Oluwatosin Oluwadare, HiCARN: resolution enhancement of Hi-C data using cascading residual networks, Bioinformatics, Volume 38, Issue 9, 1 May 2022, Pages 2414\u20132421, https://doi.org/10.1093/bioinformatics/btac156      \n___________________\n"
      },
      "source": "https://raw.githubusercontent.com/OluwadareLab/HiCARN/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/OluwadareLab/HiCARN"
      },
      "technique": "GitHub_API"
    }
  ],
  "contact": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Contact:",
        "parent_header": [
          "HiCARN: Resolution Enhancement of Hi-C Data Using Cascading Residual Networks"
        ],
        "type": "Text_excerpt",
        "value": "Oluwatosin Oluwadare, PhD <br />\nDepartment of Computer Science <br />\nUniversity of Colorado, Colorado Springs <br />\nEmail: [ooluwada@uccs.edu](mailto:ooluwada@uccs.edu)\n___________________       "
      },
      "source": "https://raw.githubusercontent.com/OluwadareLab/HiCARN/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2021-07-29T21:56:37Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2024-01-05T23:51:44Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "HiCARN: Resolution Enhancement of Hi-C Data Using Cascading Residual Networks"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 0.8200598138651249,
      "result": {
        "original_header": "Build Instructions:",
        "type": "Text_excerpt",
        "value": "HiCARN runs in a Docker-containerized environment. Before cloning this repository and attempting to build, install the Docker engine. To install and build HiCARN follow these steps. \n"
      },
      "source": "https://raw.githubusercontent.com/OluwadareLab/HiCARN/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9474606134905311,
      "result": {
        "original_header": "Data Preprocessing",
        "type": "Text_excerpt",
        "value": "Click [here](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE63525) to view the GSE62525\nGEO accession for Hi-C data from (Rao *et al.* 2014). We used [GM12878](https://www.ncbi.nlm.nih.gov/geo/download/?acc=GSE63525&format=file&file=GSE63525%5FGM12878%5Fprimary%5Fintrachromosomal%5Fcontact%5Fmatrices%2Etar%2Egz)\nprimary intrachromosomal, [K562](https://www.ncbi.nlm.nih.gov/geo/download/?acc=GSE63525&format=file&file=GSE63525%5FK562%5Fintrachromosomal%5Fcontact%5Fmatrices%2Etar%2Egz)\nintrachromasomal, and [CH12-LX](https://www.ncbi.nlm.nih.gov/geo/download/?acc=GSE63525&format=file&file=GSE63525%5FCH12%2DLX%5Fintrachromosomal%5Fcontact%5Fmatrices%2Etar%2Egz)\n(mouse) intrachromosomal contact matrices. \n* Set your root directory as a string in `Data/Arg_Parser.py`. For example, we set `root_dir = './Datasets_NPZ'`\n* Make a new direcrory named `raw` to store your raw datasets. Command:  `mkdir $root_dir/raw`\n* Download and Unzip your data into the `$root_dir/raw` directory.  For example for GM12878 data, a folder with\nthe cell line name will be created containing contact matrices for all chromosomes for all available resolutions. See\nthe [README](https://www.ncbi.nlm.nih.gov/geo/download/?acc=GSE63525&format=file&file=GSE63525%5FOVERALL%5FREADME%2Ertf)\nfor further details. \nFollow the following steps to generate datasets in .npz format:\n1. **Read the raw data.** \n   * This will create a new directory `$root_dir/mat/<cell_line_name>` where all chrN_[HR].npz files will be stored.\n```bash\n$ python Read_Data.py -c GM12878 \n```\nRequired arguments:\n* `-c`: Specify only the name of the directory holding the  Unziped Cell line data you downloaded in above `$root_dir/raw/<cell_line_name>`. In our case,  the directory <cell_line_name> = GM12878 \n \nOptional arguments:\n* `-hr`: Specified resolution. You can choose from 5kb, 10kb, 25kb, 50kb, 100kb, 250kb, 500kb, and 1mb. Default is 10kb.\n* `-q`: Specified map quality. Options are MAPQGE30 and MAPQG0. Default is MAPQGE30.\n* `-n`: Normalization. Options are KRnorm, SQRTVCnorm, and VCnorm. Default is KRnorm. \n2. **Randomly downsample the data.** This adds downsampled HR data to `$root_dir/mat/<cell_line_name>` as chrN_[LR].npz.\n```bash\n$ python Downsample.py -hr 10kb -lr 40kb -r 16 -c GM12878\n```\nAll arguments:\n* `-hr`: Specified resolution from the previous step. Default is 10kb\n* `lr`: Provides a resolution for [LR] in chrN_[LR].npz. Default is 40kb\n* `-r`: Downsampling ratio. Default is 16\n* `-c`: Cell line name.\n \n***Note***: For training, you must have both training and validation files present in `$root_dir/data`. Change the option `-s` to generate the validation and other datasets needed \n"
      },
      "source": "https://raw.githubusercontent.com/OluwadareLab/HiCARN/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9864927368772622,
      "result": {
        "original_header": "Using Our Processed Data",
        "type": "Text_excerpt",
        "value": "Processed data from our `Data/` directory should be placed in your `$root_dir/data` directory. There you can find training and validation files in `Data/Train_and_Validate/` and also test sets in `Data/Test/` where you may choose from a group file containing four chromosomes or a file containing only chromosome 4. \n            \n___________________ \n"
      },
      "source": "https://raw.githubusercontent.com/OluwadareLab/HiCARN/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9439812290275044,
      "result": {
        "original_header": "Training",
        "type": "Text_excerpt",
        "value": "We provide training files for both HiCARN-1 and HiCARN-2.  \nTo train:\n```bash\n$ python HiCARN_[1 or 2]_Train.py\n```\nThis function will output .pytorch checkpoint files containing the trained weights. During validation, if the highest SSIM score is attained, then the weights of that epoch will be saved as `bestg`. There will be multiple `bestg` checkpoint files during a single training. Once training is complete after the full set of epochs, a `finalg` checkpoint file will be created. We used the `finalg` checkpoint files for our predictions.\n \n**_Note:_** After training HiCARN-2, a `finald` checkpoint file will be generated. This contains the weights for the HiCARN-2 discriminator and is not used in predictions.\n___________________ \n"
      },
      "source": "https://raw.githubusercontent.com/OluwadareLab/HiCARN/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9282429766496726,
      "result": {
        "original_header": "Predicting",
        "type": "Text_excerpt",
        "value": "We provide pretrained weights for HiCARN and all other compared models. You can also use the weights generated by \nyour own trained model. For quick predictions use the following commands below: \nIf you would like to perform analysis metrics for your predictions use the following commands: \n"
      },
      "source": "https://raw.githubusercontent.com/OluwadareLab/HiCARN/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/OluwadareLab/HiCARN/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 2
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/OluwadareLab/HiCARN/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "OluwadareLab/HiCARN"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "HiCARN: Resolution Enhancement of Hi-C Data Using Cascading Residual Networks"
      },
      "source": "https://raw.githubusercontent.com/OluwadareLab/HiCARN/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "has_script_file": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/OluwadareLab/HiCARN/master/zfinal_runner.sh"
      },
      "technique": "file_exploration"
    }
  ],
  "installation": [
    {
      "confidence": 0.9999999892543131,
      "result": {
        "original_header": "Build Instructions:",
        "type": "Text_excerpt",
        "value": "HiCARN runs in a Docker-containerized environment. Before cloning this repository and attempting to build, install the Docker engine. To install and build HiCARN follow these steps. \n1. Clone this repository locally using the command `git clone https://github.com/OluwadareLab/HiCARN.git && cd HiCARN`.\n2. Pull the HiCARN docker image from docker hub using the command `docker pull oluwadarelab/hicarn:latest`. This may take a few minutes. Once finished, check that the image was sucessfully pulled using `docker image ls`.\n3. Run the HiCARN container and mount the present working directory to the container using `docker run --rm --gpus all -it --name hicarn -v ${PWD}:${PWD} oluwadarelab/hicarn`.\n4. `cd` to your home directory.\n___________________ \n"
      },
      "source": "https://raw.githubusercontent.com/OluwadareLab/HiCARN/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9609585539174245,
      "result": {
        "original_header": "Data Preprocessing",
        "type": "Text_excerpt",
        "value": "* Set your root directory as a string in `Data/Arg_Parser.py`. For example, we set `root_dir = './Datasets_NPZ'`\n* Make a new direcrory named `raw` to store your raw datasets. Command:  `mkdir $root_dir/raw`\n* Download and Unzip your data into the `$root_dir/raw` directory.  For example for GM12878 data, a folder with\nthe cell line name will be created containing contact matrices for all chromosomes for all available resolutions. See\nthe [README](https://www.ncbi.nlm.nih.gov/geo/download/?acc=GSE63525&format=file&file=GSE63525%5FOVERALL%5FREADME%2Ertf)\nfor further details. \nFollow the following steps to generate datasets in .npz format:\n1. **Read the raw data.** \n   * This will create a new directory `$root_dir/mat/<cell_line_name>` where all chrN_[HR].npz files will be stored.\n```bash\n$ python Read_Data.py -c GM12878 \n```\nRequired arguments:\n* `-c`: Specify only the name of the directory holding the  Unziped Cell line data you downloaded in above `$root_dir/raw/<cell_line_name>`. In our case,  the directory <cell_line_name> = GM12878 \n \nCongratulations! You now have your datasets.  \n"
      },
      "source": "https://raw.githubusercontent.com/OluwadareLab/HiCARN/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.963284855842728,
      "result": {
        "original_header": "Predicting",
        "type": "Text_excerpt",
        "value": "1. If predicting with HiCARN-1, HiCARN-2, or DeepHiC:\n```bash\n$ python 40x40_Predict.py -m HiCARN_1 -lr 40kb -ckpt root_dir/checkpoints/weights_file.pytorch -f hicarn_10kb40kb_c40_s40_b201_nonpool_human_GM12878_test.npz -c GM12878_HiCARN_1\n``` \nIf you would like to perform analysis metrics for your predictions use the following commands: \n1. If predicting with HiCARN-1, HiCARN-2, or DeepHiC:\n```bash\n$ python 40x40_Predict_With_Metrics.py -m HiCARN_1 -lr 40kb -ckpt root_dir/checkpoints/weights_file.pytorch -f hicarn_10kb40kb_c40_s40_b201_nonpool_human_GM12878_test.npz -c GM12878_HiCARN_1\n``` \n2. If predicting with HiCSR, HiCNN, or HiCPlus:\n```bash\n$ python 28x28_Predict_With_Metrics.py -m HiCSR -lr 40kb -ckpt root_dir/checkpoints/weights_file.pytorch -f hicarn_10kb40kb_c40_s40_b201_nonpool_human_GM12878_test.npz -c GM12878_HiCSR\n```\n___________________\n             \n"
      },
      "source": "https://raw.githubusercontent.com/OluwadareLab/HiCARN/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "invocation": [
    {
      "confidence": 0.8664936174980878,
      "result": {
        "original_header": "Data Preprocessing",
        "type": "Text_excerpt",
        "value": "* Set your root directory as a string in `Data/Arg_Parser.py`. For example, we set `root_dir = './Datasets_NPZ'`\n* Make a new direcrory named `raw` to store your raw datasets. Command:  `mkdir $root_dir/raw`\n* Download and Unzip your data into the `$root_dir/raw` directory.  For example for GM12878 data, a folder with\nthe cell line name will be created containing contact matrices for all chromosomes for all available resolutions. See\nthe [README](https://www.ncbi.nlm.nih.gov/geo/download/?acc=GSE63525&format=file&file=GSE63525%5FOVERALL%5FREADME%2Ertf)\nfor further details. \nFollow the following steps to generate datasets in .npz format:\n1. **Read the raw data.** \n   * This will create a new directory `$root_dir/mat/<cell_line_name>` where all chrN_[HR].npz files will be stored.\n```bash\n$ python Read_Data.py -c GM12878 \n```\nRequired arguments:\n* `-c`: Specify only the name of the directory holding the  Unziped Cell line data you downloaded in above `$root_dir/raw/<cell_line_name>`. In our case,  the directory <cell_line_name> = GM12878 \n \n"
      },
      "source": "https://raw.githubusercontent.com/OluwadareLab/HiCARN/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.845959425947213,
      "result": {
        "original_header": "Using Our Processed Data",
        "type": "Text_excerpt",
        "value": "Processed data from our `Data/` directory should be placed in your `$root_dir/data` directory. There you can find training and validation files in `Data/Train_and_Validate/` and also test sets in `Data/Test/` where you may choose from a group file containing four chromosomes or a file containing only chromosome 4. \n            \n___________________ \n"
      },
      "source": "https://raw.githubusercontent.com/OluwadareLab/HiCARN/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8499578541116295,
      "result": {
        "original_header": "Training",
        "type": "Text_excerpt",
        "value": "To train:\n```bash\n$ python HiCARN_[1 or 2]_Train.py\n```\nThis function will output .pytorch checkpoint files containing the trained weights. During validation, if the highest SSIM score is attained, then the weights of that epoch will be saved as `bestg`. There will be multiple `bestg` checkpoint files during a single training. Once training is complete after the full set of epochs, a `finalg` checkpoint file will be created. We used the `finalg` checkpoint files for our predictions.\n \n"
      },
      "source": "https://raw.githubusercontent.com/OluwadareLab/HiCARN/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8317449783212455,
      "result": {
        "original_header": "Predicting",
        "type": "Text_excerpt",
        "value": "1. If predicting with HiCARN-1, HiCARN-2, or DeepHiC:\n```bash\n$ python 40x40_Predict.py -m HiCARN_1 -lr 40kb -ckpt root_dir/checkpoints/weights_file.pytorch -f hicarn_10kb40kb_c40_s40_b201_nonpool_human_GM12878_test.npz -c GM12878_HiCARN_1\n``` \n1. If predicting with HiCARN-1, HiCARN-2, or DeepHiC:\n```bash\n$ python 40x40_Predict_With_Metrics.py -m HiCARN_1 -lr 40kb -ckpt root_dir/checkpoints/weights_file.pytorch -f hicarn_10kb40kb_c40_s40_b201_nonpool_human_GM12878_test.npz -c GM12878_HiCARN_1\n``` \n2. If predicting with HiCSR, HiCNN, or HiCPlus:\n```bash\n$ python 28x28_Predict_With_Metrics.py -m HiCSR -lr 40kb -ckpt root_dir/checkpoints/weights_file.pytorch -f hicarn_10kb40kb_c40_s40_b201_nonpool_human_GM12878_test.npz -c GM12878_HiCSR\n```\n___________________\n             \n"
      },
      "source": "https://raw.githubusercontent.com/OluwadareLab/HiCARN/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/OluwadareLab/HiCARN/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "deep-learning, enhancement, genome-analysis, hi-c, machine-learning, oluwadare-lab, super-resolution"
      },
      "technique": "GitHub_API"
    }
  ],
  "license": [
    {
      "confidence": 1,
      "result": {
        "name": "MIT License",
        "spdx_id": "MIT",
        "type": "License",
        "url": "https://api.github.com/licenses/mit",
        "value": "https://api.github.com/licenses/mit"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "type": "File_dump",
        "value": "MIT License\n\nCopyright (c) 2021 phicks22\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
      },
      "source": "https://raw.githubusercontent.com/OluwadareLab/HiCARN/master/LICENSE",
      "technique": "file_exploration"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "HiCARN"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "User",
        "value": "OluwadareLab"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 94312,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Shell",
        "size": 722,
        "type": "Programming_language",
        "value": "Shell"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/OluwadareLab/HiCARN/master/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "requirements": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Dependencies",
        "parent_header": [
          "HiCARN: Resolution Enhancement of Hi-C Data Using Cascading Residual Networks"
        ],
        "type": "Text_excerpt",
        "value": "HiCARN is written in Python3 and uses the Pytorch module. All dependencies are included in the Docker environment. <br />\n**_Note:_** GPU usage for training and testing is highly recommended.\n\n\n\nThe following versions are recommended when using HiCARN:\n- Python 3.8\n- Pytorch 1.10.0, CUDA 11.3\n- Numpy 1.21.1\n- Scipy 1.7.0\n- Pandas 1.3.1\n- Scikit-learn 0.15.2\n- Matplotlib 3.4.2\n- tqdm 4.61.2\n\n___________________\n"
      },
      "source": "https://raw.githubusercontent.com/OluwadareLab/HiCARN/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "somef_missing_categories": [
    "acknowledgement",
    "run",
    "download",
    "contributors",
    "documentation",
    "usage",
    "faq",
    "support",
    "identifier",
    "has_build_file",
    "executable_example"
  ],
  "somef_provenance": {
    "date": "2024-10-06 00:22:41",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 4
      },
      "technique": "GitHub_API"
    }
  ]
}