{
  "citation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "References",
        "parent_header": [
          "ALiBaSeq"
        ],
        "type": "Text_excerpt",
        "value": "Knyshov A, Gordon ERL, Weirauch C. 2021. New alignment-based sequence extraction software (ALiBaSeq) and its utility for deep level phylogenetics. PeerJ 9:e11019 https://doi.org/10.7717/peerj.11019\n"
      },
      "source": "https://raw.githubusercontent.com/AlexKnyshov/alibaseq/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/AlexKnyshov/alibaseq"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2019-03-01T17:54:24Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2024-07-09T08:04:57Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "Alignment-Based Sequence extraction"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Description",
        "parent_header": [
          "ALiBaSeq"
        ],
        "type": "Text_excerpt",
        "value": "The core of the software - `alibaseq.py` - is designed to retrieve homologous regions from a FASTA file with contigs (e.g., an NGS read assembly file). The retrieval is done based on reading BLAST, HMMER, or LASTZ search tab-delimited output tables or SAM / BAM alignment files and then searching for the results in an assembly file. Software is designed to compile gene regions for phylogenetic inference (grouping all taxa being processed per locus and appending this data to given loci files), however this is not required and a different output structure can be selected. Optionally, a reverse search (reciprocal best hit check) table and a reference search (baits searched against a complete assembly / proteome of taxon they are derived from) table can be provided.\nThe following assumptions were used when developing the script:\n* Technical\n\t- input (forward) search table has locus name or locus file name in the query column and contig name in the hit column\n\t- **in case of multiple samples processed at once**, input forward tables (baits against samples) located in the same folder, and named exactly as assemblies apart from having the following extensions appended: `.blast` for BLAST, `.hmmer` for HMMER, `.lastz` for LASTZ, `.sam` for SAM, `.bam` for BAM. Reciprocal search tables (samples against the reference sample) have suffix `_reciprocal.blast` appended to forward search table name, and located in the same or different folder as the forward search tables. Assemblies have extension `.fasta`. See examples below.\n\t- For the reference search table (baits against reference sample) BLAST or BED formats are supported.\n\t- if provided scripts are used for forward searches, bait files are to be organized one per locus in the same folder, with `.fas` extension\n\t- sequence names do not contain `@`, and, additionally, sample names and sample sequence names do not contain `|` or the delimiter supplied with `-d`.\n\t- for the supporting shell scripts - appropriate dependencies and commands are available in path and in python. Module load options are provided for some bash scripts, however the user might need to adjust these scripts if they do not appear to work properly / locate necessary dependencies on their system.\n* Methodological\n\t- bait sequences can correspond to multiple hit regions in a given contig (a case of missing data or variable region in the bait, or intron presence in the sample contig)\n\t- bait sequences can correspond to multiple contigs in the assembly (a case of low-coverage assembly with broken up gene sequences)\n\t- no sequence fragment order rearrangements are assumed (in case of multiple hits or multiple contigs they are arranged as in the bait)\n\t- bait pool can contain paralogs or otherwise similar sequences; each contig region by default is checked to match only one bait, and pairing is done based on forward search similarity score and optionally reciprocal best hit score; multiple contigs may be paired with the same bait, but each contig region may only correspond to one bait (the check can be disabled).\n\t- paralogs can be located on the same contig in the assembly (since both contig name and coordinates are utilized to assign hits to queries, 'unused' regions of contigs can contribute to other loci)\n\t- nested genes can be extracted without disabling assembly contig 'usage check' if they share same general contig region but actual matching sequence regions are different (e.g., introns in one gene contain exons of another); alternatively a check for a given contig region to be used only once can be disabled, with all the consequences; both procedures require adjusting `--lr` option.\n\n\n"
      },
      "source": "https://raw.githubusercontent.com/AlexKnyshov/alibaseq/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "workflow / directory pointers",
        "parent_header": [
          "ALiBaSeq",
          "Other features and parameter description"
        ],
        "type": "Text_excerpt",
        "value": "option `-f` specifies whether a single alignment table, or multiple tables are used. In the latter, only the path to the folder needs be specified. (MANDATORY, NO DEFAULT)\n\noption `-b` specifies the path to alignment table file or a folder with such tables. When multiple tables are used, match between the table and the assembly is done based on cutting out `.blast` extension from the table and using the resulting name to search for the assembly file. (MANDATORY, NO DEFAULT)\n\noption `-t` specifies the path to the sample file (when `-f S`) or to the folder with sample files. Filename matching is done as described for `-b` option. (default: None, switches off sequence output, only table output of what would be extracted)\n\noption `-q` specifies the path to the folder with query file(s) to which extracted results are to be appended. (default: None, output sequences are written to empty files)\n\noption `-o` specifies the name of the output folder to be created; previous content is erased. (default: alibaseq_out)\n\noption `-r` specifies path to the reciprocal search output table file or the folder with such files. In case of multiple files, match is done based on suffix `_reciprocal.blast`. (default: None)\n\noption `-R` specifies path to the query search against the reference assembly. (default: None)\n\noption `-s` specifies output log suffix. (default: default)\n\noption `--log-header` adds a header to the table-like log files. (default: False)\n"
      },
      "source": "https://raw.githubusercontent.com/AlexKnyshov/alibaseq/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "table type",
        "parent_header": [
          "ALiBaSeq",
          "Other features and parameter description"
        ],
        "type": "Text_excerpt",
        "value": "option `--bt` specifies the alignment table type (only for forward searches; reciprocal and reference tables are always parsed as `blast`). `blast` is a standard blast table, `hmmer22` is a --domtblout table of hmmer, `hmmer18` is a protein --tblout table of hmmer, `hmmer15` is a dna --tblout table of hmmer, `lastz` is a Phyluce-style LASTZ output, `sam` is a SAM format, `bam` is a BAM format (default: blast)\n\noption `--btR` specifies the reference alignment table type, `blast` or `bed`. (default: blast)\n\noption `--ac` specifies the alignment table type. `dna-dna` is default, and has no special effects, except is not allowed to run with `--bt hmmer18` as the latter is a protein table. In `tdna-tdna`, `tdna-aa` and `aa-tdna` overlapping hits are checked for frameshift before joining. When set to `tdna-aa` or `aa-tdna`, coordinates of blast tables are modified accordingly to convert between AA and NT values. In `tdna-aa` and `aa-aa` output sequence translation is not allowed. (default: dna-dna)\n\noption `--acr` specifies the alignment table type for reciprocal search table (supplied with `-r`), see `--ac` for details. (default: dna-dna)\n\noption `--acR` specifies the alignment table type for the reference table (supplied with `-R`), see `--ac` for details. (default: dna-dna)\n"
      },
      "source": "https://raw.githubusercontent.com/AlexKnyshov/alibaseq/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "extraction parameters",
        "parent_header": [
          "ALiBaSeq",
          "Other features and parameter description"
        ],
        "type": "Text_excerpt",
        "value": "option `-x` specifies the extraction type: `n` extracts the whole contig, `s` extracts only single best hit, `a` extracts all hit regions and joins them together, `b`extracts region between two outmost hit regions. (MANDATORY, NO DEFAULT)\n\n![extraction_modes.png](extraction_modes.png)\n\noption `-c` specifies the max number of (super)contigs to extract. When set to 0, all matched supercontigs will be extracted. If a single (best matching) contig needs to be extracted, `-c` should be set to 1. If a set of one or several closely similar hits to be extracted, should be set to -1 (`-c=-1`) (default: 1) \n\noption `--fl` specifies flanks on each side in bp. This option is only available when `-x` is set to `s` or `b`. (default: 0)\n\nDISABLED ~~option `--translate` turns on sequence translation (for `-x s` or `-x a`), only works when appropriate `--ac`. (default: False)~~\n\noption `--om` specifies the way sequences are output. When set to `query`, sequences are grouped into per query files, when set to `target`, they are grouped into per sample files, and when set to `combined`, all sequences from all tables are extracted into a single file. (default: query)\n\noption `--keep-strand` turns off sequence reversal according to the query and outputs sequence in original direction (only has effect in combination with `-x n`). (default: False)\n\noption `--cname` appends original contig name to output sequence name, even for the cases where only single sequence per sample per bait is extracted. See `-d` below for customization. (default: False)\n\noption `-d` specifies the delimiter to be used in cases where several sequences extracted from the same samples for the same bait, delimits the sample name and the original sequence name. (default: |)\n"
      },
      "source": "https://raw.githubusercontent.com/AlexKnyshov/alibaseq/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "scoring",
        "parent_header": [
          "ALiBaSeq",
          "Other features and parameter description"
        ],
        "type": "Text_excerpt",
        "value": "option `-e` specifies the evalue cutoff. Nothing will be considered above this cutoff as it filters out initial alignment table parsing. (default: 0.01)\n\noption `-B` specifies the bitscore (or SAM / BAM metric) cutoff. Nothing will be considered below this cutoff as it filters out initial alignment table parsing. (default: 0.0)\n\noption `-i` specifies the identity cutoff (not used for HMMER and SAM/BAM unless `=`/`X` instead of `M` are present in CIGAR of the latter). Nothing will be considered below this cutoff as it filters out initial alignment table parsing. (default: 0.0)\n\noption `-m` specifies the order of metrics to be used for discriminating between hits/contigs (e - evalue, b - bitscore, i - identity); by default the evalue and bitscore differentials are compared and if not congruent, identitry is used for final decision. (default: e/b-i)\n\noption `--rescale-metric` rescales the metric value by the length of the match (not recommended for most situations since bitscore and evalue already incorporate hit sizes) (default: False)\n\noption `--hmmer-global` - for hmmer22 tables only - uses contig scores instead of domain (hit) scores; do not use in combination with `--amalgamate-hits` (default: False)\n\noption `--samScore` specifies whether the mapping quality (`MAPQ`) or a custom SAM / BAM file attribute (for example, `AS` [alignment score], that is provided by many aligners) is used as a scoring metric (default: MAPQ)\n\noption `--dd` - in case a hit matches several queries with exactly equal score, assign such hit to all queries / none of the queries / at random to only one. A conservative `none` is the default option. (default: none)\n"
      },
      "source": "https://raw.githubusercontent.com/AlexKnyshov/alibaseq/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "hit stitcher",
        "parent_header": [
          "ALiBaSeq",
          "Other features and parameter description"
        ],
        "type": "Text_excerpt",
        "value": "option `--hit-ovlp` specifies max allowed hit overlap on query, 0 or >= 1 in bp, or relative 0 < N < 1. If two hits overlap more than this amount, and overlap on the sample contig is greater than 0, the hits are considered to be indeed overlapping. (default: 0.1)\n\n![hit_stitcher.png](hit_stitcher.png)\n\noption `--amalgamate-hits` - when scoring the contig, use combination of scores of the hits and their average identity (default: False)\n\noption `--metric-merge-corr` - used together with `--amalgamate-hits` to reduce the combined score of multiple hits (default: 1.0)\n\noption `--no-hs` prevents running hit stitcher on the forward search table (default: False)\n\noption `--ref-hs` turns on hit sticher on the reciprocal table (slow). Typically reciprocal table is much larger, and takes considerable amount of time to parse. The alternative, default, approach is for a given sample contig region to simply pick the best hit to reference that is located in the same region. (default: False)\n\noption `--max-gap` (if greater than 0) specifies the maximum distance between hits of a contig, if greater hits are split into alternative versions of the same sample contig; setting to 0 turns it off. For very contiguous assemblies such as chromosome-level assemblies, it is highly recommended to set the maximum gap to some non-zero values, perhaps by using an average intron size for the organism in question. (default: 0)\n\noption `--synteny` specifies whether to stitch only the hits that are in synteny to query, or to stitch hits without such check. (default: 1)\n"
      },
      "source": "https://raw.githubusercontent.com/AlexKnyshov/alibaseq/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "contig stitcher",
        "parent_header": [
          "ALiBaSeq",
          "Other features and parameter description"
        ],
        "type": "Text_excerpt",
        "value": "option `--is` turns on contig stiching. (default: False)\n\noption `--ctg-ovlp` specifies max allowed contig overlap on query, 0 or >= 1 in bp, or relative 0 < N < 1. If two contigs overlap more than this amount they are considered to be indeed overlapping. (default: 0.2)\n\n![contig.png](contig.png)\n"
      },
      "source": "https://raw.githubusercontent.com/AlexKnyshov/alibaseq/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "homology checks",
        "parent_header": [
          "ALiBaSeq",
          "Other features and parameter description"
        ],
        "type": "Text_excerpt",
        "value": "option `--lr` specifies local single best match check (prevents same part of the sample contig being extracted to multiple queries). When set to `range`, each region of the sample contig (after joining multiple hits) is allowed to be matched to only one query. When set to `actual`, individual hits are checked for the same condition prior to being joined together. Can be switched off by setting `none`. (default: range)\n\noption `--both-strands 1` treats different strands of the same contig region as potentially separate loci and not be removed by the local homology check. `--both-strands 0` allows only one best strand for each contig to be considered. Leaving the option set to 1 increases the chances of a single correct sequenced picked since the two strands would survive until the final supercontig filtering step. However, when `-c` is set such that multiple supercontigs to be extracted, it is advised to set `--both-strands` to 0 to avoid extracting the same sequence twice. (default: 1)\n\noption `--recip-ovlp` specifies max allowed hit/contig overlap on query for reciprocal check (both \"local\" and \"global\" checks), 0 or >= 1 in bp, or relative 0 < N < 1. If two hits/contigs overlap more than this amount, they are considered to be sufficiently overlapping to pick only one best out of the two. (default: 10)\n\n![recip.png](recip.png)\n\noption `--rm-rec-not-found` turns on the STRICT RBH check, by not considering contig regions that are found in forward search but not in reverse search or in the reference search; by default, missing data equates to contig passing reciprocal best match criterion (RELAXED RBH check) (default: False)\n\noption `--srt` can be used to adjust the definition of the close suboptimal hits, via the ratio of log(E value) and ratio of bit scores between two hits. If ratio is greater than the supplied values, two hits are considered to be similar enough for the paralog warning and the `-c=-1` suboptimal hit extraction option purposes. (default: 0.9)\n \n"
      },
      "source": "https://raw.githubusercontent.com/AlexKnyshov/alibaseq/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Log file description",
        "parent_header": [
          "ALiBaSeq"
        ],
        "type": "Text_excerpt",
        "value": "The following log files are output\n* `alibaseq_<suffix>.log` contains generic information about the parameters used to run the script, reference sample processed (if any), and summary data on each sample processed.\n* `<sample name>_<logsuffix>.log` contains information about processing an individual sample\n* `<sample name>_<logsuffix>_qtable.tab` contains per-query (bait) information about an individual sample. The format is described in the subsection below.\n* `<sample name>_<logsuffix>_qtableH.tab` contains a more easily readable CSV with query (bait) - sample supercontig pairs, the fields are as follows: query name, supercontig index, hit name, pseudocontig index, direction (strand), pseudocontig start, pseudocontig end, query start, query end, evalue, bitscore, identity.\n* `<sample name>_<logsuffix>_ttable.tab` is a comma-delimited file, contains per-contig information about an individual sample. Each line corresponds to the contig used in the first column, number of baits it contributed to in the second column, and bait names in the subsequent columns\n"
      },
      "source": "https://raw.githubusercontent.com/AlexKnyshov/alibaseq/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "qtable log format",
        "parent_header": [
          "ALiBaSeq",
          "Log file description"
        ],
        "type": "Text_excerpt",
        "value": "Each line of the log corresponds to a bait sequence and its extracted match from the sample assembly. Below is the description, nested constructs are expanded for readability using markdown lists. Direction `True` means the same strand, `False` - an opposite strand. `<contig_name>@<index>` together comprise a \"pseudocontig\" - a particular instance of an original contig, with its own start/end coordinates and direction. HSP regions are listed in order they would be arranged during sequence extraction. Note that these HSPs may be different from the original search program HSP regions, as some may have been merged. Gap value represents gap between hits of the same contig, as well as between different contigs, as assessed based on query sequence. Negative gap values denote overlap.\n* `<bait_name> [`\n\t* `[<supercontig_index>, [`\n\t\t* `[True],`\n\t\t* `[<supercontig_evalue>, <supercontig_bitscore>, <supercontig_identity>],`\n\t\t* `[<supercontig_start_on_bait>,<supercontig_end_on_bait>], [`\n\t\t\t* `[<contig_name>@<index>, [`\n\t\t\t\t* `[<pseudocontig_direction>], `\n\t\t\t\t* `[<pseudocontig_evalue>, <pseudocontig_bitscore>, <pseudocontig_identity>], `\n\t\t\t\t* `[<pseudocontig_start_on_sample_contig>, <pseudocontig_end_on_sample_contig>, \n\t\t\t\t<pseudocontig_start_on_bait>, <pseudocontig_start_on_bait>], [`\n\t\t\t\t\t* `[<HSP_start_on_sample_contig>, <HSP_end_on_sample_contig>, \n\t\t\t\t\t<HSP_start_on_bait>, <HSP_end_on_bait>, \n\t\t\t\t\t<HSP_evalue>, <HSP_bitscore>, <HSP_identity>], `\n\t\t\t\t\t* `<gap>,` \n\t\t\t\t\t* `[<another HSP>], `\n\t\t\t\t\t* `<gap>,`\n\t\t\t\t\t* `...`\n\t\t\t\t\t* `[<last HSP>]`\n\t\t\t\t* `]`\n\t\t\t* `]],`\n\t\t\t* `<gap>,`\n\t\t\t* `[... another pseudocontig] `\n\t\t* `]`\n\t* `]],`\n\t* `[... another supercontig]`\n* `]`\n"
      },
      "source": "https://raw.githubusercontent.com/AlexKnyshov/alibaseq/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 0.8650834546627509,
      "result": {
        "original_header": "Single sample",
        "type": "Text_excerpt",
        "value": "Create a blast database\n```\nmakeblastdb -in assembly.fasta -dbtype nucl -parse_seqids\n```\nPerform the search\nBASH2*\nAdjust E-value and number of threads approapriately \nCreate a blast database for the sample\n```\nmakeblastdb -in assembly.fasta -dbtype nucl -parse_seqids\n``` \nCreate a blast database for the reference sample\n```\nmakeblastdb -in reference.fasta -dbtype nucl -parse_seqids\n``` \nSearch baits vs the sample\n```\nblastn -task dc-megablast -query baits.fas -db assembly.fasta -outfmt 6 \\\n-out assembly.fasta.blast -evalue 1e-10 -num_threads 1\n```\nAdjust E-value and number of threads appropriately \nFor the RBH check, the sample assembly needs to be searched against the reference assembly (or proteome). Since it takes longer and, as opposed to an OrthoMCL type orthology prediction, only sample contigs that had hits to the bait sequences will be considered, we suggest the following shortcut: only contigs appeared in the forward search are reciprocally searched against the reference taxon. This can be done as follows:\n```\nbash reciprocal_search.sh assembly.fasta.blast assembly.fasta \\\nreference.fasta dc-megablast 1 n reciprocal_get_contigs.py\n```\nAdjust the number of threads appropriately \n"
      },
      "source": "https://raw.githubusercontent.com/AlexKnyshov/alibaseq/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9843338288756351,
      "result": {
        "original_header": "Multiple samples",
        "type": "Text_excerpt",
        "value": "For a group of files, located in the same folder, the dbs can be created like this\n```\nfor f in folder_with_assemblies/*.fasta\ndo\n\tmakeblastdb -in $f -dbtype nucl -parse_seqids\ndone\n```\nPerform the search\nBASH2*\nAdjust E-value and number of threads approapriately \nFor a group of files, located in the same folder, the dbs can be created like this\n```\nfor f in folder_with_assemblies/*.fasta\ndo\n\tmakeblastdb -in $f -dbtype nucl -parse_seqids\ndone\n```\nCreate a blast database for the reference sample\nBASH5*\nPerform the forward search\nBASH6*\nAdjust E-value and number of threads appropriately \n"
      },
      "source": "https://raw.githubusercontent.com/AlexKnyshov/alibaseq/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9265769975665522,
      "result": {
        "original_header": "Variable baits / genetically distant samples - Protein-based search",
        "type": "Text_excerpt",
        "value": "Search baits vs the sample\n```\ntblastx -query baits.fas -db assembly.fasta -outfmt 6 \\\n-out assembly.fasta.blast -evalue 1e-10 -num_threads 1\n```\nAdjust E-value and number of threads appropriately \nFor the RBH check, the sample assembly needs to be searched against the reference assembly (or proteome). Since it takes longer and, as opposed to an OrthoMCL type orthology prediction, only sample contigs that had hits to the bait sequences will be considered, we suggest the following shortcut: only contigs appeared in the forward search are reciprocally searched against the reference taxon. If tblastx search takes too long, or requires a lot of resources (typically only for large and highly contiguous assembly), a dc-megablast search can be performed instead.\n```\nbash reciprocal_search.sh assembly.fasta.blast assembly.fasta \\\nreference.fasta tblastx 1 n reciprocal_get_contigs.py\n```\nAdjust the number of threads appropriately \nFor a group of files, located in the same folder, the dbs can be created like this\n```\nfor f in folder_with_assemblies/*.fasta\ndo\n\tmakeblastdb -in $f -dbtype nucl -parse_seqids\ndone\n```\nPerform the search\nBASH11*\nAdjust E-value and number of threads approapriately \nFor a group of files, located in the same folder, the dbs can be created like this\n```\nfor f in folder_with_assemblies/*.fasta\ndo\n\tmakeblastdb -in $f -dbtype nucl -parse_seqids\ndone\n```\nCreate a blast database for the reference sample\nBASH5*\nPerform the forward search\nBASH14*\nAdjust E-value and number of threads appropriately \n"
      },
      "source": "https://raw.githubusercontent.com/AlexKnyshov/alibaseq/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9861111668665105,
      "result": {
        "original_header": "HMMER profiles",
        "type": "Text_excerpt",
        "value": "We highly recommend using the `--domtblout` output format of HMMER whenever possible, since it provides detailed information about domains detected (for the purposes of alibaseq, those are equivalent to HSP in BLAST and LASTZ). \n"
      },
      "source": "https://raw.githubusercontent.com/AlexKnyshov/alibaseq/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/AlexKnyshov/alibaseq/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "faq": [
    {
      "confidence": 1,
      "result": {
        "original_header": "FAQ",
        "parent_header": [
          "ALiBaSeq"
        ],
        "type": "Text_excerpt",
        "value": "*What kinds of datasets are suitable for AliBaSeq?*\n\nAny kind of genetic datasets in which you want to analyse a subset of loci for a phylogeny. The subset may include predetermined single copy orthologous genes (BUSCO or OrthoDB), predetermined genes for which probes are supposed to enrich loci (targeted capture, UCE or AHE approaches) or even other datasets in which you want to recover a set of known genes for new taxa for further analysis. \n\nIt can be used on transcriptomic, low coverage or well-assembled genomic data or sequence capture assemblies. It is especially useful for combining these different types of data for a comprehensive phylogenetic analysis. It is also particularly robust for recovering genes across large phylogenetic distances unlike many other programs.\n\n*What is the best search tool (BLAST/HMMER/LASTZ) to use for my dataset before using AliBaSeq?* \n\nIf baits are similar enough to the samples, DNA-based searches should be used, as they are fast and lack the risk of increased false-positive results. Tools like blastn, blastn -task dc-megablast, nhmmer, hmmsearch with DNA profiles, and LASTZ can all be used, with BLAST being one of the fastest and easiest to set up and use.\n\nIf baits are divergent from the samples, DNA-based tools are suggested to be tried first, but it is likely that even discontinuous megablast might not give enough hits. In this case, or when only protein bait sequences are available, protein-based searches need to be conducted. The easiest options are tblastn (if baits are protein) and tblastx (if baits are CDS) searches, they are relatively fast and easy to set up. If multiple bait sequences are desired to be used, for example when looking for difficult loci with large variation even between reference taxa, HMMER profiles can be used instead. DNA-based HMMER search is straightforward to set up. Potein-based search would require producing six-frame-translated copies of sample assemblies, and the search would likely take longer (it runs best if it is possible to MPI-parallelize it as on a compute cluster, the tutorials are coming up...).\n\n*If I want to recover a set of pre-determined loci from newly sequences transcriptomes what default parameters would I use? What parameters might I adjust to get better recovery?*\n\nDepending on the contiguity of the transcriptomic assembly, use of the contig stitcher may be unnecessary. Lowering the evalue, bitscore, and identity thresholds may help with recovery of divergent hits.\n\n*If I want to recover a set of pre-determined loci from newly sequenced low coverage genome data what default parameters would I use? What parameters might I adjust to get better recovery?*\n\nA whole genome assembly produced from short reads is in our experience not very contiguous. If baits permit (i.e., they target putatively single-copy divergent from each other loci), the contig stitcher may help with recovery of larger regions. If a protein search is used, --hit-ovlp and --ctg-ovlp should be increased in our experience to about 30-40bp. This will help recovering larger sequences, at the expense of having larger unmatching 'splash zones' between the exons. Trimming those via after generation fo the multiple sequence alignment (MSA) or exonerate is possible. Lowering the evalue, bitscore, and identity thresholds may help with recovery of divergent hits.\n\n*If I want to recover a set of pre-determined loci from newly sequenced target capture data what default parameters would I use? What parameters might I adjust to get better recovery?*\n\nIf the capture targeted shorter regions (e.g., UCE), the same simple procedure as for transcriptomes can be used. If the capture targeted longer multiexon genes, it depends on the size of the introns. In AHE projects, introns are typically small, thus the assembly would likely have a complete target region for a given bait in a single contig, thus making the contig stitcher unnecessary. However, if introns were large and the assembly becomes discontinuous, the contig stitcher may help. See the low coverage genome question for details. Another caveat with hybrid capture data using assembly of all reads is the lack of reference to read coverage. While for UCE data (which uses a similar `assemble > search for contigs` approach) this empirically appears to have little problems, theoretically low coverage contaminants (either other samples or other organisms in a given sample) may be erroneously picked up. Thus it may be reasonable after the assembly stage to filter low covered contigs either from the assembly or from the resulting blast table (e.g., Velvet and Spades append k-mer coverage to contig names).\n\n*What is the best way to assess different parameters I've used to determine which ones work the best in terms of low false positive rates and maximum recovery?*\n\nIt is hard to come up with an accurate way to assess the false positive rate for an empirical study, where the true homolog sequence is unknown. But typically false positives manifest themselves in downstream analyses. If false positives are a problem (for example, when using a protein bait on a divergent organism), using the RBH check is highly recommended. For divergent from bait organisms or very low coverage genomes a strict RBH check as well as using tblastx for the reciprocal searches are recommended. Additionally, it is recommended to experiment with the scoring options (`-m` and `--rescale-metric`, `--amalgamate-hits`, and `--metric-merge-corr`).\nThe recovery may be assessed by the number of hits recovered, as well as by looking at coverage breadth of loci at the alignment stage. If recovery is not sufficient, while false-positives are not a problem, lowering the search sequence similarity thresholds as well as using a relaxed RBH check may help. If recovery is patchy from exon to exon, `--hit-ovlp` might need to be increased. If it is hard to get a good balance between the recovery and the false positive rates, assuming the sample was sequenced well, the bait sequence set may need to be adjusted (use more similar baits, avoid loci with known paralogs)\n\n*I work on a non-model organism and I have a very low coverage genome but I want to include it in a phylogenetic analysis with some well relatively well sequenced trancriptomes from the same kind of organism without any annotations. What is the best way to test out the program to see if it works for me?*\n\nALiBaSeq is designed for the datasets that have predetermined bait (loci) set. If no baits are available for the set of transcriptomes, transcripts can be turned into putative proteins and subjected to an all-vs-all orthology prediction (e.g., OrthoMCL). Alternatively, an available bait set can be used (OrthoDB, UCE, AHE, other publicly available loci sets). In this case, after getting the bait file with bait sequences formatted (see workflow or in the test folder), BLAST/HMMER/LASTZ searches can be done and ALiBaSeq can be then used to process the search results. Since the genome sample will likely require different parameters, we recommend to process it separately from the transcriptomes (one after another). We also recommend using a reciprocal search, for which a reference taxon would be needed. If baits used came from a different source and the assembly / transcriptome / proteome of the bait donor organism is no available, one of the sample transcriptomes (ideally, the most complete one) can be used as the reference. In addition to the baits vs samples searches, the baits vs reference sample search (same way as bait vs sample) as well as reciprocal search (sample vs reference sample) should be performed (see workflow).\n\n*Aren't UCEs and AHE loci very different? Why didn't you evaluate AHE loci?* \n\nIn vertebrates, UCEs appear to be a unique sequence element that doesn't code for proteins. In invertebrates, the most highly conserved sequences are almost entirely exonic and are part of a protein coding sequence. \n\n*Will this program work for pulling out vertebrate UCEs?* \n\nYes!.... but probably almost all alternatives will work well too. An advantage of ALiBaSeq is flexibility with respect to search tools used and the way user data is organized.\n\n"
      },
      "source": "https://raw.githubusercontent.com/AlexKnyshov/alibaseq/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 5
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/AlexKnyshov/alibaseq/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "AlexKnyshov/alibaseq"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "ALiBaSeq"
      },
      "source": "https://raw.githubusercontent.com/AlexKnyshov/alibaseq/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "has_script_file": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/AlexKnyshov/alibaseq/master/reciprocal_search.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/AlexKnyshov/alibaseq/master/blast_wrapper.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/AlexKnyshov/alibaseq/master/loci_type_tutorial/run_test.sh"
      },
      "technique": "file_exploration"
    }
  ],
  "images": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/erg55/alibaseq/master/logiillustrator.png?raw=true"
      },
      "source": "https://raw.githubusercontent.com/AlexKnyshov/alibaseq/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/AlexKnyshov/alibaseq/master/extraction_modes.png"
      },
      "source": "https://raw.githubusercontent.com/AlexKnyshov/alibaseq/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/AlexKnyshov/alibaseq/master/hit_stitcher.png"
      },
      "source": "https://raw.githubusercontent.com/AlexKnyshov/alibaseq/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/AlexKnyshov/alibaseq/master/contig.png"
      },
      "source": "https://raw.githubusercontent.com/AlexKnyshov/alibaseq/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/AlexKnyshov/alibaseq/master/recip.png"
      },
      "source": "https://raw.githubusercontent.com/AlexKnyshov/alibaseq/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "installation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Installation",
        "parent_header": [
          "ALiBaSeq"
        ],
        "type": "Text_excerpt",
        "value": "Clone the repository like this:\n```\ngit clone https://github.com/AlexKnyshov/alibaseq.git\n```\nAlternatively, download and unpack the most recent version from the releases page: https://github.com/AlexKnyshov/alibaseq/releases\n"
      },
      "source": "https://raw.githubusercontent.com/AlexKnyshov/alibaseq/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 0.8502332794369395,
      "result": {
        "original_header": "Single sample",
        "type": "Text_excerpt",
        "value": "Then run ALiBaSeq:\n```\npython alibaseq.py -x a -f S -b assembly.fasta.blast -t assembly.fasta \\\n -e 1e-10 --is --amalgamate-hits\n``` \nThen run ALiBaSeq:\n```\npython alibaseq.py -x a -f S -b assembly.fasta.blast -t assembly.fasta \\\n-e 1e-10 --is --amalgamate-hits -r assembly.fasta.blast_reciprocal.blast \\\n-R reference.fasta.blast\n``` \n"
      },
      "source": "https://raw.githubusercontent.com/AlexKnyshov/alibaseq/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9387660565797061,
      "result": {
        "original_header": "Multiple samples",
        "type": "Text_excerpt",
        "value": "Then run ALiBaSeq:\n```\npython alibaseq.py -x a -f M -b ./blast_results/ -t ./folder_with_assemblies/ \\\n-e 1e-10 --is --amalgamate-hits\n``` \nPerform the reciprocal search\n```\nbash reciprocal_search.sh blast_results folder_with_assemblies \\\nreference.fasta dc-megablast 1 n reciprocal_get_contigs.py \\\nlist_of_files_to_seach_against.txt\n```\nAdjust the number of threads appropriately \nThen run ALiBaSeq:\n```\npython alibaseq.py -x a -f M -b blast_results -t folder_with_assemblies \\\n-e 1e-10 --is --amalgamate-hits -r blast_results -R reference.fasta.blast\n``` \n"
      },
      "source": "https://raw.githubusercontent.com/AlexKnyshov/alibaseq/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.915807770975876,
      "result": {
        "original_header": "Variable baits / genetically distant samples - Protein-based search",
        "type": "Text_excerpt",
        "value": "DNA baits are assumed. If baits are protein, replace tblastx commands below with tblastn \nThen run ALiBaSeq:\n```\npython alibaseq.py -x a -f S -b assembly.fasta.blast -t assembly.fasta \\\n -e 1e-10 --is --amalgamate-hits --ac tdna-tdna\n``` \nThen run ALiBaSeq:\n```\npython alibaseq.py -x a -f S -b assembly.fasta.blast -t assembly.fasta \\\n-e 1e-10 --is --amalgamate-hits -r assembly.fasta.blast_reciprocal.blast \\\n-R reference.fasta.blast --ac tdna-tdna --acr tdna-tdna\n``` \nThen run ALiBaSeq:\n```\npython alibaseq.py -x a -f M -b ./blast_results/ -t ./folder_with_assemblies/ \\\n-e 1e-10 --is --amalgamate-hits --ac tdna-tdna\n``` \nPerform the reciprocal search\n```\nbash reciprocal_search.sh blast_results folder_with_assemblies \\\nreference.fasta tblastx 1 n reciprocal_get_contigs.py \\\nlist_of_files_to_seach_against.txt\n```\nAdjust the number of threads appropriately \nThen run ALiBaSeq:\n```\npython alibaseq.py -x a -f M -b blast_results -t folder_with_assemblies \\\n-e 1e-10 --is --amalgamate-hits -r blast_results -R reference.fasta.blast \\\n--ac tdna-tdna --acr tdna-tdna\n``` \n"
      },
      "source": "https://raw.githubusercontent.com/AlexKnyshov/alibaseq/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "invocation": [
    {
      "confidence": 0.861025356232766,
      "result": {
        "original_header": "Single sample",
        "type": "Text_excerpt",
        "value": "Then run ALiBaSeq:\n```\npython alibaseq.py -x a -f S -b assembly.fasta.blast -t assembly.fasta \\\n -e 1e-10 --is --amalgamate-hits\n``` \nThen run ALiBaSeq:\n```\npython alibaseq.py -x a -f S -b assembly.fasta.blast -t assembly.fasta \\\n-e 1e-10 --is --amalgamate-hits -r assembly.fasta.blast_reciprocal.blast \\\n-R reference.fasta.blast\n``` \n"
      },
      "source": "https://raw.githubusercontent.com/AlexKnyshov/alibaseq/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.861025356232766,
      "result": {
        "original_header": "Multiple samples",
        "type": "Text_excerpt",
        "value": "Then run ALiBaSeq:\n```\npython alibaseq.py -x a -f M -b ./blast_results/ -t ./folder_with_assemblies/ \\\n-e 1e-10 --is --amalgamate-hits\n``` \nThen run ALiBaSeq:\n```\npython alibaseq.py -x a -f M -b blast_results -t folder_with_assemblies \\\n-e 1e-10 --is --amalgamate-hits -r blast_results -R reference.fasta.blast\n``` \n"
      },
      "source": "https://raw.githubusercontent.com/AlexKnyshov/alibaseq/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8613154325241998,
      "result": {
        "original_header": "Variable baits / genetically distant samples - Protein-based search",
        "type": "Text_excerpt",
        "value": "Then run ALiBaSeq:\n```\npython alibaseq.py -x a -f S -b assembly.fasta.blast -t assembly.fasta \\\n -e 1e-10 --is --amalgamate-hits --ac tdna-tdna\n``` \nThen run ALiBaSeq:\n```\npython alibaseq.py -x a -f S -b assembly.fasta.blast -t assembly.fasta \\\n-e 1e-10 --is --amalgamate-hits -r assembly.fasta.blast_reciprocal.blast \\\n-R reference.fasta.blast --ac tdna-tdna --acr tdna-tdna\n``` \nThen run ALiBaSeq:\n```\npython alibaseq.py -x a -f M -b ./blast_results/ -t ./folder_with_assemblies/ \\\n-e 1e-10 --is --amalgamate-hits --ac tdna-tdna\n``` \nThen run ALiBaSeq:\n```\npython alibaseq.py -x a -f M -b blast_results -t folder_with_assemblies \\\n-e 1e-10 --is --amalgamate-hits -r blast_results -R reference.fasta.blast \\\n--ac tdna-tdna --acr tdna-tdna\n``` \n"
      },
      "source": "https://raw.githubusercontent.com/AlexKnyshov/alibaseq/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/AlexKnyshov/alibaseq/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ""
      },
      "technique": "GitHub_API"
    }
  ],
  "license": [
    {
      "confidence": 1,
      "result": {
        "name": "MIT License",
        "spdx_id": "MIT",
        "type": "License",
        "url": "https://api.github.com/licenses/mit",
        "value": "https://api.github.com/licenses/mit"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "type": "File_dump",
        "value": "MIT License\n\nCopyright (c) 2019 AlexKnyshov\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
      },
      "source": "https://raw.githubusercontent.com/AlexKnyshov/alibaseq/master/LICENSE",
      "technique": "file_exploration"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "alibaseq"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "User",
        "value": "AlexKnyshov"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 198297,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Shell",
        "size": 7516,
        "type": "Programming_language",
        "value": "Shell"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/AlexKnyshov/alibaseq/master/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "releases": [
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "AlexKnyshov",
          "type": "User"
        },
        "date_created": "2021-04-01T15:09:11Z",
        "date_published": "2021-04-01T15:12:00Z",
        "description": "Used in the final paper version published in PeerJ",
        "html_url": "https://github.com/AlexKnyshov/alibaseq/releases/tag/v1.2",
        "name": "v1.2",
        "release_id": 40831555,
        "tag": "v1.2",
        "tarball_url": "https://api.github.com/repos/AlexKnyshov/alibaseq/tarball/v1.2",
        "type": "Release",
        "url": "https://api.github.com/repos/AlexKnyshov/alibaseq/releases/40831555",
        "value": "https://api.github.com/repos/AlexKnyshov/alibaseq/releases/40831555",
        "zipball_url": "https://api.github.com/repos/AlexKnyshov/alibaseq/zipball/v1.2"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "AlexKnyshov",
          "type": "User"
        },
        "date_created": "2020-09-01T04:22:09Z",
        "date_published": "2020-09-05T16:35:05Z",
        "description": "Used in the first revised version of the paper on biorxiv, modified to work better for divergent plant species",
        "html_url": "https://github.com/AlexKnyshov/alibaseq/releases/tag/v1.1",
        "name": "v1.1",
        "release_id": 30781221,
        "tag": "v1.1",
        "tarball_url": "https://api.github.com/repos/AlexKnyshov/alibaseq/tarball/v1.1",
        "type": "Release",
        "url": "https://api.github.com/repos/AlexKnyshov/alibaseq/releases/30781221",
        "value": "https://api.github.com/repos/AlexKnyshov/alibaseq/releases/30781221",
        "zipball_url": "https://api.github.com/repos/AlexKnyshov/alibaseq/zipball/v1.1"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "AlexKnyshov",
          "type": "User"
        },
        "date_created": "2020-03-25T22:26:45Z",
        "date_published": "2020-04-24T23:16:37Z",
        "description": "Used in the original version of the paper",
        "html_url": "https://github.com/AlexKnyshov/alibaseq/releases/tag/v1.0",
        "name": "Inintial release",
        "release_id": 25869868,
        "tag": "v1.0",
        "tarball_url": "https://api.github.com/repos/AlexKnyshov/alibaseq/tarball/v1.0",
        "type": "Release",
        "url": "https://api.github.com/repos/AlexKnyshov/alibaseq/releases/25869868",
        "value": "https://api.github.com/repos/AlexKnyshov/alibaseq/releases/25869868",
        "zipball_url": "https://api.github.com/repos/AlexKnyshov/alibaseq/zipball/v1.0"
      },
      "technique": "GitHub_API"
    }
  ],
  "requirements": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Dependencies",
        "parent_header": [
          "ALiBaSeq"
        ],
        "type": "Text_excerpt",
        "value": "Python 2 or 3, Biopython, Pysam (only if SAM / BAM used as input)\n"
      },
      "source": "https://raw.githubusercontent.com/AlexKnyshov/alibaseq/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Requirements:",
        "parent_header": [
          "ALiBaSeq",
          "Workflow"
        ],
        "type": "Text_excerpt",
        "value": "- bait sequences in a single file or in multiple files, one file per locus (can contain multiple sequences); for multiple files, an extension `.fas` is assumed for the bait files.\n- sample files (typically, assembled contigs) in FASTA format, a single file, or multiple files in the same folder\n- if search to be using the wrapper scripts, the search programs (BLAST or HMMER) are in the path\n- for BLAST searches, a database with the same name as the sample file was created in the same folder\n"
      },
      "source": "https://raw.githubusercontent.com/AlexKnyshov/alibaseq/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "somef_missing_categories": [
    "acknowledgement",
    "run",
    "download",
    "contact",
    "contributors",
    "documentation",
    "usage",
    "support",
    "identifier",
    "has_build_file",
    "executable_example"
  ],
  "somef_provenance": {
    "date": "2024-10-06 07:49:02",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 13
      },
      "technique": "GitHub_API"
    }
  ]
}