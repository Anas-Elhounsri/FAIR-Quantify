{
  "citation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Part 2. Detection of Reference Allele Bias",
        "parent_header": [
          "VADT (VCF ASE Detection Tool)",
          "Program Overview"
        ],
        "type": "Text_excerpt",
        "value": "A concern with detection of ASE variants is reference allele bias where the reference genome causes the reference allele to be mapped more. So, VADT tests all \"testable\" variants that pass the prior filters for reference allele bias and reports the final total of (reference allele count / total allele count) for a VCF file. \n"
      },
      "source": "https://raw.githubusercontent.com/mjtiv/VADT/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "References",
        "parent_header": [
          "VADT (VCF ASE Detection Tool)",
          "VADT Outputs"
        ],
        "type": "Text_excerpt",
        "value": "Benjamini, Y. and Y. Hochberg, Controlling the false discovery rate: a pratical and powerful approach to multiple testing. Journal of the Royal Statistical Society, 1995. 57(1): p. 289-300\n\nFisher, R., Statistical Methods for Research Workers (Thirteenth Edition-Revised). 1958, New York: Hafner Publishing Company Inc.\n\nGuo, W., S.K. Sarkar, and S.D. Peddada, Controlling false discoveries in multidimensional directional decisions, with applications to gene expression data on ordered categories. Biometrics, 2010. 66(2): p. 485-92.\n\n\n\n\n\n\n\n\n"
      },
      "source": "https://raw.githubusercontent.com/mjtiv/VADT/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/mjtiv/VADT"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2019-08-12T01:51:09Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2023-03-04T04:02:51Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "VADT_3.0.0 New and Improved"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Program Description",
        "parent_header": [
          "VADT (VCF ASE Detection Tool)"
        ],
        "type": "Text_excerpt",
        "value": "Program takes in a raw VCF file, filters the data and then performs various statistical analysis for\ndetection of allele specific expression (ASE) to identify highly confident occurrences of ASE.\n\nOverall program was originally developed in the Abasht Laboratory at the University of Delaware under the supervision of [Dr. Behnam Abasht](http://canr.udel.edu/faculty/behnam-abasht/). The statistical models and overall accuracy of their code development was overseen by [Dr. Jing Qiu](https://canr.udel.edu/faculty/jing-qiu/)\n\nPlease contact Dr. Behnam Abasht (abasht@udel.edu) with any questions or concerns. \n\nImportant Notes:\nProgram was written using Python 3.6.\nThe input VCF file should be formatted in the following format described by GATK here:\nhttps://gatkforums.broadinstitute.org/gatk/discussion/1268/what-is-a-vcf-and-how-should-i-interpret-it\n"
      },
      "source": "https://raw.githubusercontent.com/mjtiv/VADT/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 0.9921718120795487,
      "result": {
        "original_header": "Part 1. Filtering of Data",
        "type": "Text_excerpt",
        "value": "VADT performs various filtering steps of a VCF file before testing for ASE. The first filter performed is removing all variants that have been flagged as failing (FILTER column). Specifically the program looks for a \"PASS\" in the filter column to include that variant in further analysis. VADT removes all variants within a certain distance of an indel defined by the user. VADT also  removes all variants with multiple reference and alternative alleles and variants with less than the minimum quality score defined by user. \nNow VADT also performs sample level filtering of the data. Sample level filtering consists of filtering based on removing all samples that are homozygous, low read count (user parameter), allele count is <1% of the total counts or \"No data\". So, a variant can fail for any one of these filters or can fail for a combination of these filters being implemented.\n \n"
      },
      "source": "https://raw.githubusercontent.com/mjtiv/VADT/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9902281415331816,
      "result": {
        "original_header": "Part 4 Statistical Analysis of Binomial Results",
        "type": "Text_excerpt",
        "value": "VADT performs two different types of statistical analysis of the data (varying models) to identify significant ASE results, a meta-analysis (variants) or multi-dimensional p-value adjustment (samples). Each test is examining the data in a different way either to identify significant variants or significant samples.\n \n"
      },
      "source": "https://raw.githubusercontent.com/mjtiv/VADT/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9302896194233466,
      "result": {
        "original_header": "Part 4 A. Meta-Analysis (Variants)",
        "type": "Text_excerpt",
        "value": "After implementing the binomial test, VADT next performs a meta-analysis accross all tested samples on per variant basis using Fisher's Method (Fisher 1958). The underlying idea of Fisher's meta-analysis is that by combining p-values together significance may be indentified from the aggregation of samples. After getting the final p-value from the meta-analysis an FDR (Benjamini-Hochberg 1995) is implemented on the final meta p-values. The cutoff for significance of the adjusted p-values is determined by the user in the parameter file.  \n"
      },
      "source": "https://raw.githubusercontent.com/mjtiv/VADT/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9800051187831993,
      "result": {
        "original_header": "Note to Users",
        "type": "Text_excerpt",
        "value": "It is important to point out VADT is not a black box program and all intermediate files are retained for the user to help the user better understand each step performed and also identify bugs in the program. No program is perfect and can always be improved! \n"
      },
      "source": "https://raw.githubusercontent.com/mjtiv/VADT/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8795415854038067,
      "result": {
        "original_header": "Parameters",
        "type": "Text_excerpt",
        "value": "`--Output_File_Location` **REQUIRED** Location where to output the data (give full pathway of output) \n`--Indel_Exclusion_Region_Length` (Default = 1) Length of indel exclusion region to exclude variants. Value should NOT be set to 0 because indels must be removed from datasets for ASE analysis.  \n`--Meta_sample_p_value_cutoff` 0.05 (Default = 0.05) P-value cutoff for estimating the total tally of statistically significant samples statistically significant variants identified from the meta-analysis.  \nNote: If a user cannot mask the reference genome, this value can be adjusted to correct for reference allele bias.   \n"
      },
      "source": "https://raw.githubusercontent.com/mjtiv/VADT/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9753382295284588,
      "result": {
        "original_header": "VADT Outputs",
        "type": "Text_excerpt",
        "value": "VADT produces a global output directory called \"VADT_output_\" that is date and time stamped. This is done to prevent a user from overwriting their prior result runs, which a good Computional Biologist has never done (cough cough)... Inside this global directory are three directories called: Filtering_Results, Meta_Analysis_Results and Multi_Dim_Adj_Results. Each directory will now further broken down. \n"
      },
      "source": "https://raw.githubusercontent.com/mjtiv/VADT/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9522579784914669,
      "result": {
        "original_header": "Filtering_Results",
        "type": "Text_excerpt",
        "value": "The log directory consists of 4 files that show various steps of the filtering process of VCF file. \n`GATK_Failing_RNA_Seq_variants.txt` - Consists of all the variants failed by GATK (variants do not contain a PASS in the filter column). These datasets was specifically seperated from the rest of the filtering datasets because this data is huge and makes opening up the filtering file for QCing much more difficult.  \n`Other_Failing_RNA_Seq_variants.txt` - Consints of all the variants failed by the various filtering criterias: located near an indel, all samples homozygous, low read count (user parameter), allele count is <1% of the total counts or \"No data\". The specific reason why the variant failed can be seen in the first column called \"Failure\" and is self explanotory. \nNote: Sample_Combo_Filter refers to the fact that variant had a combination of samples fail for various reasons that ultimately resulted in the variant failing. \n`Testable_Informative_Filt_Variants.txt` - A txt file that contains all passing variants that can be further analyzed. It is important to point out the original VCF format in this file has been drastically filtered/changed from the original vcf , so that each sample record now consists of four features. \nVerdict = Overall verdict of the sample record. Important only \"Biallelic\" and \"Homo\" tags utilized in further analysis, rest of the tags refer to why the sample failed. \nCounts: Raw counts of the reference and alternative allele  \n"
      },
      "source": "https://raw.githubusercontent.com/mjtiv/VADT/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.896502454853353,
      "result": {
        "original_header": "Meta_Analysis_Results (10 Files)",
        "type": "Text_excerpt",
        "value": "`variant_meta_analysis_results.txt` - All meta-analysis results from the testable variants including the FDR corrected p-value and if the value is significant (user input parameter).  \n`alt_allele_freq_binning_one_ase_hit.txt` - Frequency binning based alternative allele frequency of all variants with atleast one ASE significant hit \n`ase_freq_prevalence_among_samples.txt` - Frequency binning of ASE prevalance among all samples to see the overall occurrence of ASE among the samples \n"
      },
      "source": "https://raw.githubusercontent.com/mjtiv/VADT/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.912868073257193,
      "result": {
        "original_header": "Multi_Dim_Adj_Results (9 Files)",
        "type": "Text_excerpt",
        "value": "`multi_dim_adj_pvalues_testable.txt` - File consists of all the informative \"testable\" samples with a new entry in the sample column on whether that sample passed the cutoff for that specific variant. The cutoff p-value for each variant calcualted from the multi-dimensional p-value algorithm can be found in the variants format column (last entry). It is important to note each variant will have a different cutoff p-value.  \n`maf_freq_binning_one_ase_hit.txt` - Frequency binning based minor allele frequency (maf) of all variants with atleast one ASE significant hit \n"
      },
      "source": "https://raw.githubusercontent.com/mjtiv/VADT/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/mjtiv/VADT/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 1
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/mjtiv/VADT/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "mjtiv/VADT"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "VADT (VCF ASE Detection Tool)"
      },
      "source": "https://raw.githubusercontent.com/mjtiv/VADT/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "installation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Installation and Use",
        "parent_header": [
          "VADT (VCF ASE Detection Tool)"
        ],
        "type": "Text_excerpt",
        "value": "Download the program file and optional parameter file from website and place in local working directory on computer or server.\n\n"
      },
      "source": "https://raw.githubusercontent.com/mjtiv/VADT/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Required input files:",
        "parent_header": [
          "VADT (VCF ASE Detection Tool)",
          "Installation and Use"
        ],
        "type": "Text_excerpt",
        "value": "* VCF file\n\nNote: VCF files utilized by VADT were produced by GATK's Haplotypecaller and so VCF files produced by other programs could potentially have some bugs.\n"
      },
      "source": "https://raw.githubusercontent.com/mjtiv/VADT/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 0.9999823414870467,
      "result": {
        "original_header": "Part 3. Binomial Test",
        "type": "Text_excerpt",
        "value": "Link for Binomial Test: https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.stats.binom_test.html\n \n"
      },
      "source": "https://raw.githubusercontent.com/mjtiv/VADT/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9999492546082416,
      "result": {
        "original_header": "Part 4 A. Meta-Analysis (Variants)",
        "type": "Text_excerpt",
        "value": "Linke for Combine P-values Test: https://docs.scipy.org/doc/scipy-0.19.1/reference/generated/scipy.stats.combine_pvalues.html\n \n"
      },
      "source": "https://raw.githubusercontent.com/mjtiv/VADT/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.938665348276226,
      "result": {
        "original_header": "Parameters",
        "type": "Text_excerpt",
        "value": "Optional Binomial Test Probability Value \nNote: If a user cannot mask the reference genome, this value can be adjusted to correct for reference allele bias.   \n"
      },
      "source": "https://raw.githubusercontent.com/mjtiv/VADT/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9508866754099401,
      "result": {
        "original_header": "Meta_Analysis_Results (10 Files)",
        "type": "Text_excerpt",
        "value": "`data_for_ref_allele_bias_plotting.txt` - Counts for all testable variants, so overall reference allele bias can be investigated on a per variant basis or globally \n`sig_samples_report.txt` - Tallying report of samples results from the sig_meta_analysis_variants.txt file \n`sig_variants_report.txt` - Tallying report of variants results from the sig_meta_analysis_variants.txt file \n`sig_variants_report_and_meta_results.txt` - merged results from sig_variants_report.txt and variant_meta_analysis.results.txt \n"
      },
      "source": "https://raw.githubusercontent.com/mjtiv/VADT/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9292765759467092,
      "result": {
        "original_header": "Multi_Dim_Adj_Results (9 Files)",
        "type": "Text_excerpt",
        "value": "`data_for_ref_allele_bias_plotting.txt` - Counts for all the informative \"testable\" variants, so overall reference allele bias can be investigated on a per variant basis or globally \n`sig_samples_report.txt` - Tallying report of samples results from the sig_multi_dim_adj_results.txt file \n`sig_variants_report.txt` - Tallying report of variants results from the sig_multi_dim_adj_results.txt file \n"
      },
      "source": "https://raw.githubusercontent.com/mjtiv/VADT/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "invocation": [
    {
      "confidence": 0.8708621310858238,
      "result": {
        "original_header": "Part 3. Binomial Test",
        "type": "Text_excerpt",
        "value": "VADT performs a binomial test on all informative \"testable\" biallelic samples in the dataset using SciPy's binomial test module. Utilizing the raw read counts from the VCF file.  \n"
      },
      "source": "https://raw.githubusercontent.com/mjtiv/VADT/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8154976176438612,
      "result": {
        "original_header": "Meta_Analysis_Results (10 Files)",
        "type": "Text_excerpt",
        "value": "`sig_samples_report.txt` - Tallying report of samples results from the sig_meta_analysis_variants.txt file \n`sig_variants_report.txt` - Tallying report of variants results from the sig_meta_analysis_variants.txt file \n"
      },
      "source": "https://raw.githubusercontent.com/mjtiv/VADT/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8154976176438612,
      "result": {
        "original_header": "Multi_Dim_Adj_Results (9 Files)",
        "type": "Text_excerpt",
        "value": "`sig_samples_report.txt` - Tallying report of samples results from the sig_multi_dim_adj_results.txt file \n`sig_variants_report.txt` - Tallying report of variants results from the sig_multi_dim_adj_results.txt file \n"
      },
      "source": "https://raw.githubusercontent.com/mjtiv/VADT/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/mjtiv/VADT/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ""
      },
      "technique": "GitHub_API"
    }
  ],
  "license": [
    {
      "confidence": 1,
      "result": {
        "name": "MIT License",
        "spdx_id": "MIT",
        "type": "License",
        "url": "https://api.github.com/licenses/mit",
        "value": "https://api.github.com/licenses/mit"
      },
      "technique": "GitHub_API"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "VADT"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "User",
        "value": "mjtiv"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 340110,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/mjtiv/VADT/master/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "requirements": [
    {
      "confidence": 1,
      "result": {
        "original_header": "System Requirements",
        "parent_header": [
          "VADT (VCF ASE Detection Tool)",
          "Installation and Use"
        ],
        "type": "Text_excerpt",
        "value": "**Python 3.6** and the following packages\n\n* from __future__ import division\n* import os.path\n* import sys\n* import time\n* from scipy import stats\n* from scipy.stats import combine_pvalues\n* import numpy\n* import copy\n* from datetime import datetime\n* from platform import python_version\n\nNote: Only modules that need to be installed using \"pip\" or whl files are NumPy and SciPy\n\n"
      },
      "source": "https://raw.githubusercontent.com/mjtiv/VADT/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "run": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Running the Program",
        "parent_header": [
          "VADT (VCF ASE Detection Tool)"
        ],
        "type": "Text_excerpt",
        "value": "To run the program it is possible to run in an HPC enviroment or using a parameter file. For large datasets it is highly recommended to run in an HPC enviroment because run times can be extremely long for the program  (30 minutes to 10 hours based on datasets we utilized).\n\nParameter File (VADT_Parameter_File.txt)\n\nThe parameter file is self-explantory and all a user needs to do is open up the file and modify the parameters defined with \"--\". The rest of the lines of text explaining each parameter are ignored (program properly parses). It is important the parameter file needs to be in the same directory as the program to be run.\n\nTo run the program from a HPC enivroment provide the following parameters in submission file. Feel free to change any of the below parameters based on a user's needs and data type. \n\n<pre>\npython VADT_\"version\" \\\n--File_Name name_of_file \\\n--Output_File_Location location_of_desired/output \\\n--Indel_Exclusion_Region_Length 75 \\\n--Quality_Score_Minimum_for_Variants 20 \\\n--Minimum_Read_Counts 20 \\\n--Meta_BH_adj_p_value_cutoff 0.05 \\\n--Meta_sample_p_value_cutoff 0.05 \\\n--Multi_Dim_adjust_pvalue_cutoff 0.05 \\\n--Binomial_Probability_Value 0.5\n</pre>\n \n*NOTE:*\n\"version\" refers to the current version of VADT program that was downloaded.\nSlashes are important in a UNIX enviroment to tell the server \"go to the next line for next parameter\".\n\nDashed lines and the single space are important when submitting parameters. The order of the parameters does not matter, but capitalization, underscores and spelling do.\n\nWhen running this program on the command line locally or on a server, beware of issues that may occur if the incorrect version of python is called or if the NumPy module is not installed properly. Some computers may automatically call a prior version of python if the command \"python\" is given, so a user needs to specifically call python3.6 using full pathways and also needs to install required modules (aka NumPy) to that version. NumPy installed on prior versions of python will NOT work!\n\n*VERY IMPORTANT:* when putting pathways of the files remember to put \"/\" at the end of the pathway!\n\n"
      },
      "source": "https://raw.githubusercontent.com/mjtiv/VADT/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "somef_missing_categories": [
    "acknowledgement",
    "download",
    "contact",
    "contributors",
    "documentation",
    "faq",
    "support",
    "identifier",
    "has_build_file",
    "executable_example"
  ],
  "somef_provenance": {
    "date": "2024-10-06 08:04:28",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 2
      },
      "technique": "GitHub_API"
    }
  ],
  "type": [
    {
      "confidence": 0.82,
      "result": {
        "type": "String",
        "value": "commandline-application"
      },
      "technique": "software_type_heuristics"
    }
  ],
  "usage": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Installation and Use",
        "parent_header": [
          "VADT (VCF ASE Detection Tool)"
        ],
        "type": "Text_excerpt",
        "value": "Download the program file and optional parameter file from website and place in local working directory on computer or server.\n\n"
      },
      "source": "https://raw.githubusercontent.com/mjtiv/VADT/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Required input files:",
        "parent_header": [
          "VADT (VCF ASE Detection Tool)",
          "Installation and Use"
        ],
        "type": "Text_excerpt",
        "value": "* VCF file\n\nNote: VCF files utilized by VADT were produced by GATK's Haplotypecaller and so VCF files produced by other programs could potentially have some bugs.\n"
      },
      "source": "https://raw.githubusercontent.com/mjtiv/VADT/master/README.md",
      "technique": "header_analysis"
    }
  ]
}