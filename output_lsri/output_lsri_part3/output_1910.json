{
  "application_domain": [
    {
      "confidence": 16.11,
      "result": {
        "type": "String",
        "value": "Computer Vision"
      },
      "technique": "supervised_classification"
    }
  ],
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/evo-biomech/scAnt"
      },
      "technique": "GitHub_API"
    }
  ],
  "contributing_guidelines": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Contributing",
        "parent_header": [
          "scAnt - Open Source 3D Scanner"
        ],
        "type": "Text_excerpt",
        "value": "Pull requests are welcome. For major changes, please open an issue first to discuss what you would like to change.\n\nPlease make sure to update tests as appropriate.\n"
      },
      "source": "https://raw.githubusercontent.com/evo-biomech/scAnt/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2020-02-22T07:51:33Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2024-09-26T12:08:19Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "open-source 3D scanning and processing pipeline"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 0.9562848353138865,
      "result": {
        "original_header": "scAnt - Open Source 3D Scanner",
        "type": "Text_excerpt",
        "value": "[**scAnt**](https://peerj.com/articles/11155/) is an open-source, low-cost macro 3D scanner, designed to automate the creation of digital 3D models of insects of various sizes in full colour. **scAnt** provides example configurations for the scanning process, as well as scripts for stacking and masking of images to prepare them for the photogrammetry software of your choice. Some examples of models generated with **scAnt** can be found on http://bit.ly/ScAnt-3D as well as on our [Sketchfab Collection](https://sketchfab.com/EvoBiomech/collections/scant-collection)! \nPlum F, Labonte D. 2021. scAnt\u2014an open-source platform for the creation of 3D models of arthropods (and other small objects) PeerJ 9:e11155 https://doi.org/10.7717/peerj.11155 \nAll structural components of the scanner can be manufactured using 3D-printing and laser cutting; the required files are available for download in .ipt, .iam, .stl, and .svg format on our [thingiverse](https://www.thingiverse.com/thing:4694713) page. \n"
      },
      "source": "https://raw.githubusercontent.com/evo-biomech/scAnt/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9803362126817481,
      "result": {
        "original_header": "Updates",
        "type": "Text_excerpt",
        "value": "- **scAnt 1.3** New faster [stacking method](https://github.com/PetteriAimonen/focus-stack) and updated GUI with added post-processing functionality. We also combined post-processing steps into one file accessed through GUI and command line.\n- **scAnt 1.2** Significantly improved image capture speed for FLIR cameras. As this increases the hardware demand during scanning, it may be advisable to run stacking and masking separately (see [provided python cli scripts](https://github.com/evo-biomech/scAnt/tree/master/scripts)), instead of during scanning. We also updated the respective stacking, masking, and meta data scripts to accomodate a wider range of applications. \n- **scAnt 1.1** Now supports the use of **DSLR** cameras on **Windows 10**, in combination with [DigiCamControl](http://digicamcontrol.com/). Please refer to the [official documentation](http://digicamcontrol.com/cameras) to check whether your camera model is currently supported. **Ubuntu** support will be added soon. An updated version of the scanner construction files will be made available on our [Thingiverse](https://www.thingiverse.com/thing:4694713) page.   \n"
      },
      "source": "https://raw.githubusercontent.com/evo-biomech/scAnt/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.911987706437069,
      "result": {
        "original_header": "Original paper",
        "type": "Text_excerpt",
        "value": "Plum F, Labonte D. 2021. scAnt\u2014an open-source platform for the creation of 3D models of arthropods (and other small objects) \nPeerJ 9:e11155 https://doi.org/10.7717/peerj.11155\n \n"
      },
      "source": "https://raw.githubusercontent.com/evo-biomech/scAnt/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/evo-biomech/scAnt/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 38
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/evo-biomech/scAnt/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "evo-biomech/scAnt"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "scAnt - Open Source 3D Scanner"
      },
      "source": "https://raw.githubusercontent.com/evo-biomech/scAnt/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "images": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "http://raw.githubusercontent.com/evo-biomech/scAnt/master/images/model_collection_showcase_04_updated.jpg"
      },
      "source": "https://raw.githubusercontent.com/evo-biomech/scAnt/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "http://raw.githubusercontent.com/evo-biomech/scAnt/master/images/scanner_3D_comp.png"
      },
      "source": "https://raw.githubusercontent.com/evo-biomech/scAnt/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "http://raw.githubusercontent.com/evo-biomech/scAnt/master/images/stepper_set_up.png"
      },
      "source": "https://raw.githubusercontent.com/evo-biomech/scAnt/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "http://raw.githubusercontent.com/evo-biomech/scAnt/master/images/stepper_set_up.png"
      },
      "source": "https://raw.githubusercontent.com/evo-biomech/scAnt/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "http://raw.githubusercontent.com/evo-biomech/scAnt/master/images/GUI.png"
      },
      "source": "https://raw.githubusercontent.com/evo-biomech/scAnt/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "http://raw.githubusercontent.com/evo-biomech/scAnt/master/images/ProjectSettingsWin.png"
      },
      "source": "https://raw.githubusercontent.com/evo-biomech/scAnt/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "http://raw.githubusercontent.com/evo-biomech/scAnt/master/images/meshroom_correctly_loaded.png"
      },
      "source": "https://raw.githubusercontent.com/evo-biomech/scAnt/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "installation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Installation",
        "parent_header": [
          "scAnt - Open Source 3D Scanner"
        ],
        "type": "Text_excerpt",
        "value": "**scAnt** is supported by 64 bit versions of **Windows 10** and **Ubuntu 18.04** (newer releases of Ubuntu will likely work but have not been tested). The pipeline and GUI have been designed specifically for use with [FLIR Blackfly](https://www.flir.co.uk/products/blackfly-s-usb3/) cameras, and [Pololu USB Stepper drivers](https://www.pololu.com/category/212/tic-stepper-motor-controllers). We have now added support for **DSLR** cameras for **Windows** operating systems as well. Please refer to our [Thingiverse](https://www.thingiverse.com/thing:4694713) page for a full list of components.\n\nThe easiest way to get your scanner up and running is through installation of our pre-configured anaconda environment:\n\n**for Ubuntu 18.04**\n\n```bash\ncd conda_environment\nconda env create -f scAnt_UBUNTU.yml\n```\n\n**for Windows 10**\n\n```bash\ncd conda_environment\nconda env create -f scAnt_WINDOWS.yml\n```\n\nAfter the environment has been created successfully, re-start the terminal, and run the following line to activate the environment, and to continue the installation.\n\n ```bash\nconda activate scAnt\n```\n\nIf you do not wish to install the pre-configured environment, here are the dependencies:\n\n  - python >= 3.6\n  - pip\n  - numpy\n  - matplotlib\n  - opencv >= 4.1.0\n  - pyqt 5\n  - imutils\n  - pillow\n  - scikit-image\n\n\nAdditional drivers and libraries for the camera and stepper drivers need to be installed, as described for both Ubuntu and Windows below.\n***\n"
      },
      "source": "https://raw.githubusercontent.com/evo-biomech/scAnt/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Ubuntu 18.04",
        "parent_header": [
          "scAnt - Open Source 3D Scanner",
          "Installation"
        ],
        "type": "Text_excerpt",
        "value": "**FLIR setup**\n\n***\n\n**NOTE** The latest version (3.0 and above) of **Spinnaker** & **PySpin** causes the **scAnt** application to freeze for some capture commands. \nFor now, we reccomend using a legacy version (1.29 - 2.7) of **Spinnaker** & **PySpin** to avoid this issue! These versions can be found under **FLIR Support / Spinnaker / archive**. In there, you will find both **Ubuntu** as well as **Windows** files, so be sure to double check you are using the version appropriate to your system and python installation.\n\n***\n\nDownload the drivers and python bindings for **Spinnaker & Pyspin** from the official FLIR page: [FLIR - Spinnaker & PySpin](https://www.flir.co.uk/products/spinnaker-sdk/?vertical=machine+vision&segment=iis)\n\nSpinnaker has recently moved their API and criver files into a new repository and you will need to create an account in order to access them.\nOnce you have created an account head to the bottom of the download page to the section **Previous Versions** and download the **2.7.0.128** version for your respective operating system.\nUnpack the folder and you should find both the Spinakker API installation, as well as the required python package inside.\n\nUnpack all files in a folder of your choice. Then proceed with the following steps:\n\n1. Install all required dependencies\n\n```bash\nsudo apt-get install libavcodec57 libavformat57 libswscale4 libswresample2 libavutil55 libusb-1.0-0 libgtkmm-2.4-dev\n```\n\n2. Install spinnaker from its extracted folder. During installation, ensure to add your user to the user-group and accept increasing allocated USB-FS memory size to 1000 MB in order to increase the video stream buffer size.\n\n```bash\nsudo sh install_spinnaker.sh\n```\n\n3. **Reboot** your computer\n\nIn some cases the installer will not be able to update the allocated memory automatically. Check that the memory is set to at least **1000** MB by running:\n\n```bash\ncat /sys/module/usbcore/parameters/usbfs_memory_mb\n```\n\nIn case the **memory allocation** has **not been updated**, you can either increase it temporarily by running\n\n```bash\nsudo sh -c 'echo 1000 > /sys/module/usbcore/parameters/usbfs_memory_mb'\n```\n\nor permanently, by following the instructions outlined in the **README** file of the downloaded **Spinnaker installation** folder.\n\n4. Launch spinview and connect your FLIR camera to verify your installation (if the application is already launched when plugging in your camera, refresh the list)\n\n5. Next, install the downloaded **.whl** file for your python environment. Ensure you activate your python environment before running the **pip install** command below.\n\n```bash\npip install spinnaker_python-2.7.x.x-cp37-cp37m-linux_x86_64.whl\n```\n\n6. To verify everything has been installed correctly, run **Live_view_FLIR.py** from the GUI folder. \n\n```bash\ncd scant/GUI\npython Live_view_FLIR.py\n```\n\nIf a live preview of the camera appears for a few seconds and an example image is saved (within the GUI folder), all camera drivers and libraries have been installed correctly.\n\n**Stepper driver setup**\n\n1. The Pololu stepper drivers can be controlled and set up via a console. Download the drivers specific to your system from [pololu.com](https://www.pololu.com/docs/0J71/3.2), which also provides additional information regarding installation and a list of supported commands. All drivers are open-source, and the respective code can be found on [Pololu's Git](https://github.com/pololu/pololu-tic-software).\n\n2. Unpack the downloaded .tar.xy file and install the driver:\n\n```bash\nsudo pololu-tic-*/install.sh\n```\n\n3. Next, **reboot** your computer to update your user privileges automatically, otherwise you will have to use **sudo** to access your USB stepper drivers.\n\n4. If one or all of the stepper controllers were previously plugged into your computer re-plug them, so they are recognised correctly by your computer. Now, open the terminal and run:\n\n```bash\nticcmd --list\n```\n\nThis should output a list of all connected USB stepper drivers.\n\n6. To test which ID corresponds to which stepper, launch the **Tic Control Center** application and move the sliders. You can use this application to test each motor and set up turning speeds and assign pins for the connected endstops. \n\nDouble check your end-stop cables are connected to the correct pins on the pololu-tic board:\n\n- **GND**: Black\n- **TX**: Green\n- **RX**: Red\n\nThen the setup should be:\n\n**for the Z-axis (camera slider)**\n\n![](images/stepper_set_up.png)\n\nThe TX of the limit switch of the **Z-axis** (camera slider) needs to be set to *\"limit switch forward\"* and to *\"limit switch reverse\"* for the **X-axis** (gimbal).\n\nFrom **/scripts**, open the **Scanner_Controller.py** script in an editor of choice and add the **IDs** of each the stepper to the corresponding axes:\n\n```python\nself.stepperX_ID = \"XXXXXXXX\"\nself.stepperY_ID = \"YYYYYYYY\"\nself.stepperZ_ID = \"ZZZZZZZZ\"\n```\n\n\n**Image Processing**\n\nA number of open source tools are used for processing the RAW images captured by the scanner. For a detailed explanation of each, refer to the official [hugin](http://hugin.sourceforge.net/docs/) and [exiftool](https://exiftool.org/) documentation. The following lines will install _all_ the good stuff:\n\n```bash\nsudo add-apt-repository ppa:hugin/hugin-builds\nsudo apt-get update\nsudo apt-get install hugin enblend\nsudo apt install hugin-tools\nsudo apt install enfuse\nsudo apt install libimage-exiftool-perl\n```\n\n***\n"
      },
      "source": "https://raw.githubusercontent.com/evo-biomech/scAnt/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "FLIR setup",
        "parent_header": [
          "scAnt - Open Source 3D Scanner",
          "Installation",
          "Windows 10"
        ],
        "type": "Text_excerpt",
        "value": "(**Optional**: you only need to install the software required for your respective camera)\n\n(Instructions for using **DSLR** cameras in the section below. You can skip the **FLIR** installation section, if you are not planning on using **FLIR** cameras.) \n\n***\n\n**NOTE** The latest version (3.0 and above) of **Spinnaker** & **PySpin** causes the **scAnt** application to freeze for some capture commands. \nFor now, we reccomend using a legacy version (1.29 - 2.7) of **Spinnaker** & **PySpin** to avoid this issue! These versions can be found under **FLIR Support / Spinnaker / archive**. In there, you will find both **Ubuntu** as well as **Windows** files, so be sure to double check you are using the version appropriate to your system and python installation.\n\n***\n\nDownload the drivers and python bindings for **Spinnaker & Pyspin** from the official FLIR page: [FLIR - Spinnaker & PySpin](https://www.flir.co.uk/products/spinnaker-sdk/?vertical=machine+vision&segment=iis)\n\nSpinnaker has recently moved their API and criver files into a new repository and you will need to create an account in order to access them.\nOnce you have created an account head to the bottom of the download page to the section **Previous Versions** and download the **2.7.0.128** version for your respective operating system.\nUnpack the folder and you should find both the Spinakker API installation, as well as the required python package inside.\n\nUnpack all files in a folder of your choice. Then proceed with the following steps:\n\n1. Install the SpinnakerSDK...exe (likely the x64 version):\n* choose **Application Development** in the installation profile.\n* if you have **not** installed Visual Studio, choose the latest version shown in the installer and the recommeneded packages\n* select \"I will use GigE cameras\" if applicable (we use a USB 3.0 version of the FLIR BFS) \n* no need to participate in any evaluation programs if you don't want to\n\n2. Next, install the downloaded **.whl** file for your python environment. Ensure you activate your python environment before running the **pip install** command below. Ensure your python environment is active and that it corresponds to the version of the chosen **.whl** file, e.g. ```python version 3.7 -> spinnaker_python-2.7.0.128-cp37-cp37m-win_amd64.whl```.\n\n```bash\npip install spinnaker_python-x.x.x.x-cpX-cpXm-win_amd64.whl\n```\n\n3. To verify everything has been installed correctly, run **Live_view_FLIR.py** from the GUI folder. \n\n```bash\ncd scant/GUI\npython Live_view_FLIR.py\n```\n\nIf a live preview of the camera appears for a few seconds and an example image is saved (within the GUI folder), all camera drivers and libraries have been installed correctly.\n\n"
      },
      "source": "https://raw.githubusercontent.com/evo-biomech/scAnt/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "DSLR setup",
        "parent_header": [
          "scAnt - Open Source 3D Scanner",
          "Installation",
          "Windows 10"
        ],
        "type": "Text_excerpt",
        "value": "(**Optional**: you only need to install the software required for your respective camera)\nTo use scAnt with DSLR cameras, instead of FLIR machine vision cameras, you need to install [DigiCamControl](http://digicamcontrol.com/) from the following website:\n\n[digiCamControl Stable Version](http://digicamcontrol.com/download)\n\nFollow the installation instructions and note the **installation path**. By default the path should be:\n\n```bash\n'C:Program Files (x86)/digiCamControl'\n```\n\nIf your installation **path is different**, you will need to add the updated folder path to **GUI/Live_view_DSLR.py**\n\n```python\n# Update with the path to CameraControlCmd.exe file.\ndigi_cam_path = join('C:' + sep, 'Program Files (x86)', 'digiCamControl')\n```\n\nTo check whether the installation and setup was successful, connect your DSLR camera to the computer (must be in MANUAL mode) and run the following commands:\n\n```bash\nconda activate scAnt\ncd GUI\npython Live_view_DSLR.py\n```\n\nThe script will launch an instance of **digiCamControl**, read the current camera settings, and capture three images at different ISO values.\n\n\n**Stepper driver setup**\n\n1. The Pololu stepper drivers can be controlled and set up via a console. Download the drivers specific to your system from [pololu.com](https://www.pololu.com/docs/0J71/3.1), which also provides additional information regarding installation and a list of supported commands. All drivers are open-source, and the respective code can be found on [Pololu's Git](https://github.com/pololu/pololu-tic-software).\n\n2. Unpack the downloaded pololu-tic-x.x.x-win.msi file and install the driver:\n* double click the file to start the installation\n* check \"Add the bin directory to the **PATH environment variable**\"\n\n3. If one or all of the stepper controllers were previously plugged into your computer re-plug them, so they are recognised correctly by your computer. Now, open the terminal and run:\n\n```bash\nticcmd --list\n```\n\nThis should output a list of all connected USB stepper drivers.\n\n4. To test which ID corresponds to which stepper, launch the **Tic Control Center** application and move the sliders. You can use this application to test each motor and set up turning speeds and assign pins for the connected endstops. \n\nDouble check your end-stop cables are connected to the correct pins on the pololu-tic board:\n\n- **GND**: Black\n- **TX**: Green\n- **RX**: Red\n\nThen the setup should be:\n\n**for the Z-axis (camera slider)**\n\n![](images/stepper_set_up.png)\n\nThe TX of the limit switch of the **Z-axis** (camera slider) needs to be set to *\"limit switch forward\"* and to *\"limit switch reverse\"* for the **X-axis** (gimbal).\n\nFrom **/scripts**, open the **Scanner_Controller.py** script in an editor of choice and add the **IDs** of each the stepper to the corresponding axes:\n\n```python\nself.stepperX_ID = \"XXXXXXXX\"\nself.stepperY_ID = \"YYYYYYYY\"\nself.stepperZ_ID = \"ZZZZZZZZ\"\n```\n\n**Image Processing**\n\nA number of open source tools are used for processing the RAW images captured by the scanner. For a detailed explanation of each access to their source code, refer to the official [hugin](http://hugin.sourceforge.net/docs/) and [exiftool](https://exiftool.org/), as well as PetteriAimonen's [focus-stack](https://github.com/PetteriAimonen/focus-stack) documentation. For Windows, we provide a set of precombiled executable files of the required applications in **/external**.\n\n***\n"
      },
      "source": "https://raw.githubusercontent.com/evo-biomech/scAnt/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Quick Start Guide",
        "parent_header": [
          "scAnt - Open Source 3D Scanner"
        ],
        "type": "Text_excerpt",
        "value": "After the installation, the scanner hardware and connected camera can be fully controlled via the scAnt GUI (python scAnt.py). While there is no right or wrong order to configure each component and your workflow might depend on your exact hardware, we generally set up the scanner in 3 steps: **(1) Project Creation**,  **(2) Configuring the Camera**, **(3) Configuring the Stepper Motors**, and **(4) Configuring the Scanning Process**, i.e. saving the project as well as starting the scan.\n\n![](images/GUI.png)\n\n**Project Creation**\n\nBefore editing any presets you must chose to create a new scAnt project or open an existing one. In creating a new project, you can chose a location and a name  - as well as load presets from a previous project.\n\n![](images/ProjectSettingsWin.png)\n\n**Configuring the Camera**\n\nFrom the first box in the Camera Settings box, **select your connected camera**. Depending on which type of camera model you have connected, you will be able to control different settings. For FLIR Blackfly cameras, the options include:\n\n* **Exposure auto** \u2013 Automatically sets exposure time. Useful for finding initial values but needs to be disabled for the scanning process\n* **Exposure time [us]** \u2013 The total time to capture an entire scan scales linearly with the exposure time chosen here. However, as a larger exposure time allows the user to minimise the gain level which in turn minimises noise, quality may dominate speed here.  \n* **Gain auto** \u2013 Similarly to Exposure auto, this option should only be used for the initial setup and not during scanning.\n* **Gain Level** \u2013 influences the brightness of the image by setting the image sensor's sensitivity higher or lower. Lower levels generally reduce image noise.\n* **Gamma** \u2013 Applies contrast correction, affecting primarily mid-tones.\n* **Balance Ratio (Red/Blue)** \u2013 used to adjust the white balance of the image\n* **Highlight Exposure** \u2013 Highlights overexposed regions of the live view image in red and displays normalised colour curves in the bottom right corner.\n* **Start / Stop Live View** \u2013 displays the current video feed of the connected camera (when using DSLR cameras, an instance of DigiCamControl will be opened in an external window, and the camera live view is displayed there)\n* **Capture image** \u2013 An image will be captured with the current settings and saved to the output folder specified in the **Scanner Setup section**.\n\n1. Before picking your settings, you should first move the camera to a position where the specimen within the scanner is in focus and occupies as much of the field of view as possible while not extending beyond it. In the **Stepper Controller** section, you will first have to click \"**Home X-Axis**\" and \"**Home Z-Axis**\", which returns the motors to their zero positions. Afterwards, set the **X-Axis** to **190**, which moves the gimbal arm's pitch perpendicular to the ground. The position of the camera will depend on the used camera type and model. In our case, a value of ~ **-20000** will bring the specimen (partially) into focus. \n\n2. Turn on \"**Start Live View**\" and \"**Highlight Exposure**\" to display overexposed areas (red) and normalised colour curves on top of the live view image. \n\n3. Increase the **exposure/gain** until the image is evenly exposed. Ensure no parts of the specimen are highlighted in red, as these overexposed areas will result in loss of information (you may ignore the pin here).\n\n4. Correct the white balance of the image by adjusting the red and blue **Balance Ratio**, respectively. You can use the colour curves displayed in the **Live View** as a rough guide by aligning the blue and red curves with the green curve, as the neutrally grey background makes up the largest number of image pixels. If you cannot find suitable settings or the specimen appears discoloured, remove it from the illumination chamber, and calibrate the white balance only based on the background. For a finer colour calibration and correction, refer to the official [OpenCV documentation](https://docs.opencv.org/master/d1/dc1/tutorial_ccm_color_correction_model.html) or your camera's manufacturer.\n\n5. Open up the camera info window using the \"Add Camera & Lens Info\" button, then choose your camera's make and model if it hasn't automatically updated. Also fill in the lens and camera details (most importantly the focal length of your lens - the corresponding focal length in 35mm format should update automatically)\n\n**Configuring the Stepper Motors**\n\nThe most critical parameters that need to be configured for the scan are the step sizes for each axis and the Min **[Z axis]** and Max **[Z axis]** values. \n\n1. We have achieved the best results with a **[X Axis]** step value of **50**, and a **[Y axis]** step value of **40**. Although finer resolutions are possible, we haven't observed notable changes in mesh quality when decreasing the step size further. The **Max [X Axis]** and **Max [Y Axis]** should be left unchanged unless the scanner is supposed to be used as a stacking rail only, in which case both values should be equivalent to their respective **Min** value.\n2. The  **Step [Z Axis]** should be determined by your chosen lens and aperture's depth of field. As a rule of thumb, the step size should be equivalent to roughly half the field's depth to achieve adequate overlap of in-focus areas during image stacking.\n3. The **Min [Z axis]** and **Max [Z axis]** values should be chosen based on the size of the scanned specimen, where the **Min [Z axis]** allows the nearest part and the **Max [Z axis]** the furthest part to be in focus. \n\n**ATTENTION**: It may be that these positions change depending on the **X** and **Y-axis** positions, so move both (by using the **sliders** of the respective axis) to find these points. Images that are not in focus can be removed automatically, but **if a part is never in focus** in specific orientations during the scan, it will be **poorly reconstructed**.\n\n**Configuring the Scanning Process**\n\n1. Choose an **Output Folder** location by clicking the browse button in the **Scanner Setup** section. Or open an existing scAnt project using ctrl+o.\n2. Pick an easily identifiable name for your project, such as the species of your scanned specimen. When capturing an image, saving your configuration, or starting a scan, the GUI will generate a folder with your project name in the output folder you have chosen.\n3. Next, configure which processing steps you want to execute in parallel with the scan. The number of threads run in the background will be automatically determined based on the number of (virtual) threads your computer suppports.\n\n[OPTIONAL]\n\nAll processing functions, including removing out of focus images, generating Extended Depth Of Field (EDOF) images, and generating alpha masks, can be run while capturing images or through the standalone script (processStack.py). You can also choose to run all post processing steps from the GUI by selecting a RAW image folder and hitting **Run Post Processing**. The default values shown in the GUI generally work well for most specimens with our setup. However, the following adjustments may aid in achieving the best quality for yours:\n\n4. Enabling **Stack images** will cause scAnt to automatically process the captured files into EDOF images. Information on the default stacking method can be found [here](https://github.com/PetteriAimonen/focus-stack).  The **Threshold (focus)** is a scalar value representing the Laplacian variance of each image required for it to be considered *\"sharp enough for stacking\"*. Simply put, this is used to discard images that appear entirely out of focus. This parameter is sensitive to image noise, resolution, and specimen size. Pay close attention to the messages **printed in the console**. To anticipate the results to some degree, you can use stacking option in the standalone script **(processStack.py)** to monitor the process.\n\n5. Enabling **Mask Images** will generate an alpha mask for each stacked EDOF image. While the outline is extracted using a pretrained [random forest](https://docs.opencv.org/3.1.0/d0/da5/tutorial_ximgproc_prediction.html), the infill is removed using a simple adaptive thresholding step where pixels of a specific brightness are removed from the mask, before being cleaned up using [connected component labelling]( https://aishack.in/tutorials/connected-component-labelling/). The upper and lower bounds of the threshold need to be defined here. The easiest way to find suitable values is to capture an image of your specimen (in the Camera Settings section, click on **Capture image**) and open it in an image editor of your choice (*e.g. GIMP, MS Paint, Photoshop*). Use the **colour picker tool** to return the RGB value from various background locations, ideally close to the specimen.  Note the lowest and highest values out of all channels and fill them into the respective box. You could also do this with a system-wide color picking tool such as the one in [Microsoft PowerToys](https://learn.microsoft.com/en-us/windows/powertoys/), in which case the values can be selected from the live view in the GUI. Again, you can use the masking function of the standalone script **(processStack.py)** to verify your tests before conducting a full scan. \n\n6. Once everything is set up to your liking, hit **Start Scan**, and grab a cup of coffee/tea/beer, depending on the time of day.\n\n**Happy Scanning!**\n\n\n***"
      },
      "source": "https://raw.githubusercontent.com/evo-biomech/scAnt/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Meshroom Guide",
        "parent_header": [
          "scAnt - Open Source 3D Scanner"
        ],
        "type": "Text_excerpt",
        "value": "**Add your camera to the sensor database**\n\nWithin the directory of the downloaded Meshroom installation, go to the following folder and, if you can't find your camera, edit the file \u201c**cameraSensors.db**\u201d using any common text editor:\n\n*\u2026/Meshroom-2019.2.0/AliceVision/share/AliceVision/cameraSensors.db*\n\nThe entry should contain the following:\n\n```bash\nMake;Model;SensorWidth\n```\nEnsure to enter these details as they are listed in your project configuration file, thus, metadata of your stacked and masked images. There should be no spaces between the entries. If you are using the same FLIR camera as in the original **scAnt**, add the following line:\n\n```bash\nFLIR;BFS-U3-200S6C-C;13.1\n```\nAdding the correct sensor width is crucial in computing the camera intrinsics, such as distortion parameters, object scale, and distances. Otherwise the camera alignment, during feature matching and structure-from-motion steps are likely to fail.\n\nOnce these details have been added, launch **Meshroom** and drag your images named *\u2026cutout.tif* into **Meshroom**. If the metadata and added camera sensor are recognised, a **green aperture icon** should be displayed over all images.\n\n![](images/meshroom_correctly_loaded.png)\n\nIf not all images are listed, or the aperture icon remains red / yellow, execute the helper script \u201cbatch_fix_meta_data.py\u201d to fix any issues resulting from your images' exif files. \n\n**Setting up the reconstruction pipeline**\n\n*Try to run the pipeline with this configuration, before attempting to use approximated camera positions. Approximate positions should only be used if issues with the alignment of multiple camera poses arise, as fine differences in the scanner setup can cause poorer reconstruction results, without **guided matching** (available only in the **2020 version** of **Meshroom**)!*\n\n1. **CameraInit**\n\n- *No parameters need to be changed here.*\n- However, ensure that only one element is listed under **Intrinsics**. If there is more than one, remove all images you imported previously, delete all elements listed under **Intrinsics**, and load your images again. If the issue persists, execute the helper script \u201cbatch_fix_meta_data.py\u201d to fix any issues resulting from your images exif files. \n\n2. **FeatureExtraction**\n\n- Enable Advanced Attributes** by clicking on the three dots at the upper right corner.\n- Describer Types: Check **sift** and **akaze**\n- Describer Preset: Normal (pick High if your subject has many fine structures)\n- Force CPU Extraction: Uncheck\n\n3. **ImageMatching**\n\n- Max Descriptors: 10000\n- Nb Matches: 200\n\n4. **FeatureMatching**\n\n- Describer Types: Check **sift** and **akaze**\n- Guided Matching: Check\n\n5. **StructureFromMotion**\n\n- Describer Types: Check **sift** and **akaze**\n- Local Bundle Adjustment: Check\n- Maximum Number of Matches: 0 (ensures all matches are retained)\n\n6. **PrepareDenseScene**\n\n- *No parameters need to be changed here.*\n\n7. **DepthMap**\n\n- Downscale: 1 (use maximum resolution of each image to compute depth maps)\n\n8. **DepthMapFilter**\n\n- Min View Angle: 1\n- Compute Normal Maps: Check\n\n9. **Meshing**\n\n- Estimate Space from SfM: Uncheck (while this will potentially produce \u201cfloaters\u201d that need to be removed during post processing it assists in reserving very fine / long structures, such as antennae)\n- Min Observations for SfM Space Estimation: 2 (only required if above attribute remains checked)\n- Min Observations Angle for SfM Space Estimation: 5 (only required if above attribute remains checked)\n- Max Input Points: 100000000\n- simGaussianSizeInit: 5\n- simGaussianSize: 5\n- Add landmarks to the Dense Point Cloud: Check\t\n\n10. **MeshFiltering**\n\n- Filter Large Triangles Factor: 40\n- Smoothing Iterations: 2\n\n11. Texturing\n\n- Texture Side: 16384\n- Unwrap Method: **LSCM** (will lead to larger texture files, but much higher surface quality)\n- Texture File Type: png\n- Fill Holes: Check\n\nNow click on **start** and watch the magic happen. Actually, this is the best time to grab a cup of coffee, as the reconstruction process takes between 3 and 10 hours, depending on your step size, camera resolution, and system specs.\n\n**Exporting the textured mesh:**\n\nAll outputs within Meshroom are automatically saved in the project\u2019s environment. By right clicking on the **Texturing node** and choosing \u201c**Open Folder**\u201d the location of the created mesh (**.obj** file) is shown.\n"
      },
      "source": "https://raw.githubusercontent.com/evo-biomech/scAnt/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 0.9546011854714346,
      "result": {
        "original_header": "Updates",
        "type": "Text_excerpt",
        "value": "> [!TIP]\nWhen using [Max Simon's]([simonmax@oregonstate.edu](mailto:simonmax@oregonstate.edu)) wonderful [scAnt reconstruction protocol](https://docs.google.com/document/d/1OiYXgazRmuOaInz6f8jFZRLZI9l8wS4ZWVEVKSMpMTQ/edit), use [THIS v1.2](https://github.com/evo-biomech/scAnt/releases/tag/V_1.2.0) release instead! \n"
      },
      "source": "https://raw.githubusercontent.com/evo-biomech/scAnt/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/evo-biomech/scAnt/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ""
      },
      "technique": "GitHub_API"
    }
  ],
  "license": [
    {
      "confidence": 1,
      "result": {
        "name": "MIT License",
        "spdx_id": "MIT",
        "type": "License",
        "url": "https://api.github.com/licenses/mit",
        "value": "https://api.github.com/licenses/mit"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "type": "File_dump",
        "value": "MIT License\n\nCopyright (c) 2020 Fabian Plum\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
      },
      "source": "https://raw.githubusercontent.com/evo-biomech/scAnt/master/LICENSE",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "License",
        "parent_header": [
          "scAnt - Open Source 3D Scanner"
        ],
        "type": "Text_excerpt",
        "value": "**scAnt** - Open Source 3D Scanner and Processing Pipeline\n\n\u00a9 Fabian Plum, 2020\n[MIT License](https://choosealicense.com/licenses/mit/)\n"
      },
      "source": "https://raw.githubusercontent.com/evo-biomech/scAnt/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "scAnt"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "User",
        "value": "evo-biomech"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 337620,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/evo-biomech/scAnt/master/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "releases": [
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "FabianPlum",
          "type": "User"
        },
        "date_created": "2024-02-29T11:10:20Z",
        "date_published": "2024-04-16T09:50:37Z",
        "description": "Official scAnt v1.3.0 release\r\n\r\n[![license](https://img.shields.io/github/license/FabianPlum/OmniTrax.svg?style=flat)](https://github.com/FabianPlum/OmniTrax) [![made-with-python](https://img.shields.io/badge/Made%20with-Python-1f425f.svg)](https://www.python.org/)\r\n\r\nThis version includes the latest updates and incredible contributions to the scAnt project made by @Brit0sh (and some smaller ones by @FabianPlum)!\r\n\r\nMajor updates:\r\n- **DARK MODE**\r\n- added display for focus threshold for improved value selection\r\n- fixed bugs related to out-of-sync motor control\r\n- migrated fully to new [stacking process](https://github.com/PetteriAimonen/focus-stack) (on Windows)\r\n- Addition of **experimental** Meshroom routines for apture-to-mesh pipeline\r\n- Improved processing funcitonality, grouped into separate windows in the main GUI\r\n- Unified post-processing via [processStack](https://github.com/evo-biomech/scAnt/blob/master/processStack.py) for both GUI and CLI access",
        "html_url": "https://github.com/evo-biomech/scAnt/releases/tag/V_1.3.0",
        "name": "scAnt Version 1.3.0",
        "release_id": 151329140,
        "tag": "V_1.3.0",
        "tarball_url": "https://api.github.com/repos/evo-biomech/scAnt/tarball/V_1.3.0",
        "type": "Release",
        "url": "https://api.github.com/repos/evo-biomech/scAnt/releases/151329140",
        "value": "https://api.github.com/repos/evo-biomech/scAnt/releases/151329140",
        "zipball_url": "https://api.github.com/repos/evo-biomech/scAnt/zipball/V_1.3.0"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "FabianPlum",
          "type": "User"
        },
        "date_created": "2024-02-29T11:10:20Z",
        "date_published": "2024-04-16T09:40:38Z",
        "description": "This version is specifically created to align with the [documentation](https://docs.google.com/document/d/1OiYXgazRmuOaInz6f8jFZRLZI9l8wS4ZWVEVKSMpMTQ/edit) provided by [Max Simon]([simonmax@oregonstate.edu](mailto:simonmax@oregonstate.edu)) and [Fabian Plum](https://fabianplum.com/)\r\n\r\nThis release is specifically for novice users closely following [this](https://docs.google.com/document/d/1OiYXgazRmuOaInz6f8jFZRLZI9l8wS4ZWVEVKSMpMTQ/edit) guide for specimen capture and post processing and is closely tied to the use of [3DF Zephyr Lite](https://www.3dflow.net/3df-zephyr-photogrammetry-software/) as scan reconstruction and post-processing software.\r\n\r\nFor an up-to-date and fully open-source version refer to the official [scAnt GitHub](https://github.com/evo-biomech/scAnt) and later releases.\r\n\r\n> [!Important] \r\nUse the \"**scAnt_v1.2.zip**\" file below, NOT the \"**Source code (zip)**\" file!",
        "html_url": "https://github.com/evo-biomech/scAnt/releases/tag/V_1.2.0",
        "name": "scAnt Version 1.2.0 [legacy release]",
        "release_id": 151327471,
        "tag": "V_1.2.0",
        "tarball_url": "https://api.github.com/repos/evo-biomech/scAnt/tarball/V_1.2.0",
        "type": "Release",
        "url": "https://api.github.com/repos/evo-biomech/scAnt/releases/151327471",
        "value": "https://api.github.com/repos/evo-biomech/scAnt/releases/151327471",
        "zipball_url": "https://api.github.com/repos/evo-biomech/scAnt/zipball/V_1.2.0"
      },
      "technique": "GitHub_API"
    }
  ],
  "somef_missing_categories": [
    "citation",
    "acknowledgement",
    "run",
    "download",
    "requirements",
    "contact",
    "contributors",
    "documentation",
    "faq",
    "support",
    "identifier",
    "has_build_file",
    "executable_example"
  ],
  "somef_provenance": {
    "date": "2024-10-06 06:49:04",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 164
      },
      "technique": "GitHub_API"
    }
  ],
  "type": [
    {
      "confidence": 0.82,
      "result": {
        "type": "String",
        "value": "commandline-application"
      },
      "technique": "software_type_heuristics"
    }
  ],
  "usage": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Quick Start Guide",
        "parent_header": [
          "scAnt - Open Source 3D Scanner"
        ],
        "type": "Text_excerpt",
        "value": "After the installation, the scanner hardware and connected camera can be fully controlled via the scAnt GUI (python scAnt.py). While there is no right or wrong order to configure each component and your workflow might depend on your exact hardware, we generally set up the scanner in 3 steps: **(1) Project Creation**,  **(2) Configuring the Camera**, **(3) Configuring the Stepper Motors**, and **(4) Configuring the Scanning Process**, i.e. saving the project as well as starting the scan.\n\n![](images/GUI.png)\n\n**Project Creation**\n\nBefore editing any presets you must chose to create a new scAnt project or open an existing one. In creating a new project, you can chose a location and a name  - as well as load presets from a previous project.\n\n![](images/ProjectSettingsWin.png)\n\n**Configuring the Camera**\n\nFrom the first box in the Camera Settings box, **select your connected camera**. Depending on which type of camera model you have connected, you will be able to control different settings. For FLIR Blackfly cameras, the options include:\n\n* **Exposure auto** \u2013 Automatically sets exposure time. Useful for finding initial values but needs to be disabled for the scanning process\n* **Exposure time [us]** \u2013 The total time to capture an entire scan scales linearly with the exposure time chosen here. However, as a larger exposure time allows the user to minimise the gain level which in turn minimises noise, quality may dominate speed here.  \n* **Gain auto** \u2013 Similarly to Exposure auto, this option should only be used for the initial setup and not during scanning.\n* **Gain Level** \u2013 influences the brightness of the image by setting the image sensor's sensitivity higher or lower. Lower levels generally reduce image noise.\n* **Gamma** \u2013 Applies contrast correction, affecting primarily mid-tones.\n* **Balance Ratio (Red/Blue)** \u2013 used to adjust the white balance of the image\n* **Highlight Exposure** \u2013 Highlights overexposed regions of the live view image in red and displays normalised colour curves in the bottom right corner.\n* **Start / Stop Live View** \u2013 displays the current video feed of the connected camera (when using DSLR cameras, an instance of DigiCamControl will be opened in an external window, and the camera live view is displayed there)\n* **Capture image** \u2013 An image will be captured with the current settings and saved to the output folder specified in the **Scanner Setup section**.\n\n1. Before picking your settings, you should first move the camera to a position where the specimen within the scanner is in focus and occupies as much of the field of view as possible while not extending beyond it. In the **Stepper Controller** section, you will first have to click \"**Home X-Axis**\" and \"**Home Z-Axis**\", which returns the motors to their zero positions. Afterwards, set the **X-Axis** to **190**, which moves the gimbal arm's pitch perpendicular to the ground. The position of the camera will depend on the used camera type and model. In our case, a value of ~ **-20000** will bring the specimen (partially) into focus. \n\n2. Turn on \"**Start Live View**\" and \"**Highlight Exposure**\" to display overexposed areas (red) and normalised colour curves on top of the live view image. \n\n3. Increase the **exposure/gain** until the image is evenly exposed. Ensure no parts of the specimen are highlighted in red, as these overexposed areas will result in loss of information (you may ignore the pin here).\n\n4. Correct the white balance of the image by adjusting the red and blue **Balance Ratio**, respectively. You can use the colour curves displayed in the **Live View** as a rough guide by aligning the blue and red curves with the green curve, as the neutrally grey background makes up the largest number of image pixels. If you cannot find suitable settings or the specimen appears discoloured, remove it from the illumination chamber, and calibrate the white balance only based on the background. For a finer colour calibration and correction, refer to the official [OpenCV documentation](https://docs.opencv.org/master/d1/dc1/tutorial_ccm_color_correction_model.html) or your camera's manufacturer.\n\n5. Open up the camera info window using the \"Add Camera & Lens Info\" button, then choose your camera's make and model if it hasn't automatically updated. Also fill in the lens and camera details (most importantly the focal length of your lens - the corresponding focal length in 35mm format should update automatically)\n\n**Configuring the Stepper Motors**\n\nThe most critical parameters that need to be configured for the scan are the step sizes for each axis and the Min **[Z axis]** and Max **[Z axis]** values. \n\n1. We have achieved the best results with a **[X Axis]** step value of **50**, and a **[Y axis]** step value of **40**. Although finer resolutions are possible, we haven't observed notable changes in mesh quality when decreasing the step size further. The **Max [X Axis]** and **Max [Y Axis]** should be left unchanged unless the scanner is supposed to be used as a stacking rail only, in which case both values should be equivalent to their respective **Min** value.\n2. The  **Step [Z Axis]** should be determined by your chosen lens and aperture's depth of field. As a rule of thumb, the step size should be equivalent to roughly half the field's depth to achieve adequate overlap of in-focus areas during image stacking.\n3. The **Min [Z axis]** and **Max [Z axis]** values should be chosen based on the size of the scanned specimen, where the **Min [Z axis]** allows the nearest part and the **Max [Z axis]** the furthest part to be in focus. \n\n**ATTENTION**: It may be that these positions change depending on the **X** and **Y-axis** positions, so move both (by using the **sliders** of the respective axis) to find these points. Images that are not in focus can be removed automatically, but **if a part is never in focus** in specific orientations during the scan, it will be **poorly reconstructed**.\n\n**Configuring the Scanning Process**\n\n1. Choose an **Output Folder** location by clicking the browse button in the **Scanner Setup** section. Or open an existing scAnt project using ctrl+o.\n2. Pick an easily identifiable name for your project, such as the species of your scanned specimen. When capturing an image, saving your configuration, or starting a scan, the GUI will generate a folder with your project name in the output folder you have chosen.\n3. Next, configure which processing steps you want to execute in parallel with the scan. The number of threads run in the background will be automatically determined based on the number of (virtual) threads your computer suppports.\n\n[OPTIONAL]\n\nAll processing functions, including removing out of focus images, generating Extended Depth Of Field (EDOF) images, and generating alpha masks, can be run while capturing images or through the standalone script (processStack.py). You can also choose to run all post processing steps from the GUI by selecting a RAW image folder and hitting **Run Post Processing**. The default values shown in the GUI generally work well for most specimens with our setup. However, the following adjustments may aid in achieving the best quality for yours:\n\n4. Enabling **Stack images** will cause scAnt to automatically process the captured files into EDOF images. Information on the default stacking method can be found [here](https://github.com/PetteriAimonen/focus-stack).  The **Threshold (focus)** is a scalar value representing the Laplacian variance of each image required for it to be considered *\"sharp enough for stacking\"*. Simply put, this is used to discard images that appear entirely out of focus. This parameter is sensitive to image noise, resolution, and specimen size. Pay close attention to the messages **printed in the console**. To anticipate the results to some degree, you can use stacking option in the standalone script **(processStack.py)** to monitor the process.\n\n5. Enabling **Mask Images** will generate an alpha mask for each stacked EDOF image. While the outline is extracted using a pretrained [random forest](https://docs.opencv.org/3.1.0/d0/da5/tutorial_ximgproc_prediction.html), the infill is removed using a simple adaptive thresholding step where pixels of a specific brightness are removed from the mask, before being cleaned up using [connected component labelling]( https://aishack.in/tutorials/connected-component-labelling/). The upper and lower bounds of the threshold need to be defined here. The easiest way to find suitable values is to capture an image of your specimen (in the Camera Settings section, click on **Capture image**) and open it in an image editor of your choice (*e.g. GIMP, MS Paint, Photoshop*). Use the **colour picker tool** to return the RGB value from various background locations, ideally close to the specimen.  Note the lowest and highest values out of all channels and fill them into the respective box. You could also do this with a system-wide color picking tool such as the one in [Microsoft PowerToys](https://learn.microsoft.com/en-us/windows/powertoys/), in which case the values can be selected from the live view in the GUI. Again, you can use the masking function of the standalone script **(processStack.py)** to verify your tests before conducting a full scan. \n\n6. Once everything is set up to your liking, hit **Start Scan**, and grab a cup of coffee/tea/beer, depending on the time of day.\n\n**Happy Scanning!**\n\n\n***"
      },
      "source": "https://raw.githubusercontent.com/evo-biomech/scAnt/master/README.md",
      "technique": "header_analysis"
    }
  ]
}