{
  "application_domain": [
    {
      "confidence": 81.6,
      "result": {
        "type": "String",
        "value": "Computer Vision"
      },
      "technique": "supervised_classification"
    }
  ],
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/sartorius-research/LIVECell"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2021-02-25T12:33:24Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2024-09-24T04:25:17Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 0.9780487555525796,
      "result": {
        "original_header": "LIVECell dataset",
        "type": "Text_excerpt",
        "value": "This document contains instructions of how to access the data associated with the submitted\nmanuscript \"LIVECell - A large-scale dataset for label-free live cell segmentation\" by Edlund et. al. 2021.\n \n"
      },
      "source": "https://raw.githubusercontent.com/sartorius-research/LIVECell/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9995164430670752,
      "result": {
        "original_header": "Background",
        "type": "Text_excerpt",
        "value": "Light microscopy is a cheap, accessible, non-invasive modality that when combined with well-established\nprotocols of two-dimensional cell culture facilitates high-throughput quantitative imaging to study biological\nphenomena. Accurate segmentation of individual cells enables exploration of complex biological questions, but\nthis requires sophisticated imaging processing pipelines due to the low contrast and high object density.\nDeep learning-based methods are considered state-of-the-art for most computer vision problems but require vast\namounts of annotated data, for which there is no suitable resource available in the field of label-free cellular\nimaging. To address this gap we present LIVECell, a high-quality, manually annotated and expert-validated dataset\nthat is the largest of its kind to date, consisting of over 1.6 million cells from a diverse set of cell morphologies\nand culture densities. To further demonstrate its utility, we provide convolutional neural network-based models\ntrained and evaluated on LIVECell.\n \n"
      },
      "source": "https://raw.githubusercontent.com/sartorius-research/LIVECell/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9798382290257537,
      "result": {
        "original_header": "Comparison to fluorescence-based object counts",
        "type": "Text_excerpt",
        "value": "The images and corresponding json-file with object count per image is available together with the raw fluorescent \nimages the counts is based on. \n"
      },
      "source": "https://raw.githubusercontent.com/sartorius-research/LIVECell/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9406561289170463,
      "result": {
        "original_header": "File structure",
        "type": "Text_excerpt",
        "value": "The top-level structure of the files is arranged like:\n```\n/livecell-dataset/\n    \u251c\u2500\u2500 LIVECell_dataset_2021  \n    |       \u251c\u2500\u2500 annotations/\n    |       \u251c\u2500\u2500 models/\n    |       \u251c\u2500\u2500 nuclear_count_benchmark/\t\n    |       \u2514\u2500\u2500 images.zip  \n    \u251c\u2500\u2500 README.md  \n    \u2514\u2500\u2500 LICENSE\n```\n \n"
      },
      "source": "https://raw.githubusercontent.com/sartorius-research/LIVECell/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.992644205597201,
      "result": {
        "original_header": "LIVECell_dataset_2021/images",
        "type": "Text_excerpt",
        "value": "Within `images.zip` are the training/validation-set and test-set images are completely separate to\nfacilitate fair comparison between studies. The images require 1.3 GB disk space unzipped and are arranged like:\n```\nimages/\n    \u251c\u2500\u2500 livecell_test_images\n    |       \u2514\u2500\u2500 <Cell Type>\n    |               \u2514\u2500\u2500 <Cell Type>_Phase_<Well>_<Location>_<Timestamp>_<Crop>.tif\n    \u2514\u2500\u2500 livecell_train_val_images\n            \u2514\u2500\u2500 <Cell Type>\n```\nWhere `<Cell Type>` is each of the eight cell-types in LIVECell (A172, BT474, BV2, Huh7, MCF7, SHSY5Y, SkBr3, SKOV3).\nWells `<Well>` are the location in the 96-well plate used to culture cells, `<Location>` indicates location in the well\nwhere the image was acquired, `<Timestamp>` the time passed since the beginning of the experiment to image acquisition\nand `<Crop>` index of the crop of the original larger image. An example image name is `A172_Phase_C7_1_02d16h00m_2.tif`,\nwhich is an image of A172-cells, grown in well C7 where the image is acquired in position 1 two days and 16 hours after\nexperiment start (crop position 2).\n \n"
      },
      "source": "https://raw.githubusercontent.com/sartorius-research/LIVECell/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8479387360308723,
      "result": {
        "original_header": "LIVECell_dataset_2021/annotations/",
        "type": "Text_excerpt",
        "value": "*  `annotations/LIVECell` contains the annotations used for the LIVECell-wide train and evaluate task.\n*  `annotations/LIVECell_single_cells` contains the annotations used for Single cell type train and evaluate as well\n   as the Single cell type transferability tasks.\n*  `annotations/LIVECell_dataset_size_split` contains the annotations used to investigate the impact of training set\n   scale. \nAll annotations are in [Microsoft COCO Object Detection-format](https://cocodataset.org/#format-data), and can for\ninstance be parsed by the Python package [`pycocotools`](https://pypi.org/project/pycocotools/).\n \n"
      },
      "source": "https://raw.githubusercontent.com/sartorius-research/LIVECell/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9780260734586917,
      "result": {
        "original_header": "models/",
        "type": "Text_excerpt",
        "value": "ALL models trained and evaluated for tasks associated with LIVECell are made available for wider use. The models\nare trained using [detectron2](https://github.com/facebookresearch/detectron2), Facebook's framework for\nobject detection and instance segmentation. The models require 15 GB of disk space and are arranged like:\n```\nmodels/\n   \u2514\u2500\u2500 Anchor_<free/based>\n            \u251c\u2500\u2500 ALL/\n            |    \u2514\u2500\u2500<Model>.pth\n            \u2514\u2500\u2500 <Cell Type>/\n                 \u2514\u2500\u2500<Model>.pths\n       \n```\n \n"
      },
      "source": "https://raw.githubusercontent.com/sartorius-research/LIVECell/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9372413506488859,
      "result": {
        "original_header": "nuclear_count_benchmark/",
        "type": "Text_excerpt",
        "value": "The images and fluorescence-based object counts are stored as the label-free images in a zip-archive\nand the corresponding counts in a json as below:\n```\nnuclear_count_benchmark/\n    \u251c\u2500\u2500 A172.zip\n    \u251c\u2500\u2500 A172_counts.json\n    \u251c\u2500\u2500 A172_fluorescent_images.zip\n    \u251c\u2500\u2500 A549.zip\n    \u251c\u2500\u2500 A549_counts.json \n    \u2514\u2500\u2500 A549_fluorescent_images.zip\n```\nThe json files are on the following format:\n```\n{\n    \"<filename>\": \"<count>\"\n}\n```\nWhere `<filename>` points to one of the images in the zip-archive, and `<count>` refers to the object count\naccording fluorescent nuclear labels.\n \n"
      },
      "source": "https://raw.githubusercontent.com/sartorius-research/LIVECell/main/README.md",
      "technique": "supervised_classification"
    }
  ],
  "download": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Download all of LIVECell",
        "parent_header": [
          "LIVECell dataset",
          "How to access LIVECell"
        ],
        "type": "Text_excerpt",
        "value": "The LIVECell-dataset and trained models is stored in an Amazon Web Services (AWS) S3-bucket. It is easiest to\ndownload the dataset if you have an AWS IAM-user using the\n[AWS-CLI](https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-install.html) in the folder\nyou would like to download the dataset to by simply:\n```\naws s3 sync s3://livecell-dataset .\n```\n\nIf you do not have an AWS IAM-user, the procedure is a little bit more involved. We can use `curl` to make an\nHTTP-request to get the S3 XML-response and save to `files.xml`:\n\n```\ncurl -H \"GET /?list-type=2 HTTP/1.1\" \\\n     -H \"Host: livecell-dataset.s3.eu-central-1.amazonaws.com\" \\\n     -H \"Date: 20161025T124500Z\" \\\n     -H \"Content-Type: text/plain\" http://livecell-dataset.s3.eu-central-1.amazonaws.com/ > files.xml\n```\n\nWe then get the urls from files using `grep`:\n\n```\ngrep -oPm1 \"(?<=<Key>)[^<]+\" files.xml | sed -e 's/^/http:\\/\\/livecell-dataset.s3.eu-central-1.amazonaws.com\\//' > urls.txt\n```\n\nThen download the files you like using `wget`.\n"
      },
      "source": "https://raw.githubusercontent.com/sartorius-research/LIVECell/main/README.md",
      "technique": "header_analysis"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/sartorius-research/LIVECell/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "executable_example": [
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/sartorius-research/LIVECell/main/code/Fluorescence%20cell%20count%20evaluation.ipynb"
      },
      "source": "https://raw.githubusercontent.com/sartorius-research/LIVECell/main/code/Fluorescence%20cell%20count%20evaluation.ipynb",
      "technique": "file_exploration"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 37
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/sartorius-research/LIVECell/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "sartorius-research/LIVECell"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "LIVECell dataset"
      },
      "source": "https://raw.githubusercontent.com/sartorius-research/LIVECell/main/README.md",
      "technique": "regular_expression"
    }
  ],
  "installation": [
    {
      "confidence": 0.9731911523998092,
      "result": {
        "original_header": "How to access LIVECell",
        "type": "Text_excerpt",
        "value": "All images in LIVECell are available following [this link](http://livecell-dataset.s3.eu-central-1.amazonaws.com/LIVECell_dataset_2021/images.zip)  (requires 1.3 GB). Annotations for the different experiments are linked below.\nTo see a more details regarding benchmarks and how to use our models, see [this link](model/README.md).\n \n"
      },
      "source": "https://raw.githubusercontent.com/sartorius-research/LIVECell/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9254612249481418,
      "result": {
        "original_header": "Single cell-type experiments",
        "type": "Text_excerpt",
        "value": "\n| Cell Type      | Training set  | Validation set | Test set |\n| ---------------|:-------------:|:--------------:|:--------:|\n| A172           | [link](//livecell-dataset.s3.eu-central-1.amazonaws.com/LIVECell_dataset_2021/annotations/LIVECell_single_cells/a172/train.json) | [link](//livecell-dataset.s3.eu-central-1.amazonaws.com/LIVECell_dataset_2021/annotations/LIVECell_single_cells/a172/val.json) | [link](//livecell-dataset.s3.eu-central-1.amazonaws.com/LIVECell_dataset_2021/annotations/LIVECell_single_cells/a172/test.json) |\n| BT474          | [link](//livecell-dataset.s3.eu-central-1.amazonaws.com/LIVECell_dataset_2021/annotations/LIVECell_single_cells/bt474/train.json) | [link](//livecell-dataset.s3.eu-central-1.amazonaws.com/LIVECell_dataset_2021/annotations/LIVECell_single_cells/bt474/val.json) | [link](//livecell-dataset.s3.eu-central-1.amazonaws.com/LIVECell_dataset_2021/annotations/LIVECell_single_cells/bt474/test.json) |\n| BV-2           | [link](//livecell-dataset.s3.eu-central-1.amazonaws.com/LIVECell_dataset_2021/annotations/LIVECell_single_cells/bv2/train.json) | [link](//livecell-dataset.s3.eu-central-1.amazonaws.com/LIVECell_dataset_2021/annotations/LIVECell_single_cells/bv2/val.json) | [link](//livecell-dataset.s3.eu-central-1.amazonaws.com/LIVECell_dataset_2021/annotations/LIVECell_single_cells/bv2/test.json) |\n| Huh7           | [link](//livecell-dataset.s3.eu-central-1.amazonaws.com/LIVECell_dataset_2021/annotations/LIVECell_single_cells/huh7/train.json) | [link](//livecell-dataset.s3.eu-central-1.amazonaws.com/LIVECell_dataset_2021/annotations/LIVECell_single_cells/huh7/val.json) | [link](//livecell-dataset.s3.eu-central-1.amazonaws.com/LIVECell_dataset_2021/annotations/LIVECell_single_cells/huh7/test.json) |\n| MCF7           | [link](//livecell-dataset.s3.eu-central-1.amazonaws.com/LIVECell_dataset_2021/annotations/LIVECell_single_cells/mcf7/train.json) | [link](//livecell-dataset.s3.eu-central-1.amazonaws.com/LIVECell_dataset_2021/annotations/LIVECell_single_cells/mcf7/val.json) | [link](//livecell-dataset.s3.eu-central-1.amazonaws.com/LIVECell_dataset_2021/annotations/LIVECell_single_cells/mcf7/test.json) |\n| SH-SHY5Y       | [link](//livecell-dataset.s3.eu-central-1.amazonaws.com/LIVECell_dataset_2021/annotations/LIVECell_single_cells/shsy5y/train.json) | [link](//livecell-dataset.s3.eu-central-1.amazonaws.com/LIVECell_dataset_2021/annotations/LIVECell_single_cells/shsy5y/val.json) | [link](//livecell-dataset.s3.eu-central-1.amazonaws.com/LIVECell_dataset_2021/annotations/LIVECell_single_cells/shsy5y/test.json) |\n| SkBr3          | [link](//livecell-dataset.s3.eu-central-1.amazonaws.com/LIVECell_dataset_2021/annotations/LIVECell_single_cells/skbr3/train.json) | [link](//livecell-dataset.s3.eu-central-1.amazonaws.com/LIVECell_dataset_2021/annotations/LIVECell_single_cells/skbr3/val.json) | [link](//livecell-dataset.s3.eu-central-1.amazonaws.com/LIVECell_dataset_2021/annotations/LIVECell_single_cells/skbr3/test.json) |\n| SK-OV-3        | [link](//livecell-dataset.s3.eu-central-1.amazonaws.com/LIVECell_dataset_2021/annotations/LIVECell_single_cells/skov3/train.json) | [link](//livecell-dataset.s3.eu-central-1.amazonaws.com/LIVECell_dataset_2021/annotations/LIVECell_single_cells/skov3/val.json) | [link](//livecell-dataset.s3.eu-central-1.amazonaws.com/LIVECell_dataset_2021/annotations/LIVECell_single_cells/skov3/test.json) | \n"
      },
      "source": "https://raw.githubusercontent.com/sartorius-research/LIVECell/main/README.md",
      "technique": "supervised_classification"
    }
  ],
  "invocation": [
    {
      "confidence": 0.8645382524434592,
      "result": {
        "original_header": "Single cell-type experiments",
        "type": "Text_excerpt",
        "value": "\n| Cell Type      | Training set  | Validation set | Test set |\n| ---------------|:-------------:|:--------------:|:--------:|\n| A172           | [link](//livecell-dataset.s3.eu-central-1.amazonaws.com/LIVECell_dataset_2021/annotations/LIVECell_single_cells/a172/train.json) | [link](//livecell-dataset.s3.eu-central-1.amazonaws.com/LIVECell_dataset_2021/annotations/LIVECell_single_cells/a172/val.json) | [link](//livecell-dataset.s3.eu-central-1.amazonaws.com/LIVECell_dataset_2021/annotations/LIVECell_single_cells/a172/test.json) |\n| BT474          | [link](//livecell-dataset.s3.eu-central-1.amazonaws.com/LIVECell_dataset_2021/annotations/LIVECell_single_cells/bt474/train.json) | [link](//livecell-dataset.s3.eu-central-1.amazonaws.com/LIVECell_dataset_2021/annotations/LIVECell_single_cells/bt474/val.json) | [link](//livecell-dataset.s3.eu-central-1.amazonaws.com/LIVECell_dataset_2021/annotations/LIVECell_single_cells/bt474/test.json) |\n| BV-2           | [link](//livecell-dataset.s3.eu-central-1.amazonaws.com/LIVECell_dataset_2021/annotations/LIVECell_single_cells/bv2/train.json) | [link](//livecell-dataset.s3.eu-central-1.amazonaws.com/LIVECell_dataset_2021/annotations/LIVECell_single_cells/bv2/val.json) | [link](//livecell-dataset.s3.eu-central-1.amazonaws.com/LIVECell_dataset_2021/annotations/LIVECell_single_cells/bv2/test.json) |\n| Huh7           | [link](//livecell-dataset.s3.eu-central-1.amazonaws.com/LIVECell_dataset_2021/annotations/LIVECell_single_cells/huh7/train.json) | [link](//livecell-dataset.s3.eu-central-1.amazonaws.com/LIVECell_dataset_2021/annotations/LIVECell_single_cells/huh7/val.json) | [link](//livecell-dataset.s3.eu-central-1.amazonaws.com/LIVECell_dataset_2021/annotations/LIVECell_single_cells/huh7/test.json) |\n| MCF7           | [link](//livecell-dataset.s3.eu-central-1.amazonaws.com/LIVECell_dataset_2021/annotations/LIVECell_single_cells/mcf7/train.json) | [link](//livecell-dataset.s3.eu-central-1.amazonaws.com/LIVECell_dataset_2021/annotations/LIVECell_single_cells/mcf7/val.json) | [link](//livecell-dataset.s3.eu-central-1.amazonaws.com/LIVECell_dataset_2021/annotations/LIVECell_single_cells/mcf7/test.json) |\n| SH-SHY5Y       | [link](//livecell-dataset.s3.eu-central-1.amazonaws.com/LIVECell_dataset_2021/annotations/LIVECell_single_cells/shsy5y/train.json) | [link](//livecell-dataset.s3.eu-central-1.amazonaws.com/LIVECell_dataset_2021/annotations/LIVECell_single_cells/shsy5y/val.json) | [link](//livecell-dataset.s3.eu-central-1.amazonaws.com/LIVECell_dataset_2021/annotations/LIVECell_single_cells/shsy5y/test.json) |\n| SkBr3          | [link](//livecell-dataset.s3.eu-central-1.amazonaws.com/LIVECell_dataset_2021/annotations/LIVECell_single_cells/skbr3/train.json) | [link](//livecell-dataset.s3.eu-central-1.amazonaws.com/LIVECell_dataset_2021/annotations/LIVECell_single_cells/skbr3/val.json) | [link](//livecell-dataset.s3.eu-central-1.amazonaws.com/LIVECell_dataset_2021/annotations/LIVECell_single_cells/skbr3/test.json) |\n| SK-OV-3        | [link](//livecell-dataset.s3.eu-central-1.amazonaws.com/LIVECell_dataset_2021/annotations/LIVECell_single_cells/skov3/train.json) | [link](//livecell-dataset.s3.eu-central-1.amazonaws.com/LIVECell_dataset_2021/annotations/LIVECell_single_cells/skov3/val.json) | [link](//livecell-dataset.s3.eu-central-1.amazonaws.com/LIVECell_dataset_2021/annotations/LIVECell_single_cells/skov3/test.json) | \n"
      },
      "source": "https://raw.githubusercontent.com/sartorius-research/LIVECell/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8017800998730795,
      "result": {
        "original_header": "models/",
        "type": "Text_excerpt",
        "value": "Where each `<Model>.pth` is a binary file containing the model weights.\n \n"
      },
      "source": "https://raw.githubusercontent.com/sartorius-research/LIVECell/main/README.md",
      "technique": "supervised_classification"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/sartorius-research/LIVECell/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ""
      },
      "technique": "GitHub_API"
    }
  ],
  "license": [
    {
      "confidence": 1,
      "result": {
        "name": "MIT License",
        "spdx_id": "MIT",
        "type": "License",
        "url": "https://api.github.com/licenses/mit",
        "value": "https://api.github.com/licenses/mit"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "type": "File_dump",
        "value": "MIT License\n\nCopyright (c) 2021 Sartorius AG\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
      },
      "source": "https://raw.githubusercontent.com/sartorius-research/LIVECell/main/LICENSE",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "LICENSE",
        "parent_header": [
          "LIVECell dataset"
        ],
        "type": "Text_excerpt",
        "value": "All images, annotations and models associated with LIVECell are published under\nAttribution-NonCommercial 4.0 International ([CC BY-NC 4.0](https://creativecommons.org/licenses/by-nc/4.0/)) license.\n\nAll software source code associated associated with LIVECell are published under the MIT License.\n"
      },
      "source": "https://raw.githubusercontent.com/sartorius-research/LIVECell/main/README.md",
      "technique": "header_analysis"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "LIVECell"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "Organization",
        "value": "sartorius-research"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 59552,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Jupyter Notebook",
        "size": 8351,
        "type": "Programming_language",
        "value": "Jupyter Notebook"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/sartorius-research/LIVECell/main/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "somef_missing_categories": [
    "citation",
    "acknowledgement",
    "run",
    "requirements",
    "contact",
    "contributors",
    "documentation",
    "usage",
    "faq",
    "support",
    "identifier",
    "has_build_file"
  ],
  "somef_provenance": {
    "date": "2024-10-06 03:01:23",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 177
      },
      "technique": "GitHub_API"
    }
  ]
}