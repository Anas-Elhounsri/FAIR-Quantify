{
  "application_domain": [
    {
      "confidence": 50.9,
      "result": {
        "type": "String",
        "value": "Computer Vision"
      },
      "technique": "supervised_classification"
    }
  ],
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/lmbxmu/CLR-RNF"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2020-03-19T12:03:58Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2024-09-22T15:34:23Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "Pytorch implementation of our paper (TNNLS) -- Pruning Networks with Cross-Layer Ranking & k-Reciprocal Nearest Filters"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 0.991862537215932,
      "result": {
        "original_header": "Pruning Networks with Cross-Layer Ranking &amp; k-Reciprocal Nearest Filters",
        "type": "Text_excerpt",
        "value": "Pytorch implementation of our paper under review -- Pruning Networks with Cross-Layer Ranking & k-Reciprocal Nearest Filters\n \n"
      },
      "source": "https://raw.githubusercontent.com/lmbxmu/CLR-RNF/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9603549525965323,
      "result": {
        "original_header": "Other Arguments",
        "type": "Text_excerpt",
        "value": "```shell\noptional arguments:\n  -h, --help            show this help message and exit\n  --gpus GPUS [GPUS ...]\n                        Select gpu_id to use. default:[0]\n  --dataset DATASET     Select dataset to train. default:cifar10\n  --data_path DATA_PATH\n                        The dictionary where the input is stored.\n                        default:/home/data/cifar10/\n  --job_dir JOB_DIR     The directory where the summaries will be stored.\n                        default:./experiments\n  --arch ARCH           Architecture of model. default:resnet_imagenet. optional:resnet_cifar/mobilenet_v1/mobilenet_v2\n  --cfg CFG             Detail architecuture of model. default:resnet56. optional:resnet110/18/34/50/101/152 mobilenet_v1/mobilenet_v2\n  --graph_gpu           Use gpu to graph the filters or not. default:False\n  --init_method INIT_METHOD\n                        Initital method of pruned model. default:direct_project. optional:random_project\n  --pr_target           Target prune ratio of parameters \n  --lr_type             lr scheduler. default: step. optional:exp/cos/step/fixed\n  --criterion           Loss function. default:Softmax. optional:SmoothSoftmax\n  --graph_method        Method to recontruct the graph of filters. default:knn other:kmeans/random\n  --resume              Continue training from specific checkpoint. For example:./experiment/imagenet/resnet50_redidual/checkpoint/model_last.pt\n  --use_dali            If this parameter exists, use dali module to load ImageNet data.\n```\n \n"
      },
      "source": "https://raw.githubusercontent.com/lmbxmu/CLR-RNF/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/lmbxmu/CLR-RNF/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 1
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/lmbxmu/CLR-RNF/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "lmbxmu/CLR-RNF"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "Pruning Networks with Cross-Layer Ranking &amp; k-Reciprocal Nearest Filters"
      },
      "source": "https://raw.githubusercontent.com/lmbxmu/CLR-RNF/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "invocation": [
    {
      "confidence": 0.8432842518087941,
      "result": {
        "original_header": "Other Arguments",
        "type": "Text_excerpt",
        "value": "```shell\noptional arguments:\n  -h, --help            show this help message and exit\n  --gpus GPUS [GPUS ...]\n                        Select gpu_id to use. default:[0]\n  --dataset DATASET     Select dataset to train. default:cifar10\n  --data_path DATA_PATH\n                        The dictionary where the input is stored.\n                        default:/home/data/cifar10/\n  --job_dir JOB_DIR     The directory where the summaries will be stored.\n                        default:./experiments\n  --arch ARCH           Architecture of model. default:resnet_imagenet. optional:resnet_cifar/mobilenet_v1/mobilenet_v2\n  --cfg CFG             Detail architecuture of model. default:resnet56. optional:resnet110/18/34/50/101/152 mobilenet_v1/mobilenet_v2\n  --graph_gpu           Use gpu to graph the filters or not. default:False\n  --init_method INIT_METHOD\n                        Initital method of pruned model. default:direct_project. optional:random_project\n  --pr_target           Target prune ratio of parameters \n  --lr_type             lr scheduler. default: step. optional:exp/cos/step/fixed\n  --criterion           Loss function. default:Softmax. optional:SmoothSoftmax\n  --graph_method        Method to recontruct the graph of filters. default:knn other:kmeans/random\n  --resume              Continue training from specific checkpoint. For example:./experiment/imagenet/resnet50_redidual/checkpoint/model_last.pt\n  --use_dali            If this parameter exists, use dali module to load ImageNet data.\n```\n \n"
      },
      "source": "https://raw.githubusercontent.com/lmbxmu/CLR-RNF/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/lmbxmu/CLR-RNF/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "acceleration, compression, network-pruning"
      },
      "technique": "GitHub_API"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "CLR-RNF"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "User",
        "value": "lmbxmu"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 169065,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/lmbxmu/CLR-RNF/master/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "run": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Running code",
        "parent_header": [
          "Pruning Networks with Cross-Layer Ranking &amp; k-Reciprocal Nearest Filters"
        ],
        "type": "Text_excerpt",
        "value": "You can run the following code to prune model on CIFAR-10:\n```shell\npython cifar.py \n--arch vgg_cifar \n--cfg vgg16 \n--data_path /data/cifar \n--job_dir ./experiment/cifar/vgg_1 \n--pretrain_model /home/pretrain/vgg16_cifar10.pt \n--lr 0.01 \n--lr_decay_step 50 100 \n--weight_decay 0.005  \n--num_epochs 150 \n--gpus 0\n--pr_target 0.7 \n--graph_gpu\n```\n\n\n You can run the following code to prune resnets on ImageNet: \n\n```shell\npython imagenet.py \n--dataset imagenet \n--data_path /data/ImageNet/ \n--pretrain_model /data/model/resnet50.pth \n--job_dir /data/experiment/resnet50 \n--arch resnet_imagenet \n--cfg resnet50 \n--lr 0.1 \n--lr_type step\n--num_epochs 90 \n--train_batch_size 256 \n--weight_decay 1e-4 \n--gpus 0 1 2 \n--pr_target 0.7 \n--graph_gpu\n```\n\n You can run the following code to prune mobilenet_v1 on ImageNet: \n\n```shell\npython imagenet.py \n--dataset imagenet \n--arch mobilenet_v1\n--cfg mobilenet_v1 \n--data_path /media/disk2/zyc/ImageNet2012 \n--pretrain_model ./pretrain/checkpoints/mobilenet_v1.pth.tar \n--job_dir ./experiment/imagenet/mobilenet_v1 \n--lr 0.1 \n--lr_type cos\n--weight_decay 4e-5 \n--num_epochs 150 \n--gpus 0  \n--train_batch_size 256 \n--eval_batch_size 256 \n--pr_target 0.58\n--graph_gpu\n```\n\n\n You can run the following code to prune mobilenet_v2 on ImageNet: \n\n```shell\npython imagenet.py \n--dataset imagenet \n--arch mobilenet_v2 \n--cfg mobilenet_v2 \n--data_path /media/disk2/zyc/ImageNet2012 \n--pretrain_model ./pretrain/checkpoints/mobilenet_v2.pth.tar \n--job_dir ./experiment/imagenet/mobilenet_v2 \n--lr 0.1 \n--lr_type cos\n--weight_decay 4e-5 \n--num_epochs 150 \n--gpus 0  \n--train_batch_size 256 \n--eval_batch_size 256 \n--pr_target 0.25\n--graph_gpu\n```\n\nYou can run the following code to get FLOPs prune ratio under a given parameters prune target:\n\n```shell\npython get_flops.py \n--arch resnet_imagenet \n--cfg resnet50 \n--pretrain_model /media/disk2/zyc/prune_result/resnet_50/pruned_checkpoint/resnet50-19c8e357.pth \n--job_dir ./experiment/imagenet/resnet50_flop \n--graph_gpu \n--pr_target 0.1\n```\n\nYou can run the following code to compare the loss between graph\uff0cKmeans & random: \n\n```shell\npython cal_graph_loss.py \n--arch vgg_cifar \n--cfg vgg16 \n--data_path /data/cifar \n--job_dir ./experiment/vgg\n--pretrain_model pretrain/vgg16_cifar10.pt \n--gpus 0 \n--graph_gpu\n```\n\n\nYou can run the following code to test our model:\n\n```shell\npython test.py\n--arch resnet_imagenet \n--cfg resnet50 \n--data_path /media/disk2/zyc/ImageNet2012 \n--resume ./pretrain/checkpoints/model_best.pt \n--pretrain_model /media/disk2/zyc/prune_result/resnet_50/pruned_checkpoint/resnet50-19c8e357.pth \n--pr_target 0.44 \n--job_dir ./experiment/imagenet/test \n--eval_batch_size 256\n```"
      },
      "source": "https://raw.githubusercontent.com/lmbxmu/CLR-RNF/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "somef_missing_categories": [
    "installation",
    "citation",
    "acknowledgement",
    "download",
    "requirements",
    "contact",
    "contributors",
    "documentation",
    "license",
    "usage",
    "faq",
    "support",
    "identifier",
    "has_build_file",
    "executable_example"
  ],
  "somef_provenance": {
    "date": "2024-10-06 00:28:24",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 12
      },
      "technique": "GitHub_API"
    }
  ],
  "type": [
    {
      "confidence": 0.82,
      "result": {
        "type": "String",
        "value": "commandline-application"
      },
      "technique": "software_type_heuristics"
    }
  ]
}