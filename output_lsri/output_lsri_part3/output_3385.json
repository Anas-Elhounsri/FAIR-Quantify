{
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/phiweger/darkq"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2020-02-28T16:00:24Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2024-05-29T13:15:39Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "A message queue for genomic surveillance"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 0.9706788156786186,
      "result": {
        "original_header": "DarkQ",
        "type": "Text_excerpt",
        "value": "_Disclaimer: This is a proof-of-concept on how we might share data for genomic surveillance in the future. The code should be stable, but it is certainly not polished. Any feedback is welcome, both in terms of code and design. Pull requests welcome._  \nGenomic surveillance is not only limited by the speed at which genomes can be shared, but by how fast they can reach the right person or algorithm to analyse them. If you are monitoring a regional outbreak of a multiresistant _Klebsiella pneumoniae_ and I send you some viral genomes, this will not be too useful. \nDarkQ is a messaging queue for microbial genomes. It tries to solve two problems: First, how to know about interesting genomes having been sequenced elsewhere, without having to download these genomes first. And second, how to retrieve the original genomes easily once we observe something interesting. \nWith DarkQ, publishers (P) send (infectious) messages and consumers (C) subscribe to a filtered subset, depending on their preferences as expressed by a set of tags (see below). Say I publish all the stuff we sequence in my lab  during the month, amongst other things some _Klebsiella_. Now you subscribe to the _Klebsiella_ queue, or even more general to all Enterobacterales from Germany, and you filter the messages for genomes that are similar to the isolates in your current outbreak. You might discover that some of my isolates are from the same lineage as your outbreak isolates. You quickly and automatically obtain the original genome sequences, analyse them in detail, and indeed, our houses are part of the same outbreak. Now you can contact me and we can take collective action to limit the spread of this strain. \nMessages are _MinHash_ signatures of the underlying genomes -- think lossy compression [1]. They can be wired efficiently across the message queue and you can compare the similarity of a pair of genomes through these signatures, too. DarkQ uses the `sourmash` implementation of _MinHash_ [2]. If a given message passes the filters (subscription, genome similarity), it is downloaded through the second component of DarkQ, namely the _Interplanetary File System_ (IPFS) [protocol](https://ipfs.io/). Basically, it allows decentralized, peer-to-peer file sharing, which we think is crucial for effective genomic surveillance. \n"
      },
      "source": "https://raw.githubusercontent.com/phiweger/darkq/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9494866357670008,
      "result": {
        "original_header": "How to subscribe to relevant message queues",
        "type": "Text_excerpt",
        "value": "DarkQ allows you to subscribe to an arbitrary number of queues via so called \"routing keys\". Each routing key is unique and has five properties: \n1. name of sender (e.g. \"phiweger\")\n2. country code (e.g. DE)\n3. taxon status (\"found\" or \"mystery\")\n4. taxon level (either one of superkingdom, phylum, class, order, family, genus, species, strain)\n5. taxon name at that level (e.g. \"Klebsiella\" for genus) -- these are adapted from and must conform to the [GTDB r89](https://gtdb.ecogenomic.org/) \nThese queues are declared in `tags.csv`, where empty fields mean \"all\". For example, let's subscribe to three queues: \nFor published messages, these tags are automatically generated. Only the receiver needs to explicitly state the desired message tags. Routing keys act as filters to the messages received over the queue. DarkQ offers a second filter, that allows similarity-based genome filtering. This filter consists of a _Sequence Bloom Tree_ (SBT) of _MinHash_ signatures as generated using `sourmash index` (see above). It is declared in the `nextflow.config`. \n"
      },
      "source": "https://raw.githubusercontent.com/phiweger/darkq/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/phiweger/darkq/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 5
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/phiweger/darkq/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "phiweger/darkq"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "DarkQ"
      },
      "source": "https://raw.githubusercontent.com/phiweger/darkq/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "images": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "http://raw.githubusercontent.com/phiweger/darkq/master/./img/queue.png"
      },
      "source": "https://raw.githubusercontent.com/phiweger/darkq/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "http://raw.githubusercontent.com/phiweger/darkq/master/./img/flow.png"
      },
      "source": "https://raw.githubusercontent.com/phiweger/darkq/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "installation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Install",
        "parent_header": [
          "DarkQ"
        ],
        "type": "Text_excerpt",
        "value": "```bash\n# DarkQ has a couple of needs\nconda create -n darkq -y python=3.7 && conda activate darkq\nconda install -y -c bioconda sourmash nextflow\nconda install -y -c conda-forge geocoder osfclient\n\n# IPFS is a peer-to-peer file sharing protocol\n# https://docs.ipfs.io/guides/guides/install/\n# for example on linux do\nwget -O go-ipfs.tar.gz https://github.com/ipfs/go-ipfs/releases/download/v0.6.0/go-ipfs_v0.6.0_linux-amd64.tar.gz\ntar xvfz go-ipfs.tar.gz\ncd go-ipfs\n# the next command might need sudo permission\n./install.sh\nipfs init\n\n# RabbitMQ is used to publish and subscribe to messages\n# https://www.rabbitmq.com/download.html\nconda install -y -c conda-forge rabbitmq-server pika\n```\n\n"
      },
      "source": "https://raw.githubusercontent.com/phiweger/darkq/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/phiweger/darkq/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ""
      },
      "technique": "GitHub_API"
    }
  ],
  "license": [
    {
      "confidence": 1,
      "result": {
        "name": "BSD 2-Clause \"Simplified\" License",
        "spdx_id": "BSD-2-Clause",
        "type": "License",
        "url": "https://api.github.com/licenses/bsd-2-clause",
        "value": "https://api.github.com/licenses/bsd-2-clause"
      },
      "technique": "GitHub_API"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "darkq"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "User",
        "value": "phiweger"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 15894,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Nextflow",
        "size": 6771,
        "type": "Programming_language",
        "value": "Nextflow"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/phiweger/darkq/master/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "releases": [
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "hoelzer",
          "type": "User"
        },
        "date_created": "2021-10-14T13:25:21Z",
        "date_published": "2021-10-14T16:57:41Z",
        "description": "Fixed Nextflow version check #5 ",
        "html_url": "https://github.com/phiweger/darkq/releases/tag/v0.2",
        "name": "v0.2",
        "release_id": 51378109,
        "tag": "v0.2",
        "tarball_url": "https://api.github.com/repos/phiweger/darkq/tarball/v0.2",
        "type": "Release",
        "url": "https://api.github.com/repos/phiweger/darkq/releases/51378109",
        "value": "https://api.github.com/repos/phiweger/darkq/releases/51378109",
        "zipball_url": "https://api.github.com/repos/phiweger/darkq/zipball/v0.2"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "phiweger",
          "type": "User"
        },
        "date_created": "2021-09-13T09:25:01Z",
        "date_published": "2021-09-13T09:38:17Z",
        "description": "A proof-of-principle implementation to illustrate the concept of an online message queue for genomic surveillance",
        "html_url": "https://github.com/phiweger/darkq/releases/tag/v0.1",
        "name": "MVP",
        "release_id": 49442125,
        "tag": "v0.1",
        "tarball_url": "https://api.github.com/repos/phiweger/darkq/tarball/v0.1",
        "type": "Release",
        "url": "https://api.github.com/repos/phiweger/darkq/releases/49442125",
        "value": "https://api.github.com/repos/phiweger/darkq/releases/49442125",
        "zipball_url": "https://api.github.com/repos/phiweger/darkq/zipball/v0.1"
      },
      "technique": "GitHub_API"
    }
  ],
  "run": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Run",
        "parent_header": [
          "DarkQ"
        ],
        "type": "Text_excerpt",
        "value": "```bash\ngit clone https://github.com/phiweger/darkq && cd darkq\n\n# We need a taxonomy database to assign genomes to queues\nosf -p wxf9z fetch \\\n    release89/gtdb-release89-k31.lca.json.gz \\\n    databases/gtdb-release89-k31.lca.json.gz\n# Thanks Titus -- http://ivory.idyll.org/blog/2019-sourmash-lca-db-gtdb.html\n\n# Create a custom database, which will filter the messages for similar genomes\nsourmash compute -k31 --scale 1000 data/filter/*\nsourmash index databases/filter *.sig && rm *.sig\n\n# Start message queue server (to send via localhost)\nrabbitmq-server &\n\n# Start IPFS daemon\nipfs daemon &\n\n# Start sending/ receiving infectious messages\nmkdir -p data/send\nnextflow run main.nf \n```\n\nNow pull some genomes from the `data/test` folder into `data/send` and see how they turn up in `data/receive`. After copying all genomes from `data/test` to `data/send` you should find three genomes in `data/receive` -- while we sent _E. coli_, _Klebsiella_, _Prochlorococcus_ and _Enterococcus_ over the message queue, and our subscription made us receive them all, our genome similarity filter passed only _Enterococcus_ to the `data/receive` folder. Let's turn this filter off. Put all genomes from `data/send` back into `data/test`, clear `data/receive`, then run:\n\n```bash \nnextflow run main.nf --filter false\n# Now draw the files as before, and all genomes should pass\n```\n\nIn this example, you only shared data with yourself. To start sharing with your friends and colleagues, connect to the queue we provide:\n\n```bash\nURL=amqp://ubugbkyk:GgNs09Y0fnCTTFgEFaBnowTOD-ZFYm3v@swan.rmq.cloudamqp.com/ubugbkyk\nnextflow run main.nf --url $URL\n```\n\nMore settings, such as sketch size and user name, can be found in the `nextflow.config` file.\n\n"
      },
      "source": "https://raw.githubusercontent.com/phiweger/darkq/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "somef_missing_categories": [
    "citation",
    "acknowledgement",
    "download",
    "requirements",
    "contact",
    "contributors",
    "documentation",
    "usage",
    "faq",
    "support",
    "identifier",
    "has_build_file",
    "executable_example"
  ],
  "somef_provenance": {
    "date": "2024-10-06 12:35:27",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 20
      },
      "technique": "GitHub_API"
    }
  ],
  "workflows": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/phiweger/darkq/master/main.nf"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/phiweger/darkq/master/modules/processes.nf"
      },
      "technique": "file_exploration"
    }
  ]
}