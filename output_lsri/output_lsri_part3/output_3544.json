{
  "acknowledgement": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Citations and Acknowledgements",
        "type": "Text_excerpt",
        "value": "Macher, Jan-Niklas, Till-Hendrik Macher, and Florian Leese. \"Combining NCBI and BOLD databases for OTU assignment in metabarcoding and metagenomic datasets: The BOLD_NCBI _Merger.\" Metabarcoding and Metagenomics 1 (2017): e22262.\n\nPorter, Teresita M., and Mehrdad Hajibabaei. \"Over 2.5 million COI sequences in GenBank and growing.\" PloS one 13.9 (2018): e0200177.\n\nWoRMS Editorial Board (2020). World Register of Marine Species. Available from http://www.marinespecies.org at VLIZ. Accessed 2020-04-01. doi:10.14284/170\n\nGuiry, M.D. & Guiry, G.M. 2020. AlgaeBase. World-wide electronic publication, National University of Ireland, Galway. https://www.algaebase.org; searched on 01 April 2020.\n\nPlease also cite: https://doi.org/10.5281/zenodo.3701276 if you're usage involved the addition of custom TaxIDs (this is included by default within the pipeline)\n\nThe genbank_to_fasta.py script was developed by the Rocap Lab https://rocaplab.ocean.washington.edu/\n\nSpecial mention and acknowledgments to Edgar Valdez who help creating the Docker image for MARES. \n"
      },
      "source": "https://raw.githubusercontent.com/wpearman1996/MARES_database_pipeline/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Questions",
        "parent_header": [
          "Citations and Acknowledgements"
        ],
        "type": "Text_excerpt",
        "value": "If there are any questions or issues - please email William Pearman (wpearman1996@gmail.com) or Vanessa Arranz (vanearranz@hotmail.com), or alternatively leave comment on this repository.\n\n"
      },
      "source": "https://raw.githubusercontent.com/wpearman1996/MARES_database_pipeline/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "citation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Building custom reference databases for metabarcoding",
        "type": "Text_excerpt",
        "value": "This pipeline can be used to develop a de-contamination database (i.e used to create a database of potential contaminants), or as a database for general purpose metabarcoding. We have provided three databases - a very small database composed of common contaminants (i.e human, sheep, goat, flies etc), as well as two metabarcoding databases for marine eukaryotes. \n\nThese scripts support the MARES (MARine Eukaryote Species) pipeline used to create the MARES database of COI sequences for metabarcoding studies (presented in [Arranz, V., Pearman, W.S., Aguirre, J.D. & Liggins, L. MARES, a replicable pipeline and curated reference database for marine eukaryote metabarcoding. Sci Data 7, 209 (2020)](https://doi.org/10.1038/s41597-020-0549-9)). The scripts are designed to be run using a Linux OS, and were developed on Ubuntu 16.04. If you use windows, you may be able to use the Windows Linux subsystem (https://docs.microsoft.com/en-us/windows/wsl/install-win10) but you may have additional dependencies to install that aren't covered by the list below. \n\n![Flowchart](https://github.com/wpearman1996/MARES_database_pipeline/blob/master/Flowchart_metabarcodingdb.svg)\n*The MARES bioinformatic pipeline for generating a custom reference database combining sequences retrieved from the Barcode of Life Database (BOLD) and NCBI for a taxonomic group of interest. Shaded boxes detail the workflow within each step and the names of the scripts required. Smaller open boxes describe the subroutines including the functions, packages, and software required (in italics). Boxes with solid outlines indicate input files and boxes with dotted-lined boxes indicate the output files. Many of the scripts and functions used in the MARES pipeline were developed by others; asterisks denote the original contributions of the MARES pipeline.*\n"
      },
      "source": "https://raw.githubusercontent.com/wpearman1996/MARES_database_pipeline/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Before using MARES pipeline",
        "parent_header": [
          "Building custom reference databases for metabarcoding"
        ],
        "type": "Text_excerpt",
        "value": "Installing some of the dependencies can be problematic. We provide two options to set up the dependencies in your computer before running the step-by-step MARES pipeline. \n\nChose one of the two Option below to set up the dependencies in your computer: \n"
      },
      "source": "https://raw.githubusercontent.com/wpearman1996/MARES_database_pipeline/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "OPTION 1. DOCKER container (recommended)",
        "parent_header": [
          "Building custom reference databases for metabarcoding",
          "Before using MARES pipeline"
        ],
        "type": "Text_excerpt",
        "value": "**What is a Docker container-image?**\n\n\"A container is a standard unit of software that packages up code and all its dependencies so the application runs quickly and reliably from one computing environment to another. A Docker container image is a lightweight, standalone, executable package of software that includes everything needed to run an application: code, runtime, system tools, system libraries and settings.\" Learn more: https://www.docker.com/resources/what-container\n\nWe have built a **Docker image for MARES** and you can pull it in your computer (regardless the operting system you have) with 3 main steps and... forget about installing dependencies locally. It will be all ready to go! You can follow the step-by-step MARES pipeline to create your own custom made reference sequence database.\n"
      },
      "source": "https://raw.githubusercontent.com/wpearman1996/MARES_database_pipeline/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "+ R packages",
        "parent_header": [
          "Building custom reference databases for metabarcoding",
          "Before using MARES pipeline",
          "Dependency List"
        ],
        "type": "Text_excerpt",
        "value": "`stringr`\n`rvest`\n`httr`\n`taxize`\n`dplyr`\n`bold`\n`betapart`\n`stingi`\n`qdapDictionaries`\n`splitstackshape`\n`taxizedb`\n`readr`\n`optparse`\n\nThe following commands should help you install the dependencies and get started. If you don't have sudo access, then execute the cpanm commands without the `sudo`, and it will give you an explanation of how to install it without sudo access.\n\n        sudo apt-get install cpanminus\n        sudo apt-get install parallel\n        conda install -c bioconda BioPython\n        conda install -c bioconda seqtk\n        conda install -c bioconda seqkit\n        wget https://cpan.metacpan.org/authors/id/M/MI/MIROD/XML-DOM-XPath-0.14.tar.gz\n        tar xvzf ./XML-DOM-XPath-0.14.tar.gz\n\nThen modify the file at t/test_non_ascii.t and change line 9 from \"use encoding 'utf8';\" \nto \"use utf8;\" - https://stackoverflow.com/questions/47966512/error-installing-xmldomxpath\n\n        rm XML-DOM-XPath-0.14.tar.gz \n        tar -czvf XML-DOM-XPath.tar.gz XML-DOM-XPath-0.14 \n        cpanm XML-DOM-XPath.tar.gz\n\nGenerally we suggest not using conda to install the perl modules, as this seems to cause dependency issues. We recommend to install the perl modules with cpanm. \n\n        sudo cpanm Encode\n        sudo cpanm HTTP::Date\n        sudo cpanm Bio::LITE::Taxonomy::NCBI\n        conda install -c bioconda perl-bio-eutilities\n        sudo cpanm LWP::Simple --force\n        sudo cpanm LWP::UserAgent --force\n        "
      },
      "source": "https://raw.githubusercontent.com/wpearman1996/MARES_database_pipeline/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "**YOUR CUSTOM REFERENCE DATABASE IS COMPLETED!!**",
        "parent_header": [
          "MARES pipeline"
        ],
        "type": "Text_excerpt",
        "value": "---\nYou can find it in the main folder of the repository **MARES_database_pipeline/yourdatabasename_db.fasta**\nOR\nIn Docker **MARES/yourdatabasename_db.fasta**\n\nFeel free to use this reference sequence database fasta file OR move to the next Step 5 (5a. Kraken2 or 5b.MEGAN) to format the fasta file for taxomic classifiers. \n\n\n"
      },
      "source": "https://raw.githubusercontent.com/wpearman1996/MARES_database_pipeline/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Using MARES pre-compiled reference database",
        "type": "Text_excerpt",
        "value": "We would recommend users compile their own reference database, as our pre-compiled reference database will not necessarily be appropriate for every use case. However, in the event you wish to use our databases - they are accessible at the following link: https://osf.io/8rdqk/\n\nFor the MARES reference sequences database, our list of taxa included all families known to have marine species (based on the World Registry of Marine Species, WoRMS, http://www.marinespecies.org/), and we additionally built a database that included common laboratory contaminants.\n\nWe used Cytochrome oxydase 1 (CO1) mirhochondrial gene region as universal DNA barcode for our target system. \n\nThere are two files - MARES_BAR.tar.gz and MARES_NOBAR.tar.gz. \n\nThese represent whether \"BARCODE\" was used as a keyword during compilation of NCBI sequences. In the unzipped files, there are the appropriate names.dmp, nodes.dmp, and the custom accession2taxid files required to use our database. You will still need to download the nucl_gb.accession2taxid & nucl_wgs.accession2taxid files - these are large and thus we have not included them with our pre-compiled databases.\n\n"
      },
      "source": "https://raw.githubusercontent.com/wpearman1996/MARES_database_pipeline/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Technical Validation",
        "parent_header": [
          "Using MARES pre-compiled reference database"
        ],
        "type": "Text_excerpt",
        "value": "To highlight the value and potential utility of our curated reference databases (MARES_COI_BAR and MARES_COI_NOBAR) we compare them with previously published reference databases for the metabarcoding locus CO1. \n\nTo compare the MARES databases with databases in terms of taxonomic composition, we used pairwise beta (\u03b2)\u2010diversity measures based on the presence and absence of taxa within each database. Additionally, we calculated the proportion of marine species out of the total of unique species names for each database.\n\nThe scripts to reproduce our comparisons are in in the technical_validation folder. \n\nThe script *database_formatting.R* first re-formats the species names of each database to find the unique species names after a quality control procedure for retaining fully identified taxa with binomial species names. For this step the sequence names of each reference database are needed, these can be found in the technical validation folder. Next, all the species names across all databases were merged and a presence/absence species matrix was generated to use as input for the script *bdiv_database_comparison.R*. Lastly, the species list from all the databases was checked against WORMS database to identify which were the marine species and to calculate the proportion present in each database.  \n\nThe script *bdiv_database_comparison.R* includes the calculations for the pairwise beta (\u03b2)\u2010diversity measures between databases. \n\nDatabases included in this comparison: \n-\tBOLD \n-\tGenbank\n-\tMiDori-LONGEST\n-\tdb_COI_MBPK\n-\tAnacapa CO1\n\n"
      },
      "source": "https://raw.githubusercontent.com/wpearman1996/MARES_database_pipeline/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Citations and Acknowledgements",
        "type": "Text_excerpt",
        "value": "Macher, Jan-Niklas, Till-Hendrik Macher, and Florian Leese. \"Combining NCBI and BOLD databases for OTU assignment in metabarcoding and metagenomic datasets: The BOLD_NCBI _Merger.\" Metabarcoding and Metagenomics 1 (2017): e22262.\n\nPorter, Teresita M., and Mehrdad Hajibabaei. \"Over 2.5 million COI sequences in GenBank and growing.\" PloS one 13.9 (2018): e0200177.\n\nWoRMS Editorial Board (2020). World Register of Marine Species. Available from http://www.marinespecies.org at VLIZ. Accessed 2020-04-01. doi:10.14284/170\n\nGuiry, M.D. & Guiry, G.M. 2020. AlgaeBase. World-wide electronic publication, National University of Ireland, Galway. https://www.algaebase.org; searched on 01 April 2020.\n\nPlease also cite: https://doi.org/10.5281/zenodo.3701276 if you're usage involved the addition of custom TaxIDs (this is included by default within the pipeline)\n\nThe genbank_to_fasta.py script was developed by the Rocap Lab https://rocaplab.ocean.washington.edu/\n\nSpecial mention and acknowledgments to Edgar Valdez who help creating the Docker image for MARES. \n"
      },
      "source": "https://raw.githubusercontent.com/wpearman1996/MARES_database_pipeline/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Questions",
        "parent_header": [
          "Citations and Acknowledgements"
        ],
        "type": "Text_excerpt",
        "value": "If there are any questions or issues - please email William Pearman (wpearman1996@gmail.com) or Vanessa Arranz (vanearranz@hotmail.com), or alternatively leave comment on this repository.\n\n"
      },
      "source": "https://raw.githubusercontent.com/wpearman1996/MARES_database_pipeline/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Suggested Citation",
        "type": "Text_excerpt",
        "value": "Please refer to the publication: Arranz, V., Pearman, W.S., Aguirre, J.D. & Liggins, L,. MARES, a replicable pipeline and curated reference database for marine eukaryote metabarcoding. Sci Data 7, 209 (2020). https://doi.org/10.1038/s41597-020-0549-9\n\n"
      },
      "source": "https://raw.githubusercontent.com/wpearman1996/MARES_database_pipeline/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "In addition, if you make use of this pipeline, please also cite the following publications:",
        "parent_header": [
          "Suggested Citation"
        ],
        "type": "Text_excerpt",
        "value": "Macher, Jan-Niklas, Till-Hendrik Macher, and Florian Leese. \"Combining NCBI and BOLD databases for OTU assignment in metabarcoding and metagenomic datasets: The BOLD_NCBI _Merger.\" Metabarcoding and Metagenomics 1 (2017): e22262.\n\nPorter, Teresita M., and Mehrdad Hajibabaei. \"Over 2.5 million COI sequences in GenBank and growing.\" PloS one 13.9 (2018): e0200177.\n\nhttps://doi.org/10.5281/zenodo.3701276\n"
      },
      "source": "https://raw.githubusercontent.com/wpearman1996/MARES_database_pipeline/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "If you used the MARES reference sequence database - please also cite:",
        "parent_header": [
          "Suggested Citation"
        ],
        "type": "Text_excerpt",
        "value": "WoRMS Editorial Board (2020). World Register of Marine Species. Available from http://www.marinespecies.org at VLIZ. Accessed 2020-04-01. doi:10.14284/170\n\nGuiry, M.D. & Guiry, G.M. 2020. AlgaeBase. World-wide electronic publication, National University of Ireland, Galway. https://www.algaebase.org; searched on 01 April 2020.\n\n\n"
      },
      "source": "https://raw.githubusercontent.com/wpearman1996/MARES_database_pipeline/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/wpearman1996/MARES_database_pipeline"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2019-10-02T19:34:31Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2024-10-04T15:03:22Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 0.9844105988116484,
      "result": {
        "original_header": "MARES pipeline",
        "type": "Text_excerpt",
        "value": "Either you choose Option 1 or 2 to set up your dependencies, now you are ready to start running the step-by-step MARES pipeline and build your own custom reference sequences database for taxonomic classification of your metabarcoding data!  \nYou need to run each of the following steps in order and choose different parameters to customise your database in the different steps of the pipeline (see MODIFICATIONS in each step of the pipeline).  \n"
      },
      "source": "https://raw.githubusercontent.com/wpearman1996/MARES_database_pipeline/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9367398316767048,
      "result": {
        "original_header": "Step 1: NCBI COI Retrieval",
        "type": "Text_excerpt",
        "value": "First, it is necessary to modify the **taxa.list** file - this file contains the list of taxa that you are interested in. \nYou can use different lists for BOLD or NCBI, or the same for both.  \n1. Converts your list of taxa (i.e. taxa.list) into a list of taxids for every species. For example, \"Chordata\" will be turned into a list of taxids for every species found in Chordata.\n2. Converts taxids to binomial names that can be searched for in NCBI.\n3. Searches NCBI and downloads all relevant genbank files (.gb format).\n4. Convert genbank files to fasta files  \n- *By default* : Script to grab COI records from NCBI nucleotide database using 4 COI search terms, for all Eukaryota, from 2003 to 2021, with the BARCODE keyword\n        - edit the CO1 term to look for other barcode of interest ex. \"COXI\\\"[GENE]\n        - edit the search term below for one year or many years ex. 2017 or 2003:2021[PDAT]\n        - edit whether you want to match the BARCODE in the keyword field or remove it ex. BARCODE[KYWD] \nNote - if there are no sequences in NCBI for any of your chosen taxa, this will return an error:\n\"Use of uninitialized value $count in numeric lt (<) at ../../coi_ret/grab_many_gb_catch_errors_auto_CO1_year.plx line 58.\" \n"
      },
      "source": "https://raw.githubusercontent.com/wpearman1996/MARES_database_pipeline/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9525302872649611,
      "result": {
        "original_header": "Step 2: BOLD Retrieval",
        "type": "Text_excerpt",
        "value": "The Step2_retrieve_bold.r script takes a list of taxa from **taxa.list** and retrieves the BOLD genetic data, and formats this data as a fasta file.  \nThis can take a while for large taxonomic groups, and may timeout when connecting to BOLD if you do not have large amounts of RAM. If this does become problematic, it may be wise to remove this group from your taxlist, replacing it with the subtaxa for that group to avoid timing out.  \n- *By default* it uses same **taxa.list** as in the previous step. If different, you have to specify the taxa list files you wish to use on line 48 in the step2_retrieve_bold.r script.  \n"
      },
      "source": "https://raw.githubusercontent.com/wpearman1996/MARES_database_pipeline/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9660893429357754,
      "result": {
        "original_header": "Step 3: The BOLD_NCBI merger",
        "type": "Text_excerpt",
        "value": "The Step 3 BOLD_NCBI merger is based largely on Macher J, Macher T, Leese F (2017) Combining NCBI and BOLD databases for OTU assignment in metabarcoding and metagenomic datasets: The BOLD_NCBI _Merger. Metabarcoding and Metagenomics 1: e22262. https://doi.org/10.3897/mbmg.1.22262 \nThis process takes the BOLD file, ensures it is for the COI-5P region, and processes the names to enable dereplication of sequences and the merging of sequences from NCBI and BOLD into a single file. Last, the headers are reformatted, and the sequences converted to single line fasta format. \n- You may want to modify the script in line 42 to a greater max sequence length, as vsearch defaults to 50KB (which means it is unlikely to get many plant or algal mitogenomes). \n- The step also removes a list of accessions that can be provided by a user. This is the **blacklisted_accessions.txt** file that will allow removal of accesion numbers and corresponding DNA sequences. In case there are certain accessions (i.e ones that you know have the wrong species associated with the sequence) that you wish to remove from the database. \n**blacklisted_accessions.txt** - this file contains a list of accessions that you do not want included in your database. This should include BOTH NCBI and BOLD accessions. For BOLD the accession should be formatted as ABCI122225-19 (example case), while NCBI accessions should be WITHOUT the version i.e AC1234 rather than AC1234.1.  \n"
      },
      "source": "https://raw.githubusercontent.com/wpearman1996/MARES_database_pipeline/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.958816076209201,
      "result": {
        "original_header": "Step 4: Normalise taxonomy IDs",
        "type": "Text_excerpt",
        "value": "Many taxonomic classifiers software use lowest common ancestor (LCA) approaches for taxonomic classification, and rely on the NCBI taxonomy to do this. However, many species do not have taxonomic identification number (taxid) in NCBI or have been uploaded with synonym names, making the retrieval of reliable taxonomic classifications difficult. \nIn our pipeline, we identify any synonyms and consolidate them so that each taxon has only one name, and is provided with the appropriate taxid. If a taxon does not have a taxid assigned, we will create a new one based on the genus name and incorporate this into the nodes and names dmp files. This only occurs if the genus name is unique taxonomically (i.e \"Acanthocephala\" is both a genus of fly, and phylum of worms, as a result of ambiguous naming, we do not assign a taxid). If a taxid cannot be assigned because the genus was not able to be identified, then the sequence is removed from the database. \nTo normalise the taxonomic IDs we first export a list of sequence names from the merged BOLD and NCBI database. \nWe then generate two lists of sequence names - the first is the original sequence names, for sequences that have taxids. The second is the new set of names for the sequences, that now are in a standardized format, with taxid included in the seq name. We use these lists to rename and generate a new fasta called *databasename_BOLD_NCBI_sl_reformatted.fasta* which is now our completed database. \nIf you have changed the name of your database, you should also specify it in:  \n"
      },
      "source": "https://raw.githubusercontent.com/wpearman1996/MARES_database_pipeline/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9555723412320405,
      "result": {
        "original_header": "Step 6 : Marine and contaminants check",
        "type": "Text_excerpt",
        "value": "We suggest that users ensure their database is representative of not only the taxa they expect to encounter, but also of possible contaminants. One way to do this is to include potential contaminants in your taxa list. The other way is to create a separate contaminant list. In our MARES database, we have opted for the latter. This enables you to screen your sequence reads for contaminants, and remove them, before processing and further analysing your data. Alternatively, you could merge these two databases (i.e. fasta files) together.  \nIn our workflow, we provide scripts that help trawl through your sequence reads, and taxa list, and provide a list of reads or taxa that are potentially contaminants and/or marine species. \nYou can then use the *step6_marine_contaminants_checker.R* script on the taxonomically classified sequences output from MEGAN and Kraken2, and it will flag potential contaminants (based on a provided list of contaminants) or marine species (Based on the WoRMS local database). Please note, not all species of algae are in the local WoRMS download, so algal taxa may not be identified as marine. \nIf you want to check for contaminants or marine taxa you need the following:\n1) A list of contaminant taxa (taxa_contam.list)\n2) The WoRMS local database\n \n"
      },
      "source": "https://raw.githubusercontent.com/wpearman1996/MARES_database_pipeline/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.904817647458405,
      "result": {
        "original_header": "Requesting a local copy of WoRMS",
        "type": "Text_excerpt",
        "value": "To request a local copy of WoRMS visit https://www.marinespecies.org/usersrequest.php and fill in the forms. We would encourage people who do this to consider financially supporting WoRMS during funding applications.  \nThen modify lines 5 & 6 to point to the local WoRMS taxonlist, and your contaminant list.\nAlso modify lines 10 or 34 to point to the Kraken or Megan output, and finally modify line 24 to the location of the names.dmp file.\n \n"
      },
      "source": "https://raw.githubusercontent.com/wpearman1996/MARES_database_pipeline/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/wpearman1996/MARES_database_pipeline/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 6
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/wpearman1996/MARES_database_pipeline/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "wpearman1996/MARES_database_pipeline"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "Building custom reference databases for metabarcoding"
      },
      "source": "https://raw.githubusercontent.com/wpearman1996/MARES_database_pipeline/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "has_build_file": [
    {
      "confidence": 1,
      "result": {
        "format": "dockerfile",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/wpearman1996/MARES_database_pipeline/master/Dockerfile"
      },
      "source": "https://raw.githubusercontent.com/wpearman1996/MARES_database_pipeline/master/Dockerfile",
      "technique": "file_exploration"
    }
  ],
  "has_script_file": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/wpearman1996/MARES_database_pipeline/master/step1_NCBI_COI_Retrieval.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/wpearman1996/MARES_database_pipeline/master/step4e_Ncorrection.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/wpearman1996/MARES_database_pipeline/master/step5_make_krakendb.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/wpearman1996/MARES_database_pipeline/master/step4b_taxid_generation.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/wpearman1996/MARES_database_pipeline/master/step5b_prepare_to_MEGAN.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/wpearman1996/MARES_database_pipeline/master/step4d_taxid_processing.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/wpearman1996/MARES_database_pipeline/master/step3_merge_bold_ncbi.sh"
      },
      "technique": "file_exploration"
    }
  ],
  "images": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/wpearman1996/MARES_database_pipeline/master/Flowchart_metabarcodingdb.svg"
      },
      "source": "https://raw.githubusercontent.com/wpearman1996/MARES_database_pipeline/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "installation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "OPTION 2. Install the dependencies locally in your computer",
        "parent_header": [
          "Building custom reference databases for metabarcoding",
          "Before using MARES pipeline"
        ],
        "type": "Text_excerpt",
        "value": "Installation of dependencies for ubuntu 20.04 - please note this is an evolving section and may not work on all systems. \n"
      },
      "source": "https://raw.githubusercontent.com/wpearman1996/MARES_database_pipeline/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "5a : Prepare for KRAKEN2",
        "parent_header": [
          "MARES pipeline",
          "Step 5: Format for taxonomy classifiers"
        ],
        "type": "Text_excerpt",
        "value": "At this point, we want to format our database for taxonomic classification using Kraken2. For this to work the header for each fasta needs to be reformatted to kraken:taxid|{taxid}. Run the following script to generate the Kraken2 database: \n\n```\nsh step5_make_krakendb.sh\n```\nYou will need to adjust the code on line 3 of step5_make_krakendb if you have changed the name of your database. *By default: database.*\n\nMore information on how to use KRAKEN2 : https://github.com/DerrickWood/kraken2/wiki/Manual#kraken-2-databases\nCitation: Wood DE, Lu J, Langmead B. Improved metagenomic analysis with Kraken 2 (2019). Genome Biology. 2019 Nov;p. 76230. https://doi.org/10.1186/s13059-019-1891-0\n"
      },
      "source": "https://raw.githubusercontent.com/wpearman1996/MARES_database_pipeline/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "5b : Prepare for MEGAN",
        "parent_header": [
          "MARES pipeline",
          "Step 5: Format for taxonomy classifiers"
        ],
        "type": "Text_excerpt",
        "value": "In this step, we build a BLAST database with our custom made reference sequences. More information: https://www.ncbi.nlm.nih.gov/books/NBK569841/\n\n```\nsh step5b_prepare_to_MEGAN.sh\n```\n\nSpecifically, our script : \n- Trims the fasta file names to just the accession.\nBecause BLAST imposes length limits on the sequence names, we trim the sequence names down to just the accession. If you wish to retain that information after classification, then the information is available in the *yourdatbase*_informative_name_table.tsv file. \n- Generates an additional file mapping the accesion numbers to taxids, called **cust_taxid_map**.\n- Use ```makeblastdb``` to build a BLAST database with your custom made reference sequences.  \n\n- Create a new folder with the relevant files to use your CUSTOM MADE REFERENCE DATABASE for taxonomic assignment. \n\n**NOTE**: At this point you can export the relevant database files from the Docker container to your local computer to use YOUR CUSTOM MADE REFERENCE DATABASE for taxonomic assignment. \n\nIn your local command-line: \n```\ndocker cp <containerId>:/file/path/within/container /host/path/target\n```\n\n**ADDITIONAL NOTES**\nBefore import it to MEGAN you should Blast the fasta file containing your metabarcoding sequences against the database you just built. Adjust blast settings according to your needs. More information: https://www.ncbi.nlm.nih.gov/books/NBK279684/\n\n```\n# Example\nblastn -db yourcustommadedatabase -query yourmetabarcodingreads.fasta -evalue 1e-60 -outfmt 5 -out yourdesiredpath/megan.txt -num_threads 8\n```\nThe output is a XML Blast output that can be imported into MEGAN (Husson et al. 2007) for taxonomic assignment using Lower Common Ancestor (LCA) algorithm. \n\nMEGAN is freely available at http://www-ab.informatik.uni-tuebingen.de/software/megan.\nCitation : Huson, D. H., Auch, A. F., Qi, J., & Schuster, S. C. (2007). MEGAN analysis of metagenomic data. Genome research, 17(3), 377-386. https://doi.org/10.1101/gr.5969107\n"
      },
      "source": "https://raw.githubusercontent.com/wpearman1996/MARES_database_pipeline/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 0.960851121405355,
      "result": {
        "original_header": "MARES pipeline",
        "type": "Text_excerpt",
        "value": "Either you choose Option 1 or 2 to set up your dependencies, now you are ready to start running the step-by-step MARES pipeline and build your own custom reference sequences database for taxonomic classification of your metabarcoding data!  \nFirst, download the contents of this repository if you chose running MARES pipeline locally (Option 2). If you chose Docker contaoner option (Option 1) the contents of the repository are already in the Docker image. \nNote: make sure you are in the same folder as the steps scripts to run the pipeline.  \nMay the force be with you! \n"
      },
      "source": "https://raw.githubusercontent.com/wpearman1996/MARES_database_pipeline/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9993858850392445,
      "result": {
        "original_header": "Step 1: NCBI COI Retrieval",
        "type": "Text_excerpt",
        "value": "Then, from the terminal run the Step1 script :\n```\nsh step1_NCBI_COI_Retrieval.sh  \n```\n \n- If you want to modify the search terms to include additional genes or keywords, modify line 29 in the following script ./coi_ret/grab_many_gb_catch_errors_auto_CO1_year.plx   \n"
      },
      "source": "https://raw.githubusercontent.com/wpearman1996/MARES_database_pipeline/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9564093611203842,
      "result": {
        "original_header": "Step 2: BOLD Retrieval",
        "type": "Text_excerpt",
        "value": "For BOLD retrieval, run the R script : \n```\nr step2_retrieve_bold.r\n``` \n- *By default* it uses same **taxa.list** as in the previous step. If different, you have to specify the taxa list files you wish to use on line 48 in the step2_retrieve_bold.r script.  \n- If you want to modify the search terms to include additional genes (barcodes), you can specify on line 6 in the step2_retrieve_bold.r script. \n"
      },
      "source": "https://raw.githubusercontent.com/wpearman1996/MARES_database_pipeline/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9536341907279797,
      "result": {
        "original_header": "Step 3: The BOLD_NCBI merger",
        "type": "Text_excerpt",
        "value": "Run the script : \n```\nsh step3_merge_bold_ncbi.sh\n``` \n- You may need to modify Step3_merge_bold_ncbi.sh on line 6 to specify the name for your reference database. *By default : \"database\".* \n- You may want to modify the script in line 42 to a greater max sequence length, as vsearch defaults to 50KB (which means it is unlikely to get many plant or algal mitogenomes). \n**blacklisted_accessions.txt** - this file contains a list of accessions that you do not want included in your database. This should include BOTH NCBI and BOLD accessions. For BOLD the accession should be formatted as ABCI122225-19 (example case), while NCBI accessions should be WITHOUT the version i.e AC1234 rather than AC1234.1.  \n"
      },
      "source": "https://raw.githubusercontent.com/wpearman1996/MARES_database_pipeline/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9532669375038524,
      "result": {
        "original_header": "Step 4: Normalise taxonomy IDs",
        "type": "Text_excerpt",
        "value": "Run the following commands in order : \n```\nr step4a_taxid_addition.r\n```\nBASH2*\nBASH3*\nBASH4* \nOptional, Step4e remove sequences that have excessive numbers of ambiguous bases (N), and trim leading or trailing Ns.\n```\nsh step4e_Ncorrection.sh\n```\n \nIf you have changed the name of your database, you should also specify it in:  \n- step4a_taxid_addition.r: modify the file name of the sequences in line 3. *By default: seqnames_database_nobarcode.txt* \n- step4d_taxid_processing.sh: modify the database name in line 3 to your chosen database name. *By default: database* \n- step4e_Ncorrection.sh: modify the database name in line 3 to your chosen database name. *By default: database* \n"
      },
      "source": "https://raw.githubusercontent.com/wpearman1996/MARES_database_pipeline/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9078829735428772,
      "result": {
        "original_header": "Step 6 : Marine and contaminants check",
        "type": "Text_excerpt",
        "value": "> Run the the R script step6_marine_contaminants_checker.R in R.  \nIf you want to check for contaminants or marine taxa you need the following:\n1) A list of contaminant taxa (taxa_contam.list)\n2) The WoRMS local database\n \n"
      },
      "source": "https://raw.githubusercontent.com/wpearman1996/MARES_database_pipeline/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "invocation": [
    {
      "confidence": 0.8298896483115964,
      "result": {
        "original_header": "Step 3: The BOLD_NCBI merger",
        "type": "Text_excerpt",
        "value": "Run the script : \n```\nsh step3_merge_bold_ncbi.sh\n``` \n"
      },
      "source": "https://raw.githubusercontent.com/wpearman1996/MARES_database_pipeline/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/wpearman1996/MARES_database_pipeline/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ""
      },
      "technique": "GitHub_API"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "MARES_database_pipeline"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "User",
        "value": "wpearman1996"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Perl",
        "size": 72524,
        "type": "Programming_language",
        "value": "Perl"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "R",
        "size": 21381,
        "type": "Programming_language",
        "value": "R"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 11841,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Shell",
        "size": 10818,
        "type": "Programming_language",
        "value": "Shell"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Dockerfile",
        "size": 2296,
        "type": "Programming_language",
        "value": "Dockerfile"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/wpearman1996/MARES_database_pipeline/master/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "requirements": [
    {
      "confidence": 1,
      "result": {
        "original_header": "OPTION 2. Install the dependencies locally in your computer",
        "parent_header": [
          "Building custom reference databases for metabarcoding",
          "Before using MARES pipeline"
        ],
        "type": "Text_excerpt",
        "value": "Installation of dependencies for ubuntu 20.04 - please note this is an evolving section and may not work on all systems. \n"
      },
      "source": "https://raw.githubusercontent.com/wpearman1996/MARES_database_pipeline/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Dependency List",
        "parent_header": [
          "Building custom reference databases for metabarcoding",
          "Before using MARES pipeline"
        ],
        "type": "Text_excerpt",
        "value": "`vsearch`\n`BLAST+`\n`cpanminus`\n`biopython`\n`Bio::Lite::Taxonomy::NCBI`\n`Bio::DB::EUtilities`\n`HTTP::Date`\n`LWP::Simple`\n`LWP::UserAgent`\n`parallel`\n`perl`\n`r`\n`python2`\n`seqtk`\n`Kraken2`\n"
      },
      "source": "https://raw.githubusercontent.com/wpearman1996/MARES_database_pipeline/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "+ R packages",
        "parent_header": [
          "Building custom reference databases for metabarcoding",
          "Before using MARES pipeline",
          "Dependency List"
        ],
        "type": "Text_excerpt",
        "value": "`stringr`\n`rvest`\n`httr`\n`taxize`\n`dplyr`\n`bold`\n`betapart`\n`stingi`\n`qdapDictionaries`\n`splitstackshape`\n`taxizedb`\n`readr`\n`optparse`\n\nThe following commands should help you install the dependencies and get started. If you don't have sudo access, then execute the cpanm commands without the `sudo`, and it will give you an explanation of how to install it without sudo access.\n\n        sudo apt-get install cpanminus\n        sudo apt-get install parallel\n        conda install -c bioconda BioPython\n        conda install -c bioconda seqtk\n        conda install -c bioconda seqkit\n        wget https://cpan.metacpan.org/authors/id/M/MI/MIROD/XML-DOM-XPath-0.14.tar.gz\n        tar xvzf ./XML-DOM-XPath-0.14.tar.gz\n\nThen modify the file at t/test_non_ascii.t and change line 9 from \"use encoding 'utf8';\" \nto \"use utf8;\" - https://stackoverflow.com/questions/47966512/error-installing-xmldomxpath\n\n        rm XML-DOM-XPath-0.14.tar.gz \n        tar -czvf XML-DOM-XPath.tar.gz XML-DOM-XPath-0.14 \n        cpanm XML-DOM-XPath.tar.gz\n\nGenerally we suggest not using conda to install the perl modules, as this seems to cause dependency issues. We recommend to install the perl modules with cpanm. \n\n        sudo cpanm Encode\n        sudo cpanm HTTP::Date\n        sudo cpanm Bio::LITE::Taxonomy::NCBI\n        conda install -c bioconda perl-bio-eutilities\n        sudo cpanm LWP::Simple --force\n        sudo cpanm LWP::UserAgent --force\n        "
      },
      "source": "https://raw.githubusercontent.com/wpearman1996/MARES_database_pipeline/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "run": [
    {
      "confidence": 1,
      "result": {
        "original_header": "List of Files that need modification before running the step-by-step MARES pipeline",
        "parent_header": [
          "MARES pipeline"
        ],
        "type": "Text_excerpt",
        "value": "Email authentification: \n* ./coi_ret/ebot_taxonomy3.plx - line 86 requires email\n* ./coi_ret/grab_many_gb_catch_errors_auto_CO1_year.plx - line 32 requires email\n\nNCBI taxonomy - modify only if OPTION 2 was used to install dependencies. \n* ./coi_ret/taxonomy_crawl_for_genus_species_list.plx lines 29 and 30 require location of names.dmp and nodes.dmp files\n* step4a_taxid_addition.r - line 75, may need to change location of nodes.dmp and names.dmp \n\n"
      },
      "source": "https://raw.githubusercontent.com/wpearman1996/MARES_database_pipeline/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "somef_missing_categories": [
    "download",
    "contact",
    "contributors",
    "documentation",
    "license",
    "faq",
    "support",
    "identifier",
    "executable_example"
  ],
  "somef_provenance": {
    "date": "2024-10-06 13:09:34",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 14
      },
      "technique": "GitHub_API"
    }
  ],
  "type": [
    {
      "confidence": 0.82,
      "result": {
        "type": "String",
        "value": "commandline-application"
      },
      "technique": "software_type_heuristics"
    }
  ],
  "usage": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Steps to use MARES Docker image",
        "parent_header": [
          "Building custom reference databases for metabarcoding",
          "Before using MARES pipeline",
          "OPTION 1. DOCKER container (recommended)"
        ],
        "type": "Text_excerpt",
        "value": "1. Install Docker : https://docs.docker.com/get-docker/\n\nIn the command-line:\n\n2. Pull MARES Docker image from Docker Hub : https://hub.docker.com/r/vanearranz/mares\n```\ndocker pull vanearranz/mares\n```\n3. Run the MARES container in interactive mode. This means you can execute commands inside the container while it is running.\n```\ndocker container run -it vanearranz/mares /bin/bash\n```\nMake sure you are in MARES folder to follow the steps: \n```\ncd MARES\n```\n\n*NOTE: The text editor installed in MARES image is ```vim```. More information on how to use vim text editor: https://www.arubacloud.com/tutorial/how-to-instal-and-use-vim-text-editor-on-linux-ubuntu.aspx*  \n"
      },
      "source": "https://raw.githubusercontent.com/wpearman1996/MARES_database_pipeline/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "In addition, if you make use of this pipeline, please also cite the following publications:",
        "parent_header": [
          "Suggested Citation"
        ],
        "type": "Text_excerpt",
        "value": "Macher, Jan-Niklas, Till-Hendrik Macher, and Florian Leese. \"Combining NCBI and BOLD databases for OTU assignment in metabarcoding and metagenomic datasets: The BOLD_NCBI _Merger.\" Metabarcoding and Metagenomics 1 (2017): e22262.\n\nPorter, Teresita M., and Mehrdad Hajibabaei. \"Over 2.5 million COI sequences in GenBank and growing.\" PloS one 13.9 (2018): e0200177.\n\nhttps://doi.org/10.5281/zenodo.3701276\n"
      },
      "source": "https://raw.githubusercontent.com/wpearman1996/MARES_database_pipeline/master/README.md",
      "technique": "header_analysis"
    }
  ]
}