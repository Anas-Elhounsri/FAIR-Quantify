{
  "application_domain": [
    {
      "confidence": 10.59,
      "result": {
        "type": "String",
        "value": "Computer Vision"
      },
      "technique": "supervised_classification"
    }
  ],
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/esolares/HapSolo"
      },
      "technique": "GitHub_API"
    }
  ],
  "contact": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Note: For more information on how to run and configure array jobs, please contact your IT help desk or refer the your job scheduler's manual.",
        "parent_header": [
          "BUSCO run for each contig fasta file"
        ],
        "type": "Text_excerpt",
        "value": "Next you wil need to make sure you have the proper lineage and species selected for your particular sample. You can look this up at https://busco.ezlab.org/ and http://bioinf.uni-greifswald.de/augustus/ respectively. Once these changes have been made to your sbatch_busco.sh or qsub_busco.sh script, you can submit them to your HPC queue.\n\n"
      },
      "source": "https://raw.githubusercontent.com/esolares/HapSolo/main/README.md",
      "technique": "header_analysis"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2019-06-05T22:38:30Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2024-08-30T05:54:56Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "Reduction of Althaps and Duplicate Contigs for Improved Hi-C Scaffolding"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 0.9576142283310493,
      "result": {
        "original_header": "RECOMMENDED",
        "type": "Text_excerpt",
        "value": "Our singularity image of HapSolo contains all required software including BUSCO, and Augustus. Please skip the local install if you are able to pull the Singularity image.\nRunning singularity will not require running conda and is the best way to get HapSolo and BUSCO3 working. \n"
      },
      "source": "https://raw.githubusercontent.com/esolares/HapSolo/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.924757017680398,
      "result": {
        "original_header": "MiniMap2",
        "type": "Text_excerpt",
        "value": "We recommend using one of the following options below when running MiniMap2:\n```\nminimap2 -t 36 -k19 -w5 -A1 -B2 -O3,13 -E2,1 -s200 -z200 -N50 --min-occ-floor=100 ${QRY} ${QRY} > $(basename ${QRY} .fasta)_self_align.paf\nminimap2 -t 36 -P -k19 -w2 -A1 -B2 -O1,6 -E2,1 -s200 -z200 -N50 --min-occ-floor=100 ${QRY} ${QRY} > $(basename ${QRY} .fasta)_self_align.paf\nminimap2 -t 36 -P -G 500k -k19 -w2 -A1 -B2 -O2,4 -E2,1 -s200 -z200 -N50 --max-qlen 10000000 --min-occ-floor=100 --paf-no-hit ${QRY} ${QRY} > $(basename ${QRY} .fasta)_self_align.paf\n```\n-t <INT> can be set to the number of cores allocated for the job. In SLURM the variable is SLURM_CPUS_PER_TASK and in SGE the variable is NSLOTS.\nWe also recommend testing different options to see if you get better results. HapSolo also runs faster using MiniMap2 paf files.\n \n"
      },
      "source": "https://raw.githubusercontent.com/esolares/HapSolo/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9127145849129832,
      "result": {
        "original_header": "Blat all-by-all alignment",
        "type": "Text_excerpt",
        "value": "Here we provide scripts for running Blat on an HPC using SGE or SLURM job schedulers.\nTo preprocess, you should have run the qsub_preprocess.sh or the sbatch_preprocess.sh scripts above. These files only require that you assign your FASTA file name to the REF variable. Once the preprocessing step has been completed a jobfile.txt file, a new FASTA file containing _new.fasta appended to the name and a contigs directory containing FASTA files for each contig will have been created. This step does require quite a bit of memory, so it is recommended that you consider this prior to running this step. \n"
      },
      "source": "https://raw.githubusercontent.com/esolares/HapSolo/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9534841240320677,
      "result": {
        "type": "Text_excerpt",
        "value": "An optimization approach for removing secondary haplotigs during diploid genome assembly and scaffolding. \n"
      },
      "source": "https://raw.githubusercontent.com/esolares/HapSolo/main/README.md",
      "technique": "supervised_classification"
    }
  ],
  "download": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Downloading the image (only do once)",
        "parent_header": [
          "RECOMMENDED"
        ],
        "type": "Text_excerpt",
        "value": "```\n# Pull with Singularity\nsingularity pull --arch amd64 library://esolares/default/hapsolo_busco3:0.01\n# Pull by unique ID (reproducible even if tags change)\nsingularity pull library://esolares/default/hapsolo_busco3:sha256.5070a5b9119b11d7d50da0693c0c5185051a0e690e868a27367f17364ddb31be\n```\n"
      },
      "source": "https://raw.githubusercontent.com/esolares/HapSolo/main/README.md",
      "technique": "header_analysis"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/esolares/HapSolo/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "faq": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Note: For simplicity job submission scripts have been added: sbatch_preprocess.sh and qsub_preprocess.sh for SLURM and SGE respectively that only require that the REF variable be assigned to the name of your contig assembly FASTA file.",
        "parent_header": [
          "How to run HapSolo"
        ],
        "type": "Text_excerpt",
        "value": "We highly recommend you run preprocessfasta.py on your contig assembly first. \n\nThe run syntax of this python script is:\n\n```\npreprocessfasta.py -i CONTIGASSEMBLY.fasta -m INTEGERSIZEOFMAXCONTIGFORQUERY\n\nusage: preprocessfasta.py [-h] -i INPUT [-m MAXCONTIG]\n\nPreprocess FASTA file and outputs a clean FASTA and seperates contigs based on\nunique headers. Removes special chars\n\noptional arguments:\n  -h, --help            show this help message and exit\n  -i INPUT, --input INPUT\n                        Input FASTA file\n  -m MAXCONTIG, --maxcontig MAXCONTIG\n                        Max size of contig in Mb to output in contigs folder.\n```\n\nBy default the maxcontig size is set to 10000000 or 10Mb and is a not a required parameter.\n\nThis script will create a contigs directory in your current working directory that contains individual FASTA files for each contig. This script also removes any illegal characters in the FASTA header that could cause inconsistent results from either BUSCO or MUMmer. A qsub and sbatch file have been included in the scripts folder that also create the required jobfile.txt and buscojobfile.txt files, as well as convert your fasta files to 2bit for Blat alignment.\n\nHapSolo requires three arguments: Your preprocessed contig assembly file, your Blat PSL file (gzipped or uncompressed), and the location of your BUSCO results for each contig fasta file. \n\nThe run syntax is as follows:\n```\nhapsolo.py -i YOURPREPROCESSEDCONTIGASSEMBLY.fasta --psl YOURPSLFILE.psl -b YOURBUSCOOUTPUTDIRECTORY\nor\nhapsolo.py -i YOURPREPROCESSEDCONTIGASSEMBLY.fasta --paf YOURPAFFILE.paf -b YOURBUSCOOUTPUTDIRECTORY\nhapsolo.py -i contigassembly_new.fasta --paf/psl self_alignment.file -b ./contigs/busco/\n\nusage: hapsolo.py [-h] -i INPUT (-p PSL | -a PAF) -b BUSCOS [-m MAXZEROS] [-t THREADS]\n                  [-n NITERATIONS] [-B BESTN] [-S THETAS] [-D THETAD]\n                  [-F THETAF] [-M THETAM]\n\nProcess alignments and BUSCO\"s for selecting reduced assembly candidates\n\noptional arguments:\n  -h, --help            show this help message and exit\n  -i INPUT, --input INPUT\n                        Input Fasta file\n  -p PSL, --psl PSL     BLAT PSL alignnment file\n  -a PAF, --paf PAF     Minimap2 PAF alignnment file. Note. paf file\n                        functionality is currently experimental\n\n  -b BUSCOS, --buscos BUSCOS\n                        Location BUSCO output directories. i.e. buscoN/\n  -m MAXZEROS, --maxzeros MAXZEROS\n                        Max # of times cost function delta can consecutively\n                        be 0. Default = 10\n  -t THREADS, --threads THREADS\n                        # of threads. Multiplies iterations by threads.\n                        Default = 1\n  -n NITERATIONS, --niterations NITERATIONS\n                        # of total iterations to run per gradient descent.\n                        Default = 1000\n  -B BESTN, --Bestn BESTN\n                        # of best candidate assemblies to return using\n                        gradient descent. Default = 1\n  -S THETAS, --thetaS THETAS\n                        Weight for single BUSCOs in linear fxn. Default = 1.0\n  -D THETAD, --thetaD THETAD\n                        Weight for single BUSCOs in linear fxn. Default = 1.0\n  -F THETAF, --thetaF THETAF\n                        Weight for single BUSCOs in linear fxn. Default = 0.0\n  -M THETAM, --thetaM THETAM\n                        Weight for single BUSCOs in linear fxn. Default = 1.0\n\n-p/--psl and -a/--paf are mutually exclusive\n\n```"
      },
      "source": "https://raw.githubusercontent.com/esolares/HapSolo/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Note: If the RAM usage is managed by your job scheduler, you will need to alot a sufficient amount of RAM to your job submission script. The contig size will determine how much RAM will be required. We recommend setting this to a minimum of 4GB. Larger files may require 8-16GB of RAM. For mammals, which are repeat rich, require a minimum value of 16GB.",
        "parent_header": [
          "Blat all-by-all alignment"
        ],
        "type": "Text_excerpt",
        "value": "If all alignment jobs completed successfully, we will then need to concatenate the individual PSL files into a larger aligment file. To do this we have provided the bash_andreaconcatpsl.sh script provided by A. Minio at the Cantu Lab in UC Davis.\n\nTo run:\n```\nbash_andreaconcatpsl.sh myoutput_selfaln.PSL\n```\nThis script will look for all job*.PSL files that have been created by the parallel all-by-all alignment. "
      },
      "source": "https://raw.githubusercontent.com/esolares/HapSolo/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Note: For more information on how to run and configure array jobs, please contact your IT help desk or refer the your job scheduler's manual.",
        "parent_header": [
          "BUSCO run for each contig fasta file"
        ],
        "type": "Text_excerpt",
        "value": "Next you wil need to make sure you have the proper lineage and species selected for your particular sample. You can look this up at https://busco.ezlab.org/ and http://bioinf.uni-greifswald.de/augustus/ respectively. Once these changes have been made to your sbatch_busco.sh or qsub_busco.sh script, you can submit them to your HPC queue.\n\n"
      },
      "source": "https://raw.githubusercontent.com/esolares/HapSolo/main/README.md",
      "technique": "header_analysis"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 6
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/esolares/HapSolo/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "esolares/HapSolo"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "Singularity Installation Requirements"
      },
      "source": "https://raw.githubusercontent.com/esolares/HapSolo/main/README.md",
      "technique": "regular_expression"
    }
  ],
  "has_script_file": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/esolares/HapSolo/main/scripts/sbatch_blat.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/esolares/HapSolo/main/scripts/sbatch_preprocess.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/esolares/HapSolo/main/scripts/sbatch_busco.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/esolares/HapSolo/main/scripts/qsub_blat.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/esolares/HapSolo/main/scripts/qsub_preprocess.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/esolares/HapSolo/main/scripts/bash_quastbusco.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/esolares/HapSolo/main/scripts/bash_gnuparallelbusco.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/esolares/HapSolo/main/scripts/bash_buscopreprocess.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/esolares/HapSolo/main/scripts/bash_andreaconcatpsl.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/esolares/HapSolo/main/scripts/bash_gnuparallelblat.sh"
      },
      "technique": "file_exploration"
    }
  ],
  "installation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Installation",
        "type": "Text_excerpt",
        "value": "```\ngit clone https://github.com/esolares/HapSolo.git\ncd HapSolo\nHAPSOLO=$(pwd)\n```\nMake sure to export your path to your ENV variables by doing the following and adding this line to all your scripts that run preprocessfasta.py or hapsolo.py\n```\nexport PATH=$HAPSOLO:$PATH\nexport PATH=$HAPSOLO/scripts:$PATH\n```"
      },
      "source": "https://raw.githubusercontent.com/esolares/HapSolo/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Note: If the RAM usage is managed by your job scheduler, you will need to alot a sufficient amount of RAM to your job submission script. The contig size will determine how much RAM will be required. We recommend setting this to a minimum of 4GB. Larger files may require 8-16GB of RAM. For mammals, which are repeat rich, require a minimum value of 16GB.",
        "parent_header": [
          "Blat all-by-all alignment"
        ],
        "type": "Text_excerpt",
        "value": "If all alignment jobs completed successfully, we will then need to concatenate the individual PSL files into a larger aligment file. To do this we have provided the bash_andreaconcatpsl.sh script provided by A. Minio at the Cantu Lab in UC Davis.\n\nTo run:\n```\nbash_andreaconcatpsl.sh myoutput_selfaln.PSL\n```\nThis script will look for all job*.PSL files that have been created by the parallel all-by-all alignment. "
      },
      "source": "https://raw.githubusercontent.com/esolares/HapSolo/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Note: For more information on how to run and configure array jobs, please contact your IT help desk or refer the your job scheduler's manual.",
        "parent_header": [
          "BUSCO run for each contig fasta file"
        ],
        "type": "Text_excerpt",
        "value": "Next you wil need to make sure you have the proper lineage and species selected for your particular sample. You can look this up at https://busco.ezlab.org/ and http://bioinf.uni-greifswald.de/augustus/ respectively. Once these changes have been made to your sbatch_busco.sh or qsub_busco.sh script, you can submit them to your HPC queue.\n\n"
      },
      "source": "https://raw.githubusercontent.com/esolares/HapSolo/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 0.9003600576793961,
      "result": {
        "original_header": "RECOMMENDED",
        "type": "Text_excerpt",
        "value": "Our singularity image of HapSolo contains all required software including BUSCO, and Augustus. Please skip the local install if you are able to pull the Singularity image.\nRunning singularity will not require running conda and is the best way to get HapSolo and BUSCO3 working. \n"
      },
      "source": "https://raw.githubusercontent.com/esolares/HapSolo/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9933453139657046,
      "result": {
        "original_header": "MiniMap2",
        "type": "Text_excerpt",
        "value": "We recommend using one of the following options below when running MiniMap2:\n```\nminimap2 -t 36 -k19 -w5 -A1 -B2 -O3,13 -E2,1 -s200 -z200 -N50 --min-occ-floor=100 ${QRY} ${QRY} > $(basename ${QRY} .fasta)_self_align.paf\nminimap2 -t 36 -P -k19 -w2 -A1 -B2 -O1,6 -E2,1 -s200 -z200 -N50 --min-occ-floor=100 ${QRY} ${QRY} > $(basename ${QRY} .fasta)_self_align.paf\nminimap2 -t 36 -P -G 500k -k19 -w2 -A1 -B2 -O2,4 -E2,1 -s200 -z200 -N50 --max-qlen 10000000 --min-occ-floor=100 --paf-no-hit ${QRY} ${QRY} > $(basename ${QRY} .fasta)_self_align.paf\n```\n-t <INT> can be set to the number of cores allocated for the job. In SLURM the variable is SLURM_CPUS_PER_TASK and in SGE the variable is NSLOTS.\nWe also recommend testing different options to see if you get better results. HapSolo also runs faster using MiniMap2 paf files.\n \n"
      },
      "source": "https://raw.githubusercontent.com/esolares/HapSolo/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9865872430314383,
      "result": {
        "original_header": "Blat all-by-all alignment",
        "type": "Text_excerpt",
        "value": "Here we provide scripts for running Blat on an HPC using SGE or SLURM job schedulers.\nTo preprocess, you should have run the qsub_preprocess.sh or the sbatch_preprocess.sh scripts above. These files only require that you assign your FASTA file name to the REF variable. Once the preprocessing step has been completed a jobfile.txt file, a new FASTA file containing _new.fasta appended to the name and a contigs directory containing FASTA files for each contig will have been created. This step does require quite a bit of memory, so it is recommended that you consider this prior to running this step. \nTo submit the Blat all-by-all alignment job, we have provided scripts for either SLURM or SGE, sbatch_blat.sh and qsub_blat.sh. \nTo run:\n```\nsbatch sbatch_preprocess.sh\nwc -l jobfile.txt\n```\nHere we recommend you insert the output of wc -l to the array setting in your job submission script. Here you will need to assign the new FASTA file that has been created by the preprocess.py Python script to the REF variable in the blat.sh submission scripts. For all intensive purposes, we recommend that you use this new file for all subsequent runs. \nTo run:\n```\nsbatch sbatch_blat.sh\n``` \n"
      },
      "source": "https://raw.githubusercontent.com/esolares/HapSolo/main/README.md",
      "technique": "supervised_classification"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/esolares/HapSolo/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ""
      },
      "technique": "GitHub_API"
    }
  ],
  "license": [
    {
      "confidence": 1,
      "result": {
        "name": "GNU General Public License v2.0",
        "spdx_id": "GPL-2.0",
        "type": "License",
        "url": "https://api.github.com/licenses/gpl-2.0",
        "value": "https://api.github.com/licenses/gpl-2.0"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "type": "File_dump",
        "value": "                    GNU GENERAL PUBLIC LICENSE\n                       Version 2, June 1991\n\n Copyright (C) 1989, 1991 Free Software Foundation, Inc.,\n 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\n Everyone is permitted to copy and distribute verbatim copies\n of this license document, but changing it is not allowed.\n\n                            Preamble\n\n  The licenses for most software are designed to take away your\nfreedom to share and change it.  By contrast, the GNU General Public\nLicense is intended to guarantee your freedom to share and change free\nsoftware--to make sure the software is free for all its users.  This\nGeneral Public License applies to most of the Free Software\nFoundation's software and to any other program whose authors commit to\nusing it.  (Some other Free Software Foundation software is covered by\nthe GNU Lesser General Public License instead.)  You can apply it to\nyour programs, too.\n\n  When we speak of free software, we are referring to freedom, not\nprice.  Our General Public Licenses are designed to make sure that you\nhave the freedom to distribute copies of free software (and charge for\nthis service if you wish), that you receive source code or can get it\nif you want it, that you can change the software or use pieces of it\nin new free programs; and that you know you can do these things.\n\n  To protect your rights, we need to make restrictions that forbid\nanyone to deny you these rights or to ask you to surrender the rights.\nThese restrictions translate to certain responsibilities for you if you\ndistribute copies of the software, or if you modify it.\n\n  For example, if you distribute copies of such a program, whether\ngratis or for a fee, you must give the recipients all the rights that\nyou have.  You must make sure that they, too, receive or can get the\nsource code.  And you must show them these terms so they know their\nrights.\n\n  We protect your rights with two steps: (1) copyright the software, and\n(2) offer you this license which gives you legal permission to copy,\ndistribute and/or modify the software.\n\n  Also, for each author's protection and ours, we want to make certain\nthat everyone understands that there is no warranty for this free\nsoftware.  If the software is modified by someone else and passed on, we\nwant its recipients to know that what they have is not the original, so\nthat any problems introduced by others will not reflect on the original\nauthors' reputations.\n\n  Finally, any free program is threatened constantly by software\npatents.  We wish to avoid the danger that redistributors of a free\nprogram will individually obtain patent licenses, in effect making the\nprogram proprietary.  To prevent this, we have made it clear that any\npatent must be licensed for everyone's free use or not licensed at all.\n\n  The precise terms and conditions for copying, distribution and\nmodification follow.\n\n                    GNU GENERAL PUBLIC LICENSE\n   TERMS AND CONDITIONS FOR COPYING, DISTRIBUTION AND MODIFICATION\n\n  0. This License applies to any program or other work which contains\na notice placed by the copyright holder saying it may be distributed\nunder the terms of this General Public License.  The \"Program\", below,\nrefers to any such program or work, and a \"work based on the Program\"\nmeans either the Program or any derivative work under copyright law:\nthat is to say, a work containing the Program or a portion of it,\neither verbatim or with modifications and/or translated into another\nlanguage.  (Hereinafter, translation is included without limitation in\nthe term \"modification\".)  Each licensee is addressed as \"you\".\n\nActivities other than copying, distribution and modification are not\ncovered by this License; they are outside its scope.  The act of\nrunning the Program is not restricted, and the output from the Program\nis covered only if its contents constitute a work based on the\nProgram (independent of having been made by running the Program).\nWhether that is true depends on what the Program does.\n\n  1. You may copy and distribute verbatim copies of the Program's\nsource code as you receive it, in any medium, provided that you\nconspicuously and appropriately publish on each copy an appropriate\ncopyright notice and disclaimer of warranty; keep intact all the\nnotices that refer to this License and to the absence of any warranty;\nand give any other recipients of the Program a copy of this License\nalong with the Program.\n\nYou may charge a fee for the physical act of transferring a copy, and\nyou may at your option offer warranty protection in exchange for a fee.\n\n  2. You may modify your copy or copies of the Program or any portion\nof it, thus forming a work based on the Program, and copy and\ndistribute such modifications or work under the terms of Section 1\nabove, provided that you also meet all of these conditions:\n\n    a) You must cause the modified files to carry prominent notices\n    stating that you changed the files and the date of any change.\n\n    b) You must cause any work that you distribute or publish, that in\n    whole or in part contains or is derived from the Program or any\n    part thereof, to be licensed as a whole at no charge to all third\n    parties under the terms of this License.\n\n    c) If the modified program normally reads commands interactively\n    when run, you must cause it, when started running for such\n    interactive use in the most ordinary way, to print or display an\n    announcement including an appropriate copyright notice and a\n    notice that there is no warranty (or else, saying that you provide\n    a warranty) and that users may redistribute the program under\n    these conditions, and telling the user how to view a copy of this\n    License.  (Exception: if the Program itself is interactive but\n    does not normally print such an announcement, your work based on\n    the Program is not required to print an announcement.)\n\nThese requirements apply to the modified work as a whole.  If\nidentifiable sections of that work are not derived from the Program,\nand can be reasonably considered independent and separate works in\nthemselves, then this License, and its terms, do not apply to those\nsections when you distribute them as separate works.  But when you\ndistribute the same sections as part of a whole which is a work based\non the Program, the distribution of the whole must be on the terms of\nthis License, whose permissions for other licensees extend to the\nentire whole, and thus to each and every part regardless of who wrote it.\n\nThus, it is not the intent of this section to claim rights or contest\nyour rights to work written entirely by you; rather, the intent is to\nexercise the right to control the distribution of derivative or\ncollective works based on the Program.\n\nIn addition, mere aggregation of another work not based on the Program\nwith the Program (or with a work based on the Program) on a volume of\na storage or distribution medium does not bring the other work under\nthe scope of this License.\n\n  3. You may copy and distribute the Program (or a work based on it,\nunder Section 2) in object code or executable form under the terms of\nSections 1 and 2 above provided that you also do one of the following:\n\n    a) Accompany it with the complete corresponding machine-readable\n    source code, which must be distributed under the terms of Sections\n    1 and 2 above on a medium customarily used for software interchange; or,\n\n    b) Accompany it with a written offer, valid for at least three\n    years, to give any third party, for a charge no more than your\n    cost of physically performing source distribution, a complete\n    machine-readable copy of the corresponding source code, to be\n    distributed under the terms of Sections 1 and 2 above on a medium\n    customarily used for software interchange; or,\n\n    c) Accompany it with the information you received as to the offer\n    to distribute corresponding source code.  (This alternative is\n    allowed only for noncommercial distribution and only if you\n    received the program in object code or executable form with such\n    an offer, in accord with Subsection b above.)\n\nThe source code for a work means the preferred form of the work for\nmaking modifications to it.  For an executable work, complete source\ncode means all the source code for all modules it contains, plus any\nassociated interface definition files, plus the scripts used to\ncontrol compilation and installation of the executable.  However, as a\nspecial exception, the source code distributed need not include\nanything that is normally distributed (in either source or binary\nform) with the major components (compiler, kernel, and so on) of the\noperating system on which the executable runs, unless that component\nitself accompanies the executable.\n\nIf distribution of executable or object code is made by offering\naccess to copy from a designated place, then offering equivalent\naccess to copy the source code from the same place counts as\ndistribution of the source code, even though third parties are not\ncompelled to copy the source along with the object code.\n\n  4. You may not copy, modify, sublicense, or distribute the Program\nexcept as expressly provided under this License.  Any attempt\notherwise to copy, modify, sublicense or distribute the Program is\nvoid, and will automatically terminate your rights under this License.\nHowever, parties who have received copies, or rights, from you under\nthis License will not have their licenses terminated so long as such\nparties remain in full compliance.\n\n  5. You are not required to accept this License, since you have not\nsigned it.  However, nothing else grants you permission to modify or\ndistribute the Program or its derivative works.  These actions are\nprohibited by law if you do not accept this License.  Therefore, by\nmodifying or distributing the Program (or any work based on the\nProgram), you indicate your acceptance of this License to do so, and\nall its terms and conditions for copying, distributing or modifying\nthe Program or works based on it.\n\n  6. Each time you redistribute the Program (or any work based on the\nProgram), the recipient automatically receives a license from the\noriginal licensor to copy, distribute or modify the Program subject to\nthese terms and conditions.  You may not impose any further\nrestrictions on the recipients' exercise of the rights granted herein.\nYou are not responsible for enforcing compliance by third parties to\nthis License.\n\n  7. If, as a consequence of a court judgment or allegation of patent\ninfringement or for any other reason (not limited to patent issues),\nconditions are imposed on you (whether by court order, agreement or\notherwise) that contradict the conditions of this License, they do not\nexcuse you from the conditions of this License.  If you cannot\ndistribute so as to satisfy simultaneously your obligations under this\nLicense and any other pertinent obligations, then as a consequence you\nmay not distribute the Program at all.  For example, if a patent\nlicense would not permit royalty-free redistribution of the Program by\nall those who receive copies directly or indirectly through you, then\nthe only way you could satisfy both it and this License would be to\nrefrain entirely from distribution of the Program.\n\nIf any portion of this section is held invalid or unenforceable under\nany particular circumstance, the balance of the section is intended to\napply and the section as a whole is intended to apply in other\ncircumstances.\n\nIt is not the purpose of this section to induce you to infringe any\npatents or other property right claims or to contest validity of any\nsuch claims; this section has the sole purpose of protecting the\nintegrity of the free software distribution system, which is\nimplemented by public license practices.  Many people have made\ngenerous contributions to the wide range of software distributed\nthrough that system in reliance on consistent application of that\nsystem; it is up to the author/donor to decide if he or she is willing\nto distribute software through any other system and a licensee cannot\nimpose that choice.\n\nThis section is intended to make thoroughly clear what is believed to\nbe a consequence of the rest of this License.\n\n  8. If the distribution and/or use of the Program is restricted in\ncertain countries either by patents or by copyrighted interfaces, the\noriginal copyright holder who places the Program under this License\nmay add an explicit geographical distribution limitation excluding\nthose countries, so that distribution is permitted only in or among\ncountries not thus excluded.  In such case, this License incorporates\nthe limitation as if written in the body of this License.\n\n  9. The Free Software Foundation may publish revised and/or new versions\nof the General Public License from time to time.  Such new versions will\nbe similar in spirit to the present version, but may differ in detail to\naddress new problems or concerns.\n\nEach version is given a distinguishing version number.  If the Program\nspecifies a version number of this License which applies to it and \"any\nlater version\", you have the option of following the terms and conditions\neither of that version or of any later version published by the Free\nSoftware Foundation.  If the Program does not specify a version number of\nthis License, you may choose any version ever published by the Free Software\nFoundation.\n\n  10. If you wish to incorporate parts of the Program into other free\nprograms whose distribution conditions are different, write to the author\nto ask for permission.  For software which is copyrighted by the Free\nSoftware Foundation, write to the Free Software Foundation; we sometimes\nmake exceptions for this.  Our decision will be guided by the two goals\nof preserving the free status of all derivatives of our free software and\nof promoting the sharing and reuse of software generally.\n\n                            NO WARRANTY\n\n  11. BECAUSE THE PROGRAM IS LICENSED FREE OF CHARGE, THERE IS NO WARRANTY\nFOR THE PROGRAM, TO THE EXTENT PERMITTED BY APPLICABLE LAW.  EXCEPT WHEN\nOTHERWISE STATED IN WRITING THE COPYRIGHT HOLDERS AND/OR OTHER PARTIES\nPROVIDE THE PROGRAM \"AS IS\" WITHOUT WARRANTY OF ANY KIND, EITHER EXPRESSED\nOR IMPLIED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF\nMERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE.  THE ENTIRE RISK AS\nTO THE QUALITY AND PERFORMANCE OF THE PROGRAM IS WITH YOU.  SHOULD THE\nPROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF ALL NECESSARY SERVICING,\nREPAIR OR CORRECTION.\n\n  12. IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING\nWILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MAY MODIFY AND/OR\nREDISTRIBUTE THE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES,\nINCLUDING ANY GENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING\nOUT OF THE USE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED\nTO LOSS OF DATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY\nYOU OR THIRD PARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER\nPROGRAMS), EVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE\nPOSSIBILITY OF SUCH DAMAGES.\n\n                     END OF TERMS AND CONDITIONS\n\n            How to Apply These Terms to Your New Programs\n\n  If you develop a new program, and you want it to be of the greatest\npossible use to the public, the best way to achieve this is to make it\nfree software which everyone can redistribute and change under these terms.\n\n  To do so, attach the following notices to the program.  It is safest\nto attach them to the start of each source file to most effectively\nconvey the exclusion of warranty; and each file should have at least\nthe \"copyright\" line and a pointer to where the full notice is found.\n\n    <one line to give the program's name and a brief idea of what it does.>\n    Copyright (C) <year>  <name of author>\n\n    This program is free software; you can redistribute it and/or modify\n    it under the terms of the GNU General Public License as published by\n    the Free Software Foundation; either version 2 of the License, or\n    (at your option) any later version.\n\n    This program is distributed in the hope that it will be useful,\n    but WITHOUT ANY WARRANTY; without even the implied warranty of\n    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n    GNU General Public License for more details.\n\n    You should have received a copy of the GNU General Public License along\n    with this program; if not, write to the Free Software Foundation, Inc.,\n    51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA.\n\nAlso add information on how to contact you by electronic and paper mail.\n\nIf the program is interactive, make it output a short notice like this\nwhen it starts in an interactive mode:\n\n    Gnomovision version 69, Copyright (C) year name of author\n    Gnomovision comes with ABSOLUTELY NO WARRANTY; for details type `show w'.\n    This is free software, and you are welcome to redistribute it\n    under certain conditions; type `show c' for details.\n\nThe hypothetical commands `show w' and `show c' should show the appropriate\nparts of the General Public License.  Of course, the commands you use may\nbe called something other than `show w' and `show c'; they could even be\nmouse-clicks or menu items--whatever suits your program.\n\nYou should also get your employer (if you work as a programmer) or your\nschool, if any, to sign a \"copyright disclaimer\" for the program, if\nnecessary.  Here is a sample; alter the names:\n\n  Yoyodyne, Inc., hereby disclaims all copyright interest in the program\n  `Gnomovision' (which makes passes at compilers) written by James Hacker.\n\n  <signature of Ty Coon>, 1 April 1989\n  Ty Coon, President of Vice\n\nThis General Public License does not permit incorporating your program into\nproprietary programs.  If your program is a subroutine library, you may\nconsider it more useful to permit linking proprietary applications with the\nlibrary.  If this is what you want to do, use the GNU Lesser General\nPublic License instead of this License.\n"
      },
      "source": "https://raw.githubusercontent.com/esolares/HapSolo/main/LICENSE",
      "technique": "file_exploration"
    }
  ],
  "logo": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/esolares/HapSolo/main/img src=./hapsolo_logo.png width=50%/></p>\n<p>An optimization approach for removing secondary haplotigs during diploid genome assembly and scaffolding.</p>\n<h1>Singularity Installation Requirements</h1>\n<h1>RECOMMENDED</h1>\n<p>Our singularity image of HapSolo contains all required software including BUSCO, and Augustus. Please skip the local install if you are able to pull the Singularity image.\nRunning singularity will not require running conda and is the best way to get HapSolo and BUSCO3 working.</p>\n<h3>Downloading the image (only do once)</h3>\n<p>```</p>\n<h1>Pull with Singularity</h1>\n<p>singularity pull --arch amd64 library://esolares/default/hapsolo_busco3:0.01</p>\n<h1>Pull by unique ID (reproducible even if tags change)</h1>\n<p>singularity pull library://esolares/default/hapsolo_busco3:sha256.5070a5b9119b11d7d50da0693c0c5185051a0e690e868a27367f17364ddb31be\n```</p>\n<h3>Singularity RUN COMMANDS:</h3>\n<p>This section will be required for running HapSolo and BUSCO3 using singularity initiate singularity and mount current working directory\n<br>Augustus 3.2.2 Config directory Link: <a href="
      },
      "source": "https://raw.githubusercontent.com/esolares/HapSolo/main/README.md",
      "technique": "regular_expression"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "HapSolo"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "User",
        "value": "esolares"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 51282,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Shell",
        "size": 10915,
        "type": "Programming_language",
        "value": "Shell"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/esolares/HapSolo/main/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "releases": [
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "esolares",
          "type": "User"
        },
        "date_created": "2020-10-23T23:56:54Z",
        "date_published": "2020-10-23T23:59:41Z",
        "description": "This is the release of HapSolo for our publication",
        "html_url": "https://github.com/esolares/HapSolo/releases/tag/v0.1",
        "name": "v0.1",
        "release_id": 33002300,
        "tag": "v0.1",
        "tarball_url": "https://api.github.com/repos/esolares/HapSolo/tarball/v0.1",
        "type": "Release",
        "url": "https://api.github.com/repos/esolares/HapSolo/releases/33002300",
        "value": "https://api.github.com/repos/esolares/HapSolo/releases/33002300",
        "zipball_url": "https://api.github.com/repos/esolares/HapSolo/zipball/v0.1"
      },
      "technique": "GitHub_API"
    }
  ],
  "run": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Singularity RUN COMMANDS:",
        "parent_header": [
          "RECOMMENDED"
        ],
        "type": "Text_excerpt",
        "value": "This section will be required for running HapSolo and BUSCO3 using singularity initiate singularity and mount current working directory\n<br>Augustus 3.2.2 Config directory Link: [config.tar.gz](https://drive.google.com/file/d/1zrHS6mqmIM5f_7n5DW4LrPd1sw32uUrf/view?usp=sharing)\n<br>Note: You will need to download this then upload to your work directory saved in HOSTDIR. to see this echo $HOSTDIR\n```\n\n## MOUNDIR is the mounting point within singulariy\nMOUNTDIR=/data\n## HOSTDIR is your current working directory with all your files\n## Note: You will need the Augustus config folder in your work directory as well as the contigs folder and the odb9 folder for your taxa\nHOSTDIR=$(pwd)\n\n# You will need to download the Augustus 3.2.2 config directory. I have provided a link from gdrive above.\n# Note: You will need to download this then upload to your work directory saved in HOSTDIR. to see this echo $HOSTDIR\n\n# I will work on getting this so you can execute curl or wget. For now you will need to download using a browser and upload via scp or winscp or other method\n# once it is upload you will need to run: \ntar xzvf config.tar.gz\n\n# Here we will spin up the singularity instance. Please make sure you are running all these commands in your compute node\n# Note: Spinning up the instance will keep this loaded on the server until you execute the singularity stop instance://hapsolo command\nsingularity instance start --bind ${HOSTDIR}:${MOUNTDIR} hapsolo_busco3_0.01.sif hapsolo\n\n# Here we will test BUSCO3 and HapSolo as well as ls your current working directory\nsingularity exec instance://hapsolo BUSCO.py --help\nsingularity exec instance://hapsolo hapsolo.py --help\nsingularity exec instance://hapsolo ls /data/\n# you should now see all your files. This means that singularity has access to all your files from the instance. If it does not match please check your HOSTDIR \n# and make sure you are mounting your HOSTDIR to your MOUNTDIR as noted above.\n# CONGRATULATIONS! You know have singularity running.\n\n# Here is an example BUSCO3 command\nsingularity exec instance://hapsolo BUSCO.py -c 24 -m geno -i /data/contigs/tig00000002.fasta -l /data/embryophyta_odb9 -sp arabidopsis -t ./tmp -o testbusco\n\n# Please make sure to append \"singularity exec instance://hapsolo\" to any command you see in this documentation or scripts to get them to work with singularity. \n# Also please make sure you have hapsolo running as an instance. You can check by running the following:\nsingularity instance list\n\n# To stop your instance you can run the following\nsingularity instance stop hapsolo\n\n# Please submit bug reports if you have any issues. Sometimes google will not notify me and you can reach me via my website: edwinsolares.com or on twitter: @edwinsolares10\n# If you are having errors with your odb9, make sure you are not linking it (ln -s) and have a hard copy in your working directory i.e. ${HOSTDIR}/embryophyta_odb9\n```\n"
      },
      "source": "https://raw.githubusercontent.com/esolares/HapSolo/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "How to run HapSolo",
        "type": "Text_excerpt",
        "value": "HapSolo requires a Blat alignment file and a busco directory that contains a busco output for each of the contigs in your contig assembly. To do this we have included a scripts directory that contains scripts that can be used for preprocessing and postprocessing for your HapSolo run. "
      },
      "source": "https://raw.githubusercontent.com/esolares/HapSolo/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "BUSCO run for each contig fasta file",
        "type": "Text_excerpt",
        "value": "Here we need to extract contigs larger than 10Mb. Make sure to run this after the initial preprocess.py step mentioned above.\nTo do this we recommend you run the following:\n```\nbash_buscopreprocess.sh\ncd contigs\nwc -l buscojobfile.txt\n```\nWe will use the output of the last line and enter it into the job array of either the sbatch or qsub script. This should look like this: 1-N, where N is the number returned by wc -l. You will also need to set the number of cores to run for each array job. "
      },
      "source": "https://raw.githubusercontent.com/esolares/HapSolo/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Note: For more information on how to run and configure array jobs, please contact your IT help desk or refer the your job scheduler's manual.",
        "parent_header": [
          "BUSCO run for each contig fasta file"
        ],
        "type": "Text_excerpt",
        "value": "Next you wil need to make sure you have the proper lineage and species selected for your particular sample. You can look this up at https://busco.ezlab.org/ and http://bioinf.uni-greifswald.de/augustus/ respectively. Once these changes have been made to your sbatch_busco.sh or qsub_busco.sh script, you can submit them to your HPC queue.\n\n"
      },
      "source": "https://raw.githubusercontent.com/esolares/HapSolo/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "run HapSolo",
        "type": "Text_excerpt",
        "value": "Once you have concatenated all your psl output files or finished minimap2, and finished your BUSCO3 run. You can run HapSolo. Currently HapSolo does not accept absolute paths. This is a known bug and wil be fixed shortly. If your current working directy is:\n```\n/nfsmount/mydir/hapsolowd\n```\nand your input files shoud look like this:\n```\n/nfsmount/mydir/hapsolowd/myalignmentfile\n/nfsmount/mydir/hapsolowd/myassembly.fasta\n/nfsmount/mydir/hapsolowd/contigs/busco\n```\nthen you should run HapSolo as the following:\n```\nhapsolo.py -i myassembly.fasta --psl myalignmentfile.psl -b contigs/busco\n```\nor\n```\nhapsolo.py -i myassembly.fasta --paf myalignmentfile.paf -b contigs/busco\n```\n"
      },
      "source": "https://raw.githubusercontent.com/esolares/HapSolo/main/README.md",
      "technique": "header_analysis"
    }
  ],
  "somef_missing_categories": [
    "citation",
    "acknowledgement",
    "requirements",
    "contributors",
    "documentation",
    "identifier",
    "has_build_file",
    "executable_example"
  ],
  "somef_provenance": {
    "date": "2024-10-06 09:35:09",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 19
      },
      "technique": "GitHub_API"
    }
  ],
  "support": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Note: For more information on how to run and configure array jobs, please contact your IT help desk or refer the your job scheduler's manual.",
        "parent_header": [
          "BUSCO run for each contig fasta file"
        ],
        "type": "Text_excerpt",
        "value": "Next you wil need to make sure you have the proper lineage and species selected for your particular sample. You can look this up at https://busco.ezlab.org/ and http://bioinf.uni-greifswald.de/augustus/ respectively. Once these changes have been made to your sbatch_busco.sh or qsub_busco.sh script, you can submit them to your HPC queue.\n\n"
      },
      "source": "https://raw.githubusercontent.com/esolares/HapSolo/main/README.md",
      "technique": "header_analysis"
    }
  ],
  "usage": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Please try to use the singularity image instead as there have been issues with the conda version of BUSCO.",
        "parent_header": [
          "Local Installation Requirements (Local install not required if you are running singularity)"
        ],
        "type": "Text_excerpt",
        "value": "HapSolo is compatible with Python 2.7 and requires the PANDAS package be installed. There is support for Python 3, but Python 2.7 runs faster.\n\nTo do this please install conda and run:\n```\nconda create --name HapSolo python=2.7\nconda activate HapSolo\nconda install -c anaconda pandas\n```"
      },
      "source": "https://raw.githubusercontent.com/esolares/HapSolo/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Note: If the RAM usage is managed by your job scheduler, you will need to alot a sufficient amount of RAM to your job submission script. The contig size will determine how much RAM will be required. We recommend setting this to a minimum of 4GB. Larger files may require 8-16GB of RAM. For mammals, which are repeat rich, require a minimum value of 16GB.",
        "parent_header": [
          "Blat all-by-all alignment"
        ],
        "type": "Text_excerpt",
        "value": "If all alignment jobs completed successfully, we will then need to concatenate the individual PSL files into a larger aligment file. To do this we have provided the bash_andreaconcatpsl.sh script provided by A. Minio at the Cantu Lab in UC Davis.\n\nTo run:\n```\nbash_andreaconcatpsl.sh myoutput_selfaln.PSL\n```\nThis script will look for all job*.PSL files that have been created by the parallel all-by-all alignment. "
      },
      "source": "https://raw.githubusercontent.com/esolares/HapSolo/main/README.md",
      "technique": "header_analysis"
    }
  ]
}