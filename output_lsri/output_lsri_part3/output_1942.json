{
  "application_domain": [
    {
      "confidence": 14.99,
      "result": {
        "type": "String",
        "value": "Computer Vision"
      },
      "technique": "supervised_classification"
    }
  ],
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/liulizhi1996/HPOFiller"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2020-10-12T12:34:21Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2024-04-22T01:51:04Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "The implementation of paper \"HPOFiller: identifying missing protein-phenotype associations by graph convolutional network\"."
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 0.9117871935015334,
      "result": {
        "original_header": "HPO Semantic Similarity",
        "type": "Text_excerpt",
        "value": "- `hpo_sim.py`: We choose **Information coefficient measure** (IC) as HPO similarity measure. Please set `'method'` in config file as `'ic'`. The generated json file containing IC similarity is organized as \n"
      },
      "source": "https://raw.githubusercontent.com/liulizhi1996/HPOFiller/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9385613313028872,
      "result": {
        "original_header": "Evaluation",
        "type": "Text_excerpt",
        "value": "- `evaluation.py`: We provide three kinds of metrics to evaluate the performance of our model:\n\t- AUC: calculated on the whole pairs of protein-HPO term in the test set\n\t- AUPR: calculated on the whole pairs of protein-HPO term in the test set\n\t- AP@K: average precision at k, where k = 5000, 10000, 20000, 50000, also calculated on the whole pairs of protein-HPO term in the test set\n\t\n\tPlease note that there are two running modes:\n\t\n\t- Cross-validation: Evaluate on each fold. Please set `'mode'` in config file as `'cv'`.\n\t- Temporal validation: Evaluate on single prediction result. Please set `'mode'` in config file as `'single'`.\n \n"
      },
      "source": "https://raw.githubusercontent.com/liulizhi1996/HPOFiller/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "download": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Download the prediction results",
        "parent_header": [
          "HPOFiller"
        ],
        "type": "Text_excerpt",
        "value": "We upload the prediction results made by HPOFiller for the HPO annotation released by 2019-02-12. The data is available at:\n\n[https://doi.org/10.6084/m9.figshare.13487277](https://doi.org/10.6084/m9.figshare.13487277)\n\nThis file is so large (585.8 MB), which contains the rank, UniProt ID of protein, HPO term ID and the predictive score. You are free to download it."
      },
      "source": "https://raw.githubusercontent.com/liulizhi1996/HPOFiller/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/liulizhi1996/HPOFiller/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 1
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/liulizhi1996/HPOFiller/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "liulizhi1996/HPOFiller"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "HPOFiller"
      },
      "source": "https://raw.githubusercontent.com/liulizhi1996/HPOFiller/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "installation": [
    {
      "confidence": 0.9976792327325051,
      "result": {
        "original_header": "Preprocessing",
        "type": "Text_excerpt",
        "value": "- `extract_gene_id.py`: First, please download gene annotations file from [http://compbio.charite.de/jenkins/job/hpo.annotations.monthly/](http://compbio.charite.de/jenkins/job/hpo.annotations.monthly/) with all sources and all frequencies: `ALL_SOURCES_ALL_FREQUENCIES_genes_to_phenotype.txt`. Then run the script, you will get a .txt file containing all gene ids. Finally, please upload this file to [http://www.uniprot.org/mapping/](http://www.uniprot.org/mapping/) to map Entrez Gene ID to UniProt ID.\n \n"
      },
      "source": "https://raw.githubusercontent.com/liulizhi1996/HPOFiller/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9988066676784918,
      "result": {
        "original_header": "STRING",
        "type": "Text_excerpt",
        "value": "- `string.py`: Please firstly open [https://string-db.org/cgi/download.pl](https://string-db.org/cgi/download.pl) and choose \"organism\" as \"Homo sapiens\", then download \"9606.protein.links.v11.0.txt.gz\" (version number may change). Meanwhile, download mapping file under \"ACCESSORY DATA\" category, or open website\n[https://string-db.org/mapping\\_files/uniprot\\_mappings/](https://string-db.org/mapping_files/uniprot_mappings/) to download it. After downloading, you can run this code to get a json file containing PPI data organized as \n"
      },
      "source": "https://raw.githubusercontent.com/liulizhi1996/HPOFiller/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "invocation": [
    {
      "confidence": 0.8960328941610586,
      "result": {
        "original_header": "Preprocessing",
        "type": "Text_excerpt",
        "value": "- `extract_gene_id.py`: First, please download gene annotations file from [http://compbio.charite.de/jenkins/job/hpo.annotations.monthly/](http://compbio.charite.de/jenkins/job/hpo.annotations.monthly/) with all sources and all frequencies: `ALL_SOURCES_ALL_FREQUENCIES_genes_to_phenotype.txt`. Then run the script, you will get a .txt file containing all gene ids. Finally, please upload this file to [http://www.uniprot.org/mapping/](http://www.uniprot.org/mapping/) to map Entrez Gene ID to UniProt ID.\n \n"
      },
      "source": "https://raw.githubusercontent.com/liulizhi1996/HPOFiller/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.898903810217499,
      "result": {
        "original_header": "Cross-validation",
        "type": "Text_excerpt",
        "value": "- `create_annotation.py`: After generating Gene ID mapping file, you can run this script to generate protein-HPO annotations file without propagation. The output json file contains leaf annotations of each protein, like \n- `split_train_test_pa.py `: Run this script to split `n_folds` folds and then generate `n_folds` mask files which contain train and test mask.\n \n"
      },
      "source": "https://raw.githubusercontent.com/liulizhi1996/HPOFiller/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8945607646835818,
      "result": {
        "original_header": "STRING",
        "type": "Text_excerpt",
        "value": "- `string.py`: Please firstly open [https://string-db.org/cgi/download.pl](https://string-db.org/cgi/download.pl) and choose \"organism\" as \"Homo sapiens\", then download \"9606.protein.links.v11.0.txt.gz\" (version number may change). Meanwhile, download mapping file under \"ACCESSORY DATA\" category, or open website\n[https://string-db.org/mapping\\_files/uniprot\\_mappings/](https://string-db.org/mapping_files/uniprot_mappings/) to download it. After downloading, you can run this code to get a json file containing PPI data organized as \n"
      },
      "source": "https://raw.githubusercontent.com/liulizhi1996/HPOFiller/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/liulizhi1996/HPOFiller/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "graph-convolutional-network, human-phenotype-ontology, matrix-completion"
      },
      "technique": "GitHub_API"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "HPOFiller"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "User",
        "value": "liulizhi1996"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 96995,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/liulizhi1996/HPOFiller/master/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "requirements": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Dependencies",
        "parent_header": [
          "HPOFiller"
        ],
        "type": "Text_excerpt",
        "value": "Our model is implemented by Python 3.6 with Pytorch 1.4.0 and Pytorch-geometric 1.5.0, and run on Nvidia GPU with CUDA 10.0.\n"
      },
      "source": "https://raw.githubusercontent.com/liulizhi1996/HPOFiller/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "run": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Run the model",
        "parent_header": [
          "HPOFiller"
        ],
        "type": "Text_excerpt",
        "value": "- `train.py`: We provide two modes:\n\t- Cross-validation: The program will conduct 10-folds CV and output corresponding predictions. Please set `'mode'` in config file as `'cv'`.\n\t- Temporal validation: This is a simulated real scene. The model will predict missing protein-HPO term associations based on current HPO annotations. Please set `'mode'` in config file as `'single'`.\n"
      },
      "source": "https://raw.githubusercontent.com/liulizhi1996/HPOFiller/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "somef_missing_categories": [
    "citation",
    "acknowledgement",
    "contact",
    "contributors",
    "documentation",
    "license",
    "usage",
    "faq",
    "support",
    "identifier",
    "has_build_file",
    "executable_example"
  ],
  "somef_provenance": {
    "date": "2024-10-06 06:56:11",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 11
      },
      "technique": "GitHub_API"
    }
  ]
}