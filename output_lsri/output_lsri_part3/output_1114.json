{
  "citation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Reference prefix removal",
        "parent_header": [
          "Workflows",
          "Going further"
        ],
        "type": "Text_excerpt",
        "value": "The names of contigs/paths/haplotypes in pangenomes sometimes contains a prefix that we'd want to remove.\nIn the HPRC pangenomes, for example, the chromosomal contigs from GRCh38 are named *GRCh38.chr1*, etc.\nIn practice, we want to remove this prefix from the variant calls (VCFs), or reads aligned to that reference (BAMs).\n\nThis is controlled by the `REFERENCE_PREFIX` parameters in the workflows.\nSetting `REFERENCE_PREFIX=\"GRCh38.\"` for example will ensure the VCFs/BAMs have *chr1*, etc. for contig names.\n\nBecause the pangenome uses them, **the prefix must still be present when specifying the paths to project the reads** too\nthough.\nHence, the `CONTIGS` and `PATH_LIST_FILE` must use the prefix.\n\nHowever, **provided reference FASTAs or dictionary must not have the prefix**.\nThese could be FASTA or `.dict` files from the \"official\" reference genome or pre-computed for them, hence no prefix.\nSo, no prefix in `REFERENCE_FILE`, `REFERENCE_INDEX_FILE`, `REFERENCE_DICT_FILE`.\n"
      },
      "source": "https://raw.githubusercontent.com/vgteam/vg_wdl/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Cite HPRC",
        "parent_header": [
          "Citation"
        ],
        "type": "Text_excerpt",
        "value": "If you use the Giraffe-DeepVariant workflows, please cite\nthe [HPRC preprint](https://www.biorxiv.org/content/10.1101/2022.07.09.499321v1):\n\n```\nLiao, Asri, Ebler, et al. A Draft Human Pangenome Reference. preprint, bioRxiv 2022; doi: https://doi.org/10.1101/2022.07.09.499321 \n```\n"
      },
      "source": "https://raw.githubusercontent.com/vgteam/vg_wdl/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Cite Giraffe-SV",
        "parent_header": [
          "Citation"
        ],
        "type": "Text_excerpt",
        "value": "If you use the SV genotyping workflow with vg giraffe, please\ncite [this article](https://doi.org/10.1126/science.abg8871):\n\n```\nSir\u00e9n, Monlong, Chang, Novak, Eizenga, et al. Pangenomics Enables Genotyping of Known Structural Variants in 5202 Diverse Genomes. Science, vol. 374, no. 6574, Dec. 2021; doi: https://doi.org/10.1126/science.abg8871.\n```\n"
      },
      "source": "https://raw.githubusercontent.com/vgteam/vg_wdl/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Cite Pedigree-VG",
        "parent_header": [
          "Citation"
        ],
        "type": "Text_excerpt",
        "value": "If you use the pedigree-based workflow for rare variant discovery, please\ncite [this article](https://pubmed.ncbi.nlm.nih.gov/35483961/):\n\n```\nMarkello et al. A Complete Pedigree-Based Graph Workflow for Rare Candidate Variant Analysis. Genome Research, Apr. 2022; doi: https://doi.org/10.1101/gr.276387.121.\n```\n"
      },
      "source": "https://raw.githubusercontent.com/vgteam/vg_wdl/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/vgteam/vg_wdl"
      },
      "technique": "GitHub_API"
    }
  ],
  "contributing_guidelines": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Contributing, Help, Bugs and Requests",
        "type": "Text_excerpt",
        "value": "Please open an Issue on [GitHub](https://github.com/vgteam/vg_wdl/issues) for help, bug reports, or feature requests.\nWhen doing so, please remember that vg\\_wdl is open-source software made by a community of developers.\nPlease be considerate and support a positive environment.\n"
      },
      "source": "https://raw.githubusercontent.com/vgteam/vg_wdl/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2018-12-10T04:02:34Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2024-09-02T01:41:55Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "Workflow Description Language (WDL) scripts for common vg workflows"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 0.9292202199050295,
      "result": {
        "original_header": "vg_wdl",
        "type": "Text_excerpt",
        "value": "Eric T Dawson, Mike Lin and Charles Markello, Jean Monlong, Adam Novak\nMIT License, 2023 \n"
      },
      "source": "https://raw.githubusercontent.com/vgteam/vg_wdl/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9779943048878085,
      "result": {
        "original_header": "Workflows",
        "type": "Text_excerpt",
        "value": "- **Giraffe-DeepVariant workflows**. Either the full Giraffe-DeepVariant workflow, or parts of it are available:\n    - [Giraffe-DeepVariant workflow](#giraffe-deepvariant-workflow) to perform the full workflow: starting from\n      FASTQs/CRAM, align reads to a pangenome and run [DeepVariant](https://github.com/google/deepvariant).\n    - [Giraffe workflow](#giraffe-workflow) to map reads and produce BAMs ready to use\n      by [DeepVariant](https://github.com/google/deepvariant).\n    - [Giraffe-DeepVariant from GAF workflow](#giraffe-deepvariant-from-gaf-workflow) to project reads aligned to a\n      pangenome (GAF), prepare them and run [DeepVariant](https://github.com/google/deepvariant).\n- [Happy workflow](#happy-workflow) to evaluate small variants against a truthset\n  using [hap.py](https://github.com/Illumina/hap.py)/[vcfeval](https://github.com/RealTimeGenomics/rtg-tools).\n- [GAF to sorted GAM workflow](#gaf-to-sorted-gam-workflow) to convert a GAF into a sorted and indexed GAM. E.g. to use\n  with the [sequenceTubeMap](https://github.com/vgteam/sequenceTubeMap).\n- [Giraffe SV workflow](#Giraffe-SV-workflow) to map short reads to a pangenome and genotype SVs\n  with [vg](https://github.com/vgteam/vg).\n- [Haplotype Sampling workflow](#Haplotype-Sampling-workflow) to create a personalized pangenome using haplotype\n  sampling\n- [Map-call workflow](#Map-call-workflow) to map reads and call small variants [vg](https://github.com/vgteam/vg),\n  DeepVariant and GATK (legacy?).\n- [Map-call Pedigree workflow](#Map-call-Pedigree-workflow) to map reads and call variants in a pedigree\n  with [vg](https://github.com/vgteam/vg) (legacy?). \n"
      },
      "source": "https://raw.githubusercontent.com/vgteam/vg_wdl/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9915782718203913,
      "result": {
        "original_header": "Giraffe-DeepVariant workflow",
        "type": "Text_excerpt",
        "value": "- *INPUT_READ_FILE_1*: Input sample 1st read pair fastq.gz\n- *INPUT_READ_FILE_2*: Input sample 2nd read pair fastq.gz\n- *INPUT_CRAM_FILE*: Input CRAM file\n- *CRAM_REF*: Genome fasta file associated with the CRAM file\n- *CRAM_REF_INDEX*: Index of the fasta file associated with the CRAM file\n- *GBZ_FILE*: Path to .gbz index file\n- *DIST_FILE*: Path to .dist index file\n- *MIN_FILE*: Path to .min index file\n- *SAMPLE_NAME*: The sample name\n- *OUTPUT_GAF*: Should a GAF file with the aligned reads be saved? Default is 'true'.\n- *OUTPUT_SINGLE_BAM*: Should a single merged BAM file be saved? If yes, unmapped reads will be inluded and 'calling\n  bams' (one per contig) won't be outputed. Default is 'true'.\n- *PAIRED_READS*: Are the reads paired? Default is 'true'.\n- *READS_PER_CHUNK*: Number of reads contained in each mapping chunk. Default 20 000 000.\n- *PATH_LIST_FILE*: (OPTIONAL) Text file where each line is a path name in the GBZ index, to use instead of CONTIGS. If\n  neither is given, paths are extracted from the GBZ and subset to chromosome-looking paths.\n- *CONTIGS*: (OPTIONAL) Desired reference genome contigs, which are all paths in the GBZ index.\n- *REFERENCE_PREFIX*: Remove this off the beginning of path names in surjected BAM (set to match prefix in\n  PATH_LIST_FILE)\n- *REFERENCE_FILE*: (OPTIONAL) If specified, use this FASTA reference instead of extracting it from the graph. Required\n  if the graph does not contain all bases of the reference.\n- *REFERENCE_INDEX_FILE*: (OPTIONAL) If specified, use this .fai index instead of indexing the reference file.\n- *REFERENCE_DICT_FILE*: (OPTIONAL) If specified, use this pre-computed .dict file of sequence lengths. Required if\n  REFERENCE_INDEX_FILE is set\n- *LEFTALIGN_BAM*: Whether or not to left-align reads in the BAM. Default is 'true'.\n- *REALIGN_INDELS*: Whether or not to realign reads near indels. Default is 'true'.\n- *REALIGNMENT_EXPANSION_BASES*: Number of bases to expand indel realignment targets by on either side, to free up read\n  tails in slippery regions. Default is 160.\n- *MIN_MAPQ*: Minimum MAPQ of reads to use for calling. 4 is the lowest at which a mapping is more likely to be right\n  than wrong. Default is 1\n- *MAX_FRAGMENT_LENGTH*: Maximum distance at which to mark paired reads properly paired. Default is 3000.\n- *GIRAFFE_OPTIONS*: (OPTIONAL) extra command line options for Giraffe mapper\n- *TRUTH_VCF*: (OPTIONAL) Path to .vcf.gz to compare against\n- *TRUTH_VCF_INDEX*: (OPTIONAL) Path to Tabix index for TRUTH_VCF\n- *EVALUATION_REGIONS_BED*: (OPTIONAL) BED to restrict comparison against TRUTH_VCF to\n- *DV_MODEL_META*: (OPTIONAL) .meta file for a custom DeepVariant calling model\n- *DV_MODEL_INDEX*: (OPTIONAL) .index file for a custom DeepVariant calling model\n- *DV_MODEL_DATA*: (OPTIONAL) .data-00000-of-00001 file for a custom DeepVariant calling model\n- *DV_KEEP_LEGACY_AC*: Should DV use the legacy allele counter behavior? Default is 'true'.\n- *DV_NORM_READS*: Should DV normalize reads itself? Default is 'false'.\n- *OTHER_MAKEEXAMPLES_ARG*: Additional arguments for the make_examples step of DeepVariant\n- *SPLIT_READ_CORES*: Number of cores to use when splitting the reads into chunks. Default is 8.\n- *MAP_CORES*: Number of cores to use when mapping the reads. Default is 16.\n- *MAP_MEM*: Memory, in GB, to use when mapping the reads. Default is 120.\n- *CALL_CORES*: Number of cores to use when calling variants. Default is 8.\n- *CALL_MEM*: Memory, in GB, to use when calling variants. Default is 50. \n"
      },
      "source": "https://raw.githubusercontent.com/vgteam/vg_wdl/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9813817895171852,
      "result": {
        "original_header": "Giraffe workflow",
        "type": "Text_excerpt",
        "value": "Core VG Giraffe mapping, usable for [DeepVariant](https://github.com/google/deepvariant).\nReads are mapped to a pangenome with [vg giraffe](https://github.com/vgteam/vg) and pre-processed (e.g. indel\nrealignment). \n- *INPUT_READ_FILE_1*: Input sample 1st read pair fastq.gz\n- *INPUT_READ_FILE_2*: Input sample 2nd read pair fastq.gz\n- *INPUT_CRAM_FILE*: Input CRAM file\n- *CRAM_REF*: Genome fasta file associated with the CRAM file\n- *CRAM_REF_INDEX*: Index of the fasta file associated with the CRAM file\n- *GBZ_FILE*: Path to .gbz index file\n- *DIST_FILE*: Path to .dist index file\n- *MIN_FILE*: Path to .min index file\n- *SAMPLE_NAME*: The sample name\n- *OUTPUT_SINGLE_BAM*: Should a single merged BAM file be saved? If yes, unmapped reads will be inluded and 'calling\n  bams' (one per contig) won't be outputed. Default is 'true'.\n- *OUTPUT_CALLING_BAMS*: Should individual contig BAMs be saved? Default is 'false'.\n- *OUTPUT_GAF*: Should a GAF file with the aligned reads be saved? Default is 'false'.\n- *PAIRED_READS*: Are the reads paired? Default is 'true'.\n- *READS_PER_CHUNK*: Number of reads contained in each mapping chunk. Default 20 000 000.\n- *PATH_LIST_FILE*: (OPTIONAL) Text file where each line is a path name in the GBZ index, to use instead of CONTIGS. If\n  neither is given, paths are extracted from the GBZ and subset to chromosome-looking paths.\n- *CONTIGS*: (OPTIONAL) Desired reference genome contigs, which are all paths in the GBZ index.\n- *REFERENCE_PREFIX*: Remove this off the beginning of path names in surjected BAM (set to match prefix in\n  PATH_LIST_FILE)\n- *REFERENCE_FILE*: (OPTIONAL) If specified, use this FASTA reference instead of extracting it from the graph. Required\n  if the graph does not contain all bases of the reference.\n- *REFERENCE_INDEX_FILE*: (OPTIONAL) If specified, use this .fai index instead of indexing the reference file.\n- *REFERENCE_DICT_FILE*: (OPTIONAL) If specified, use this pre-computed .dict file of sequence lengths. Required if\n  REFERENCE_INDEX_FILE i\n- *LEFTALIGN_BAM*: Whether or not to left-align reads in the BAM. Default is 'true'.\n- *REALIGN_INDELS*: Whether or not to realign reads near indels. Default is 'true'.\n- *REALIGNMENT_EXPANSION_BASES*: Number of bases to expand indel realignment targets by on either side, to free up read\n  tails in slippery regions. Default is 160.\n- *MAX_FRAGMENT_LENGTH*: Maximum distance at which to mark paired reads properly paired. Default is 3000.\n- *GIRAFFE_OPTIONS*: (OPTIONAL) extra command line options for Giraffe mapper\n- *SPLIT_READ_CORES*: Number of cores to use when splitting the reads into chunks. Default is 8.\n- *MAP_CORES*: Number of cores to use when mapping the reads. Default is 16.\n- *MAP_MEM*: Memory, in GB, to use when mapping the reads. Default is 120.\n- *HAPLOTYPE_SAMPLING*: Whether or not to use haplotype sampling before running giraffe. Default is 'true'\n- *IN_DIPLOID*:Whether or not to use diploid sampling while doing haplotype sampling. Has to use with Haplotype_sampling=true. Default is 'true'\n- *HAPL_FILE*: (OPTIONAL) Path to .hapl file used in haplotype sampling\n- *R_INDEX_FILE*: (OPTIONAL) Path to .ri file used in haplotype sampling\n- *IN_KFF_FILE*: (OPTIONAL) Path to .kff file used in haplotype sampling\n- *IN_HAPLOTYPE_NUMBER*: Number of generated synthetic haplotypes used in haplotype sampling. (Default: 4) \n"
      },
      "source": "https://raw.githubusercontent.com/vgteam/vg_wdl/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9613591277468467,
      "result": {
        "original_header": "Giraffe-DeepVariant from GAF workflow",
        "type": "Text_excerpt",
        "value": "Surject a GAF and prepare the BAMs (e.g. fix names, indel realign), and call small variants\nwith [DeepVariant](https://github.com/google/deepvariant). \n- *INPUT_GAF*: Input gzipped GAF file\n- *GBZ_FILE*: Path to .gbz index file\n- *SAMPLE_NAME*: The sample name\n- *OUTPUT_SINGLE_BAM*: Should a single merged BAM file be saved? If yes, unmapped reads will be inluded and 'calling\n  bams' (one per contig) won't be outputed. Default is 'true'.\n- *PAIRED_READS*: Are the reads paired? Default is 'true'.\n- *PATH_LIST_FILE*: (OPTIONAL) Text file where each line is a path name in the GBZ index, to use instead of CONTIGS. If\n  neither is given, paths are extracted from the GBZ and subset to chromosome-looking paths.\n- *CONTIGS*: (OPTIONAL) Desired reference genome contigs, which are all paths in the GBZ index.\n- *REFERENCE_PREFIX*: Remove this off the beginning of path names in surjected BAM (set to match prefix in\n  PATH_LIST_FILE)\n- *REFERENCE_FILE*: (OPTIONAL) If specified, use this FASTA reference instead of extracting it from the graph. Required\n  if the graph does not contain all bases of the reference.\n- *REFERENCE_INDEX_FILE*: (OPTIONAL) If specified, use this .fai index instead of indexing the reference file.\n- *REFERENCE_DICT_FILE*: (OPTIONAL) If specified, use this pre-computed .dict file of sequence lengths. Required if\n  REFERENCE_INDEX_FILE is set\n- *LEFTALIGN_BAM*: Whether or not to left-align reads in the BAM. Default is 'true'.\n- *REALIGN_INDELS*: Whether or not to realign reads near indels. Default is 'true'.\n- *REALIGNMENT_EXPANSION_BASES*: Number of bases to expand indel realignment targets by on either side, to free up read\n  tails in slippery regions. Default is 160.\n- *MIN_MAPQ*: Minimum MAPQ of reads to use for calling. 4 is the lowest at which a mapping is more likely to be right\n  than wrong. Default is 1\n- *MAX_FRAGMENT_LENGTH*: Maximum distance at which to mark paired reads properly paired. Default is 3000.\n- *DV_MODEL_META*: (OPTIONAL) .meta file for a custom DeepVariant calling model\n- *DV_MODEL_INDEX*: (OPTIONAL) .index file for a custom DeepVariant calling model\n- *DV_MODEL_DATA*: (OPTIONAL) .data-00000-of-00001 file for a custom DeepVariant calling model\n- *DV_KEEP_LEGACY_AC*: Should DV use the legacy allele counter behavior? Default is 'true'.\n- *DV_NORM_READS*: Should DV normalize reads itself? Default is 'fasle'.\n- *OTHER_MAKEEXAMPLES_ARG*: Additional arguments for the make_examples step of DeepVariant\n- *VG_CORES*: Number of cores to use when projecting the reads. Default is 16.\n- *VG_MEM*: Memory, in GB, to use when projecting the reads. Default is 120.\n- *CALL_CORES*: Number of cores to use when calling variants. Default is 8.\n- *CALL_MEM*: Memory, in GB, to use when calling variants. Default is 50. \n"
      },
      "source": "https://raw.githubusercontent.com/vgteam/vg_wdl/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9641543013129507,
      "result": {
        "original_header": "Happy workflow",
        "type": "Text_excerpt",
        "value": "- *VCF*: bgzipped VCF with variant calls\n- *VCF_INDEX*: (Optional) If specified, use this tabix index for the VCF instead of indexing it\n- *TRUTH_VCF*: bgzipped VCF with truthset\n- *TRUTH_VCF_INDEX*: (Optional) If specified, use this index for the truth VCF instead of indexing it\n- *REFERENCE_FILE*: Use this FASTA reference.\n- *REFERENCE_INDEX_FILE*: (Optional) If specified, use this .fai index instead of indexing the reference file.\n- *EVALUATION_REGIONS_BED*: (Optional) BED to restrict comparison against TRUTH_VCF to\n- *REFERENCE_PREFIX*: (Optional) Remove this off the beginning of sequence names in the VCF \n"
      },
      "source": "https://raw.githubusercontent.com/vgteam/vg_wdl/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9114001784923527,
      "result": {
        "original_header": "GAF to sorted GAM workflow",
        "type": "Text_excerpt",
        "value": "Currently, only GAM file can be sorted and indexed, for example to extract and subgraph and visualize, or use with\nthe [sequenceTubeMap](https://github.com/vgteam/sequenceTubeMap).\nThis workflow converts reads aligned to a pangenome in a GAF file to a sorted and indexed GAM file. \n- *GAF_FILE*: GAF file to convert and sort.\n- *GBZ_FILE*: the GBZ index of the graph\n- *SAMPLE_NAME*: (Optional) a sample name \n"
      },
      "source": "https://raw.githubusercontent.com/vgteam/vg_wdl/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9305023683214567,
      "result": {
        "original_header": "Giraffe SV workflow",
        "type": "Text_excerpt",
        "value": "Workflow for mapping short reads and genotyping the structural variants in a pangenome. \n- [workflow file](https://github.com/vgteam/vg_wdl/raw/svpack/workflows/vg_map_call_sv.wdl)\n- [parameter file](https://github.com/vgteam/vg_wdl/raw/svpack/params/vg_map_call_sv_test.inputs.json)\n- [Dockstore page](https://dockstore.org/workflows/github.com/vgteam/vg_wdl/vg_map_call_sv:svpack?tab=info)\n- If you use this workflow, please cite [the Giraffe-SV article](#cite-giraffe-sv).\n \n"
      },
      "source": "https://raw.githubusercontent.com/vgteam/vg_wdl/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9282372460173532,
      "result": {
        "original_header": "Haplotype Sampling workflow",
        "type": "Text_excerpt",
        "value": "Workflow for creating a personalized pangenome with [haplotype sampling](https://github.com/vgteam/vg/wiki/Haplotype-Sampling). \nParameters  (semi-auto-generated from the *parameter_meta* section):\n- *IN_GBZ_FILE*: Path to .gbz index file\n- *INPUT_READ_FILE_FIRST*: Input sample 1st read pair fastq.gz\n- *INPUT_READ_FILE_SECOND*: Input sample 2st read pair fastq.gz\n- *HAPL_FILE*: Path to .hapl file\n- *IN_DIST_FILE*: Path to .dist file\n- *R_INDEX_FILE*: Path to .ri file\n- *KFF_FILE*: Path to .kff file\n- *IN_OUTPUT_NAME_PREFIX*: Name of the output file (Default: haplotype_sampled_graph)\n- *IN_KMER_LENGTH*: Size of kmer using for sampling (Up to 31) (Default: 29)\n- *CORES*: Number of cores to use with commands. (Default: 16)\n- *WINDOW_LENGTH*: Window length used for building the minimizer index. (Default: 11)\n- *SUBCHAIN_LENGTH*: Target length (in bp) for subchains. (Default: 10000)\n- *HAPLOTYPE_NUMBER*: Number of generated synthetic haplotypes. (Default: 4)\n- *PRESENT_DISCOUNT*: Multiplicative factor for discounting scores for present kmers. (Default: 0.9)\n- *HET_ADJUST*: Additive term for adjusting scores for heterozygous kmers. (Default: 0.05)\n- *ABSENT_SCORE*: Score for absent kmers. (Default: 0.8)\n- *INCLUDE_REFERENCE*: Include reference paths and generic paths from the full graph in the sampled graph. (Default:\ntrue)\n- *DIPLOID*: Activate diploid sampling. (Default: true) \n"
      },
      "source": "https://raw.githubusercontent.com/vgteam/vg_wdl/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8667336899070157,
      "result": {
        "original_header": "Map-call Pedigree workflow",
        "type": "Text_excerpt",
        "value": "- [workflow file](https://github.com/vgteam/vg_wdl/raw/master/workflows/vg_trio_multi_map_call.wdl)\n- [parameter file](https://github.com/vgteam/vg_wdl/raw/master/params/vg_trio_multi_map_call.inputs_tiny.http_url.json)\n- If you use this workflow, please cite the [Pedigree-VG article](#Cite-Pedigree-VG).\n \n"
      },
      "source": "https://raw.githubusercontent.com/vgteam/vg_wdl/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9757733888018668,
      "result": {
        "original_header": "Testing locally",
        "type": "Text_excerpt",
        "value": "[Miniwdl](#using-miniwdl) might be slightly more useful when developing/testing a WDL because is catches errors in WDL\nsyntax faster, and is a bit more explicit about them.\n \n"
      },
      "source": "https://raw.githubusercontent.com/vgteam/vg_wdl/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "documentation": [
    {
      "confidence": 1,
      "result": {
        "format": "wiki",
        "type": "Url",
        "value": "https://github.com/vgteam/vg_wdl/wiki"
      },
      "source": "https://raw.githubusercontent.com/vgteam/vg_wdl/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/vgteam/vg_wdl/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 9
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/vgteam/vg_wdl/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "vgteam/vg_wdl"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ""
      },
      "source": "https://raw.githubusercontent.com/vgteam/vg_wdl/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "has_script_file": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/vgteam/vg_wdl/master/scripts/setup_pedigree_script.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/vgteam/vg_wdl/master/scripts/setup_input_reads.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/vgteam/vg_wdl/master/scripts/setup_pedigree_indel_realignment_script.part_6.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/vgteam/vg_wdl/master/scripts/setup_trio_calling_script.part_2.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/vgteam/vg_wdl/master/scripts/setup_vg_wdl.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/vgteam/vg_wdl/master/scripts/setup_sibling_mapping_script.part_4.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/vgteam/vg_wdl/master/scripts/setup_pedigree_calling_script.part_5.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/vgteam/vg_wdl/master/scripts/setup_parent_graph_construct_script.part_3.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/vgteam/vg_wdl/master/scripts/collect_outputs.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/vgteam/vg_wdl/master/scripts/setup_trio_mapping_script.part_1.sh"
      },
      "technique": "file_exploration"
    }
  ],
  "installation": [
    {
      "confidence": 0.8204332728305903,
      "result": {
        "original_header": "Happy workflow",
        "type": "Text_excerpt",
        "value": "```sh\nminiwdl run --as-me workflows/happy_evaluation.wdl -i params/happy_evaluation.json\n```\n \n"
      },
      "source": "https://raw.githubusercontent.com/vgteam/vg_wdl/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8204332728305903,
      "result": {
        "original_header": "Haplotype Sampling workflow",
        "type": "Text_excerpt",
        "value": "```sh\nminiwdl run --as-me workflows/haplotype_sampling.wdl -i params/haplotype_sampling.json\n```\n \n"
      },
      "source": "https://raw.githubusercontent.com/vgteam/vg_wdl/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9941351398537229,
      "result": {
        "original_header": "Testing locally",
        "type": "Text_excerpt",
        "value": "To test the workflow locally, e.g. on the [small simulated dataset](tests/small_sim_graph), you can run it with Cromwell\nor miniwdl (see [Usage](#usage)).\nSo, from the root of this repo, run something like:\n```sh\njava -jar $CROMWELL_JAR run workflows/WORKFLOW.wdl -i params/INPUTS.json\n## or\nminiwdl run --as-me workflows/WORKFLOW.wdl -i params/INPUTS.json\n```\n \n"
      },
      "source": "https://raw.githubusercontent.com/vgteam/vg_wdl/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "invocation": [
    {
      "confidence": 0.8175692737268448,
      "result": {
        "original_header": "Giraffe-DeepVariant workflow",
        "type": "Text_excerpt",
        "value": "```sh\nminiwdl run --as-me workflows/giraffe_and_deepvariant.wdl -i params/giraffe_and_deepvariant.json\nminiwdl run --as-me workflows/giraffe_and_deepvariant.wdl -i params/giraffe_and_deepvariant_single_end.json\nminiwdl run --as-me workflows/giraffe_and_deepvariant.wdl -i params/giraffe_and_deepvariant_cram.json\n```\n \n"
      },
      "source": "https://raw.githubusercontent.com/vgteam/vg_wdl/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8136943240881388,
      "result": {
        "original_header": "Giraffe workflow",
        "type": "Text_excerpt",
        "value": "```sh\nminiwdl run --as-me workflows/giraffe.wdl -i params/giraffe.json\nminiwdl run --as-me workflows/giraffe.wdl -i params/giraffe.singleended.json\nminiwdl run --as-me workflows/giraffe.wdl -i params/giraffe.singleended.cram.json\nminiwdl run --as-me workflows/giraffe.wdl -i params/haplotype_sampling_and_giraffe.json\n```\n \n"
      },
      "source": "https://raw.githubusercontent.com/vgteam/vg_wdl/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8243042956356613,
      "result": {
        "original_header": "Giraffe-DeepVariant from GAF workflow",
        "type": "Text_excerpt",
        "value": "```sh\nminiwdl run --as-me workflows/giraffe_and_deepvariant_fromGAF.wdl -i params/giraffe_and_deepvariant_gaf.json\nminiwdl run --as-me workflows/giraffe_and_deepvariant_fromGAF.wdl -i params/giraffe_and_deepvariant_gaf_single_end.json\n```\n \n"
      },
      "source": "https://raw.githubusercontent.com/vgteam/vg_wdl/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8372668553534557,
      "result": {
        "original_header": "Happy workflow",
        "type": "Text_excerpt",
        "value": "```sh\nminiwdl run --as-me workflows/happy_evaluation.wdl -i params/happy_evaluation.json\n```\n \n"
      },
      "source": "https://raw.githubusercontent.com/vgteam/vg_wdl/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8372668553534557,
      "result": {
        "original_header": "Haplotype Sampling workflow",
        "type": "Text_excerpt",
        "value": "```sh\nminiwdl run --as-me workflows/haplotype_sampling.wdl -i params/haplotype_sampling.json\n```\n \n"
      },
      "source": "https://raw.githubusercontent.com/vgteam/vg_wdl/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/vgteam/vg_wdl/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ""
      },
      "technique": "GitHub_API"
    }
  ],
  "license": [
    {
      "confidence": 1,
      "result": {
        "name": "MIT License",
        "spdx_id": "MIT",
        "type": "License",
        "url": "https://api.github.com/licenses/mit",
        "value": "https://api.github.com/licenses/mit"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "type": "File_dump",
        "value": "MIT License\n\nCopyright (c) 2018 \n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
      },
      "source": "https://raw.githubusercontent.com/vgteam/vg_wdl/master/LICENSE",
      "technique": "file_exploration"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "vg_wdl"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "Organization",
        "value": "vgteam"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "WDL",
        "size": 586656,
        "type": "Programming_language",
        "value": "WDL"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Shell",
        "size": 62363,
        "type": "Programming_language",
        "value": "Shell"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 592,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/vgteam/vg_wdl/master/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "related_documentation": [
    {
      "confidence": 1,
      "result": {
        "format": "readthedocs",
        "type": "Url",
        "value": "https://bedtools.readthedocs.io/"
      },
      "source": "https://raw.githubusercontent.com/vgteam/vg_wdl/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "format": "readthedocs",
        "type": "Url",
        "value": "https://miniwdl.readthedocs.io/"
      },
      "source": "https://raw.githubusercontent.com/vgteam/vg_wdl/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "format": "readthedocs",
        "type": "Url",
        "value": "https://cromwell.readthedocs.io/"
      },
      "source": "https://raw.githubusercontent.com/vgteam/vg_wdl/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "releases": [
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "jmonlong",
          "type": "User"
        },
        "date_created": "2020-10-31T04:08:02Z",
        "date_published": "2020-10-31T04:24:00Z",
        "description": "This is the version used in the vg paper about the giraffe mapper and structural variant genotyping.",
        "html_url": "https://github.com/vgteam/vg_wdl/releases/tag/sv-giraffe-paper",
        "name": "SV genotyping with giraffe",
        "release_id": 33299329,
        "tag": "sv-giraffe-paper",
        "tarball_url": "https://api.github.com/repos/vgteam/vg_wdl/tarball/sv-giraffe-paper",
        "type": "Release",
        "url": "https://api.github.com/repos/vgteam/vg_wdl/releases/33299329",
        "value": "https://api.github.com/repos/vgteam/vg_wdl/releases/33299329",
        "zipball_url": "https://api.github.com/repos/vgteam/vg_wdl/zipball/sv-giraffe-paper"
      },
      "technique": "GitHub_API"
    }
  ],
  "somef_missing_categories": [
    "acknowledgement",
    "run",
    "download",
    "requirements",
    "contact",
    "contributors",
    "faq",
    "identifier",
    "has_build_file",
    "executable_example"
  ],
  "somef_provenance": {
    "date": "2024-10-06 03:37:16",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 16
      },
      "technique": "GitHub_API"
    }
  ],
  "support": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Contributing, Help, Bugs and Requests",
        "type": "Text_excerpt",
        "value": "Please open an Issue on [GitHub](https://github.com/vgteam/vg_wdl/issues) for help, bug reports, or feature requests.\nWhen doing so, please remember that vg\\_wdl is open-source software made by a community of developers.\nPlease be considerate and support a positive environment.\n"
      },
      "source": "https://raw.githubusercontent.com/vgteam/vg_wdl/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "type": [
    {
      "confidence": 0.82,
      "result": {
        "type": "String",
        "value": "commandline-application"
      },
      "technique": "software_type_heuristics"
    }
  ],
  "usage": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Going further",
        "parent_header": [
          "Workflows"
        ],
        "type": "Text_excerpt",
        "value": "See below more information\nabout: [read realignment](#Read-realignment), [reference prefix removal](#Reference-prefix-removal), [CRAM input](#CRAM-input), [reads chunking](#Reads-chunking), [path list](#Path-list), [single-end reads](#Single-end-reads), [unmapped reads](#Unmapped-reads), [HPRC pangenomes](#HPRC-pangenomes).\n"
      },
      "source": "https://raw.githubusercontent.com/vgteam/vg_wdl/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Read realignment",
        "parent_header": [
          "Workflows",
          "Going further"
        ],
        "type": "Text_excerpt",
        "value": "Once the reads are projected to a linear reference, we've noticed that realigning the reads can improve the variant\ncalling with [DeepVariant](https://github.com/google/deepvariant).\nThis helps mostly for the small insertions-deletions (indels).\n\nThe full realignment process involves:\n\n1. Leftaligning the reads\n   with [freebayes' `bamleftalign`](https://manpages.debian.org/testing/freebayes/bamleftalign.1.en.html).\n    - Can be enabled/disabled with the `LEFTALIGN_BAM` parameter\n2. Identifying regions to realign further\n   with [GATK RealignerTargetCreator](https://github.com/broadinstitute/gatk-docs/blob/master/gatk3-tutorials/(howto)_Perform_local_realignment_around_indels.md).\n3. Expand those regions with [bedtools](https://bedtools.readthedocs.io/en/latest/content/tools/slop.html).\n    - Number of bases to expand controlled by the `REALIGNMENT_EXPANSION_BASES` parameter.\n4. Realigning the reads in those regions with [ABRA2](https://github.com/mozack/abra2).\n\nThe last 3 steps can be enabled/disabled with the `REALIGN_INDELS` parameter.\n\nAlthough it produces the best variant calls, these extra steps increase the computational resources (and cost) of the\nworkflow.\nFor a lighter run, switch off those two realignment steps and use [DeepVariant](https://github.com/google/deepvariant)'s\nintegrated realigner instead with:\n\n- `LEFTALIGN_BAM=false`\n- `REALIGN_INDELS=false`\n- `DV_NORM_READS=true`\n"
      },
      "source": "https://raw.githubusercontent.com/vgteam/vg_wdl/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "CRAM input",
        "parent_header": [
          "Workflows",
          "Going further"
        ],
        "type": "Text_excerpt",
        "value": "When the input is a CRAM file (`INPUT_CRAM_FILE`) instead of a pair of FASTQ\nfiles (`INPUT_READ_FILE_1`/`INPUT_READ_FILE_2`), the user must also provide the appropriate reference FASTA to work with\nthat CRAM file with `CRAM_REF`, and its index with `CRAM_REF_INDEX`.\n\nThe CRAM file will be converted back to a pair of FASTQs, so it costs a little bit more to analyze CRAMs than FASTQs\ncurrently.\n"
      },
      "source": "https://raw.githubusercontent.com/vgteam/vg_wdl/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Reads chunking",
        "parent_header": [
          "Workflows",
          "Going further"
        ],
        "type": "Text_excerpt",
        "value": "Sequencing reads are chunked to parallelize read mapping.\nThe amount of chunking is controlled by the `READS_PER_CHUNK` parameter which specify how many reads each chunk should\nhave.\nFor a WGS experiment, we use chunks of about 20M reads.\n"
      },
      "source": "https://raw.githubusercontent.com/vgteam/vg_wdl/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Path list",
        "parent_header": [
          "Workflows",
          "Going further"
        ],
        "type": "Text_excerpt",
        "value": "We might not always want to project the reads alignments to all the paths in the pangenome.\nFor example, we might only care about alignment to chromosomes and not alternate contigs.\nOr there might be multiple sets of paths like in the CHM13-based HPRC pangenome which contains both reference paths for\nCHM13 and GRCh38.\nIn that case, we can specify a list of paths to project the reads to using one of the following.\n\n`PATH_LIST_FILE` is a file which lists the paths names, one per line.\nFor the HPRC pangenomes it looks like:\n\n```txt\nGRCh38.chr1\nGRCh38.chr2\nGRCh38.chr3\n...etc\n```\n\nOtherwise, paths can be listed in the `CONTIGS` parameter as a list (WDL array).\n"
      },
      "source": "https://raw.githubusercontent.com/vgteam/vg_wdl/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Single-end reads",
        "parent_header": [
          "Workflows",
          "Going further"
        ],
        "type": "Text_excerpt",
        "value": "Workflows expect paired-end reads, but some workflows can also analyze single-end reads.\n\nTo use single-end reads:\n\n- If providing FASTQs, only provide `INPUT_READ_FILE_1` (no `INPUT_READ_FILE_2`).\n- Use `PAIRED_READS=false`\n"
      },
      "source": "https://raw.githubusercontent.com/vgteam/vg_wdl/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Unmapped reads",
        "parent_header": [
          "Workflows",
          "Going further"
        ],
        "type": "Text_excerpt",
        "value": "If including unmapped reads in the BAMs is important, make sure to switch on `OUTPUT_SINGLE_BAM=true` in\nthe [Giraffe-DeepVariant workflow](#Giraffe-DeepVariant-workflow) and [Giraffe workflow](#Giraffe-workflow).\n"
      },
      "source": "https://raw.githubusercontent.com/vgteam/vg_wdl/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "HPRC pangenomes",
        "parent_header": [
          "Workflows",
          "Going further"
        ],
        "type": "Text_excerpt",
        "value": "We recommend using the filtered CHM13-based pangenome (freeze 1).\nIt contains both the CHM13 and GRCh38 reference paths.\n\nUse the following indexes for the pangenome:\n\n- `GBZ_FILE`: [hprc-v1.0-mc-chm13-minaf.0.1.gbz](https://storage.googleapis.com/hprc-pangenomes/hprc-v1.0-mc-chm13-minaf.0.1.gbz)\n    - GBZ with the pangenome and haplotypes.\n- `MIN_FILE`: [hprc-v1.0-mc-chm13-minaf.0.1.min](https://s3-us-west-2.amazonaws.com/human-pangenomics/pangenomes/freeze/freeze1/minigraph-cactus/filtered/hprc-v1.0-mc-chm13-minaf.0.1.min)\n    - Minimizer index.\n- `DIST_FILE`: [hprc-v1.0-mc-chm13-minaf.0.1.dist](https://s3-us-west-2.amazonaws.com/human-pangenomics/pangenomes/freeze/freeze1/minigraph-cactus/filtered/hprc-v1.0-mc-chm13-minaf.0.1.dist)\n    - Distance index.\n\nTo project reads and call variants relative to the GRCh38 reference:\n\n- `REFERENCE_PREFIX=\"GRCh38.\"`\n- `PATH_LIST_FILE` containing *GRCh38.chr1*, *GRCh38.chr2*, etc. File available\n  at [GRCh38.path_list.txt](https://storage.googleapis.com/hprc-pangenomes/GRCh38.path_list.txt)\n- `REFERENCE_FILE`: [hg38.fa](https://storage.googleapis.com/hprc-pangenomes/hg38.fa)\n- `REFERENCE_INDEX_FILE`: [hg38.fa.fai](https://storage.googleapis.com/hprc-pangenomes/hg38.fa.fai). Optional, the\n  workflow will create it if necessary (for a small extra cost/time).\n- `REFERENCE_DICT_FILE`: [hg38.dict](https://storage.googleapis.com/hprc-pangenomes/hg38.dict). Optional, the workflow\n  will create it if necessary (for a small extra cost/time).\n\nTo project reads and call variants relative to the CHM13 reference:\n\n- `REFERENCE_PREFIX=\"CHM13.\"`\n- `PATH_LIST_FILE` containing *CHM13.chr1*, *CHM13.chr2*, etc. File available\n  at [CHM13.path_list.txt](https://storage.googleapis.com/hprc-pangenomes/CHM13.path_list.txt)\n- `REFERENCE_FILE`: [chm13v2.0.plus_hs38d1_analysis_set.compact_decoys.fa](https://storage.googleapis.com/hprc-pangenomes/chm13v2.0.plus_hs38d1_analysis_set.compact_decoys.fa)\n- `REFERENCE_INDEX_FILE`: [chm13v2.0.plus_hs38d1_analysis_set.compact_decoys.fa.fai](https://storage.googleapis.com/hprc-pangenomes/chm13v2.0.plus_hs38d1_analysis_set.compact_decoys.fa.fai).\n  Optional, the workflow will create it if necessary (for a small extra cost/time).\n- `REFERENCE_DICT_FILE`: [chm13v2.0.plus_hs38d1_analysis_set.compact_decoys.dict](https://storage.googleapis.com/hprc-pangenomes/chm13v2.0.plus_hs38d1_analysis_set.compact_decoys.dict).\n  Optional, the workflow will create it if necessary (for a small extra cost/time).\n\nFor earlier versions of DeepVariant (<1.5), models were retrained using reads aligned to the HPRC pangenomes.\nThe corresponding model files were deposited\nat: [https://s3-us-west-2.amazonaws.com/human-pangenomics/index.html?prefix=publications/PANGENOME_2022/DeepVariant/models/DEEPVARIANT_MC_Y1/](https://s3-us-west-2.amazonaws.com/human-pangenomics/index.html?prefix=publications/PANGENOME_2022/DeepVariant/models/DEEPVARIANT_MC_Y1/).\nThey can be passed to the workflows using the `DV_MODEL_META`, `DV_MODEL_INDEX`, and `DV_MODEL_DATA`.\nNote that **it is not necessary to use custom models in the latest version of the workflows** as DeepVariant v1.5\nincludes default models suited for analyzing reads mapped to pangenomes (and projected back to a linear reference).\n"
      },
      "source": "https://raw.githubusercontent.com/vgteam/vg_wdl/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Dockstore",
        "parent_header": [
          "Usage"
        ],
        "type": "Text_excerpt",
        "value": "The workflows that were deposited on [Dockstore](https://dockstore.org/) can be launched\nusing [its command line](https://docs.dockstore.org/en/stable/launch-with/launch.html) or on platform\nlike [Terra](https://app.terra.bio/).\n"
      },
      "source": "https://raw.githubusercontent.com/vgteam/vg_wdl/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Using miniwdl",
        "parent_header": [
          "Usage"
        ],
        "type": "Text_excerpt",
        "value": "[Install miniwdl](https://miniwdl.readthedocs.io/en/latest/getting_started.html#install-miniwdl), for example,\nwith `pip`:\n\n```sh\npip3 install miniwdl\n```\n\nClone this repo somewhere with `git clone https://github.com/vgteam/vg_wdl.git`\n\nRun a workflow using:\n\n```\nminiwdl run /path/to/vg_wdl/workflows/WORKFLOW.wdl -i your-inputs.json\n```\n\nTo modify the input parameters, edit the input `.json` with the necessary changes.\n"
      },
      "source": "https://raw.githubusercontent.com/vgteam/vg_wdl/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Using Cromwell",
        "parent_header": [
          "Usage"
        ],
        "type": "Text_excerpt",
        "value": "[Cromwell](https://cromwell.readthedocs.io/en/stable/) can be run WDL workflows with:\n\n```sh\njava -jar $CROMWELL_JAR run workflow.wdl -i inputs.json\n```\n\nWhere *CROMWELL_JAR* points at the Cromwell jar\ndownloaded [their release page](https://github.com/broadinstitute/cromwell/releases/), for example set\nwith `CROMWELL_JAR=/path/to/cromwell-<whatever>.jar` in your shell.\n\nTo run one of the workflows in this repo, clone the repo somewhere with `git clone https://github.com/vgteam/vg_wdl.git`\nand run the desired workflow `.wdl` file:\n\n```sh\njava -jar $CROMWELL_JAR run /path/to/vg_wdl/workflows/WORKFLOW.wdl -i inputs.json\n```\n"
      },
      "source": "https://raw.githubusercontent.com/vgteam/vg_wdl/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Docker Containers",
        "parent_header": [
          "Usage"
        ],
        "type": "Text_excerpt",
        "value": "WDL needs the runtime Docker image to be present online (e.g. Dockerhub).\n[Cromwell](#using-cromwell)/[miniwdl](#using-miniwdl) will pull those images automatically.\nVG images are available at [quay.io](https://quay.io/repository/vgteam/vg?tab=tags) and can be pulled with:\n\n```\ndocker pull quay.io/vgteam/vg:v1.44.0\n```\n\nSpecific versions can be specified like above for version `v1.44.0`.\n"
      },
      "source": "https://raw.githubusercontent.com/vgteam/vg_wdl/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "workflows": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/vgteam/vg_wdl/master/workflows/happy_evaluation.wdl"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/vgteam/vg_wdl/master/workflows/giraffe_and_deeptrio.mapper.wdl"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/vgteam/vg_wdl/master/workflows/vg_indel_realign.wdl"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/vgteam/vg_wdl/master/workflows/sort_graph_aligned_reads.wdl"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/vgteam/vg_wdl/master/workflows/vg_multi_map.wdl"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/vgteam/vg_wdl/master/workflows/vg_trio_giraffe_deeptrio_workflow.wdl"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/vgteam/vg_wdl/master/workflows/vg_2nd_iter_pedigree_indel_realign.wdl"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/vgteam/vg_wdl/master/workflows/vg_construct_and_index.wdl"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/vgteam/vg_wdl/master/workflows/vg_multi_call.wdl"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/vgteam/vg_wdl/master/workflows/vg_trio_parental_graph_construction.wdl"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/vgteam/vg_wdl/master/workflows/vg_trio_multi_map_call.wdl"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/vgteam/vg_wdl/master/workflows/haplotype_sampling.wdl"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/vgteam/vg_wdl/master/workflows/vg_2nd_iter_siblings_multi_map.wdl"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/vgteam/vg_wdl/master/workflows/vg_deeptrio_calling_workflow.wdl"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/vgteam/vg_wdl/master/workflows/vg_2nd_iter_pedigree_multi_call.wdl"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/vgteam/vg_wdl/master/workflows/giraffe_and_deeptrio.wdl"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/vgteam/vg_wdl/master/workflows/vg_trio_multi_call.wdl"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/vgteam/vg_wdl/master/workflows/giraffe.wdl"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/vgteam/vg_wdl/master/workflows/vg_trio_multi_map.wdl"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/vgteam/vg_wdl/master/workflows/TEST.wdl"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/vgteam/vg_wdl/master/workflows/giraffe_and_deepvariant.wdl"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/vgteam/vg_wdl/master/workflows/giraffe_and_deepvariant_fromGAF.wdl"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/vgteam/vg_wdl/master/workflows/vg_multi_map_call.wdl"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/vgteam/vg_wdl/master/tasks/generic_tasks.wdl"
      },
      "technique": "file_exploration"
    }
  ]
}