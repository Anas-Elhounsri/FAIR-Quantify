{
  "application_domain": [
    {
      "confidence": 94.75,
      "result": {
        "type": "String",
        "value": "Computer Vision"
      },
      "technique": "supervised_classification"
    }
  ],
  "citation": [
    {
      "confidence": 1,
      "result": {
        "author": "Ter-Sarkisov, Aram",
        "doi": "10.1101/2020.10.30.20223586",
        "format": "bibtex",
        "title": "Lightweight Model For The Prediction of COVID-19 Through The Detection And Segmentation\nof Lesions in Chest CT Scans",
        "type": "Text_excerpt",
        "value": "@article{Ter-Sarkisov2020.10.30.20223586,\n    journal = {medRxiv},\n    publisher = {Cold Spring Harbor Laboratory Press},\n    doi = {10.1101/2020.10.30.20223586},\n    year = {2020},\n    title = {Lightweight Model For The Prediction of COVID-19 Through The Detection And Segmentation\nof Lesions in Chest CT Scans},\n    author = {Ter-Sarkisov, Aram},\n}"
      },
      "source": "https://raw.githubusercontent.com/AlexTS1980/COVID-CT-Mask-Net/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "author": "Ter-Sarkisov, Aram",
        "doi": "10.1101/2020.10.23.20218461",
        "format": "bibtex",
        "title": "Detection and Segmentation of Lesion Areas in Chest CT Scans For The Prediction of COVID-19",
        "type": "Text_excerpt",
        "value": "@article{Ter-Sarkisov2020.10.23.20218461,\n    journal = {medRxiv},\n    publisher = {Cold Spring Harbor Laboratory Press},\n    doi = {10.1101/2020.10.23.20218461},\n    year = {2020},\n    title = {Detection and Segmentation of Lesion Areas in Chest CT Scans For The Prediction of COVID-19},\n    author = {Ter-Sarkisov, Aram},\n}"
      },
      "source": "https://raw.githubusercontent.com/AlexTS1980/COVID-CT-Mask-Net/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/AlexTS1980/COVID-CT-Mask-Net"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2020-10-09T22:23:18Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2024-09-28T01:24:56Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "Segmentation and Classification models for COVID CT scans (COVID, pneumonia, normal) based on Mask R-CNN."
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 0.9886937618237591,
      "result": {
        "original_header": "Update 01/11/20",
        "type": "Text_excerpt",
        "value": "I re-implemented torchvision's segmentation interface locally, in the end it was easier to keep two different files for RPN and RoI for segmentation and classification tasks: `rpn_segmentation, roi_segmentation` vs `roi` and `rpn`. For the validation split in `test_split_segmentation.txt` I get the following results for the two lightweight and two best full models (ResNet50+FPN backbone):  \nFor each script, two additional arguments were added: `backbone_name`, one of `resnet18, resnet34, resnet50` and `truncation`, one of `0,1,2`. For `resnet50`, only the full (base torchvision model) output is implemented, with 4 connections to FPN. For `resnet18` and `resnet34`, `truncation=0` means use the full backbone model, for `truncation=1` the last block is deleted and `truncation=2` the last two layers are deleted. Only the last layer is connected to the FPN.  \n"
      },
      "source": "https://raw.githubusercontent.com/AlexTS1980/COVID-CT-Mask-Net/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8783202595176349,
      "result": {
        "original_header": "Update 29/10/20",
        "type": "Text_excerpt",
        "value": "Column 1: Input CT scan slice overlaid with the output of the segmentation model.  \nColumn 2: Mask maps logit scores (pixel-level) predicted by Mask R-CNN *independently of each other*, i.e. they were output by different RoIs and resized to fit the bounding box prediction. Note COVID-CT-Mask-Net uses a fixed number of RoIs. Only the highest-ranking RoIs are plotted here to avoid the image clutter. \nColumn 3: ground truth masks for lesions (yellow) and lungs (green, treated as a background). \nColumn 4: true class (green) and logit scores output by COVID-CT-Mask-Net (red) using the score map's inputs. Note how the classification model learns the distribution and ranking of the regional predictions (bounding boxes and confidence scores) to predict the global (image) class. \n"
      },
      "source": "https://raw.githubusercontent.com/AlexTS1980/COVID-CT-Mask-Net/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9762669072994954,
      "result": {
        "original_header": "Update 19-22/10/20",
        "type": "Text_excerpt",
        "value": "I added a large number of updates across all models. Now you can train segmentation and classification models with 3 types of masks: two masks (GGO and C), only GGO and merged GGO and C  masks('lesion').  \nI added methods in the `utils` script to compute the accuracy (mean Average Precision) of Mask R-CNN segmentation models. They are based on matterport's package, but purely in pytorch, no requirements for RLE or pycocotools. A new evaluation script, `evaluation_mean_ap`, which uses these methods for a range of Intersect over Union (IoU) thresholds, has been added too.  \nAll segmentation scripts as well as the segmentation dataset interface accept `mask_type` argument, one of `both` (GGO + C), `ggo` (only GGO) and `merge` (merged GGO and C masks). The effect on the size of the model is marginal.       \n \n"
      },
      "source": "https://raw.githubusercontent.com/AlexTS1980/COVID-CT-Mask-Net/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9412699889230889,
      "result": {
        "original_header": "1. Segmentation Model",
        "type": "Text_excerpt",
        "value": "The segmentation model predicts masks of Ground Glass Opacity and Consolidation in CT scans. We trained it on the CNCB CT images with masks (http://ncov-ai.big.ac.cn/download, Experiment data files): 500 training and 150 for testing taken from COVID-positive patients, but some slices have no\nlesions. Use the splits in `train_split_segmentation.txt` and `test_split_segmentation.txt` to copy the training data into `covid_data/train/imgs` and `covid_data/train/masks` and test data into `covid_data/test/imgs` and `covid_data/test/masks`.  \nFor the explanation of plots see the paper. To get the average precision on the data, you also need the mask for each image. For example, for merged masks:\n```\npython3.5 evaluation_mean_ap.py --ckpt pretrained_weights/segmentation_model_merged_masks.pth --mask_type merge --test_data_dir covid_data/test --test_imgs_dir imgs --gt_dir masks\n```\nTo train the segmentation model, you also need images with masks. Dataset interface `dataset_segmentation.py` converts masks into binary masks with either 2 positive classes (GGO+C) or 1 (GGO only, merged GGO+C). It also extracts labels and bounding boxes that Mask R-CNN requires. \nTo train from scratch for the merged masks, run \nBASH3*\nTo get the reported results, and for the COVID-CT-Mask-Net classsifier, we trained the model for 100 epochs (about 4.5 hours on a GPU with 8Gb VRAM).   \n \n"
      },
      "source": "https://raw.githubusercontent.com/AlexTS1980/COVID-CT-Mask-Net/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9278616371246493,
      "result": {
        "original_header": "2.1 Full model (ResNet50+FPN backbone)",
        "type": "Text_excerpt",
        "value": "I reimplemented torchvision's detection library(https://github.com/pytorch/vision/tree/master/torchvision/models/detection) in `/models/mask_net/` with the classification module **s2_new** (**S** in the paper) and other hacks that convert Mask R-CNN into a classification model.\nFirst, download and unpack the CNCB dataset: (http://ncov-ai.big.ac.cn/download), a total of over 100K CT scans. The COVIDx-CT split we used is here: https://github.com/haydengunraj/COVIDNet-CT/blob/master/docs/dataset.md). To extract the COVID-19, pneumonia and normal scans, follow the instructions in the link to COVIDx-CT. You don't need to do any image preprocessing as inthe COVIDNet-CT model. We used the full validation and test split, and a small share of the training data, our sample is in `train_split_classification.txt`. To follow the convention used in the other two datsets, we set Class 0: Control, Class 1: Normal Pneumonia, Class 2: COVID. Thus the dataset interface `datasets/dataset_classification.py` extracts the labels from the file names. The convention for the names must be `[Class]_[PatientID]_[ScanNum]_[SliceNum].png`. To train the classifier, copy the images following this convention into a separate directory, e.g. `train_small`.\n \n"
      },
      "source": "https://raw.githubusercontent.com/AlexTS1980/COVID-CT-Mask-Net/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9566853645087618,
      "result": {
        "original_header": "2.2 Lightweight Models (Truncated ResNet18/34+FPN backbone)",
        "type": "Text_excerpt",
        "value": "I implemented two backbones, ResNet18 and ResNet34, both with a single FPN module, and two truncations: the last block or two last blocks.  \n"
      },
      "source": "https://raw.githubusercontent.com/AlexTS1980/COVID-CT-Mask-Net/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9030913868978532,
      "result": {
        "original_header": "3. Models' hyperparameters",
        "type": "Text_excerpt",
        "value": "There are two groups of hyperparameters: training (learning rate, weight regularization, optimizer, etc) and Mask R-CNN hyperparameters (Non-max suppression threshold, RPN and RoI batch size, RPN output, RoI score threshold, etc). The ones in the training scripts are the ones we used to get the models in the paper and the results. For the segmentation model you can use any you want, but for COVID-CT-Mask-Net the RoI score threshold (`box_score_thresh`) must be negative (e.g. `-0.01`), because otherwise not all box predictions (`box_detections_per_img`) will be accepted, and the classification module **S** will not get the batch of the right size, hence you will get a tensor mismatch error. \n[Update 22/10/20:] Also, our re-implementation of torchvision's Mask R-CNN has a hack that allows maintaining the same batch size regardless of the pre-set `box_score_thresh`.  \n"
      },
      "source": "https://raw.githubusercontent.com/AlexTS1980/COVID-CT-Mask-Net/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/AlexTS1980/COVID-CT-Mask-Net/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 15
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/AlexTS1980/COVID-CT-Mask-Net/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "AlexTS1980/COVID-CT-Mask-Net"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ""
      },
      "source": "https://raw.githubusercontent.com/AlexTS1980/COVID-CT-Mask-Net/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "images": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/AlexTS1980/COVID-CT-Mask-Net/master/plots/Kent_231120.png"
      },
      "source": "https://raw.githubusercontent.com/AlexTS1980/COVID-CT-Mask-Net/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/AlexTS1980/COVID-CT-Mask-Net/master/plots/segmentation_map_classification_score.png"
      },
      "source": "https://raw.githubusercontent.com/AlexTS1980/COVID-CT-Mask-Net/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/AlexTS1980/COVID-CT-Mask-Net/master/plots/maskrcnncovidsegment.png"
      },
      "source": "https://raw.githubusercontent.com/AlexTS1980/COVID-CT-Mask-Net/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/AlexTS1980/COVID-CT-Mask-Net/master/plots/128_92_with_mask.png"
      },
      "source": "https://raw.githubusercontent.com/AlexTS1980/COVID-CT-Mask-Net/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/AlexTS1980/COVID-CT-Mask-Net/master/plots/133_48_with_mask.png"
      },
      "source": "https://raw.githubusercontent.com/AlexTS1980/COVID-CT-Mask-Net/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/AlexTS1980/COVID-CT-Mask-Net/master/plots/covid-ct-mask-net.png"
      },
      "source": "https://raw.githubusercontent.com/AlexTS1980/COVID-CT-Mask-Net/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/AlexTS1980/COVID-CT-Mask-Net/master/plots/s_module_final.png"
      },
      "source": "https://raw.githubusercontent.com/AlexTS1980/COVID-CT-Mask-Net/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/AlexTS1980/COVID-CT-Mask-Net/master/plots/resnet18.png"
      },
      "source": "https://raw.githubusercontent.com/AlexTS1980/COVID-CT-Mask-Net/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "installation": [
    {
      "confidence": 0.9842652069769863,
      "result": {
        "original_header": "COVID-CT-Mask-Net: Prediction of COVID-19 From CT Scans Using Regional Features",
        "type": "Text_excerpt",
        "value": "<p align=\"center\">\n<img src=\"https://github.com/AlexTS1980/COVID-CT-Mask-Net/blob/master/plots/Kent_231120.png\" width=\"800\" height=\"400\" align=\"center\"/>\n</p> \n"
      },
      "source": "https://raw.githubusercontent.com/AlexTS1980/COVID-CT-Mask-Net/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9542358013191519,
      "result": {
        "original_header": "Update 29/10/20",
        "type": "Text_excerpt",
        "value": "<p align=\"center\">\n<img src=\"https://github.com/AlexTS1980/COVID-CT-Mask-Net/blob/master/plots/segmentation_map_classification_score.png\" width=\"800\" height=\"500\" align=\"center\"/>\n</p> \n"
      },
      "source": "https://raw.githubusercontent.com/AlexTS1980/COVID-CT-Mask-Net/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9978665716572932,
      "result": {
        "original_header": "1. Segmentation Model",
        "type": "Text_excerpt",
        "value": "<p align=\"center\">\n<img src=\"https://github.com/AlexTS1980/COVID-CT-Mask-Net/blob/master/plots/maskrcnncovidsegment.png\" width=\"800\" height=\"250\" align=\"center\"/>\n</p>\nTo train and test the model you need Torchvision 0.3.0+ \nTo get the inference of the segmentation model, run: \n```\npython3.5 inference_segmentation.py --ckpt pretrained_models/segmentation_model_both_classes.pth --test_data_dir covid_data/test --test_imgs_dir imgs --masks_type both\n```\nThis should output predictions like these:\n<p align=\"center\">\n<img src=\"https://github.com/AlexTS1980/COVID-CT-Mask-Net/blob/master/plots/128_92_with_mask.png\" width=\"600\" height=\"200\" align=\"center\"/>\n<img src=\"https://github.com/AlexTS1980/COVID-CT-Mask-Net/blob/master/plots/133_48_with_mask.png\" width=\"600\" height=\"200\" align=\"center\"/>\n</p> \n"
      },
      "source": "https://raw.githubusercontent.com/AlexTS1980/COVID-CT-Mask-Net/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.981951122189407,
      "result": {
        "original_header": "2.1 Full model (ResNet50+FPN backbone)",
        "type": "Text_excerpt",
        "value": "**Classification module *S***\n<p align=\"center\">\n<img src=\"https://github.com/AlexTS1980/COVID-CT-Mask-Net/blob/master/plots/s_module_final.png\" width=\"700\" height=\"400\" align=\"center\"/>\n</p> \n"
      },
      "source": "https://raw.githubusercontent.com/AlexTS1980/COVID-CT-Mask-Net/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8735791855083987,
      "result": {
        "original_header": "2.2 Lightweight Models (Truncated ResNet18/34+FPN backbone)",
        "type": "Text_excerpt",
        "value": "Backbone model:\n<p align=\"center\">\n<img src=\"https://github.com/AlexTS1980/COVID-CT-Mask-Net/blob/master/plots/resnet18.png\" width=\"800\" height=\"250\" align=\"center\"/>\n</p> \n"
      },
      "source": "https://raw.githubusercontent.com/AlexTS1980/COVID-CT-Mask-Net/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "invocation": [
    {
      "confidence": 0.8409983709409353,
      "result": {
        "original_header": "1. Segmentation Model",
        "type": "Text_excerpt",
        "value": "Download the pretrained weights into  `pretrained_models/` directory. \n"
      },
      "source": "https://raw.githubusercontent.com/AlexTS1980/COVID-CT-Mask-Net/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/AlexTS1980/COVID-CT-Mask-Net/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "chest, classification-model, computer-tomograpy, computer-vision, covid, covid-19, ct-scans, deep-learning, mask, mask-rcnn, segmentation-model"
      },
      "technique": "GitHub_API"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "COVID-CT-Mask-Net"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "User",
        "value": "AlexTS1980"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 207017,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/AlexTS1980/COVID-CT-Mask-Net/master/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "somef_missing_categories": [
    "acknowledgement",
    "run",
    "download",
    "requirements",
    "contact",
    "contributors",
    "documentation",
    "license",
    "usage",
    "faq",
    "support",
    "identifier",
    "has_build_file",
    "executable_example"
  ],
  "somef_provenance": {
    "date": "2024-10-06 13:26:03",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 27
      },
      "technique": "GitHub_API"
    }
  ],
  "type": [
    {
      "confidence": 0.82,
      "result": {
        "type": "String",
        "value": "commandline-application"
      },
      "technique": "software_type_heuristics"
    }
  ]
}