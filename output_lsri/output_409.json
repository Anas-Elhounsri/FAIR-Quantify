{
  "application_domain": [
    {
      "confidence": 0.914317959644148,
      "result": {
        "type": "String",
        "value": "Graphs"
      },
      "technique": "supervised_classification"
    },
    {
      "confidence": 74.27,
      "result": {
        "type": "String",
        "value": "Natural Language Processing"
      },
      "technique": "supervised_classification"
    }
  ],
  "citation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Citation",
        "type": "Text_excerpt",
        "value": "```bibtex\n@article{YUAN2022103983,\ntitle = {CODER: Knowledge-infused cross-lingual medical term embedding for term normalization},\njournal = {Journal of Biomedical Informatics},\npages = {103983},\nyear = {2022},\nissn = {1532-0464},\ndoi = {https://doi.org/10.1016/j.jbi.2021.103983},\nurl = {https://www.sciencedirect.com/science/article/pii/S1532046421003129},\nauthor = {Zheng Yuan and Zhengyun Zhao and Haixia Sun and Jiao Li and Fei Wang and Sheng Yu},\nkeywords = {medical term normalization, cross-lingual, medical term representation, knowledge graph embedding, contrastive learning}\n}\n```\n\n```bibtex\n@inproceedings{zeng-etal-2022-automatic,\n    title = \"Automatic Biomedical Term Clustering by Learning Fine-grained Term Representations\",\n    author = \"Zeng, Sihang  and\n      Yuan, Zheng  and\n      Yu, Sheng\",\n    booktitle = \"Proceedings of the 21st Workshop on Biomedical Language Processing\",\n    month = may,\n    year = \"2022\",\n    address = \"Dublin, Ireland\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2022.bionlp-1.8\",\n    pages = \"91--96\",\n    abstract = \"Term clustering is important in biomedical knowledge graph construction. Using similarities between terms embedding is helpful for term clustering. State-of-the-art term embeddings leverage pretrained language models to encode terms, and use synonyms and relation knowledge from knowledge graphs to guide contrastive learning. These embeddings provide close embeddings for terms belonging to the same concept. However, from our probing experiments, these embeddings are not sensitive to minor textual differences which leads to failure for biomedical term clustering. To alleviate this problem, we adjust the sampling strategy in pretraining term embeddings by providing dynamic hard positive and negative samples during contrastive learning to learn fine-grained representations which result in better biomedical term clustering. We name our proposed method as CODER++, and it has been applied in clustering biomedical concepts in the newly released Biomedical Knowledge Graph named BIOS.\",\n}\n```\n"
      },
      "source": "https://raw.githubusercontent.com/GanjinZero/CODER/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "author": "Zheng Yuan and Zhengyun Zhao and Haixia Sun and Jiao Li and Fei Wang and Sheng Yu",
        "doi": "https://doi.org/10.1016/j.jbi.2021.103983",
        "format": "bibtex",
        "title": "CODER: Knowledge-infused cross-lingual medical term embedding for term normalization",
        "type": "Text_excerpt",
        "url": "https://www.sciencedirect.com/science/article/pii/S1532046421003129",
        "value": "@article{YUAN2022103983,\n    keywords = {medical term normalization, cross-lingual, medical term representation, knowledge graph embedding, contrastive learning},\n    author = {Zheng Yuan and Zhengyun Zhao and Haixia Sun and Jiao Li and Fei Wang and Sheng Yu},\n    url = {https://www.sciencedirect.com/science/article/pii/S1532046421003129},\n    doi = {https://doi.org/10.1016/j.jbi.2021.103983},\n    issn = {1532-0464},\n    year = {2022},\n    pages = {103983},\n    journal = {Journal of Biomedical Informatics},\n    title = {CODER: Knowledge-infused cross-lingual medical term embedding for term normalization},\n}"
      },
      "source": "https://raw.githubusercontent.com/GanjinZero/CODER/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "author": "Zeng, Sihang  and\nYuan, Zheng  and\nYu, Sheng",
        "format": "bibtex",
        "title": "Automatic Biomedical Term Clustering by Learning Fine-grained Term Representations",
        "type": "Text_excerpt",
        "url": "https://aclanthology.org/2022.bionlp-1.8",
        "value": "@inproceedings{zeng-etal-2022-automatic,\n    abstract = {Term clustering is important in biomedical knowledge graph construction. Using similarities between terms embedding is helpful for term clustering. State-of-the-art term embeddings leverage pretrained language models to encode terms, and use synonyms and relation knowledge from knowledge graphs to guide contrastive learning. These embeddings provide close embeddings for terms belonging to the same concept. However, from our probing experiments, these embeddings are not sensitive to minor textual differences which leads to failure for biomedical term clustering. To alleviate this problem, we adjust the sampling strategy in pretraining term embeddings by providing dynamic hard positive and negative samples during contrastive learning to learn fine-grained representations which result in better biomedical term clustering. We name our proposed method as CODER++, and it has been applied in clustering biomedical concepts in the newly released Biomedical Knowledge Graph named BIOS.},\n    pages = {91--96},\n    url = {https://aclanthology.org/2022.bionlp-1.8},\n    publisher = {Association for Computational Linguistics},\n    address = {Dublin, Ireland},\n    year = {2022},\n    month = {May},\n    booktitle = {Proceedings of the 21st Workshop on Biomedical Language Processing},\n    author = {Zeng, Sihang  and\nYuan, Zheng  and\nYu, Sheng},\n    title = {Automatic Biomedical Term Clustering by Learning Fine-grained Term Representations},\n}"
      },
      "source": "https://raw.githubusercontent.com/GanjinZero/CODER/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/GanjinZero/CODER"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2020-08-12T00:40:19Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2024-09-17T15:29:30Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "CODER: Knowledge infused cross-lingual medical term embedding for term normalization. [JBI, ACL-BioNLP 2022]"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 0.8047606654322826,
      "result": {
        "original_header": "DDBRC",
        "type": "Text_excerpt",
        "value": "Only sampled data is provided.\n```shell\ncd test/diseasedb\npython train.py your_embedding embedding_type freeze_or_not gpu_id\n```\n- embedding_type should be in [bert, word, cui]\n- freeze_or_not should be in [T, F], T means freeze the embedding, and F means fine-tune the embedding\n \n"
      },
      "source": "https://raw.githubusercontent.com/GanjinZero/CODER/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/GanjinZero/CODER/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 5
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/GanjinZero/CODER/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "GanjinZero/CODER"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "CODER"
      },
      "source": "https://raw.githubusercontent.com/GanjinZero/CODER/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "has_script_file": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/GanjinZero/CODER/master/coderpp/clustering/utils/run.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/GanjinZero/CODER/master/coderpp/train/run.sh"
      },
      "technique": "file_exploration"
    }
  ],
  "images": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/GanjinZero/CODER/master/img/coder++.png"
      },
      "source": "https://raw.githubusercontent.com/GanjinZero/CODER/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "installation": [
    {
      "confidence": 0.9978665785892964,
      "result": {
        "original_header": "Train your model",
        "type": "Text_excerpt",
        "value": "```shell\ncd pretrain\npython train.py --umls_dir your_umls_dir --model_name_or_path monologg/biobert_v1.1_pubmed\n```\nyour_umls_dir should contain **MRCONSO.RRF**, **MRREL.RRF** and **MRSTY.RRF**.\nUMLS Download path:[UMLS](https://www.nlm.nih.gov/research/umls/licensedcontent/umlsarchives04.html#2020AA).\n \n"
      },
      "source": "https://raw.githubusercontent.com/GanjinZero/CODER/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.99680721638393,
      "result": {
        "original_header": "CADEC",
        "type": "Text_excerpt",
        "value": "```shell\ncd test\npython cadec/cadec_eval.py bert_model_name_or_path\npython cadec/cadec_eval.py word_embedding_path\n```\n \n"
      },
      "source": "https://raw.githubusercontent.com/GanjinZero/CODER/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9991383353763342,
      "result": {
        "original_header": "MANTRA GSC",
        "type": "Text_excerpt",
        "value": "Download [the Mantra GSC](https://files.ifi.uzh.ch/cl/mantra/gsc/GSC-v1.1.zip) and unzip the xml files to /test/mantra/dataset, run\n```\ncd test/mantra\npython test.py\n```\n \n"
      },
      "source": "https://raw.githubusercontent.com/GanjinZero/CODER/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9866382623130188,
      "result": {
        "original_header": "MCSM",
        "type": "Text_excerpt",
        "value": "```shell\ncd test/embeddings_reimplement\npython mcsm.py\n```\n \n"
      },
      "source": "https://raw.githubusercontent.com/GanjinZero/CODER/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "invocation": [
    {
      "confidence": 0.9260026270467135,
      "result": {
        "original_header": "Train your model",
        "type": "Text_excerpt",
        "value": "```shell\ncd pretrain\npython train.py --umls_dir your_umls_dir --model_name_or_path monologg/biobert_v1.1_pubmed\n```\nyour_umls_dir should contain **MRCONSO.RRF**, **MRREL.RRF** and **MRSTY.RRF**.\nUMLS Download path:[UMLS](https://www.nlm.nih.gov/research/umls/licensedcontent/umlsarchives04.html#2020AA).\n \n"
      },
      "source": "https://raw.githubusercontent.com/GanjinZero/CODER/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8799187336857348,
      "result": {
        "original_header": "A small tool for load UMLS RRF",
        "type": "Text_excerpt",
        "value": "```python\nfrom pretrain.load_umls import UMLS\numls = UMLS(your_umls_dir)\n```\n \n"
      },
      "source": "https://raw.githubusercontent.com/GanjinZero/CODER/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9509034243664976,
      "result": {
        "original_header": "CADEC",
        "type": "Text_excerpt",
        "value": "```shell\ncd test\npython cadec/cadec_eval.py bert_model_name_or_path\npython cadec/cadec_eval.py word_embedding_path\n```\n \n"
      },
      "source": "https://raw.githubusercontent.com/GanjinZero/CODER/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.966510487001158,
      "result": {
        "original_header": "MANTRA GSC",
        "type": "Text_excerpt",
        "value": "Download [the Mantra GSC](https://files.ifi.uzh.ch/cl/mantra/gsc/GSC-v1.1.zip) and unzip the xml files to /test/mantra/dataset, run\n```\ncd test/mantra\npython test.py\n```\n \n"
      },
      "source": "https://raw.githubusercontent.com/GanjinZero/CODER/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9467082840831852,
      "result": {
        "original_header": "MCSM",
        "type": "Text_excerpt",
        "value": "```shell\ncd test/embeddings_reimplement\npython mcsm.py\n```\n \n"
      },
      "source": "https://raw.githubusercontent.com/GanjinZero/CODER/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/GanjinZero/CODER/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "embeddings, medical, multi-language, nlp, pretrained-language-model, umls"
      },
      "technique": "GitHub_API"
    }
  ],
  "logo": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/GanjinZero/CODER/master/img/1.png"
      },
      "source": "https://raw.githubusercontent.com/GanjinZero/CODER/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "CODER"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "User",
        "value": "GanjinZero"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 223759,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Shell",
        "size": 5202,
        "type": "Programming_language",
        "value": "Shell"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/GanjinZero/CODER/master/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "related_papers": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://arxiv.org/abs/2204.00391"
      },
      "source": "https://raw.githubusercontent.com/GanjinZero/CODER/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "somef_missing_categories": [
    "acknowledgement",
    "run",
    "download",
    "requirements",
    "contact",
    "contributors",
    "documentation",
    "license",
    "faq",
    "support",
    "identifier",
    "has_build_file",
    "executable_example"
  ],
  "somef_provenance": {
    "date": "2024-10-06 00:50:18",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 74
      },
      "technique": "GitHub_API"
    }
  ],
  "usage": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Use the model by transformers",
        "type": "Text_excerpt",
        "value": "Models have been uploaded to huggingface/transformers repo.\n\n```python\nfrom transformers import AutoTokenizer, AutoModel\n\ntokenizer = AutoTokenizer.from_pretrained(\"GanjinZero/UMLSBert_ENG\")\nmodel = AutoModel.from_pretrained(\"GanjinZero/UMLSBert_ENG\")\n```\nEnglish checkpoint: **GanjinZero/coder_eng** or GanjinZero/UMLSBert_ENG (old name)\n\nEnglish checkpoint CODER++: **GanjinZero/coder_eng_pp** (with hard negative sampling)\n\n\nMultilingual checkpoint: **GanjinZero/coder_all** ~~or GanjinZero/UMLSBert_ALL  (discarded old name)~~\n"
      },
      "source": "https://raw.githubusercontent.com/GanjinZero/CODER/master/README.md",
      "technique": "header_analysis"
    }
  ]
}