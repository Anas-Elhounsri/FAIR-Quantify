{
  "application_domain": [
    {
      "confidence": 53.51,
      "result": {
        "type": "String",
        "value": "Computer Vision"
      },
      "technique": "supervised_classification"
    }
  ],
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/PathologyDataScience/NuCLS"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2021-02-17T23:09:21Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2024-09-07T07:53:02Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "NuCLS: A scalable crowdsourcing, deep learning approach and dataset for nucleus classification, localization and segmentation"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Summary of contributions",
        "parent_header": [
          "NuCLS crowdsourcing approach, dataset, and explainable deep-learning method"
        ],
        "type": "Text_excerpt",
        "value": "We describe the following contributions:\n"
      },
      "source": "https://raw.githubusercontent.com/PathologyDataScience/NuCLS/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "1. <a href=\"https://sites.google.com/view/nucls\">NuCLS datasets</a>",
        "parent_header": [
          "NuCLS crowdsourcing approach, dataset, and explainable deep-learning method",
          "Summary of contributions"
        ],
        "type": "Text_excerpt",
        "value": "<img src=\"https://user-images.githubusercontent.com/22067552/140637897-87adddc5-b9e3-4151-8937-844202b56530.png\" width=\"400\" />\n\nOver 220,000 labeled nuclei from breast cancer images from TCGA; one of the largest datasets for nucleus detection, classification and segmentation of hematoxylin and eosin-stained digital slides of breast cancer. These nuclei were annotated through the collaborative effort of pathologists, pathology residents, and medical students using the Digital Slide Archive. These data can be used in several ways to develop and validate algorithms for nuclear detection, classification, and segmentation, or as a resource to develop and evaluate methods for interrater analysis. Data from both single-rater and multi-rater studies are provided. For single-rater data we provide both pathologist-reviewed and uncorrected annotations. For multi-rater datasets we provide annotations generated with and without suggestions from weak segmentation and classification algorithms.\n"
      },
      "source": "https://raw.githubusercontent.com/PathologyDataScience/NuCLS/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "2. A novel crowdsourcing framework",
        "parent_header": [
          "NuCLS crowdsourcing approach, dataset, and explainable deep-learning method",
          "Summary of contributions"
        ],
        "type": "Text_excerpt",
        "value": "<img src=\"https://user-images.githubusercontent.com/22067552/140638162-c57c78f6-8b7e-4736-ba52-a468cf315895.png\" width=\"600\" />\n\nThis paper describes a novel collaborative framework for engaging crowds of medical students and pathologists to produce quality labels for cell nuclei. This builds on [prior work](https://academic.oup.com/bioinformatics/article/35/18/3461/5307750) labeling tissue regions to produce an integrated tissue region- and cell-level annotation dataset for training that is the largest such resource for multi-scale analysis of breast cancer histology. This paper presents data and analysis results for single and multi-rater annotations from both non-experts and pathologists. We present a novel method for suggesting annotations that\nallows us to collect accurate segmentation data without the need for laborious manual tracing of cells. Our results indicate that\neven noisy algorithmic suggestions do not adversely affect pathologist accuracy, and can help non-experts improve annotation\nquality. We also present a new approach for inferring truth from multiple raters, and show that non-experts can produce accurate\nannotations for visually distinctive classes.\n"
      },
      "source": "https://raw.githubusercontent.com/PathologyDataScience/NuCLS/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "3. Mask R-CNN improvements",
        "parent_header": [
          "NuCLS crowdsourcing approach, dataset, and explainable deep-learning method",
          "Summary of contributions"
        ],
        "type": "Text_excerpt",
        "value": "<img src=\"https://user-images.githubusercontent.com/22067552/140638550-76f88308-bcd2-4f56-a5ea-792fbb45ba30.png\" width=\"600\" />\n\nWe show how modifications to the widely used Mask R-CNN architecture, including decoupling the detection and classification tasks, improves accuracy and enables learning from hybrid annotation datasets like NuCLS, which contain mixtures of bounding boxes and segmentation boundaries. \n"
      },
      "source": "https://raw.githubusercontent.com/PathologyDataScience/NuCLS/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "4. Decision Tree Approximation of Learned Embeddings",
        "parent_header": [
          "NuCLS crowdsourcing approach, dataset, and explainable deep-learning method",
          "Summary of contributions"
        ],
        "type": "Text_excerpt",
        "value": "<img src=\"https://user-images.githubusercontent.com/22067552/140638638-1c3a3a14-c61d-43b7-ae9c-f0fabda981a7.png\" width=\"600\" />\n\nWe introduce an explainability method called Decision Tree Approximation of Learned Embeddings (DTALE), which provides explanations for classification model behavior globally, as well as for individual nuclear predictions. DTALE explanations are simple, quantitative, and can flexibly use any measurable morphological features that make sense to practicing pathologists, without sacrificing model accuracy.\n\n"
      },
      "source": "https://raw.githubusercontent.com/PathologyDataScience/NuCLS/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 0.8903777686661186,
      "result": {
        "original_header": "NuCLS crowdsourcing approach, dataset, and explainable deep-learning method",
        "type": "Text_excerpt",
        "value": "This repository contains the codebase corresponding to the following two papers: \n_Amgad M, Atteya LA, Hussein H, Mohammed KH, Hafiz E, Elsebaie MA, Alhusseiny AM, AlMoslemany MA, Elmatboly AM, Pappalardo PA, Sakr RA. **NuCLS: A scalable crowdsourcing approach & dataset for nucleus classification and segmentation in breast cancer.** GigaScience 2022 (in print). (Access [ArXiv preprint](https://arxiv.org/abs/2102.09099))_ \n_Amgad M, Atteya LA, Hussein H, Mohammed KH, Hafiz E, Elsebaie MA, Mobadersany P, Manthey D, Gutman DA, Elfandy H, Cooper LA. **Explainable nucleus classification using Decision Tree Approximation of Learned Embeddings.** Bioinformatics. 2021 Sep 29._ \nPlease consult these papers for details on the context in which these scripts and methods were used in our research to generate and analyse the NuCLS dataset. \n"
      },
      "source": "https://raw.githubusercontent.com/PathologyDataScience/NuCLS/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.972957321373056,
      "result": {
        "original_header": "Repository structure",
        "type": "Text_excerpt",
        "value": "Structure and high-level documentation of the repository is included below:\n```\n\u2502\n\u2514\u2500\u2500\u2500 Mask_RCNN @ 403afaf : This is our fork from the Matterport Mask-RCNN implementation. We used this implementation as-is to refine the algorithmic suggestions that the participants saw.\n\u2502\n\u2514\u2500\u2500\u2500 algorithmic_suggestions : Python methods and scripts used to generate the algorithmic suggestions. \n|  |  \n\u2502  \u2514\u2500\u2500\u2500 jupyter_notebooks : Walk-through examples of the steps used to suggestion generation and refinement.\n|  |    \u2514\u2500\u2500\u2500 jn1_inspect_bootstrapping_workflow_TCGA.ipynb : Sample walk-through from the generation of algorithmic suggestions using image processing.\n|  |    \u2514\u2500\u2500\u2500 jn2_inspect_maskrcnn_training.ipynb : Training the Matterport Mask R-CNN implementation.\n|  |    \u2514\u2500\u2500\u2500 jn4_inspect_maskrcnn_inference.ipynb : Inference using the Matterport Mask R-CNN model to produce refined algorithmic suggestions.\n|  |    \u2514\u2500\u2500\u2500 jn5_inspect_integrate_maskrcnn_prediction_with_region_priors.ipynb : Integrating region priors from the BCSS region annotation dataset to produce more sensible algorithmic suggestions.\n|  |    \n\u2502  \u2514\u2500\u2500\u2500 scripts : python scripts used to generate bootstrapped suggestions using classical image processing, refine those suggestions using Mask R-CNN, further improve refinement by integrating region prior knowledge from the BCSS region annotation dataset, and saving the refined suggestions to a database to be shown to participants.\n|  |    \u2514\u2500\u2500\u2500 m1_bootstrap_nuclei_from_regions_TCGA.py : Obtaining nuclear boundaries and preliminary classification by bootstrapping using classical image processing.\n|  |    \u2514\u2500\u2500\u2500 m2_train_TCGA_maskrcnn.py : Training Matterport Mask R-CNN model.\n|  |    \u2514\u2500\u2500\u2500 m3_save_extra_TCGA_tiles_for_inference.py : Saving dataset for inference.\n|  |    \u2514\u2500\u2500\u2500 m4_inference_TCGA_maskrcnn.py : Inference using the Matterport Mask R-CNN model to produce refined algorithmic suggestions.\n|  |    \u2514\u2500\u2500\u2500 m5_integrate_maskrcnn_prediction_with_region_priors.py : Integrating region priors from the BCSS region annotation dataset to produce more sensible algorithmic suggestions.\n|  |    \u2514\u2500\u2500\u2500 m6_save_bootstrap_to_db.py : Saving predictions in coordinate-form into an SQLite database to be visualized through the HistomicsUI interface.\n\u2502  |\n|  \u2514\u2500\u2500\u2500 SQLite_Methods.py : Methods for SQLite databse parsing.\n|  \u2514\u2500\u2500\u2500 bootstrapping_utils.py : Methods for generating algorithmic suggestions using classical image processing.\n|  \u2514\u2500\u2500\u2500 configs_for_AlgorithmicSuggestions_MaskRCNN.py : Configurations used for the Matterport Mask R-CNN implementation.\n|  \u2514\u2500\u2500\u2500 data_management.py : utilities used for data management and wrangling.\n|  \u2514\u2500\u2500\u2500 maskrcnn_region_integration_utils.py : Methods used for integrating region priors to improve refined suggestions.\n|  \u2514\u2500\u2500\u2500 maskrcnn_utils_local.py : Other utilities to facilitate Mas R-CNN training.\n\u2502\n\u2514\u2500\u2500\u2500 configs : configurations used, including color and ground truth codes\n|  \u2514\u2500\u2500\u2500 nucleus_GTcodes.csv : Ground truth codes for forming nucleus masks.\n|  \u2514\u2500\u2500\u2500 nucleus_model_configs.py : Configurations used for the NuCLS model (our modified Mask R-CNN implementation, as described in the Bioinformatics paper).\n|  \u2514\u2500\u2500\u2500 nucleus_style_defaults.py : Color coding scheme and other configurations used.\n|\n\u2514\u2500\u2500\u2500 interrater : Python methods and scripts used for the interrater and intra-rater analysis.\n|  |  \n\u2502  \u2514\u2500\u2500\u2500 scripts : scripts used to perform the interrater and intra-rater analysis and plots\n|  |    \u2514\u2500\u2500\u2500 i1_get_all_nucleus_anchors.py : Obtain nucleus anchors using constrained agglomerative clustering and infer classification truth using expectation-maximization.\n|  |    \u2514\u2500\u2500\u2500 i1b_get_krippendorph_summary.py : Ontaing Krippendorph alpha interrater agreement statistics\n|  |    \u2514\u2500\u2500\u2500 i1c_get_accuracy_stats.py : Obtain detection accuracy statistics for individual participants and vaarious participant groups.\n|  |    \u2514\u2500\u2500\u2500 i1d_get_interrater_and_intrarater_stats.py :  Obtain interrater and intrarater agreement statistics for detection and classification.\n|  |    \u2514\u2500\u2500\u2500 i1e_run_NPs_accuracy_simulations.py : Run simulations to determine minimal number of participants needed to achieve desired accuracy of inferred truth.\n|  |    \u2514\u2500\u2500\u2500 i1f_parse_anchors_dataset.py : Parse a ground truth dataset using consensus anchor locations and inferred true classifications.\n|  |    \u2514\u2500\u2500\u2500 i2_show_effect_of_constrained_clustering.py : Investigate the impact of clustering constraint in the constrained agglomerative clustering approach used.\n|  |    \u2514\u2500\u2500\u2500 i3_get_anchor_composition_summary.py : Get and plot a summary of the composition of the distribution and composition of inferred labels and classifications.\n|  |    \u2514\u2500\u2500\u2500 i4_get_detection_and_classification_tally.py : An extension of i3_get_anchor_composition_summary.py\n|  |    \u2514\u2500\u2500\u2500 i5_plot_participant_accuracy_stats.py : Plot participant accuracy results. \n|  |    \u2514\u2500\u2500\u2500 i6_plot_segmentation_accuracy_stats.py : Plot segmentation accuracy of nuclei that were determined to have accurate algorithmically-suggested segmentation boundary.\n|  |    \u2514\u2500\u2500\u2500 i7_plot_participant_confusion.py : Plot confusion matrix of participant classifications.\n|  |    \u2514\u2500\u2500\u2500 i8_plot_intrarater_stats.py : Plot intrarater statistics (self-agreement).\n|  |    \u2514\u2500\u2500\u2500 i9_plot_interrater_stats.py : Plot interrater statistics.\n|  |    \u2514\u2500\u2500\u2500 i10_plot_krippendorph_summary.py : Plot Krippendorph alpha values.\n|  |    \u2514\u2500\u2500\u2500 i11_plot_NPs_accuracy_simulations.py : Plot the results of the simulations from i1e_run_NPs_accuracy_simulations.py\n|  |    \u2514\u2500\u2500\u2500 i12_statistical_tests.py : Run statistical tests to compare various results and obtain p-values.\n\u2502  |\n|  \u2514\u2500\u2500\u2500 DawidAndSkene1979_EMGtruthInference.py : This is code by Zheng et al, implementing the Expectation-Maximization based method for ground truth inference from multi-observer datasets, as proposed by Dawid and Skene in 1979.\n|  \u2514\u2500\u2500\u2500 constrained_agglomerative_clustering.py : Our constrained agglomerative clustering implementation. Please refer to the paper and function documentation for details.\n|  \u2514\u2500\u2500\u2500 interrater_utils.py : Various utilities to support the interrater analysis.\n|  \u2514\u2500\u2500\u2500 krippendorff.py : Modified from Samtiago Castro, based on Thomas Grill implementation. Works on Python 3.5+.\n\u2502\n\u2514\u2500\u2500\u2500 nucls_model : Python methods used in our paper: \"Amgad M, Atteya LA, Hussein H, Mohammed KH, Hafiz E, Elsebaie MA, Mobadersany P, Manthey D, Gutman DA, Elfandy H, Cooper LA. Explainable nucleus classification using Decision Tree Approximation of Learned Embeddings. Bioinformatics. 2021 Sep 29.\"\n|  |  \n|  \u2514\u2500\u2500\u2500 torchvision_detection_utils\n|  |    \u2514\u2500\u2500\u2500 ... Minimally-modified methods from the official torchvision implimentation \n|  \u2514\u2500\u2500\u2500 BackboneSwitcher.py\n|  \u2514\u2500\u2500\u2500 DTALE.py\n|  \u2514\u2500\u2500\u2500 DataFormattingUtils.py\n|  \u2514\u2500\u2500\u2500 DataLoadingUtils.py\n|  \u2514\u2500\u2500\u2500 FasterRCNN.py\n|  \u2514\u2500\u2500\u2500 FeatureExtractor.py\n|  \u2514\u2500\u2500\u2500 GeneralizedRCNN.py\n|  \u2514\u2500\u2500\u2500 MaskRCNN.py\n|  \u2514\u2500\u2500\u2500 MiscUtils.py\n|  \u2514\u2500\u2500\u2500 ModelRunner.py\n|  \u2514\u2500\u2500\u2500 NucleusWorkflows.py\n|  \u2514\u2500\u2500\u2500 PartialMaskRCNN.py\n|  \u2514\u2500\u2500\u2500 PlottingUtils.py\n|  \u2514\u2500\u2500\u2500 ROIHeads.py\n|  \n\u2514\u2500\u2500\u2500 GeneralUtils.py\n\u2514\u2500\u2500\u2500 TorchUtils.py\n\u2514\u2500\u2500\u2500 wsi-conda-env-specs.txt\n\n```\n__________________________________________________________________________\n \n"
      },
      "source": "https://raw.githubusercontent.com/PathologyDataScience/NuCLS/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9736472089709692,
      "result": {
        "original_header": "Dataset Licensing",
        "type": "Text_excerpt",
        "value": "This dataset itself is licensed under a [CC0 1.0 Universal (CC0 1.0) license](https://creativecommons.org/publicdomain/zero/1.0/). \nWe would appreciate it if you cite our paper if you use the data.\n \n"
      },
      "source": "https://raw.githubusercontent.com/PathologyDataScience/NuCLS/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9685477170297292,
      "result": {
        "original_header": "Code licensing",
        "type": "Text_excerpt",
        "value": "Thise codebase is licensed with an MIT license.\n \n"
      },
      "source": "https://raw.githubusercontent.com/PathologyDataScience/NuCLS/main/README.md",
      "technique": "supervised_classification"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/PathologyDataScience/NuCLS/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "executable_example": [
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/PathologyDataScience/NuCLS/main/algorithmic_suggestions/jupyter_notebooks/jn5_inspect_integrate_maskrcnn_prediction_with_region_priors.ipynb"
      },
      "source": "https://raw.githubusercontent.com/PathologyDataScience/NuCLS/main/algorithmic_suggestions/jupyter_notebooks/jn5_inspect_integrate_maskrcnn_prediction_with_region_priors.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/PathologyDataScience/NuCLS/main/algorithmic_suggestions/jupyter_notebooks/jn1_inspect_bootstrapping_workflow_TCGA.ipynb"
      },
      "source": "https://raw.githubusercontent.com/PathologyDataScience/NuCLS/main/algorithmic_suggestions/jupyter_notebooks/jn1_inspect_bootstrapping_workflow_TCGA.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/PathologyDataScience/NuCLS/main/algorithmic_suggestions/jupyter_notebooks/jn2_inspect_maskrcnn_training.ipynb"
      },
      "source": "https://raw.githubusercontent.com/PathologyDataScience/NuCLS/main/algorithmic_suggestions/jupyter_notebooks/jn2_inspect_maskrcnn_training.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/PathologyDataScience/NuCLS/main/algorithmic_suggestions/jupyter_notebooks/jn4_inspect_maskrcnn_inference.ipynb"
      },
      "source": "https://raw.githubusercontent.com/PathologyDataScience/NuCLS/main/algorithmic_suggestions/jupyter_notebooks/jn4_inspect_maskrcnn_inference.ipynb",
      "technique": "file_exploration"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 13
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/PathologyDataScience/NuCLS/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "PathologyDataScience/NuCLS"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "NuCLS crowdsourcing approach, dataset, and explainable deep-learning method"
      },
      "source": "https://raw.githubusercontent.com/PathologyDataScience/NuCLS/main/README.md",
      "technique": "regular_expression"
    }
  ],
  "images": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://user-images.githubusercontent.com/22067552/140637808-3a827cc5-ff9e-44fe-973e-e4b7cf36a21c.png"
      },
      "source": "https://raw.githubusercontent.com/PathologyDataScience/NuCLS/main/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://user-images.githubusercontent.com/22067552/140637897-87adddc5-b9e3-4151-8937-844202b56530.png"
      },
      "source": "https://raw.githubusercontent.com/PathologyDataScience/NuCLS/main/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://user-images.githubusercontent.com/22067552/140638162-c57c78f6-8b7e-4736-ba52-a468cf315895.png"
      },
      "source": "https://raw.githubusercontent.com/PathologyDataScience/NuCLS/main/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://user-images.githubusercontent.com/22067552/140638550-76f88308-bcd2-4f56-a5ea-792fbb45ba30.png"
      },
      "source": "https://raw.githubusercontent.com/PathologyDataScience/NuCLS/main/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://user-images.githubusercontent.com/22067552/140638638-1c3a3a14-c61d-43b7-ae9c-f0fabda981a7.png"
      },
      "source": "https://raw.githubusercontent.com/PathologyDataScience/NuCLS/main/README.md",
      "technique": "regular_expression"
    }
  ],
  "installation": [
    {
      "confidence": 0.9109482000893359,
      "result": {
        "original_header": "NuCLS crowdsourcing approach, dataset, and explainable deep-learning method",
        "type": "Text_excerpt",
        "value": "<img src=\"https://user-images.githubusercontent.com/22067552/140637808-3a827cc5-ff9e-44fe-973e-e4b7cf36a21c.png\" width=\"100\" /> \n"
      },
      "source": "https://raw.githubusercontent.com/PathologyDataScience/NuCLS/main/README.md",
      "technique": "supervised_classification"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/PathologyDataScience/NuCLS/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ""
      },
      "technique": "GitHub_API"
    }
  ],
  "license": [
    {
      "confidence": 1,
      "result": {
        "name": "MIT License",
        "spdx_id": "MIT",
        "type": "License",
        "url": "https://api.github.com/licenses/mit",
        "value": "https://api.github.com/licenses/mit"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "type": "File_dump",
        "value": "MIT License\n\nCopyright (c) 2021 Computational and Integrative Pathology\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
      },
      "source": "https://raw.githubusercontent.com/PathologyDataScience/NuCLS/main/LICENSE",
      "technique": "file_exploration"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "NuCLS"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "Organization",
        "value": "PathologyDataScience"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Jupyter Notebook",
        "size": 35716746,
        "type": "Programming_language",
        "value": "Jupyter Notebook"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 777136,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/PathologyDataScience/NuCLS/main/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "related_papers": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://arxiv.org/abs/2102.09099"
      },
      "source": "https://raw.githubusercontent.com/PathologyDataScience/NuCLS/main/README.md",
      "technique": "regular_expression"
    }
  ],
  "requirements": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Requirements",
        "parent_header": [
          "NuCLS crowdsourcing approach, dataset, and explainable deep-learning method"
        ],
        "type": "Text_excerpt",
        "value": "Conda specs are exported in the file `wsi-conda-env-specs.txt`, which can be used to generate a conda environment.\n\nMinimal requirements to run the interrater analysis: `numpy`, `scipy`, `pandas`, `sqlite`, `matplotlib`, and `seaborn`.\nOther requirements are needed for the algorithmic suggestion generation, including `HistomicTK`, `tensorflow`, and the Matterport Mask R-CNN implementation, included here as a fork.\nTo run the NuCLS model (described out Bioinformatics paper), you also need `torch`.\n\n__________________________________________________________________________\n"
      },
      "source": "https://raw.githubusercontent.com/PathologyDataScience/NuCLS/main/README.md",
      "technique": "header_analysis"
    }
  ],
  "somef_missing_categories": [
    "citation",
    "acknowledgement",
    "run",
    "download",
    "contact",
    "contributors",
    "documentation",
    "usage",
    "faq",
    "support",
    "identifier",
    "has_build_file"
  ],
  "somef_provenance": {
    "date": "2024-10-06 04:01:24",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 45
      },
      "technique": "GitHub_API"
    }
  ]
}