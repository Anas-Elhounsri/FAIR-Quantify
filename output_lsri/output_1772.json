{
  "application_domain": [
    {
      "confidence": 15.35,
      "result": {
        "type": "String",
        "value": "Computer Vision"
      },
      "technique": "supervised_classification"
    }
  ],
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/GliaLab/Begonia"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2021-03-08T10:59:51Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2023-04-10T15:54:43Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "A two-photon imaging analysis pipeline for astrocytic Ca2+ signals."
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 0.9985701424388063,
      "result": {
        "original_header": "Begonia",
        "type": "Text_excerpt",
        "value": "**Begonia is a Matlab framework developed by [Glialab](https://www.med.uio.no/imb/english/research/groups/glial-cells/) that helps solve some core challenges of scientific image analysis of 2-photon imaging data of astrocytes.**  \n**Some of its features are: (1) simple and low maintainence metadata storage strategy, (2) integrating manual steps of analysis with custom Matlab tools, (3) processing of image data agnostic to miscroscope type / image source, (4) joining time series data from multiple measurement devices and sources, and (5) automatic or semi-automatic analysis of imaged cells and tissue events visible with dynamic calcium sensors**. \nThe system offers some graphical workflow for non-programmers and an API for programmers. We find that the combination of GUI tools and Matlab processing APIs works well and that researchers supported by others with more programming experience allow high productivity with this framework.  \nNon-programmers can use the framework initially for an overview of data and automatic analysis for project piloting or quick reviews of data as it is collected. \n"
      },
      "source": "https://raw.githubusercontent.com/GliaLab/Begonia/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8501990475486428,
      "result": {
        "original_header": "Known issues \u26a0\ufe0f",
        "type": "Text_excerpt",
        "value": "* A bug prevents roimanager getting keyboard event if timeseries view is raised by clicking inside the window. Workaround: click the titlebar of a window before clicking inside it to draw RoIs etc.\n* Due to and incoherence in Matlab's App Designer's behaviour, Mac users using the RoI manager need to command-click to activate buttons in windows that are not topmost. Clicks without the command button raises windows, but events do not register inside them.\n* Due to limitations in Matlab's App Designer, controls that have focus blocks keyboard shortcuts. This means you may not be able to use keyboard shortcuts after making selections in drop-down menus unless you click the editor or tool window first.\n \n"
      },
      "source": "https://raw.githubusercontent.com/GliaLab/Begonia/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8731139441206056,
      "result": {
        "original_header": "Videos and GUI hints",
        "type": "Text_excerpt",
        "value": "We refer to [our YouTube playlist](https://www.youtube.com/playlist?list=PLp3p4GiuHqnL8w1SXF-6g0CsLld0nl3zg) that demonstrates the main workflow of begonia from start to finish. \nSpecific videos:\n* [Workflow overview](https://youtu.be/mzcugrLk4rk)\n* [Installation](https://youtu.be/De_7MfuIO1E)\n* [Import, sessions, motion correction, batch operations](https://youtu.be/QuaAMHsj28g)\n* [Dataman filtering](https://youtu.be/riIy2mJ_gqQ)\n* [Dataman \"data\" menu, Matlab command window interoperability](https://youtu.be/3X8d8_k-j-U)\n* [DataLocation (metadata) overview and API](https://youtu.be/aEwbBqXdIhY)\n* Regions-of-interest (RoIs): \n    * [Marking](https://youtu.be/2501a9V6ap8)\n    * [processing 1](https://youtu.be/0ScSfpPVu1s)\n    * [processing 2](https://youtu.be/FSoLAL-Io6M)\n* RoAs (activity detection): \n    * [Part 1 - SNR optimization](https://youtu.be/tjhT51NWOj0)\n    * [Part 2 - Baseline treshold](https://youtu.be/dVeicKcn_rM)\n    * [Part 3 - Result inspection, processing with RoIs](https://youtu.be/P0BMCA14ErA)\n    * [Part 4 - Plotting, CSV export](https://youtu.be/I9_H8V7H1Wc) \n"
      },
      "source": "https://raw.githubusercontent.com/GliaLab/Begonia/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9547189476506647,
      "result": {
        "original_header": "Metadata",
        "type": "Text_excerpt",
        "value": "We define metadata as data added to recordings of various modalities that are not part of the original data.  \nPractical examples can be: a table of regions-of-interest (ROIs) marked in an image recording, the signals from these ROIs, the name of a laboratory animal used in an EEG recording, or a list states a sleeping animal undergoes during an image recording session. \nTake this example: a mouse runs on a wheel while the pupils are filmed. The experiment yields a file with the wheel's change in degrees over time and the pupil images. When the researchers later analyze these raw data, they might calculate the speed in cm/second and the pupil diameter.  \nIn Begonia, we associate such metadata directly with raw data using the `DataLocation` class, found in the `begonia.data_management` namespace. The recording data types in Begonia derive from this class, meaning it is straightforward to add new data to existing data no matter the type. \nAny path in the filesystem - files and directories - can be opened as a `DataLocation`. Example: if you have a multipage TIFF file at `C:\\imageseq.tiff` this can be opened as a `DataLocation` object in Matlab. Another example might be a directory of .PNG images at `C:\\Data\\session-2-july`. Doing so creates a metadata directory associated with the file, and any data associated with the file can be written to disk, such as the ROIs marked in the recording. No additional setup is needed, such as configuring an ontology description or a database.  \nThe `MultiTable` can collate data from multiple sources that provide time-series type data to complement this system. If your experiment sessions rely on multiple data sources, you might want to review this namespace further down in this document.  \n`DataLocation` also provides a storage engine system, adding flexibility to where the metadata is stored. By default, the system sets every `DataLocation` to use the `OnPathEngine`, meaning the metadata directory is store adjacent to the path in the filesystem. For files, this means in the file's directory, and for directories, it means inside the directory itself. At GliaLab, we often use the alternative `OffPathEngine`, which saves metadata in a separate directory that must be specified when instancing the data location.  \nThere also exists an abstract `DataLocationAdapter` class that adds the API to *any* Matlab object that inherits from it. This means Matlab objects create for other purposes can be opened using tools that expect a data location.  \nThese objects are rarely created on their own, however. In Begonia, we tend to inherit from DataLocation for almost all classes that read data from a location. It means that any object representing an image recording, be it volumetric 3D data, single images, line scans or time-series, all will take part in this metadata system. \nFor testing and technical purposes, a data location can be easily instanced:\n```matlab\nimport begonia.data_management.DataLocation;\n\nanimal = \"micky.mouse\";\ngenotype = categorical(\"imaginary\");\nage_years = 95;\n\ndloc = DataLocation(\"C:\\imageseq.tiff\");\n\n% write metadata:\ndloc.save_var(animal); % save with variable name\ndloc.save_var(\"gt\", genotype); % specify name\ndloc.save_var(\"age\", age_years); \n\n% clear variable, read data back:\nclearvar dloc\ndloc = DataLocation(\"C:\\imageseq.tiff\");\n\nanimal = dloc.load_var(\"animal\");\nage = dloc.load_var(\"age\");\nother = dloc.load_var(\"does-not-exist\", 3.14);  % default value\n\nif dloc.load_var(\"is_mouse\", false)\n    disp(\"this would not show\");\nend\n\n% check if variable exists:\nif dloc.has_var(\"age\")\n    %  ...\nend\n\n% open the location in system's default file browser:\ndloc.open();\n\n% change storage engine (see demonstration video):\nimport begonia.data_management.OffPathEngine;\n\ndloc.dloc_storage_engine = OffPathEngine(\"\\Media\\SSD_disk2\\project_metadata\");\n% use as before - data gets saved to the SSD disk instead of source\n```\n`DataLocation` also has a `.dl_changelog` property that can be read to see when a variable was saved.\n \n"
      },
      "source": "https://raw.githubusercontent.com/GliaLab/Begonia/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.968554149493164,
      "result": {
        "original_header": "DataLocation Editors",
        "type": "Text_excerpt",
        "value": "We have found it is often necessary to perform manual steps implemented in Matlab for many imaging data files in a row. Examples are setting thresholds while seeing an image, marking areas to include or exclude, marking ROIs, processing steps etc.  \nThese steps often vary from project to project and are frequently custom-made for the specific project. When there are many recordings, it is good to know what steps have been performed on what recording. \nBegonia offers a visual spreadsheet-like tool in `xylobium.dledit.Editor` for this purpose that works on any list of DataLocation or DataLocation derived data. \nWe refer to this tool as the *DataLocation Editor*. Note that Begonia's *Data Manager* is implemented in this way. A good place to start for a practical example of a completed DataLocation editor is to have a look at the script `dataman.start()`.  \nIf you have a list of data locations, programmatically opening them with an editor is easy. Notice how you can make a column editable by adding a \"!\" in front of it:\n```matlab\nimport begonia.data_management.DataLocation;\nimport xylobium.dledit.Editor;\n\ndl1 = DataLocation(\"C:\\Data\\Recording 1\");\ndl2 = DataLocation(\"C:\\Data\\Recording 2\");\ndl3 = DataLocation(\"C:\\Data\\Recording 3\");\n\n% create some test data:\ns = struct();\ns.message = \"hello dloc\";\n\ndl1.save_var(\"A\", 3.14);\ndl2.save_var(\"B\", s);\n\n% open an editor, with a editable column A:\nEditor([dl1, dl2, dl3], [], [\"path\", \"!A\", \"B\"]);\n```\nThis code produces the following view:\n \nActions to be performed on the items in the list can be added by instancing `xylobium.dledit.Action` and providing them as a list of actions. Actions have flags that display them as buttons and menu items, optionally with a button group or separator to clarify their relations. \nNote that setting an action's `.can_queue` enables it to be run as a batch operation. These actions are marked with a (b) in the user interface. Similarly, it is possible to set `.accepts_multiple_dlocs` to true to perform the action once per selected item or false for once per item. \n"
      },
      "source": "https://raw.githubusercontent.com/GliaLab/Begonia/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9073027915809039,
      "result": {
        "original_header": "Scantypes",
        "type": "Text_excerpt",
        "value": "Begonia offers a collection of functions to load imaging data and parse associated metadata. The library was developed for Bruker Prairie Microscope but has further been developed to load multipage TIFF stacks and ScanImage metadata. Functions to load imaging data is found in the `begonia.scantype` library.  \nConceptually, we have declared several abstract classes that specific source readers inherit and override. Also, these classes use multiple inheritance to mix in `DataLocation` support.  \nNota that all these classes must have a constructor that takes a filesystem path to the location of the data. \nThe library can in this way be extended to support other file formats and microscopes, yet retain compatibility with all existing tools begonia offers.  \nLoading imaging data:\n```matlab\n% get scans from a directory stucture of your choosing:\nscans = begonia.scantype.find_scans(uigetdir());\n\n% open the scans in the data manager:\ndataman.start(scans) \n```\n \n"
      },
      "source": "https://raw.githubusercontent.com/GliaLab/Begonia/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9919198596600871,
      "result": {
        "original_header": "H5 data format + custom metadata",
        "type": "Text_excerpt",
        "value": "When timer series data gets big, it is often good to have a lazy reader that can rapidly scrub to specific frames in a recording and load only what is needed. Begonia provides such a lazy reader for the H5 data format. This is the default data format of Begonia. \nFor legacy compatibility in our own data we've also implemented a H5Old reader. \n"
      },
      "source": "https://raw.githubusercontent.com/GliaLab/Begonia/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9358702661425065,
      "result": {
        "original_header": "TSeries-derived types",
        "type": "Text_excerpt",
        "value": "The most commonly used data format in our research is the `begonia.scantypes.TSeries` data type. The format support multiple channels per recording. Initially, we supported \"cycles\" as this was a feature of our microscopes at the time development started, but this is being phased out. The cycle parameter will frequently be ignored. \n* `get_mat(ch, cy)` to retrieve a reader for the requested channel\n* `get_avg_img(ch, cy)` reference image: average\n* `get_std_img(ch, cy)` reference image: standard deviation\n* `get_max_img(ch, cy)` reference image: max value \n* `load_var(name, default)` load metadata (from `DataLocation`)\n* `save_var(name, (value))` save metadata (from `DataLocation`)\n* `has_var(name` check if metadata present (from `DataLocation`)\n* `saved_vars()` list metadata (from `DataLocation`) \nNote: reference images will be generated on request, which can be time consuming. Data Manager provides a batch processing action for these operations. \n* `uuid` a unique ID for the data (generated on first request)\n* `name` recording name\n* `channels` number of channels\n* `channel_names` names of the channels\n* `source` the provider, such as Prairie, or ScanImage\n* `start_time` start time\n* `time_correction` correction to start_time \n* `start_time_abs` start time of recording, corrected for time_correcton\n* `duration` duration of recording\n* `frame_count` numebr of frames\n* `zoom` number indicating zoom level\n* `img_dim` dimentions of image [w h]\n* `dt` delta-time, seconds between frames\n* `dx`/`dy` micrometers pr. pixel on the x and y axis \nTo get the full data in x, y, and time dimensions, use `.get_mat(ch, cy)`. The returned result will depend on the underlying data format. In the example case, the data is a processed H5 TSeries, meaning we will get a lazy H5 reader and can be sure we are not overloading our memory. \nThe data type of the frames returned by the reader can also change depending on the reader and the data.  \nIn this example, we will use `roiman.show`. This opens a minimal version of the ROI Manager that takes any Matlab matrix. If the second parameter is true, a control panel will be shown. If false, it displays only the matrix. Note that roiman.show works for all matricies but does not provide details about the data. To properly open TSseries, one would use e.g. roiman.tasks.edit_rois(tseries);\n```matlab\n% to simply show a matrix, we can get that an visualize it:\nmat = tseries.get_mat(1,1);\nroiman.show(mat, true);\n```\n![QA plot for RoIs](docs/screenshots/tseries_2.png)\n \n"
      },
      "source": "https://raw.githubusercontent.com/GliaLab/Begonia/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9854146684153041,
      "result": {
        "original_header": "Other scantypes",
        "type": "Text_excerpt",
        "value": "In this initial release, we are focused on TSeries objects and only provide documentation on these. However, more scan types can be loaded from a path, such as 3D z-stacks, line scans, and single images. All adhere to the `DataLocation` mechanism.\n \n"
      },
      "source": "https://raw.githubusercontent.com/GliaLab/Begonia/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9463266996393038,
      "result": {
        "original_header": "Regions-of-activity",
        "type": "Text_excerpt",
        "value": "Calcium events can be automatically detected with the regions-of-activity algorithm (ROA). The following sections outline how to run the algorithm with the GUI or directly with code. The events are detected with essentially two functions that need configuration, the pre-processing step, and the processing step. The pre-processing step requires configuration of the smoothing parameters to estimate the baseline image, the standard deviation of the noise, and create a large intermediate file for the following processing step. The processing step requires configuration of the detection threshold and parameters for filtering events based on size, duration, and location. When the processing is done, the outputs are stored under the variables \"roa_table\" and \"roa_traces\". The binary 3D matrix of where 1's represents detected events are located under the variables \"roa_mask_ch1\", \"roa_mask_ch2\", etc. depending on the channels the events were detected.  \nThe baseline image is calculated as the most frequent value (aka. the mode) of the pixel time series traces. \nIt is possible to use a custom-defined baseline image instead, but this must be done programmatically.  \n"
      },
      "source": "https://raw.githubusercontent.com/GliaLab/Begonia/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9541444535099496,
      "result": {
        "original_header": "Process multiple recordings",
        "type": "Text_excerpt",
        "value": "To save time, the parameters of a single recording can be used to process other recordings. This is done with the following buttons: \n* Toggle template - Sets an indicator so the configuration of this recording will be used when processing multiple recordings. Both pre-processing and processing parameters must be set, see previous section.\n* Process by template - Processes the selected recordings with the parameters of the template. The template recording must be included in the selected recordings. \n"
      },
      "source": "https://raw.githubusercontent.com/GliaLab/Begonia/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9568734438902222,
      "result": {
        "original_header": "Process a single recording with code",
        "type": "Text_excerpt",
        "value": "The following code shows how to run the ROA algorithm for a single recording with 2 channels. \nIt also shows how to use a custom baseline image instead of the default calculation using the most frequent value \n(aka. mode) of the time series of each pixel. \n```matlab\n%% Load tseries\n% The following code assumes a recording (TSeries) with 2 channels. \n\n% Enable terminal printout from begonia.\nbegonia.logging.set_level(1);\n\nts_path = 'File/Path/To/Your/recording.tif';\nts = begonia.scantype.find_scans(ts_path);\n\n%% Pre processing\n% Here we create the parameters for the pre-processing programatically. It is\n% also possible to create roa_pre_param with the GUI. The GUI cannot be\n% used if we want to use a custom baseline image. The GUI can be opened\n% with the function:\n%       begonia.processing.roa.gui_config_manual(ts)\npre_param_ch1 = struct;\npre_param_ch1.roa_enabled = true;\npre_param_ch1.roa_t_smooth = 1;\npre_param_ch1.roa_xy_smooth = 2;\n\npre_param_ch2 = struct;\npre_param_ch2.roa_enabled = true;\npre_param_ch2.roa_t_smooth = 1;\npre_param_ch2.roa_xy_smooth = 2;\n\n% (Optional) Here is how to add a baseline value for each pixel. If the\n% field is empty (as done here for channel 2) or if roa_alternative_baseline\n% is missing from the struct the baseline is calculated by the default \n% method using mode. Here, for channel 1, the baseline is calculated as the\n% 5th percentile of the first 100 frames.\nmat = ts.get_mat(1);\npre_param_ch1.roa_alternative_baseline = prctile(mat(:,:,1:100),5,3);\npre_param_ch2.roa_alternative_baseline = [];\n\n% Which parameters belongs to each channel is decided by order of the\n% structs. Here pre_param_ch1 belongs to channel 1 because it is first in\n% the list.\nroa_pre_param = [pre_param_ch1,pre_param_ch2];\n\n% The pre processing loads the parameters from the key \"roa_pre_param\", so\n% the parameters must be saved under this name. \nts.save_var(roa_pre_param);\nbegonia.processing.roa.pre_process(ts);\n\n%% Detect ROA\n% Here we create the parameters for the processing programatically. It is\n% also possible to create roa_param with the GUI. The GUI to create and adjust\n% parameters can be opened with the function:\n%       begonia.processing.roa.gui_adjust_threshold(ts)\nroa_param = roa_pre_param;\n\nroa_param(1).roa_threshold = 4;\nroa_param(1).roa_min_size = 4; \nroa_param(1).roa_min_duration = 0;\nroa_param(1).roa_ignore_mask = false(ts.img_dim);\nroa_param(1).roa_ignore_border = 0;\n\nroa_param(2).roa_threshold = 4;\nroa_param(2).roa_min_size = 4;\nroa_param(2).roa_min_duration = 0;\nroa_param(2).roa_ignore_mask = false(ts.img_dim);\nroa_param(2).roa_ignore_border = 0;\n\n% The processing loads the parameters from the key \"roa_param\", so\n% the parameters must be saved under this name. \nts.save_var(roa_param);\n\n% Run the processing.\nbegonia.processing.roa.filter_roa(ts);\n\n% The results of the ROA detection are stored unde the keywords \"roa_table\"\n% and \"roa_traces\". The binary 3D matrix of outlined events are stored\n% under \"roa_mask_ch1\" and \"roa_mask_ch2\".\nroa_table = ts.load_var('roa_table');\nroa_traces = ts.load_var('roa_traces');\nroa_mask_ch1 = ts.load_var('roa_mask_ch1');\n```\n \n"
      },
      "source": "https://raw.githubusercontent.com/GliaLab/Begonia/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9431279322891003,
      "result": {
        "original_header": "Processing RoIs, RoAs and RPAs",
        "type": "Text_excerpt",
        "value": "**Regions-of-interest (RoIs)** can be processed using the `begonia.processing.roi` namespace. When a TSeries is marked in RoIMan, it will have a \"roi_table\" variable in its metadata (see metadata strategy).  \nThese three tables can be joined as needed to analyse the signals for inidividual rois. The following example will load a multipage TIFF tseries and get the data. It requires the RoIs being marked in RoIMan before running (note that ts can be a vector with multiple tseries in this and the following):\n```matlab\n% load the timeserseries and turn on verbose logging:\nts = begonia.scantype.find_scans(\"PATH-TO-TSERIES\");\nbegonia.logging.set_level(2);  % \ud83d\ude49\n\n% process the RoIs (only needed after RoIs change):\nbegonia.processing.roi.extract_signals(ts);\n\n% load the table RoIMan oututs of the RoIs:\nroi_table = ts.load_var(\"roi_table\");\n\n% load the RoIs:\nsignal = ts.load_var(\"roi_signals_raw\");\nsignal_dff = ts.load_var(\"roi_signals_dff\");\nsignal_doughnut = ts.load_var(\"roi_signals_doughnut\");\n\nrois = join(roi_table, signal);\nrois = join(rois, signal_dff);\nrois = join(rois, signal_doughnut);\n````\nAlternatively you can use this shorter function which performs the same steps for you + easily view the results for quality assurance (QA):\n```matlab\n% loads the data from the tseries (can massive):\nrois = begonia.processing.roi.load_processed_signals(ts);\n\n% view QA plots for rois:\nbegonia.processing.roi.plot_qa_signals(ts);\nbegonia.processing.roi.plot_qa_rois(ts);\n```\nThis will yield the following plots:\n \n\n**RoI pixel activity % (RPA%)** is a measure that combines RoIs and RoAs. For simplicity, we try to refer to this as \"Activity\" in the user interface.  \nPure signals from RoIs suffer from lack of sensitivity when the RoIs are large, and will ignore activity outside the marked areas that may be of interest. RoAs do not discriminate between areas in the field of view, while RoIs are used to demarcate e.g. anatomical features in which indicator activity might be intersting to review separtely from other areas.  \nRPA tries to alleviate this by counting events of RoIs and their active fractions. It will also produce statistics for entire groups of RoIs. Because of its use in astrocyte analysis, begonia refers to these RoI grous as compartments. The \"FOV\" compartmen refers to the entire field of view. \nActive fraction values are given as % of the RoI that has activity. The baseline is 0, which means event detection is easier. An active pixel in a RoI can be part of a larger activity that the RoI only partially covers. Active fraction is also subject to the RoA algorithm thresholding, temporal and spatial smoothing, and finally RoA duration and sensitivity filtering.\n \n"
      },
      "source": "https://raw.githubusercontent.com/GliaLab/Begonia/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9901540545392749,
      "result": {
        "original_header": "MultiTable",
        "type": "Text_excerpt",
        "value": "Experiments often record complex data alongside imaging data. E.g. awake animal experiments tends to record the movement of the animal alongside neuromaging to be anatomically marked up later with RoIs and other measurements. Electrophysiological data such as EEGs is another example, or electrode readouts for slice experiments.  \nWhen analysing, the experimenter usually want review this data together, and have timeseries data aligned in time so correlations can be found visually or programmatically. Often timeseries data is sampled at different rates and recording equipment can have different start times for their recordings, meaning corrections must be made.\nIn the following material, \u201centity\u201d refers to what binds the data together, e.g. a trial or session. \nA single recording session sometimes has multiple segments that is to be analysed separately. Examples include a period of stimulus introduced at the same time in all sessions (a \u201cglobal segment\u201d), or the animal entering specific sleep or movement state (an \u201centity segment\u201d, and it\u2019s dependent on that particular entity \u2013 usually a trial).  \nMultiTable offers a way to:\n* Collect data from multiple sources around entities, e.g. trials\n* Easily add new type of data sources that labs develop / purchase to the mix\n* Split the mixed data into segments derived for all or individual entities\n* Extract traces around transition points for segments\n* Extract specific time ranges for all traces\n \n"
      },
      "source": "https://raw.githubusercontent.com/GliaLab/Begonia/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9769206980978978,
      "result": {
        "original_header": "Assembling mixed data",
        "type": "Text_excerpt",
        "value": "MultiTable is a table of data sources that gets queried for data and the data time information when the user wants it. You can add custom sources that fit your projects, but begonia offers a series of ready made sources that extract data from our DataLocation metadata system and outputs of the calsium analysis. \nWe provide sourcs for DataLocation variables stored a pure vecctors (need a deltatime to be specified), timeseries (the matlab object) and matlab timeseries collections. The two latter has no need to specify deltatime as it is included in the objects. \nIn this exmaple we'll get some begonia TSeries objects and create entity names from these, then add sources for drift correction, animal movement speed, whiksing state, active fraction of RoI grops and individual roi signals in two ways. \n```matlab\nimport begonia.data_management.multitable.MultiTable;\n\nimport begonia.data_management.multitable.add_dloc_vector;\nimport begonia.data_management.multitable.add_dloc_timeseries;\nimport begonia.data_management.multitable.add_dloc_timeseries_collection;\nimport begonia.data_management.multitable.add_ca_compartment;\nimport begonia.data_management.multitable.add_ca_roi;\n\n% get some scans from a list of tseries:\ntseries = get_some_data_somehow(); % vector of TSeries objects\n\n% create multitable, then some entity names to cluster data around, e.g. \"Session 1\", \"Day 32 - session 2\", \"Trial 42 - morning\" or whatever sinks your submarine:\nmtab = MultiTable();\nentities = replace(string({tseries.name}), \"TSeries\", \"Experiment\");\n\n% add drift correction traces from datalocations as category \"drift\":\nadd_dloc_vector(mtab, entities, \"drift\", tseries, \"drift_correction_trace\", [tseries.dt]);\nadd_dloc_timeseries(mtab, entities, \"speed\", tseries, \"delta_angle\");\nadd_dloc_timeseries_collection(mtab, entities, \"whisk\", tseries, \"camera_regions\", \"whisker\");\nadd_ca_compartment(mtab, entities, \"ca-active-fraction\", tseries, \"active-fraction\");\nadd_ca_roi(mtab, entities, \"ca-roi-dff\", tseries, \"roi_signals_dff\");\nadd_ca_roi(mtab, entities, \"ca-roi-rpa\", tseries, \"roi_signal_rpa\");\n\n% get all the drift traces:\ndisp(\"By category\"); \ntraces = mtab.by_cat([\"drift\", \"speed\", \"whisk\", \"ca-active-fraction\", \"ca-new-events\", \"ca-roi-dff\", \"ca-roi-rpa\"]);\n``` \nAlso note that sources can add custom columns to a MultiTable. In this example `add_ca_roi` added a column for the roi type the traces is read from, and `add_ca_compartment` in the same way added a column for the compartment. This allows easier filtering of the outout as it goes into analysis. \n"
      },
      "source": "https://raw.githubusercontent.com/GliaLab/Begonia/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8960952768872992,
      "result": {
        "original_header": "Time alignment",
        "type": "Text_excerpt",
        "value": "Traces can be aligned in time based on the absolute start time, so that frames in the traces correlate as much as possible. Performing time alignment means all traces returned have the same start time.  \n"
      },
      "source": "https://raw.githubusercontent.com/GliaLab/Begonia/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9246476098941281,
      "result": {
        "original_header": "Global segmentation",
        "type": "Text_excerpt",
        "value": "The TSeries from the periprevious example are 5 minute sessions with awake animals where a airpuff is given in at half time. It makes sens to analyse the pre-, prei- and postpuff segments separtely. They are the same for all experiments, and is therefor a *global segmentation*. \nWe'll build this categorical array, the default begonia way to provide segments. Categorical arrays are good because the can be easily visualzied, re-sampled and re-segmented easily. They can also be made in a different framerate than the other data analysed. \n"
      },
      "source": "https://raw.githubusercontent.com/GliaLab/Begonia/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9967422902459231,
      "result": {
        "original_header": "Entity segmentation",
        "type": "Text_excerpt",
        "value": "Create a new classifier that is unique for each entity. We'll do this by loading the animal speed trace (delta angle/sec on a running wheel), and making a super simple classification. This is individual for each entity, and thus a *entity segmentation*. \n"
      },
      "source": "https://raw.githubusercontent.com/GliaLab/Begonia/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.888946489509149,
      "result": {
        "original_header": "Merge segments from category",
        "type": "Text_excerpt",
        "value": "Output will be *one row pr. entity* with all segments merged into one trace. Note that only duration property is valid after this processing, and that start and end columns will be set to missing.\n```matlab\nimport begonia.data_management.multitable.segment_entity;\n\n% get some segments:\nsegs = segment_entity(traces, \"movement-state\", [\"state.run\"]);\n\n% if segments contains multiple entries pr. timepoint, such as multiple calcium compartments, they need to be filtered:\ncomp_segs = segs(segs.ca_compartment == \"Gp\", :);\nmerged = merge_cat_segments(comp_segs);\n```\n \n"
      },
      "source": "https://raw.githubusercontent.com/GliaLab/Begonia/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9017428592055159,
      "result": {
        "original_header": "Timerange",
        "type": "Text_excerpt",
        "value": "In this example we'll use timerange to extract a specific time range from all traces. Int his case we'll get the range that covers the airpuff, with 10 seconds baseline before. \n```matlab\nimport begonia.data_management.multitable.timerange;\n\ntimepoint = seconds(150);\n\ntraces = mtab.by_cat(\"ca-active-fraction\");\nrangetab = timerange(traces, timepoint - seconds(10), timepoint + seconds(40));\n\nfigure(\"Position\", [0 0 600 200]); \nfor i = 1:height(rangetab)\n    plot(rangetab.trace{i});\n    hold on;\nend\n```\n \n"
      },
      "source": "https://raw.githubusercontent.com/GliaLab/Begonia/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8943127113935373,
      "result": {
        "original_header": "Transitions",
        "type": "Text_excerpt",
        "value": "Any categorical array can be used to get transitions. Example: a mouse changed from being still to running, or is waking up from a specific sleep state. \nIn this example we continue with the pr. entity classification of moevemnt made in the entity segmentation example, and get traces at transition points. \n```matlab\nimport begonia.data_management.multitable.transitions_entity;\n\n% how much trace to grab on either side of transition:\nleft_s = 4;\nright_s = 10;\n\ntraces = mtab.by_cat([\"speed\", \"movement-state\"]);\ntranstab = transitions_entity(traces, \"movement-state\" ...\n    , \"state.still\", \"state.run\", left_s, right_s);\n```\n \n"
      },
      "source": "https://raw.githubusercontent.com/GliaLab/Begonia/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.814736704479422,
      "result": {
        "original_header": "Equisizing left",
        "type": "Text_excerpt",
        "value": "To make traces of unequal frame length have an equal number of frames, use equisize left. The result will be as long as the shortest input trace.\n```matlab\nimport begonia.data_management.multitable.equisize_left;\n\n% all traces will now be same length and 30 fps:\neqtab = equisize_left(traces, \"trim\", 1/30)\n```\n \n"
      },
      "source": "https://raw.githubusercontent.com/GliaLab/Begonia/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8522150944025846,
      "result": {
        "original_header": "Generic table plot",
        "type": "Text_excerpt",
        "value": "A generic plot of all data in the multitable can be made the following way:\n```matlab\nimport begonia.data_management.multitable.plot_entity_data;\n\n% the figs variable will contain generic plots for the data in the multitable in the time range 0-300 seconds:\nentities = [\"A\", \"B\"]\nfigs = plot_entity_data(mtab, entities, [0 300])\n```\n \n"
      },
      "source": "https://raw.githubusercontent.com/GliaLab/Begonia/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.904358364875814,
      "result": {
        "original_header": "Export to CSV",
        "type": "Text_excerpt",
        "value": "Data from a multitable can be exported to .csv format for digestion in systems that does not support Matlab file formats. Because traces can be very large in sum, they are split up into chunks.  \nTraces can be segmented or straight from the multitable.\n```matlab\nimport begonia.data_management.multitable.export_csv\n\n% quick export to matlab working directory:\nexport_csv(traces)\n\n% export to specific directory, 1000 traces pr. chunk\nexport_csv(traces, \"D:\\Data\", 1000, \"My amazing data\");\n\n```\n \n"
      },
      "source": "https://raw.githubusercontent.com/GliaLab/Begonia/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "documentation": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/GliaLab/Begonia/tree/master/docs"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Technical documentation",
        "type": "Text_excerpt",
        "value": "System is a hybrid between data-driven and object oriented architecture. [ELABOREATE]\n"
      },
      "source": "https://raw.githubusercontent.com/GliaLab/Begonia/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Data documentation",
        "parent_header": [
          "Technical documentation"
        ],
        "type": "Text_excerpt",
        "value": "There is one Manager for each loaded stack, and each view of the stack is called a View. Data is present on either manager or view, but never both. When data is changed, modules and tools will respond to changes. \n"
      },
      "source": "https://raw.githubusercontent.com/GliaLab/Begonia/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Core",
        "parent_header": [
          "Technical documentation",
          "Data documentation"
        ],
        "type": "Text_excerpt",
        "value": "| Key | Owner | Format | Meaning     | \n| -------------| -- | ---------- |  ---------- | \n| **datatype** | m | String | The type of data being edited. currently just \"timeseries\" |\n| **message** | m | String | Message to the user about events,such as playback looping |\n| **guide_text** | m | String | Message currently rendered in help |\n"
      },
      "source": "https://raw.githubusercontent.com/GliaLab/Begonia/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Input",
        "parent_header": [
          "Technical documentation",
          "Data documentation"
        ],
        "type": "Text_excerpt",
        "value": "| Key | Owner | Format | Meaning     | \n| -------------| -- | ---------- |  ---------- | \n| **mouse_pos** | m | Struct | Contains properties win_x, win_y, viewport_x, viewport_y that corresponds to current mouse position in the viewport and the window. Note that these values can be NaN initially. |\n"
      },
      "source": "https://raw.githubusercontent.com/GliaLab/Begonia/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Mode",
        "parent_header": [
          "Technical documentation",
          "Data documentation"
        ],
        "type": "Text_excerpt",
        "value": "| Key | Owner | Format | Meaning     | \n| -------------| -- | ---------- |  ---------- | \n| **mode** | m | roiman.Mode | Current mode controller |\n"
      },
      "source": "https://raw.githubusercontent.com/GliaLab/Begonia/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Units and metrics",
        "parent_header": [
          "Technical documentation",
          "Data documentation"
        ],
        "type": "Text_excerpt",
        "value": "| Key | Owner | Format | Meaning     | \n| -------------| -- | ---------- |  ---------- | \n| **dimensions** | m | [num num]] | Width and height in units |\n| **zoom** | m | num | Current zoom level. E.g. 2x = 2x zoom. |\n| **viewport** | v | [num num num num] | [x, y, w, h] coordinates of views area. Used to create zoom on particular area. |  \n| **unit** | m | String  | Name of stack's units (default: pixels)|\n| **dunit** | m | String  | Name of units displayed (default: \u03bcm) |\n| **pix_to_dunit** | m | Function  | Function to convert stack units to displayed units (default: @(r) r * tseries.dx) |\n| **dunit_to_pix** | m | Function  | Function to convert stack units to displayed units (default: @(r) r / tseries.dx) |\n"
      },
      "source": "https://raw.githubusercontent.com/GliaLab/Begonia/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Stack, playback and time",
        "parent_header": [
          "Technical documentation",
          "Data documentation"
        ],
        "type": "Text_excerpt",
        "value": "Frame data is used by Main tool, the channel module and many others.\n\n| Key | Owner | Format | Meaning     | \n| -------------| -- | ---------- |  ---------- | \n| **tseries** | m | begonia.scantype.TSeries | Current timeseries |\n| **channels** | m | int[] | Channel numbers in current tseries |\n| **channel_names** | m | string[] | Current timeseries |\n| **matrix_ch_C** | m | H5 array (y,x,t,z) | Lazy reading H5 array for channel C (integer) |\n| **ref_img_TYPE_ch_C** | m | matrix(x,y) | Reference image of TYPE (avg, std, max) for channel C (integer) |\n| **z_plane** | m | num | Current z-plane (for 3D data) |\n| **current_frame** | m | Int | Current frame | \n| **current_time** | m | Double | Current time in seconds | \n| **frames** | m | Int[] | List of frames in current stack | \n| **frame_time** | m | Double[] | Time in seconds for each frame in 'frames' data entry| \n| **autoplay_start_time** | m | datetime| Point in time when autoplay was at frame 1 (started, or looped around from end) | \n| **autoplay_frame_time** | m | Double[] | Time in seconds for each frame at current autoplay speed. When the view updates during autoplay, the frame to display is looked up in this list from the time since autoplay was at first frame | \n"
      },
      "source": "https://raw.githubusercontent.com/GliaLab/Begonia/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Channel / channel module",
        "parent_header": [
          "Technical documentation",
          "Data documentation"
        ],
        "type": "Text_excerpt",
        "value": "| Key | Owner | Format | Meaning     | \n| -------------| -- | ---------- |  ---------- |\n| **channel** | v | int | Channel in view |  \n| **channel_mode** | v | String | Rendering mode of current view. Possible values are: Raw, Mean, Std., Max, Mean (full series), Std. (full series), Max (full series) |\n| **channel_colormap** | v | String | Name of colormap to render channel with. Must be a valid matlab colormap symbol. |\n| **channel_mode**  |v | String | Rendering mode of current view. Possible values are: Raw, Mean, Std., Max, Mean (full series), Std. (full series), Max (full series) |\n| **channel_low** | v | Int | Start of rendering range. Values below will be omitted. |\n| **channel_high** |  v | Int | End of rendering range. Values above will be omitted.  |\n"
      },
      "source": "https://raw.githubusercontent.com/GliaLab/Begonia/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "RoI rendering",
        "parent_header": [
          "Technical documentation",
          "Data documentation"
        ],
        "type": "Text_excerpt",
        "value": "| Key | Owner | Format | Meaning     | \n| -------------| -- | ---------- |  ---------- | \n| **roi_table** | m | Table | Table holding all the current rois of the tseries |\n| **roi_show_relations** | v | bool | Display arrows between related rois |\n| **roi_show_labels** | v | bool | Display labels on rois |\n| **roi_show_rois** | v | bool | Toggle RoI display |\n"
      },
      "source": "https://raw.githubusercontent.com/GliaLab/Begonia/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "RoI editing (shared)",
        "parent_header": [
          "Technical documentation",
          "Data documentation"
        ],
        "type": "Text_excerpt",
        "value": "roiedit_roi_types_available m\n\nroiedit_roi_type m\n\n| **roiedit_selected** | m | String[] | UUID(s) of roi currentlyly selected from the roi_table |\n\nroitool_* m : RoI tool's internal state and various data. Manager-locked.\n\n"
      },
      "source": "https://raw.githubusercontent.com/GliaLab/Begonia/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "RoI painting",
        "parent_header": [
          "Technical documentation",
          "Data documentation"
        ],
        "type": "Text_excerpt",
        "value": "\nroipaint_overlay_on \n\nroipaint_mask\n\nroipaint_brush_mask\n\nroipaint_brush_circle_h \n\nroipaint_brush_size_px\n\nroipaint_operation m (add/subtract)\n"
      },
      "source": "https://raw.githubusercontent.com/GliaLab/Begonia/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/GliaLab/Begonia/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 1
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/GliaLab/Begonia/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "GliaLab/Begonia"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "Begonia"
      },
      "source": "https://raw.githubusercontent.com/GliaLab/Begonia/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "images": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/GliaLab/Begonia/master/docs/cheat_sheet.png"
      },
      "source": "https://raw.githubusercontent.com/GliaLab/Begonia/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/GliaLab/Begonia/master/docs/screenshots/dledit_1.png"
      },
      "source": "https://raw.githubusercontent.com/GliaLab/Begonia/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/GliaLab/Begonia/master/docs/screenshots/dledit_2.png"
      },
      "source": "https://raw.githubusercontent.com/GliaLab/Begonia/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/GliaLab/Begonia/master/docs/screenshots/tseries_1.png"
      },
      "source": "https://raw.githubusercontent.com/GliaLab/Begonia/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/GliaLab/Begonia/master/docs/screenshots/tseries_2.png"
      },
      "source": "https://raw.githubusercontent.com/GliaLab/Begonia/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/GliaLab/Begonia/master/docs/screenshots/GUI&#32;with&#32;ROA&#32;outlined.png"
      },
      "source": "https://raw.githubusercontent.com/GliaLab/Begonia/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/GliaLab/Begonia/master/docs/screenshots/qa_plot_rois.png"
      },
      "source": "https://raw.githubusercontent.com/GliaLab/Begonia/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/GliaLab/Begonia/master/docs/screenshots/qa_plot_roi_signals.png"
      },
      "source": "https://raw.githubusercontent.com/GliaLab/Begonia/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/GliaLab/Begonia/master/docs/screenshots/mtab_output.png"
      },
      "source": "https://raw.githubusercontent.com/GliaLab/Begonia/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/GliaLab/Begonia/master/docs/screenshots/timealign.png"
      },
      "source": "https://raw.githubusercontent.com/GliaLab/Begonia/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/GliaLab/Begonia/master/docs/screenshots/global_segmentation.png"
      },
      "source": "https://raw.githubusercontent.com/GliaLab/Begonia/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/GliaLab/Begonia/master/docs/screenshots/global_segmentation_result.png"
      },
      "source": "https://raw.githubusercontent.com/GliaLab/Begonia/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/GliaLab/Begonia/master/docs/screenshots/entity_segmentation.png"
      },
      "source": "https://raw.githubusercontent.com/GliaLab/Begonia/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/GliaLab/Begonia/master/docs/screenshots/timerange.png"
      },
      "source": "https://raw.githubusercontent.com/GliaLab/Begonia/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "installation": [
    {
      "confidence": 0.9999999941671831,
      "result": {
        "original_header": "Known issues \u26a0\ufe0f",
        "type": "Text_excerpt",
        "value": "* A bug prevents roimanager getting keyboard event if timeseries view is raised by clicking inside the window. Workaround: click the titlebar of a window before clicking inside it to draw RoIs etc.\n* Due to and incoherence in Matlab's App Designer's behaviour, Mac users using the RoI manager need to command-click to activate buttons in windows that are not topmost. Clicks without the command button raises windows, but events do not register inside them.\n* Due to limitations in Matlab's App Designer, controls that have focus blocks keyboard shortcuts. This means you may not be able to use keyboard shortcuts after making selections in drop-down menus unless you click the editor or tool window first.\n \n"
      },
      "source": "https://raw.githubusercontent.com/GliaLab/Begonia/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.875213112374078,
      "result": {
        "original_header": "Videos and GUI hints",
        "type": "Text_excerpt",
        "value": "\nCheatsheet to navigate the RoI manager: \n"
      },
      "source": "https://raw.githubusercontent.com/GliaLab/Begonia/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9590862166291962,
      "result": {
        "original_header": "DataLocation Editors",
        "type": "Text_excerpt",
        "value": "Continuing with the example, we now add some buttons to the mix:\n```matlab\n% instance with actions:\nimport xylobium.dledit.Action;\n\nact_A = Action(\"Show A\", @(d, m, e) disp(d.load_var('A')));\nact_A.has_button = true;\nact_A.button_group = \"Actions\";\nact_A.menu_position = \"Tools\";\n\nact_B = Action(\"Show B's message\", @(d, m, e) disp(d.load_var('B')));\nact_B.has_button = true;\nact_B.button_group = \"Actions\";\nact_B.menu_position = \"Tools\";\n\nxylobium.dledit.Editor([dl1, dl2, dl3], [act_A, act_B], [\"path\", \"!A\", \"B\"]);\n``` \n![QA plot for RoIs](docs/screenshots/dledit_2.png)\n \n"
      },
      "source": "https://raw.githubusercontent.com/GliaLab/Begonia/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9116722884939622,
      "result": {
        "original_header": "TSeries-derived types",
        "type": "Text_excerpt",
        "value": "* `get_mat(ch, cy)` to retrieve a reader for the requested channel\n* `get_avg_img(ch, cy)` reference image: average\n* `get_std_img(ch, cy)` reference image: standard deviation\n* `get_max_img(ch, cy)` reference image: max value \n* `load_var(name, default)` load metadata (from `DataLocation`)\n* `save_var(name, (value))` save metadata (from `DataLocation`)\n* `has_var(name` check if metadata present (from `DataLocation`)\n* `saved_vars()` list metadata (from `DataLocation`) \n"
      },
      "source": "https://raw.githubusercontent.com/GliaLab/Begonia/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/GliaLab/Begonia/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ""
      },
      "technique": "GitHub_API"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "Begonia"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "Organization",
        "value": "GliaLab"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "MATLAB",
        "size": 615882,
        "type": "Programming_language",
        "value": "MATLAB"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Objective-C",
        "size": 3524,
        "type": "Programming_language",
        "value": "Objective-C"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "M",
        "size": 3425,
        "type": "Programming_language",
        "value": "M"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Limbo",
        "size": 420,
        "type": "Programming_language",
        "value": "Limbo"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/GliaLab/Begonia/master/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "somef_missing_categories": [
    "citation",
    "acknowledgement",
    "run",
    "download",
    "requirements",
    "contact",
    "contributors",
    "license",
    "faq",
    "support",
    "identifier",
    "has_build_file",
    "executable_example"
  ],
  "somef_provenance": {
    "date": "2024-10-06 06:15:11",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 5
      },
      "technique": "GitHub_API"
    }
  ],
  "type": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "non-software"
      },
      "technique": "software_type_heuristics"
    }
  ],
  "usage": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Quick start (for programmers)",
        "type": "Text_excerpt",
        "value": "The repository must be initialized with submodules to function correctly. The current submodules that Begonia depends on are the motion correction software, \nNoRMCorre, and a modified version of the TIFF reading library, TIFFStack. The submodules are located under `Begonia/external`. \n\nSubmodules can be initialized with:\n```\n# git submodule update --init --recursive\n```\n\n"
      },
      "source": "https://raw.githubusercontent.com/GliaLab/Begonia/master/README.md",
      "technique": "header_analysis"
    }
  ]
}