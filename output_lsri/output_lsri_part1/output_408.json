{
  "application_domain": [
    {
      "confidence": 51.81,
      "result": {
        "type": "String",
        "value": "Natural Language Processing"
      },
      "technique": "supervised_classification"
    }
  ],
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/SFGLab/bertrand"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2023-01-04T10:32:23Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2024-06-18T11:49:10Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Introduction",
        "parent_header": [
          "BERTrand - peptide:TCR binding prediction using BERT augmented with random TCR pairing"
        ],
        "type": "Text_excerpt",
        "value": "Our approach combines the power of NLP with biologically-relevant data-augmentation to produce a model that can predict peptide:TCR binding\n\nThe training process consists of 3 steps:\n1. Pre-training - generating a simulated peptide:TCR repertoire and training BERT MLM\n2. Negative decoys - randomly pairing peptides from the training set with reference TCRs\n3. BERT supervised training for peptide:TCR binding prediction\n\nThe detailed flow of the analysis can be seen below.\n\n![flow](flow.png)\n"
      },
      "source": "https://raw.githubusercontent.com/SFGLab/bertrand/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 0.9449262570075654,
      "result": {
        "original_header": "Data",
        "type": "Text_excerpt",
        "value": "The data in this repository comes from public sources - peptide:TCR binding databases and publications and is already curated, \nfiltered and combined into a single dataset. \nFor more details on tha data curation process, see `bertrand/notabooks/data-curation`. \nA few useful files:\n- `data/phla_tcr_all.csv.gz` contains the filtered and combined dataset of peptide:TCR binders\n- `data/phla_tcr_unique.csv.gz` contains the dataset of unique peptide:TCR binders (grouped by peptide, CDR3beta and MHC type)\n- `results/negative_decoys/datasets` contains the unique binders dataset augmented with random reference TCRs, ready for model training and evaluation. The reference pairing is repeated for 3 different random seeds.  \nOur evaluation approach is repeated cross-validation. The dataset is split into cancer and viral subsets. The cancer subset is used as an independent test set and the viral part \nis further split into train, validation (used for early stopping), and test sets. \nIf you want to recreate the splits yourself, use the snippet below:\n```python\nimport pandas as pd\nfrom bertrand.training.cv import split_train_val_test\n\ndataset = pd.read_csv('results/negative_decoys/datasets/dataset_42.csv.gz')\ncancer = dataset[dataset.is_cancer]\ntrain, val, test = split_train_val_test(dataset, seed=42) \n```\n \n"
      },
      "source": "https://raw.githubusercontent.com/SFGLab/bertrand/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8947879698514627,
      "result": {
        "original_header": "Analysis",
        "type": "Text_excerpt",
        "value": "`analysis.sh` simply calls 3 separate scripts for each step of the training process (see above). \nNote that some parts of the analysis are CPU and RAM intensive, while other need a good GPU to complete in a reasonable time, so you might want to run them on different machines. \n\nThe analysis pipeline will create a directory structure in your results folder. The important files are:\n```\n<results directory>/\n\u251c\u2500 pretraining/                            \n\u2502  \u251c\u2500 model/                    MLM model best checkpoint\n\u2502  \u2502  \u251c\u2500 pytorch_model.bin\n\u2502  \u2502  \u251c\u2500 config.json\n\u251c\u2500 negative_decoys/             Peptide:TCR datasets ready for training\n\u2502  \u2502  \u251c\u2500 dataset_42.csv.gz\n\u2502  \u2502  \u251c\u2500 dataset_43.csv.gz\n\u2502  \u2502  \u251c\u2500 dataset_44.csv.gz\n\u251c\u2500 training/\n\u2502  \u251c\u2500 dataset_42/\n\u2502  \u2502  \u251c\u2500 cv_seed=42/            Model weights and predictions for every cross-validation split \n\u2502  \u2502  \u2502  \u251c\u2500 best-checkpoint/\n\u2502  \u2502  \u2502  \u251c\u2500 predictions.pkl\n\u2502  \u2502  \u2502  \u251c\u2500 metrics.png\n\u2502  \u2502  \u251c\u2500 cv_seed=43/\n\u2502  \u2502  \u251c\u2500 ...\n\u2502  \u251c\u2500 dataset_43/\n\u2502  \u2502  \u251c\u2500 cv_seed=42/\n\u2502  \u2502  \u251c\u2500 ...\n\u2502  \u251c\u2500 results.csv               Results of cross-validation in a single file\n\n```\nMost of the scripts cache intermediate results (distance matrices, model checkpoints etc), these are omitted for brevity. \n \n"
      },
      "source": "https://raw.githubusercontent.com/SFGLab/bertrand/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8909297541049928,
      "result": {
        "original_header": "Negative decoys",
        "type": "Text_excerpt",
        "value": "Negative decoys generation is random, so it's best to generate more than one dataset. \n`negative_decoys_generation.py` will do it for you for a number of `--n-splits` different random seeds.\n`negative_decoys/datasets` will contain datasets ready for supervised training of BERT. \n`negative_decoys/cache` will contain intermediate results - distance matrices, clustering linkage, outliers filtering results etc.  \n"
      },
      "source": "https://raw.githubusercontent.com/SFGLab/bertrand/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.948277902909011,
      "result": {
        "original_header": "Inference",
        "type": "Text_excerpt",
        "value": "There are several options for inference. If you want to generate predictions for a dataset of peptide:TCR observations, you can use `bertrand/model/inference.py`\n```\npython -m bertrand.model.inference -i=<input> -m=<model> -o=<output>\n```\nwhere `<input>` is a .csv or .csv.gz file with `peptide_seq` and `CDR3b` columns and `<model>` is a BERTrand checkpoint. The prediction will be written to `<output>` as a csv file.   \nThe same thing can be done programmatically by calling `get_dataset_predictions`. \nThis function uses pytorch-lighting interface to generate the predictions. If you want a prediction for a single peptide:TCR pair, \nyou can call `get_single_prediction`, which doesn't involve pytorch-lightning.  \nThe above functions convert logits to probabilities and don't return anything else. In case you want to get logits or attention outputs, you will have to do the inference yourself. \nThis is pretty trivial, below is a minimal example to get logits, attention ouputs and hidden states. \n"
      },
      "source": "https://raw.githubusercontent.com/SFGLab/bertrand/main/README.md",
      "technique": "supervised_classification"
    }
  ],
  "download": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Downloads",
        "parent_header": [
          "BERTrand - peptide:TCR binding prediction using BERT augmented with random TCR pairing",
          "Analysis"
        ],
        "type": "Text_excerpt",
        "value": "The pre-computed results can be downloaded [here.](https://drive.google.com/file/d/1U4lA9TsW0IQJXSk-7e478AAUU_59jNdV/view?usp=sharing)\n<br>\nMoreover, you can download a single model checkpoint if you just want to do inference [here.](https://drive.google.com/file/d/1FywbDbzhhYbwf99MdZrpYQEbXmwX9Zxm/view?usp=sharing)\n<br>\nAll intermediate results for full reproducibility are available upon request. \n"
      },
      "source": "https://raw.githubusercontent.com/SFGLab/bertrand/main/README.md",
      "technique": "header_analysis"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/SFGLab/bertrand/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "executable_example": [
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/SFGLab/bertrand/main/bertrand/notebooks/validation-AUROC-no-pretraining.ipynb"
      },
      "source": "https://raw.githubusercontent.com/SFGLab/bertrand/main/bertrand/notebooks/validation-AUROC-no-pretraining.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/SFGLab/bertrand/main/bertrand/notebooks/validation-AP-with-baselines.ipynb"
      },
      "source": "https://raw.githubusercontent.com/SFGLab/bertrand/main/bertrand/notebooks/validation-AP-with-baselines.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/SFGLab/bertrand/main/bertrand/notebooks/AUROC-vs-distance.ipynb"
      },
      "source": "https://raw.githubusercontent.com/SFGLab/bertrand/main/bertrand/notebooks/AUROC-vs-distance.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/SFGLab/bertrand/main/bertrand/notebooks/reference-tcrs.ipynb"
      },
      "source": "https://raw.githubusercontent.com/SFGLab/bertrand/main/bertrand/notebooks/reference-tcrs.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/SFGLab/bertrand/main/bertrand/notebooks/bertrand-arch.ipynb"
      },
      "source": "https://raw.githubusercontent.com/SFGLab/bertrand/main/bertrand/notebooks/bertrand-arch.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/SFGLab/bertrand/main/bertrand/notebooks/validation-AUROC-with-baselines.ipynb"
      },
      "source": "https://raw.githubusercontent.com/SFGLab/bertrand/main/bertrand/notebooks/validation-AUROC-with-baselines.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/SFGLab/bertrand/main/bertrand/notebooks/mlm-results.ipynb"
      },
      "source": "https://raw.githubusercontent.com/SFGLab/bertrand/main/bertrand/notebooks/mlm-results.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/SFGLab/bertrand/main/bertrand/notebooks/validation-AP.ipynb"
      },
      "source": "https://raw.githubusercontent.com/SFGLab/bertrand/main/bertrand/notebooks/validation-AP.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/SFGLab/bertrand/main/bertrand/notebooks/data_curation/prepare_zhang_3_additional_info_about_peptides.ipynb"
      },
      "source": "https://raw.githubusercontent.com/SFGLab/bertrand/main/bertrand/notebooks/data_curation/prepare_zhang_3_additional_info_about_peptides.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/SFGLab/bertrand/main/bertrand/notebooks/data_curation/prepare_emerson.ipynb"
      },
      "source": "https://raw.githubusercontent.com/SFGLab/bertrand/main/bertrand/notebooks/data_curation/prepare_emerson.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/SFGLab/bertrand/main/bertrand/notebooks/data_curation/prepare_soon.ipynb"
      },
      "source": "https://raw.githubusercontent.com/SFGLab/bertrand/main/bertrand/notebooks/data_curation/prepare_soon.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/SFGLab/bertrand/main/bertrand/notebooks/data_curation/prepare_cukalac.ipynb"
      },
      "source": "https://raw.githubusercontent.com/SFGLab/bertrand/main/bertrand/notebooks/data_curation/prepare_cukalac.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/SFGLab/bertrand/main/bertrand/notebooks/data_curation/prepare_zhang_2_preprocess_experiments.ipynb"
      },
      "source": "https://raw.githubusercontent.com/SFGLab/bertrand/main/bertrand/notebooks/data_curation/prepare_zhang_2_preprocess_experiments.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/SFGLab/bertrand/main/bertrand/notebooks/data_curation/prepare_attaf.ipynb"
      },
      "source": "https://raw.githubusercontent.com/SFGLab/bertrand/main/bertrand/notebooks/data_curation/prepare_attaf.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/SFGLab/bertrand/main/bertrand/notebooks/data_curation/prepare_takeda.ipynb"
      },
      "source": "https://raw.githubusercontent.com/SFGLab/bertrand/main/bertrand/notebooks/data_curation/prepare_takeda.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/SFGLab/bertrand/main/bertrand/notebooks/data_curation/data-curation.ipynb"
      },
      "source": "https://raw.githubusercontent.com/SFGLab/bertrand/main/bertrand/notebooks/data_curation/data-curation.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/SFGLab/bertrand/main/bertrand/notebooks/data_curation/prepare_hakeem.ipynb"
      },
      "source": "https://raw.githubusercontent.com/SFGLab/bertrand/main/bertrand/notebooks/data_curation/prepare_hakeem.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/SFGLab/bertrand/main/bertrand/notebooks/data_curation/prepare_zhang_4_Merge_experiments.ipynb"
      },
      "source": "https://raw.githubusercontent.com/SFGLab/bertrand/main/bertrand/notebooks/data_curation/prepare_zhang_4_Merge_experiments.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/SFGLab/bertrand/main/bertrand/notebooks/data_curation/prepare_britanova.ipynb"
      },
      "source": "https://raw.githubusercontent.com/SFGLab/bertrand/main/bertrand/notebooks/data_curation/prepare_britanova.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/SFGLab/bertrand/main/bertrand/notebooks/data_curation/prepare_carey.ipynb"
      },
      "source": "https://raw.githubusercontent.com/SFGLab/bertrand/main/bertrand/notebooks/data_curation/prepare_carey.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/SFGLab/bertrand/main/bertrand/notebooks/data_curation/prepare_TCRdatabases.ipynb"
      },
      "source": "https://raw.githubusercontent.com/SFGLab/bertrand/main/bertrand/notebooks/data_curation/prepare_TCRdatabases.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/SFGLab/bertrand/main/bertrand/notebooks/data_curation/prepare_pogorelyy.ipynb"
      },
      "source": "https://raw.githubusercontent.com/SFGLab/bertrand/main/bertrand/notebooks/data_curation/prepare_pogorelyy.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/SFGLab/bertrand/main/bertrand/notebooks/data_curation/prepare_zhang_1_ST1_processing.ipynb"
      },
      "source": "https://raw.githubusercontent.com/SFGLab/bertrand/main/bertrand/notebooks/data_curation/prepare_zhang_1_ST1_processing.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/SFGLab/bertrand/main/bertrand/notebooks/data_curation/prepare_kamga.ipynb"
      },
      "source": "https://raw.githubusercontent.com/SFGLab/bertrand/main/bertrand/notebooks/data_curation/prepare_kamga.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/SFGLab/bertrand/main/bertrand/notebooks/data_curation/prepare_malekzadeh.ipynb"
      },
      "source": "https://raw.githubusercontent.com/SFGLab/bertrand/main/bertrand/notebooks/data_curation/prepare_malekzadeh.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/SFGLab/bertrand/main/bertrand/notebooks/data_curation/prepare_gee.ipynb"
      },
      "source": "https://raw.githubusercontent.com/SFGLab/bertrand/main/bertrand/notebooks/data_curation/prepare_gee.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/SFGLab/bertrand/main/bertrand/notebooks/data_curation/prepare_huth.ipynb"
      },
      "source": "https://raw.githubusercontent.com/SFGLab/bertrand/main/bertrand/notebooks/data_curation/prepare_huth.ipynb",
      "technique": "file_exploration"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 0
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/SFGLab/bertrand/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "SFGLab/bertrand"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "BERTrand - peptide:TCR binding prediction using BERT augmented with random TCR pairing"
      },
      "source": "https://raw.githubusercontent.com/SFGLab/bertrand/main/README.md",
      "technique": "regular_expression"
    }
  ],
  "has_build_file": [
    {
      "confidence": 1,
      "result": {
        "format": "dockerfile",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/SFGLab/bertrand/main/Dockerfile"
      },
      "source": "https://raw.githubusercontent.com/SFGLab/bertrand/main/Dockerfile",
      "technique": "file_exploration"
    }
  ],
  "has_script_file": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/SFGLab/bertrand/main/analysis.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/SFGLab/bertrand/main/train_and_evaluate_nopep.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/SFGLab/bertrand/main/pretraining.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/SFGLab/bertrand/main/train_and_evaluate_nomlm.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/SFGLab/bertrand/main/train_and_evaluate.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/SFGLab/bertrand/main/negative_decoys.sh"
      },
      "technique": "file_exploration"
    }
  ],
  "images": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/SFGLab/bertrand/main/flow.png"
      },
      "source": "https://raw.githubusercontent.com/SFGLab/bertrand/main/README.md",
      "technique": "regular_expression"
    }
  ],
  "installation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Installation",
        "parent_header": [
          "BERTrand - peptide:TCR binding prediction using BERT augmented with random TCR pairing"
        ],
        "type": "Text_excerpt",
        "value": "Create a conda environment using a provided env.yml\n> conda create -f env.yml\n\nNext, activate the created environment\n> conda activate bertrand\n\nYou're good to go. \n"
      },
      "source": "https://raw.githubusercontent.com/SFGLab/bertrand/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 0.9888995165023813,
      "result": {
        "original_header": "Analysis",
        "type": "Text_excerpt",
        "value": "The script `analysis.sh` lets you run everything. Simply run the script with 2 arguments: \n1. output folder,\n2. number of CPUs for the job.\n```\nbash analysis.sh results 32\n``` \n`analysis.sh` simply calls 3 separate scripts for each step of the training process (see above). \nNote that some parts of the analysis are CPU and RAM intensive, while other need a good GPU to complete in a reasonable time, so you might want to run them on different machines. \n"
      },
      "source": "https://raw.githubusercontent.com/SFGLab/bertrand/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9953996535519863,
      "result": {
        "original_header": "Negative decoys",
        "type": "Text_excerpt",
        "value": "This script will create a `negative_decoys` subdirectory in your results directory and will call the following python scripts:\n1. `basic_filtering.py` - retain reference TCRs 10-20 amino acids long with proper anchor positions\n2. `outliers_filtering.py` - remove easily detectable reference TCRs (CPU intensive)\n3. `compute_distance.py` - compute pairwise Levenshtein distances (RAM intensive)\n4. `tcr_clustering.py` - perform agglomerative clustering (RAM and CPU intensive)\n5. `assign_clusters_and_filter.py` - assign cluster and remove reference TCRs in clusters with binding TCRs\n6. `negative_decoys_generation.py` - randomly pair reference TCR clusters with peptides from the positives dataset \n"
      },
      "source": "https://raw.githubusercontent.com/SFGLab/bertrand/main/README.md",
      "technique": "supervised_classification"
    }
  ],
  "invocation": [
    {
      "confidence": 0.8211320207089662,
      "result": {
        "original_header": "Data",
        "type": "Text_excerpt",
        "value": "Our evaluation approach is repeated cross-validation. The dataset is split into cancer and viral subsets. The cancer subset is used as an independent test set and the viral part \nis further split into train, validation (used for early stopping), and test sets. \nIf you want to recreate the splits yourself, use the snippet below:\n```python\nimport pandas as pd\nfrom bertrand.training.cv import split_train_val_test\n\ndataset = pd.read_csv('results/negative_decoys/datasets/dataset_42.csv.gz')\ncancer = dataset[dataset.is_cancer]\ntrain, val, test = split_train_val_test(dataset, seed=42) \n```\n \n"
      },
      "source": "https://raw.githubusercontent.com/SFGLab/bertrand/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8568347133429218,
      "result": {
        "original_header": "Analysis",
        "type": "Text_excerpt",
        "value": "The script `analysis.sh` lets you run everything. Simply run the script with 2 arguments: \n1. output folder,\n2. number of CPUs for the job.\n```\nbash analysis.sh results 32\n``` \n\nThe analysis pipeline will create a directory structure in your results folder. The important files are:\n```\n<results directory>/\n\u251c\u2500 pretraining/                            \n\u2502  \u251c\u2500 model/                    MLM model best checkpoint\n\u2502  \u2502  \u251c\u2500 pytorch_model.bin\n\u2502  \u2502  \u251c\u2500 config.json\n\u251c\u2500 negative_decoys/             Peptide:TCR datasets ready for training\n\u2502  \u2502  \u251c\u2500 dataset_42.csv.gz\n\u2502  \u2502  \u251c\u2500 dataset_43.csv.gz\n\u2502  \u2502  \u251c\u2500 dataset_44.csv.gz\n\u251c\u2500 training/\n\u2502  \u251c\u2500 dataset_42/\n\u2502  \u2502  \u251c\u2500 cv_seed=42/            Model weights and predictions for every cross-validation split \n\u2502  \u2502  \u2502  \u251c\u2500 best-checkpoint/\n\u2502  \u2502  \u2502  \u251c\u2500 predictions.pkl\n\u2502  \u2502  \u2502  \u251c\u2500 metrics.png\n\u2502  \u2502  \u251c\u2500 cv_seed=43/\n\u2502  \u2502  \u251c\u2500 ...\n\u2502  \u251c\u2500 dataset_43/\n\u2502  \u2502  \u251c\u2500 cv_seed=42/\n\u2502  \u2502  \u251c\u2500 ...\n\u2502  \u251c\u2500 results.csv               Results of cross-validation in a single file\n\n```\nMost of the scripts cache intermediate results (distance matrices, model checkpoints etc), these are omitted for brevity. \n \n"
      },
      "source": "https://raw.githubusercontent.com/SFGLab/bertrand/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8561280003042372,
      "result": {
        "original_header": "Pre-training",
        "type": "Text_excerpt",
        "value": "```\nbash pretraining.sh <results>/pretraining\n```\nThis script will create a `pretraining` subdirectory in your results directory and will call the following python scripts:\n1. `peptide_tcr_repertoire.py` - create the peptide:TCR repertoire from simulated CDR3b sequences randomly paired with presented peptides\n2. `train_mlm.py` - pre-train BERT with masked language modeling on the said repertoire (GPU intensive)\n3. `evaluate_mlm.py` - choose the best model checkpoint and save it to `pretraining/model`\n \n"
      },
      "source": "https://raw.githubusercontent.com/SFGLab/bertrand/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8004079664635734,
      "result": {
        "original_header": "Negative decoys",
        "type": "Text_excerpt",
        "value": "This script will create a `negative_decoys` subdirectory in your results directory and will call the following python scripts:\n1. `basic_filtering.py` - retain reference TCRs 10-20 amino acids long with proper anchor positions\n2. `outliers_filtering.py` - remove easily detectable reference TCRs (CPU intensive)\n3. `compute_distance.py` - compute pairwise Levenshtein distances (RAM intensive)\n4. `tcr_clustering.py` - perform agglomerative clustering (RAM and CPU intensive)\n5. `assign_clusters_and_filter.py` - assign cluster and remove reference TCRs in clusters with binding TCRs\n6. `negative_decoys_generation.py` - randomly pair reference TCR clusters with peptides from the positives dataset \n"
      },
      "source": "https://raw.githubusercontent.com/SFGLab/bertrand/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9430737214832555,
      "result": {
        "original_header": "Training",
        "type": "Text_excerpt",
        "value": "```\nbash train_and_evaluate.sh <results>/negative_decoys/datasets <results>/pretraining/model <results>/training\n```\nThis script will create a `training` subdirectory in your results directory and will call the following python scripts:\n1. `train.py` - train BERT using repeated stratified cross-validation (GPU intensive)\n2. `evaluate.py` - choose best model based on early-stopping set, compute predictions for independent cancer set, save results for all datasets and cv splits to a single file \n \n"
      },
      "source": "https://raw.githubusercontent.com/SFGLab/bertrand/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8835270410044332,
      "result": {
        "original_header": "Inference",
        "type": "Text_excerpt",
        "value": "There are several options for inference. If you want to generate predictions for a dataset of peptide:TCR observations, you can use `bertrand/model/inference.py`\n```\npython -m bertrand.model.inference -i=<input> -m=<model> -o=<output>\n```\nwhere `<input>` is a .csv or .csv.gz file with `peptide_seq` and `CDR3b` columns and `<model>` is a BERTrand checkpoint. The prediction will be written to `<output>` as a csv file.   \n\n```python\nfrom bertrand.model import BERTrand\nfrom bertrand.model.inference import PeptideTCRDataset, single_obs_to_tensor\n\nmodel = BERTrand.from_pretrained(\"<model checkpoint>\") # see Downloads section\nmodel.eval() # don't forget this\ninput = PeptideTCRDataset.encode_peptide_cdr3b(\"ELAGIGLTV\", \"CASSGRGQEYF\")\ninput = single_obs_to_tensor(input)\nlogits, attentions, hidden_states = model(**input, output_attentions=True, output_hidden_states=True, return_dict=False)\n\n``` \n"
      },
      "source": "https://raw.githubusercontent.com/SFGLab/bertrand/main/README.md",
      "technique": "supervised_classification"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/SFGLab/bertrand/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ""
      },
      "technique": "GitHub_API"
    }
  ],
  "license": [
    {
      "confidence": 1,
      "result": {
        "name": "MIT License",
        "spdx_id": "MIT",
        "type": "License",
        "url": "https://api.github.com/licenses/mit",
        "value": "https://api.github.com/licenses/mit"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "type": "File_dump",
        "value": "MIT License\n\nCopyright (c) 2023 alexander-myronov\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
      },
      "source": "https://raw.githubusercontent.com/SFGLab/bertrand/main/LICENSE",
      "technique": "file_exploration"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "bertrand"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "Organization",
        "value": "SFGLab"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Jupyter Notebook",
        "size": 2687239,
        "type": "Programming_language",
        "value": "Jupyter Notebook"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 117345,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Shell",
        "size": 3473,
        "type": "Programming_language",
        "value": "Shell"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "R",
        "size": 597,
        "type": "Programming_language",
        "value": "R"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Dockerfile",
        "size": 373,
        "type": "Programming_language",
        "value": "Dockerfile"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/SFGLab/bertrand/main/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "somef_missing_categories": [
    "citation",
    "acknowledgement",
    "run",
    "requirements",
    "contact",
    "contributors",
    "documentation",
    "usage",
    "faq",
    "support",
    "identifier"
  ],
  "somef_provenance": {
    "date": "2024-10-04 00:37:16",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 8
      },
      "technique": "GitHub_API"
    }
  ]
}