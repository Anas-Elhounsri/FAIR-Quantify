{
  "citation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Citing MetaCerberus",
        "parent_header": [
          "Welcome to MetaCerberus"
        ],
        "type": "Text_excerpt",
        "value": "If you are publishing results obtained using MetaCerberus, please cite: <br />"
      },
      "source": "https://raw.githubusercontent.com/raw-lab/metacerberus/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Publication",
        "parent_header": [
          "Welcome to MetaCerberus",
          "Citing MetaCerberus"
        ],
        "type": "Text_excerpt",
        "value": "Figueroa III JL, Dhungel E, Bellanger M, Brouwer CR, White III RA. 2024.\nMetaCerberus: distributed highly parallelized HMM-based processing for robust functional annotation across the tree of life. [Bioinformatics](https://doi.org/10.1093/bioinformatics/btae119)  <br />\n"
      },
      "source": "https://raw.githubusercontent.com/raw-lab/metacerberus/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Pre-print",
        "parent_header": [
          "Welcome to MetaCerberus",
          "Citing MetaCerberus"
        ],
        "type": "Text_excerpt",
        "value": "Figueroa III JL, Dhungel E, Brouwer CR, White III RA. 2023.  <br />\nMetaCerberus: distributed highly parallelized HMM-based processing for robust functional annotation across the tree of life. [bioRxiv](https://www.biorxiv.org/content/10.1101/2023.08.10.552700v1)   <br />\n"
      },
      "source": "https://raw.githubusercontent.com/raw-lab/metacerberus/main/README.md",
      "technique": "header_analysis"
    }
  ],
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/raw-lab/MetaCerberus"
      },
      "technique": "GitHub_API"
    }
  ],
  "contact": [
    {
      "confidence": 1,
      "result": {
        "original_header": "CONTACT",
        "parent_header": [
          "Welcome to MetaCerberus"
        ],
        "type": "Text_excerpt",
        "value": "The informatics point-of-contact for this project is [Dr. Richard Allen White III](https://github.com/raw-lab).  \nIf you have any questions or feedback, please feel free to get in touch by email.  \n[Dr. Richard Allen White III](mailto:rwhit101@uncc.edu)<br /> \n[Jose Luis Figueroa III](mailto:jlfiguer@uncc.edu) <br />\nOr [open an issue](https://github.com/raw-lab/metacerberus/issues).  \n"
      },
      "source": "https://raw.githubusercontent.com/raw-lab/metacerberus/main/README.md",
      "technique": "header_analysis"
    }
  ],
  "contributing_guidelines": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Contributing to MetaCerberus and Fungene",
        "parent_header": [
          "Welcome to MetaCerberus"
        ],
        "type": "Text_excerpt",
        "value": "MetaCerberus as a community resource as recently acquired [FunGene](http://fungene.cme.msu.edu/), we welcome contributions of other experts expanding annotation of all domains of life (viruses, bacteria, archaea, eukaryotes).  Please send us an issue on our MetaCerberus GitHub [open an issue](https://github.com/raw-lab/metacerberus/issues); or email us we will fully annotate your genome, add suggested pathways/metabolisms of interest, make custom HMMs to be added to MetaCerberus and FunGene. \n"
      },
      "source": "https://raw.githubusercontent.com/raw-lab/metacerberus/main/README.md",
      "technique": "header_analysis"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2020-10-24T15:52:24Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2024-09-18T21:45:43Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "Python code for versatile Functional Ontology Assignments for Metagenomes searching via Hidden Markov Model (HMM) with environmental focus of shotgun metaomics data"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 0.8972769176950903,
      "result": {
        "original_header": "Welcome to MetaCerberus",
        "type": "Text_excerpt",
        "value": "Check out our [MetaCerberus ReadTheDocs Documentation](https://metacerberus.readthedocs.io/en/latest/) and [Tutorial](https://metacerberus.readthedocs.io/en/latest/tutorial1.html)!\n \n"
      },
      "source": "https://raw.githubusercontent.com/raw-lab/metacerberus/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9996505528120366,
      "result": {
        "original_header": "About",
        "type": "Text_excerpt",
        "value": "MetaCerberus transforms raw sequencing (i.e. genomic, transcriptomics, metagenomics, metatranscriptomic) data into knowledge. It is a start to finish python code for versatile analysis of the Functional Ontology Assignments for Metagenomes (FOAM), KEGG, CAZy/dbCAN, VOG, pVOG, PHROG, COG, and a variety of other databases including user customized databases via Hidden Markov Models (HMM) for functional annotation for complete metabolic analysis across the tree of life (i.e., bacteria, archaea, phage, viruses, eukaryotes, and whole ecosystems). MetaCerberus also provides automatic differential statistics using DESeq2/EdgeR, pathway enrichments with GAGE, and pathway visualization with Pathview R.  \n"
      },
      "source": "https://raw.githubusercontent.com/raw-lab/metacerberus/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9187651778084664,
      "result": {
        "original_header": "MetaCerberus Lite",
        "type": "Text_excerpt",
        "value": "We also have a lite version of MetaCerberus on anaconda that only depends on the very basic dependencies.  \nThis can make it a bit faster and easier to install as it is less likely to have conflicts with other dependencies on the system. \nAdditional dependencies such as fastqc and fastp can be installed in the environment manually if desired for those steps in the pipeline.\n \n"
      },
      "source": "https://raw.githubusercontent.com/raw-lab/metacerberus/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9991748722690996,
      "result": {
        "original_header": "MetaCerberus has three basic modes: quality control (QC) for raw reads, formatting/gene prediction, and annotation.",
        "type": "Text_excerpt",
        "value": "- MetaCerberus can use three different input files: 1) raw read data from any sequencing platform (Illumina, PacBio, or Oxford Nanopore), 2) assembled contigs, as MAGs, vMAGs, isolate genomes, or a collection of contigs, 3) amino acid fasta (.faa), previously called pORFs.\n- We offer customization, including running all databases together, individually or specifying select databases. For example, if a user wants to run prokaryotic or eukaryotic-specific KOfams, or an individual database alone such as dbCAN, both are easily customized within MetaCerberus.\n- In QC mode, raw reads are quality controlled via FastQC prior and post trim [FastQC](https://github.com/s-andrews/FastQC). Raw reads are then trimmed via data type; if the data is Illumina or PacBio, [fastp](https://doi.org/10.1093/bioinformatics/bty560)  is called, otherwise it assumes the data is Oxford Nanopore then Porechop is utilized [PoreChop](https://github.com/rrwick/Porechop).\n- If Illumina reads are utilized, an optional bbmap step to remove the phiX174 genome is available or user provided contaminate genome. Phage phiX174 is a common contaminant within the Illumina platform as their library spike-in control. We highly recommend this removal if viral analysis is conducted, as it would provide false positives to ssDNA microviruses within a sample.\n- We include a --skip_decon option to skip the filtration of phiX174, which may remove common k-mers that are shared in ssDNA phages.\n- In the formatting and gene prediction stage, contigs and genomes are checked for N repeats. These N repeats are removed by default.\n- We impute contig/genome statistics (e.g., N50, N90, max contig) via our custom module [Metaome Stats](https://github.com/raw-lab/metaome_stats).\n- Contigs can be converted to pORFs using [Prodigal](https://anaconda.org/bioconda/prodigal), [FragGeneScanRs](https://github.com/unipept/FragGeneScanRs/), and [Prodigal-gv](https://github.com/apcamargo/prodigal-gv) as specified by user preference.\n- Scaffold annotation is not recommended due to N's providing ambiguous annotation.\n- Both Prodigal and FragGeneScanRs can be used via our --super option, and we recommend using FragGeneScanRs for samples rich in eukaryotes.\n- FragGeneScanRs found more ORFs and KOs than Prodigal for a stimulated eukaryote rich metagenome. HMMER searches against the above databases via user specified bitscore and e-values or our minimum defaults (i.e., bitscore = 25, e-value = 1 x 10<sup>-9</sup> ).\n \n"
      },
      "source": "https://raw.githubusercontent.com/raw-lab/metacerberus/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.923919479982163,
      "result": {
        "original_header": "Visualization of Outputs",
        "type": "Text_excerpt",
        "value": "- We use Plotly to visualize the data\n- Once the program is executed the html reports with the visuals will be saved to the last step of the pipeline.\n- The HTML files require plotly.js to be present. One has been provided in the package and is saved to the report folder.\n \n"
      },
      "source": "https://raw.githubusercontent.com/raw-lab/metacerberus/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9944998586582846,
      "result": {
        "original_header": "Annotation Rules",
        "type": "Text_excerpt",
        "value": "- ***Rule 1*** is for finding high quality matches across databases. It is a score pre-filtering module for pORFs thresholds: which states that each pORF match to an HMM is recorded by default or a user-selected cut-off (i.e.,  e-value/bit scores) per database independently, or across all default databases (e.g, finding best hit), or per user specification of the selected database.\n- ***Rule 2*** is to avoid missing genes encoding proteins with dual domains that are not overlapping. It is imputed for non-overlapping dual domain module pORF threshold: if two HMM hits are non-overlapping from the same database, both are counted as long as they are within the default or user selected score (i.e., e-value/bit scores).\n- ***Rule 3*** is to ensure overlapping dual domains are not missed. This is the dual independent overlapping domain module for convergent binary domain pORFs. If two domains within a pORF are overlapping <10 amino acids (e.g, COG1 and COG4) then both domains are counted and reported due to the dual domain issue within a single pORF. If a function hits multiple pathways within an accession, both are counted, in pathway roll-up, as many proteins function in multiple pathways.\n- ***Rule 4*** is the equal match counter to avoid missing high quality matches within the same protein. This is an independent accession module for a single pORF: if both hits within the same database have equal values for both e-value and bit score but are different accessions from the same database (e.g., KO1 and KO3) then both are reported.\n- ***Rule 5*** is the \u2018winner take all\u2019 match rule for providing the best match. It is computed as the winner takes all module for overlapping pORFs: if two HMM hits are overlapping (>10 amino acids) from the same database the lowest resulting e-value and highest bit score wins.\n- ***Rule 6*** is to avoid partial or fractional hits being counted. This ensures that only whole discrete integer counting (e.g., 0, 1, 2 to n) are computed and that partial or fractional counting is excluded.  \n"
      },
      "source": "https://raw.githubusercontent.com/raw-lab/metacerberus/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9622784997848691,
      "result": {
        "original_header": "Database sources",
        "type": "Text_excerpt",
        "value": "\n- NOTE: The KEGG database contains KOs related to Human disease. It is possible that these will show up in the results, even when analyzing microbes. eggNOG and FunGene database are coming soon. If you want a custom HMM build please let us know by email or leaving an issue.\n \n"
      },
      "source": "https://raw.githubusercontent.com/raw-lab/metacerberus/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9362593597984847,
      "result": {
        "original_header": "Custom Database",
        "type": "Text_excerpt",
        "value": "To run a custom database, you need a HMM containing the protein family of interest and a metadata sheet describing the HMM required for look-up tables and downstream analysis. For the metadata information you need an ID that matches the HMM and a function or hierarchy. See example below. \n \n"
      },
      "source": "https://raw.githubusercontent.com/raw-lab/metacerberus/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9168198284304719,
      "result": {
        "original_header": "MetaCerberus Options",
        "type": "Text_excerpt",
        "value": "- If the metacerberus environment is not used, make sure the dependencies are in PATH or specified in the config file.\n- Run metacerberus.py with the options required for your project.\n```bash\nusage: metacerberus.py [--setup] [--update] [--list-db] [--download [DOWNLOAD ...]] [--uninstall] [-c CONFIG] [--prodigal PRODIGAL [PRODIGAL ...]]\n                       [--fraggenescan FRAGGENESCAN [FRAGGENESCAN ...]] [--super SUPER [SUPER ...]] [--prodigalgv PRODIGALGV [PRODIGALGV ...]]\n                       [--phanotate PHANOTATE [PHANOTATE ...]] [--protein PROTEIN [PROTEIN ...]] [--hmmer-tsv HMMER_TSV [HMMER_TSV ...]] [--class CLASS]\n                       [--illumina | --nanopore | --pacbio] [--dir-out DIR_OUT] [--replace] [--keep] [--hmm HMM [HMM ...]] [--db-path DB_PATH] [--address ADDRESS]\n                       [--port PORT] [--meta] [--scaffolds] [--minscore MINSCORE] [--evalue EVALUE] [--remove-n-repeats] [--skip-decon] [--skip-pca] [--cpus CPUS]\n                       [--chunker CHUNKER] [--grouped] [--version] [-h] [--adapters ADAPTERS] [--qc_seq QC_SEQ]\n\nSetup arguments:\n  --setup               Setup additional dependencies [False]\n  --update              Update downloaded databases [False]\n  --list-db             List available and downloaded databases [False]\n  --download [DOWNLOAD ...]\n                        Downloads selected HMMs. Use the option --list-db for a list of available databases, default is to download all available databases\n  --uninstall           Remove downloaded databases and FragGeneScan+ [False]\n\nInput files\nAt least one sequence is required.\n    accepted formats: [.fastq, .fq, .fasta, .fa, .fna, .ffn, .faa]\nExample:\n> metacerberus.py --prodigal file1.fasta\n> metacerberus.py --config file.config\n*Note: If a sequence is given in [.fastq, .fq] format, one of --nanopore, --illumina, or --pacbio is required.:\n  -c CONFIG, --config CONFIG\n                        Path to config file, command line takes priority\n  --prodigal PRODIGAL [PRODIGAL ...]\n                        Prokaryote nucleotide sequence (includes microbes, bacteriophage)\n  --fraggenescan FRAGGENESCAN [FRAGGENESCAN ...]\n                        Eukaryote nucleotide sequence (includes other viruses, works all around for everything)\n  --super SUPER [SUPER ...]\n                        Run sequence in both --prodigal and --fraggenescan modes\n  --prodigalgv PRODIGALGV [PRODIGALGV ...]\n                        Giant virus nucleotide sequence\n  --phanotate PHANOTATE [PHANOTATE ...]\n                        Phage sequence (EXPERIMENTAL)\n  --protein PROTEIN [PROTEIN ...], --amino PROTEIN [PROTEIN ...]\n                        Protein Amino Acid sequence\n  --hmmer-tsv HMMER_TSV [HMMER_TSV ...]\n                        Annotations tsv file from HMMER (experimental)\n  --class CLASS         path to a tsv file which has class information for the samples. If this file is included scripts will be included to run Pathview in R\n  --illumina            Specifies that the given FASTQ files are from Illumina\n  --nanopore            Specifies that the given FASTQ files are from Nanopore\n  --pacbio              Specifies that the given FASTQ files are from PacBio\n\nOutput options:\n  --dir-out DIR_OUT     path to output directory, defaults to \"results-metacerberus\" in current directory. [./results-metacerberus]\n  --replace             Flag to replace existing files. [False]\n  --keep                Flag to keep temporary files. [False]\n\nDatabase options:\n  --hmm HMM [HMM ...]   A list of databases for HMMER. 'ALL' uses all downloaded databases. Use the option --list-db for a list of available databases [KOFam_all]\n  --db-path DB_PATH     Path to folder of databases [Default: under the library path of MetaCerberus]\n\nMPP options:\n  --address ADDRESS     Address for distributed MPP. local=no networking, host=make this machine a host, ip-address=connect to remote host [local]\n  --port PORT           The port to listen/connect to [24515]\n\noptional arguments:\n  --meta                Metagenomic nucleotide sequences (for prodigal) [False]\n  --scaffolds           Sequences are treated as scaffolds [False]\n  --minscore MINSCORE   Score cutoff for parsing HMMER results [60]\n  --evalue EVALUE       E-value cutoff for parsing HMMER results [1e-09]\n  --remove-n-repeats    Remove N repeats, splitting contigs [False]\n  --skip-decon          Skip decontamination step [False]\n  --skip-pca            Skip PCA [False]\n  --cpus CPUS           Number of CPUs to use per task. System will try to detect available CPUs if not specified [Auto Detect]\n  --chunker CHUNKER     Split files into smaller chunks, in Megabytes [Disabled by default]\n  --grouped             Group multiple fasta files into a single file before processing. When used with chunker can improve speed\n  --version, -v         show the version number and exit\n  -h, --help            show this help message and exit\n\n  --adapters ADAPTERS   FASTA File containing adapter sequences for trimming\n  --qc_seq QC_SEQ       FASTA File containing control sequences for decontamination\n\nArgs that start with '--' can also be set in a config file (specified via -c). Config file syntax allows: key=value, flag=true, stuff=[a,b,c] (for details, see syntax at\nhttps://goo.gl/R74nmi). In general, command-line values override config file values which override defaults.\n```\n \n"
      },
      "source": "https://raw.githubusercontent.com/raw-lab/metacerberus/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9701858814628673,
      "result": {
        "original_header": "OUTPUTS (/final folder)",
        "type": "Text_excerpt",
        "value": "| File Extension | Description Summary |  MetaCerberus Update Version |\n| --------- | ----------- | -------- |\n| .gff | General Feature Format | 1.3 |\n| .gbk | GenBank Format | 1.3 |\n| .fna | Nucleotide FASTA file of the input contig sequences. | 1.3 |\n| .faa | Protein FASTA file of the translated CDS/ORFs sequences. | 1.3 |\n| .ffn | FASTA Feature Nucleotide file, the Nucleotide sequence of translated CDS/ORFs.| 1.3 |\n| .html | Summary statistics and/or visualizations, in step 10 folder | 1.3 |\n| .txt | Statistics relating to the annotated features found. | 1.3 |\n| level.tsv | Various levels of hierachical steps that is tab-separated file from various databases| 1.3 |\n| rollup.tsv | All levels of hierachical steps that is tab-separated file from various databases| 1.3 |\n| .tsv | Final Annotation summary, Tab-separated file of all features from various databases| 1.3 |\n \n"
      },
      "source": "https://raw.githubusercontent.com/raw-lab/metacerberus/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.93247321562826,
      "result": {
        "original_header": "GAGE / PathView",
        "type": "Text_excerpt",
        "value": "After processing the HMM files MetaCerberus calculates a KO (KEGG Orthology) counts table from KEGG/FOAM for processing through GAGE and PathView.\nGAGE is recommended for pathway enrichment followed by PathView for visualize the metabolic pathways. A \"class\" file is required through the --class option to run this analysis. \nAs we are unsure which comparisons you want to make thus you have to make a class.tsv so the code will know the comparisons you want to make. \n \n"
      },
      "source": "https://raw.githubusercontent.com/raw-lab/metacerberus/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9993855558979797,
      "result": {
        "original_header": "Copyright",
        "type": "Text_excerpt",
        "value": "This is copyrighted by University of North Carolina at Charlotte, Jose L Figueroa III, Eliza Dhungal, Madeline Bellanger, Cory R Brouwer and Richard Allen White III.  All rights reserved.  MetaCerberus is a bioinformatic tool that can be distributed freely for academic use only. Please contact us for commerical use. The software is provided \u201cas is\u201d and the copyright owners or contributors are not liable for any direct, indirect, incidental, special, or consequential damages including but not limited to, procurement of goods or services, loss of use, data or profits arising in any way out of the use of this software.<br />\n \n"
      },
      "source": "https://raw.githubusercontent.com/raw-lab/metacerberus/main/README.md",
      "technique": "supervised_classification"
    }
  ],
  "documentation": [
    {
      "confidence": 1,
      "result": {
        "format": "readthedocs",
        "type": "Url",
        "value": "https://metacerberus.readthedocs.io/"
      },
      "source": "https://raw.githubusercontent.com/raw-lab/metacerberus/main/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "format": "wiki",
        "type": "Url",
        "value": "https://github.com/raw-lab/metacerberus/wiki"
      },
      "source": "https://raw.githubusercontent.com/raw-lab/metacerberus/main/README.md",
      "technique": "regular_expression"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/raw-lab/metacerberus/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "faq": [
    {
      "confidence": 1,
      "result": {
        "original_header": "DESeq2 and Edge2 Type I errors",
        "parent_header": [
          "Welcome to MetaCerberus"
        ],
        "type": "Text_excerpt",
        "value": "Both edgeR and DeSeq2 R have the highest sensitivity when compared to other algorithms that control type-I error when the FDR was at or below 0.1. EdgeR and DESeq2 all perform fairly well in simulation and via data splitting (so no parametric assumptions). Typical benchmarks will show limma having stronger FDR control across all types of datasets (it\u2019s hard to beat the moderated t-test), and edgeR and DESeq2 having higher sensitivity for low counts (makes sense as limma has to filter these out / down-weight them to use the normal model on log counts). Further information about type I errors are present from Mike Love's vignette [here](https://bioconductor.org/packages/devel/bioc/vignettes/DESeq2/inst/doc/DESeq2.html#multi-factor-designs).\n"
      },
      "source": "https://raw.githubusercontent.com/raw-lab/metacerberus/main/README.md",
      "technique": "header_analysis"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 7
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/raw-lab/MetaCerberus/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "raw-lab/MetaCerberus"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "Welcome to MetaCerberus"
      },
      "source": "https://raw.githubusercontent.com/raw-lab/metacerberus/main/README.md",
      "technique": "regular_expression"
    }
  ],
  "has_script_file": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/raw-lab/metacerberus/main/install_metacerberus-lite.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/raw-lab/metacerberus/main/install_metacerberus.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/raw-lab/metacerberus/main/bin/get-samples.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/raw-lab/metacerberus/main/bin/ray-slurm-metacerberus.sh"
      },
      "technique": "file_exploration"
    }
  ],
  "images": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/raw-lab/MetaCerberus/main/img/Screenshot_20240614_205914_Gallery.jpg"
      },
      "source": "https://raw.githubusercontent.com/raw-lab/metacerberus/main/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/raw-lab/MetaCerberus/main/img/workflow.jpg"
      },
      "source": "https://raw.githubusercontent.com/raw-lab/metacerberus/main/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/raw-lab/MetaCerberus/main/img/Rules.jpg"
      },
      "source": "https://raw.githubusercontent.com/raw-lab/metacerberus/main/README.md",
      "technique": "regular_expression"
    }
  ],
  "installation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Option 1) Mamba",
        "parent_header": [
          "Welcome to MetaCerberus",
          "Installing MetaCerberus"
        ],
        "type": "Text_excerpt",
        "value": "- Mamba install from bioconda with all dependencies:\n"
      },
      "source": "https://raw.githubusercontent.com/raw-lab/metacerberus/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Linux/OSX-64",
        "parent_header": [
          "Welcome to MetaCerberus",
          "Installing MetaCerberus",
          "Option 1) Mamba"
        ],
        "type": "Text_excerpt",
        "value": "1. Install mamba using conda\n\n```bash\nconda install mamba\n```\n\n- NOTE: Make sure you install mamba in your base conda environment unless you have OSX with ARM architecture (M1/M2 Macs). Follow the OSX-ARM instructions below if you have a Mac with ARM architecture.\n\n2. Install MetaCerberus with mamba\n\n```bash\nmamba create -n metacerberus -c conda-forge -c bioconda metacerberus\nconda activate metacerberus\nmetacerberus.py --setup\nmetacerberus.py --download\n```\n"
      },
      "source": "https://raw.githubusercontent.com/raw-lab/metacerberus/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "OSX-ARM (M1/M2)",
        "parent_header": [
          "Welcome to MetaCerberus",
          "Installing MetaCerberus",
          "Option 1) Mamba"
        ],
        "type": "Text_excerpt",
        "value": "1. Set up conda environment\n```bash\nconda create -y -n metacerberus\nconda activate metacerberus\nconda config --env --set subdir osx-64\n```\n2. Install mamba, python, and pydantic inside the environment\n```bash\nconda install -y -c conda-forge mamba python=3.10 \"pydantic<2\"\n```\n3. Install MetaCerberus with mamba\n```bash\nmamba install -y -c conda-forge -c bioconda metacerberus\nmetacerberus.py --setup\nmetacerberus.py --download\n```\n\n- NOTE: Mamba is the fastest installer. Anaconda or miniconda can be slow. Also, install mamba from conda not from pip. The pip mamba doesn't work for install.\n"
      },
      "source": "https://raw.githubusercontent.com/raw-lab/metacerberus/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Option 2) Anaconda - Linux/OSX-64 Only",
        "parent_header": [
          "Welcome to MetaCerberus",
          "Installing MetaCerberus"
        ],
        "type": "Text_excerpt",
        "value": "- Anaconda install from bioconda with all dependencies:\n\n```bash\nconda create -n metacerberus -c conda-forge -c bioconda metacerberus -y\nconda activate metacerberus\nmetacerberus.py --setup\nmetacerberus.py --download\n\n```\n"
      },
      "source": "https://raw.githubusercontent.com/raw-lab/metacerberus/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Option 3) Manual with conda/mamba from Github",
        "parent_header": [
          "Welcome to MetaCerberus",
          "Installing MetaCerberus"
        ],
        "type": "Text_excerpt",
        "value": "```bash\ngit clone https://github.com/raw-lab/MetaCerberus.git \ncd MetaCerberus\nbash install_metacerberus.sh\nconda activate MetaCerberus\nmetacerberus.py --download\n```\n"
      },
      "source": "https://raw.githubusercontent.com/raw-lab/metacerberus/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 0.9986656841184279,
      "result": {
        "original_header": "MetaCerberus Lite",
        "type": "Text_excerpt",
        "value": "We also have a lite version of MetaCerberus on anaconda that only depends on the very basic dependencies.  \nThis can make it a bit faster and easier to install as it is less likely to have conflicts with other dependencies on the system. \nTo install the \"lite\" version, use \"metacerberus-lite\" instead of \"metacerberus\" from Bioconda, following the details listed above.\n```bash\nmamba create -n metacerberus -c conda-forge -c bioconda metacerberus-lite\nconda activate metacerberus\nmetacerberus.py --setup\nmetacerberus.py --download\n```\n \nAdditional dependencies such as fastqc and fastp can be installed in the environment manually if desired for those steps in the pipeline.\n \n"
      },
      "source": "https://raw.githubusercontent.com/raw-lab/metacerberus/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9974312533621713,
      "result": {
        "original_header": "Brief Overview",
        "type": "Text_excerpt",
        "value": "<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/raw-lab/MetaCerberus/main/img/workflow.jpg\" alt=\"MetaCerberus Workflow\" height=600>\n</p>\n \n"
      },
      "source": "https://raw.githubusercontent.com/raw-lab/metacerberus/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9861063588774946,
      "result": {
        "original_header": "Output Files",
        "type": "Text_excerpt",
        "value": "- If an output directory is given, that folder will be created where all files are stored.\n- If no output directory is specified, the 'results_metacerberus' subfolder will be created in the current directory.\n- Gage/Pathview R analysis provided as separate scripts within R.  \n \n"
      },
      "source": "https://raw.githubusercontent.com/raw-lab/metacerberus/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9997340402801581,
      "result": {
        "original_header": "Visualization of Outputs",
        "type": "Text_excerpt",
        "value": "- We use Plotly to visualize the data\n- Once the program is executed the html reports with the visuals will be saved to the last step of the pipeline.\n- The HTML files require plotly.js to be present. One has been provided in the package and is saved to the report folder.\n \n"
      },
      "source": "https://raw.githubusercontent.com/raw-lab/metacerberus/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9993565737412672,
      "result": {
        "original_header": "Annotation Rules",
        "type": "Text_excerpt",
        "value": "<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/raw-lab/MetaCerberus/main/img/Rules.jpg\" alt=\"MetaCerberus Rules\" height=600>\n</p> \n"
      },
      "source": "https://raw.githubusercontent.com/raw-lab/metacerberus/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.999999570298975,
      "result": {
        "original_header": "Database sources",
        "type": "Text_excerpt",
        "value": "| Database | Last Update | Version |  Publication | MetaCerberus Update Version |\n| ---- | --- | --------| -----| ---|\n| [KEGG/KOfams](https://www.genome.jp/ftp/db/kofam/) | 2024-01-01 | Jan24 | [Aramaki et al. 2020](https://doi.org/10.1093/bioinformatics/btz859) | beta |\n| [FOAM/KOfams](https://osf.io/3uz2j/) | 2017 | 1 | [Prestat et al. 2014](https://doi.org/10.1093/nar/gku702) | beta |\n| [COG](https://ftp.ncbi.nlm.nih.gov/pub/COG/COG2020/data/) | 2020 | 2020 | [Galperin et al. 2020](https://doi.org/10.1093/nar/gkaa1018) | beta |\n| [dbCAN/CAZy](https://bcb.unl.edu/dbCAN2/download/)| 2023-08-02 | 12 | [Yin et al., 2012](https://doi.org/10.1093/nar/gks479) | beta |\n| [VOG](https://vogdb.org/download)| 2017-03-03 | 80 | [Website](https://vogdb.org/) | beta |\n| [pVOG](https://ftp.ncbi.nlm.nih.gov/pub/kristensen/pVOGs/downloads.html#)| 2016 | 2016 | [Grazziotin et al. 2017](https://doi.org/10.1093/nar/gkw975) | 1.2 |\n| [PHROG](https://phrogs.lmge.uca.fr/)| 2022-06-15 | 4 | [Terizan et al., 2021](https://doi.org/10.1093/nargab/lqab067) | 1.2 |\n| [PFAM](http://ftp.ebi.ac.uk/pub/databases/Pfam/current_release)| 2023-09-12 | 36 | [Mistry et al. 2020](https://doi.org/10.1093/nar/gkaa913) | 1.3 |\n| [TIGRfams](https://ftp.ncbi.nlm.nih.gov/hmm/TIGRFAMs/release_15.0/) | 2018-06-19 | 15 | [Haft et al. 2003](https://doi.org/10.1093/nar/gkg128) | 1.3 |\n| [PGAPfams](https://ftp.ncbi.nlm.nih.gov/hmm/current/) | 2023-12-21 | 14 | [Tatusova et al. 2016]( https://doi.org/10.1093/nar/gkw569) | 1.3 |\n| [AMRFinder-fams](https://ftp.ncbi.nlm.nih.gov/hmm/NCBIfam-AMRFinder/latest/) | 2024-02-05 | 2024-02-05 | [Feldgarden et al. 2021](https://doi.org/10.1038/s41598-021-91456-0) | 1.3 |\n| [NFixDB](https://github.com/raw-lab/NFixDB) | 2024-01-22 | 2 | [Bellanger et al. 2024](https://doi.org/10.1101/2024.03.04.583350) | 1.3 |\n| [GVDB](https://faylward.github.io/GVDB/) | 2021 | 1 | [Aylward et al. 2021](https://doi.org/10.1371/journal.pbio.3001430)| 1.3 |\n| [Pads Arsenal](https://ngdc.cncb.ac.cn/padsarsenal/download.php) | 2019-09-09 | 1 | [Zhang et al. 2020](https://academic.oup.com/nar/article-lookup/doi/10.1093/nar/gkz916) | Coming soon |\n| [efam-XC](https://datacommons.cyverse.org/browse/iplant/home/shared/iVirus/Zayed_efam_2020.1) | 2021-05-21 | 1 | [Zayed et al. 2021](https://doi.org/10.1093/bioinformatics/btab451) | Coming soon |\n| [NMPFams](https://bib.fleming.gr/NMPFamsDB/downloads) | 2021 | 1 | [Baltoumas et al. 2024](https://doi.org/10.1093/nar/gkad800) | Coming soon |\n| [MEROPS](https://www.ebi.ac.uk/merops/download_list.shtml) | 2017 | 1 | [Rawlings et al. 2018](https://academic.oup.com/nar/article/46/D1/D624/4626772) | Coming soon |\n| [FESNov](https://zenodo.org/records/10242439) | 2024 | 1 | [Rodr\u00edguez del R\u00edo et al. 2024](https://www.nature.com/articles/s41586-023-06955-z) | Coming soon | \n"
      },
      "source": "https://raw.githubusercontent.com/raw-lab/metacerberus/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 1.0,
      "result": {
        "original_header": "MetaCerberus Options",
        "type": "Text_excerpt",
        "value": "- If the metacerberus environment is not used, make sure the dependencies are in PATH or specified in the config file.\n- Run metacerberus.py with the options required for your project.\n```bash\nusage: metacerberus.py [--setup] [--update] [--list-db] [--download [DOWNLOAD ...]] [--uninstall] [-c CONFIG] [--prodigal PRODIGAL [PRODIGAL ...]]\n                       [--fraggenescan FRAGGENESCAN [FRAGGENESCAN ...]] [--super SUPER [SUPER ...]] [--prodigalgv PRODIGALGV [PRODIGALGV ...]]\n                       [--phanotate PHANOTATE [PHANOTATE ...]] [--protein PROTEIN [PROTEIN ...]] [--hmmer-tsv HMMER_TSV [HMMER_TSV ...]] [--class CLASS]\n                       [--illumina | --nanopore | --pacbio] [--dir-out DIR_OUT] [--replace] [--keep] [--hmm HMM [HMM ...]] [--db-path DB_PATH] [--address ADDRESS]\n                       [--port PORT] [--meta] [--scaffolds] [--minscore MINSCORE] [--evalue EVALUE] [--remove-n-repeats] [--skip-decon] [--skip-pca] [--cpus CPUS]\n                       [--chunker CHUNKER] [--grouped] [--version] [-h] [--adapters ADAPTERS] [--qc_seq QC_SEQ]\n\nSetup arguments:\n  --setup               Setup additional dependencies [False]\n  --update              Update downloaded databases [False]\n  --list-db             List available and downloaded databases [False]\n  --download [DOWNLOAD ...]\n                        Downloads selected HMMs. Use the option --list-db for a list of available databases, default is to download all available databases\n  --uninstall           Remove downloaded databases and FragGeneScan+ [False]\n\nInput files\nAt least one sequence is required.\n    accepted formats: [.fastq, .fq, .fasta, .fa, .fna, .ffn, .faa]\nExample:\n> metacerberus.py --prodigal file1.fasta\n> metacerberus.py --config file.config\n*Note: If a sequence is given in [.fastq, .fq] format, one of --nanopore, --illumina, or --pacbio is required.:\n  -c CONFIG, --config CONFIG\n                        Path to config file, command line takes priority\n  --prodigal PRODIGAL [PRODIGAL ...]\n                        Prokaryote nucleotide sequence (includes microbes, bacteriophage)\n  --fraggenescan FRAGGENESCAN [FRAGGENESCAN ...]\n                        Eukaryote nucleotide sequence (includes other viruses, works all around for everything)\n  --super SUPER [SUPER ...]\n                        Run sequence in both --prodigal and --fraggenescan modes\n  --prodigalgv PRODIGALGV [PRODIGALGV ...]\n                        Giant virus nucleotide sequence\n  --phanotate PHANOTATE [PHANOTATE ...]\n                        Phage sequence (EXPERIMENTAL)\n  --protein PROTEIN [PROTEIN ...], --amino PROTEIN [PROTEIN ...]\n                        Protein Amino Acid sequence\n  --hmmer-tsv HMMER_TSV [HMMER_TSV ...]\n                        Annotations tsv file from HMMER (experimental)\n  --class CLASS         path to a tsv file which has class information for the samples. If this file is included scripts will be included to run Pathview in R\n  --illumina            Specifies that the given FASTQ files are from Illumina\n  --nanopore            Specifies that the given FASTQ files are from Nanopore\n  --pacbio              Specifies that the given FASTQ files are from PacBio\n\nOutput options:\n  --dir-out DIR_OUT     path to output directory, defaults to \"results-metacerberus\" in current directory. [./results-metacerberus]\n  --replace             Flag to replace existing files. [False]\n  --keep                Flag to keep temporary files. [False]\n\nDatabase options:\n  --hmm HMM [HMM ...]   A list of databases for HMMER. 'ALL' uses all downloaded databases. Use the option --list-db for a list of available databases [KOFam_all]\n  --db-path DB_PATH     Path to folder of databases [Default: under the library path of MetaCerberus]\n\nMPP options:\n  --address ADDRESS     Address for distributed MPP. local=no networking, host=make this machine a host, ip-address=connect to remote host [local]\n  --port PORT           The port to listen/connect to [24515]\n\noptional arguments:\n  --meta                Metagenomic nucleotide sequences (for prodigal) [False]\n  --scaffolds           Sequences are treated as scaffolds [False]\n  --minscore MINSCORE   Score cutoff for parsing HMMER results [60]\n  --evalue EVALUE       E-value cutoff for parsing HMMER results [1e-09]\n  --remove-n-repeats    Remove N repeats, splitting contigs [False]\n  --skip-decon          Skip decontamination step [False]\n  --skip-pca            Skip PCA [False]\n  --cpus CPUS           Number of CPUs to use per task. System will try to detect available CPUs if not specified [Auto Detect]\n  --chunker CHUNKER     Split files into smaller chunks, in Megabytes [Disabled by default]\n  --grouped             Group multiple fasta files into a single file before processing. When used with chunker can improve speed\n  --version, -v         show the version number and exit\n  -h, --help            show this help message and exit\n\n  --adapters ADAPTERS   FASTA File containing adapter sequences for trimming\n  --qc_seq QC_SEQ       FASTA File containing control sequences for decontamination\n\nArgs that start with '--' can also be set in a config file (specified via -c). Config file syntax allows: key=value, flag=true, stuff=[a,b,c] (for details, see syntax at\nhttps://goo.gl/R74nmi). In general, command-line values override config file values which override defaults.\n```\n \n"
      },
      "source": "https://raw.githubusercontent.com/raw-lab/metacerberus/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9671243517718602,
      "result": {
        "original_header": "GAGE / PathView",
        "type": "Text_excerpt",
        "value": "After processing the HMM files MetaCerberus calculates a KO (KEGG Orthology) counts table from KEGG/FOAM for processing through GAGE and PathView.\nGAGE is recommended for pathway enrichment followed by PathView for visualize the metabolic pathways. A \"class\" file is required through the --class option to run this analysis. \nAs we are unsure which comparisons you want to make thus you have to make a class.tsv so the code will know the comparisons you want to make. \n \n"
      },
      "source": "https://raw.githubusercontent.com/raw-lab/metacerberus/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 1.0,
      "result": {
        "original_header": "Multiprocessing / Multi-Computing with RAY",
        "type": "Text_excerpt",
        "value": "MetaCerberus uses HydraMPP for distributed processing. This is compatible with both multiprocessing on a single node (computer) or multiple nodes in a cluster.  \nMetaCerberus has been tested on a cluster using Slurm <https://github.com/SchedMD/slurm>.  \n  \n*note the extra flag \"--hydraMPP-slurm $SLURM_JOB_NODELIST\" when running MetaCerberus. HydraMPP uses this to setup the SLURM jobs.\n```bash\nsbatch example_script.sh\n```\nexample script:  \n```bash\n#!/usr/bin/env bash\n\n#SBATCH --job-name=test-job\n#SBATCH --nodes=3\n#SBATCH --tasks-per-node=1\n#SBATCH --cpus-per-task=16\n#SBATCH --mem=128MB\n#SBATCH -e slurm-%j.err\n#SBATCH -o slurm-%j.out\n#SBATCH --mail-type=END,FAIL,REQUEUE\n\necho \"=====================================================\"\necho \"Start Time  : $(date)\"\necho \"Job ID/Name : $SLURM_JOBID / $SLURM_JOB_NAME\"\necho \"Node List   : $SLURM_JOB_NODELIST\"\necho \"Num Tasks   : $SLURM_NTASKS total [$SLURM_NNODES nodes @ $SLURM_CPUS_ON_NODE CPUs/node]\"\necho \"======================================================\"\necho \"\"\n\n# Load any modules or resources here\nconda activate MetaCerberus\n\n# run MetaCerberus\nmetacerberus.py --prodigal [input_folder] --illumina --dir_out [out_folder] --hydraMPP-slurm $SLURM_JOB_NODELIST\n```\n \n"
      },
      "source": "https://raw.githubusercontent.com/raw-lab/metacerberus/main/README.md",
      "technique": "supervised_classification"
    }
  ],
  "invocation": [
    {
      "confidence": 0.8104007248349261,
      "result": {
        "original_header": "Input formats",
        "type": "Text_excerpt",
        "value": "- From any NextGen sequencing technology (from Illumina, PacBio, Oxford Nanopore)\n- type 1 raw reads (.fastq format)\n- type 2 nucleotide fasta (.fasta, .fa, .fna, .ffn format), assembled raw reads into contigs\n- type 3 protein fasta (.faa format), assembled contigs which genes are converted to amino acid sequence\n \n"
      },
      "source": "https://raw.githubusercontent.com/raw-lab/metacerberus/main/README.md",
      "technique": "supervised_classification"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/raw-lab/MetaCerberus/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ""
      },
      "technique": "GitHub_API"
    }
  ],
  "license": [
    {
      "confidence": 1,
      "result": {
        "name": "BSD 3-Clause \"New\" or \"Revised\" License",
        "spdx_id": "BSD-3-Clause",
        "type": "License",
        "url": "https://api.github.com/licenses/bsd-3-clause",
        "value": "https://api.github.com/licenses/bsd-3-clause"
      },
      "technique": "GitHub_API"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "MetaCerberus"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "User",
        "value": "raw-lab"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "HTML",
        "size": 368073830,
        "type": "Programming_language",
        "value": "HTML"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 186511,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Jupyter Notebook",
        "size": 20272,
        "type": "Programming_language",
        "value": "Jupyter Notebook"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Shell",
        "size": 16285,
        "type": "Programming_language",
        "value": "Shell"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "R",
        "size": 11085,
        "type": "Programming_language",
        "value": "R"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "CSS",
        "size": 7661,
        "type": "Programming_language",
        "value": "CSS"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Batchfile",
        "size": 769,
        "type": "Programming_language",
        "value": "Batchfile"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Makefile",
        "size": 638,
        "type": "Programming_language",
        "value": "Makefile"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/raw-lab/metacerberus/main/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "releases": [
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "decrevi",
          "type": "User"
        },
        "date_created": "2024-08-24T03:05:31Z",
        "date_published": "2024-08-24T03:23:48Z",
        "description": "## Version 1.4.0\r\n\r\n### v1.4.0 New Features\r\n\r\n- Replaced Ray with HydraMPP\r\n  - Reduced number of dependencies making install easier\r\n\r\n### v1.4.0 Improvements\r\n\r\n- Removed a redundant hmm search when using KOFam\r\n- Organized output files\r\n\r\n### v1.4.0 Bug Fixes\r\n\r\n- Fixed resume feature for hmm step\r\n- Fixed counting conflict between parser and filter steps\r\n",
        "html_url": "https://github.com/raw-lab/MetaCerberus/releases/tag/v1.4.0",
        "name": "MetaCerberus v1.4.0",
        "release_id": 171763960,
        "tag": "v1.4.0",
        "tarball_url": "https://api.github.com/repos/raw-lab/MetaCerberus/tarball/v1.4.0",
        "type": "Release",
        "url": "https://api.github.com/repos/raw-lab/MetaCerberus/releases/171763960",
        "value": "https://api.github.com/repos/raw-lab/MetaCerberus/releases/171763960",
        "zipball_url": "https://api.github.com/repos/raw-lab/MetaCerberus/zipball/v1.4.0"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "decrevi",
          "type": "User"
        },
        "date_created": "2024-07-20T02:37:57Z",
        "date_published": "2024-07-20T02:40:23Z",
        "description": "## Version 1.3.2\r\n\r\n### Bug Fixes\r\n\r\n- Fixed Ray dependency issue for MetaCerberus-lite, or when Ray is not available.\r\n",
        "html_url": "https://github.com/raw-lab/MetaCerberus/releases/tag/v1.3.2",
        "name": "MetaCerberus v1.3.2",
        "release_id": 166322025,
        "tag": "v1.3.2",
        "tarball_url": "https://api.github.com/repos/raw-lab/MetaCerberus/tarball/v1.3.2",
        "type": "Release",
        "url": "https://api.github.com/repos/raw-lab/MetaCerberus/releases/166322025",
        "value": "https://api.github.com/repos/raw-lab/MetaCerberus/releases/166322025",
        "zipball_url": "https://api.github.com/repos/raw-lab/MetaCerberus/zipball/v1.3.2"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "decrevi",
          "type": "User"
        },
        "date_created": "2024-07-19T00:17:09Z",
        "date_published": "2024-07-19T00:44:23Z",
        "description": "## Version 1.3.1\r\n\r\n### New Features\r\n\r\n- created \"lite\" version.\r\n  - removed hard dependency requirements, failing more gracefully to make some dependencies optional\r\n  - added linear override for Ray when Ray is not found\r\n- Implemented PyHMMER\r\n- Implemented Pyrodigal\r\n- Implemented Pyrodigal-gv\r\n- Added ORF start and end to output summary files\r\n- Improved speed in creating final GFF files\r\n- Fixed dependency checking for lite version\r\n- Made N removal optional\r\n- Improved Genbank output\r\n\r\n### Bug Fixes\r\n\r\n- Fixed prodigal-gv GFF\r\n- Fixed some Phanotate bugs\r\n- Fixed bug with --protein option\r\n- Fixed crash when GFF is not present\r\n- Other minor bug fixes\r\n",
        "html_url": "https://github.com/raw-lab/MetaCerberus/releases/tag/v1.3.1",
        "name": "MetaCerberus v1.3.1",
        "release_id": 166152840,
        "tag": "v1.3.1",
        "tarball_url": "https://api.github.com/repos/raw-lab/MetaCerberus/tarball/v1.3.1",
        "type": "Release",
        "url": "https://api.github.com/repos/raw-lab/MetaCerberus/releases/166152840",
        "value": "https://api.github.com/repos/raw-lab/MetaCerberus/releases/166152840",
        "zipball_url": "https://api.github.com/repos/raw-lab/MetaCerberus/zipball/v1.3.1"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "decrevi",
          "type": "User"
        },
        "date_created": "2024-05-15T19:25:15Z",
        "date_published": "2024-05-15T19:26:59Z",
        "description": "## Release 1.3.0\r\n\r\n### New Features\r\n\r\n-Custom download location for databases\r\n-Ability to download individual databases\r\n-Update downloaded databases (currently re-downloads the database)\r\n-List available databases\r\n-Custom database support\r\n  -HMM file with .hmm extension (also supports .hmm.gz)\r\n  -A TSV file is also required with minimum columns: ID, Function\r\n  -The ID field must match the NAME field of the HMM file, one row per HMM entry\r\n-Output files\r\n  -reworked output directories to separate graphs/stats from annotation files\r\n  -Final folder with annotation summary and files in GTF, genbank, GFF, .FAA, .FNA, .FFN\r\n-Other improvements\r\n  -Performance improvements\r\n  -Improved some error handling and reporting\r\n\r\n### Bug Fixes\r\n\r\n-Multi-domain in summary files\r\n  -Individual database summary files contain a line per match found\r\n  -The combined summary file lists only the best match based on e-value\r\n-Slurm on cluster with multiple nodes now working\r\n-Filtering algorithm fix (on rare circumstances it would enter an infinite loop)\r\n",
        "html_url": "https://github.com/raw-lab/MetaCerberus/releases/tag/v1.3.0",
        "name": "MetaCerberus v1.3.0",
        "release_id": 155948801,
        "tag": "v1.3.0",
        "tarball_url": "https://api.github.com/repos/raw-lab/MetaCerberus/tarball/v1.3.0",
        "type": "Release",
        "url": "https://api.github.com/repos/raw-lab/MetaCerberus/releases/155948801",
        "value": "https://api.github.com/repos/raw-lab/MetaCerberus/releases/155948801",
        "zipball_url": "https://api.github.com/repos/raw-lab/MetaCerberus/zipball/v1.3.0"
      },
      "technique": "GitHub_API"
    }
  ],
  "requirements": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Prerequisites and dependencies",
        "parent_header": [
          "Welcome to MetaCerberus"
        ],
        "type": "Text_excerpt",
        "value": "- python >= 3.8\n"
      },
      "source": "https://raw.githubusercontent.com/raw-lab/metacerberus/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Available from Bioconda - external tool list",
        "parent_header": [
          "Welcome to MetaCerberus",
          "Prerequisites and dependencies"
        ],
        "type": "Text_excerpt",
        "value": "| Tool | Version |  Publication |\n| ---- | -----| ---------|\n| [Fastqc](https://github.com/s-andrews/FastQC) | 0.12.1 | None |\n| [Fastp](https://github.com/OpenGene/fastp>) | 0.23.4 |  [Chen et al. 2018](https://doi.org/10.1093/bioinformatics/bty560) |\n| [Porechop](https://github.com/rrwick/Porechop) | 0.2.4 | None |\n| [bbmap](https://github.com/BioInfoTools/BBMap) | 39.06 | None |\n| [Prodigal](https://github.com/hyattpd/Prodigal) | 2.6.3 | [Hyatt et al. 2010](https://doi.org/10.1186/1471-2105-11-119) |\n| [FragGeneScanRs](https://github.com/unipept/FragGeneScanRs/) | v1.1.0 | [Van der Jeugt et al. 2022](https://doi.org/10.1186/s12859-022-04736-5) | \n| [Prodigal-gv](https://github.com/apcamargo/prodigal-gv) | 2.2.1 | [Camargo et al. 2023](https://www.nature.com/articles/s41587-023-01953-y) | \n| [Phanotate](https://github.com/deprekate/PHANOTATE) | 1.5.0 | [McNair et al. 2019](https://doi.org/10.1093/bioinformatics/btz265) | \n| [HMMER](https://github.com/EddyRivasLab/hmmer) | 3.4 | [Johnson et al. 2010](https://doi.org/10.1186/1471-2105-11-431) |\n| [HydraMPP](https://github.com/raw-lab/HydraMPP) | 0.0.4 | None |\n"
      },
      "source": "https://raw.githubusercontent.com/raw-lab/metacerberus/main/README.md",
      "technique": "header_analysis"
    }
  ],
  "somef_missing_categories": [
    "acknowledgement",
    "run",
    "download",
    "contributors",
    "support",
    "identifier",
    "has_build_file",
    "executable_example"
  ],
  "somef_provenance": {
    "date": "2024-10-03 23:09:59",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 47
      },
      "technique": "GitHub_API"
    }
  ],
  "type": [
    {
      "confidence": 0.82,
      "result": {
        "type": "String",
        "value": "commandline-application"
      },
      "technique": "software_type_heuristics"
    }
  ],
  "usage": [
    {
      "confidence": 1,
      "result": {
        "original_header": "All databases",
        "parent_header": [
          "Welcome to MetaCerberus",
          "Quick start examples",
          "Genome examples"
        ],
        "type": "Text_excerpt",
        "value": "```bash\nconda activate metacerberus\nmetacerberus.py --prodigal lambda.fna --hmm ALL --dir_out lambda_dir\n```\n"
      },
      "source": "https://raw.githubusercontent.com/raw-lab/metacerberus/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Only KEGG/FOAM all",
        "parent_header": [
          "Welcome to MetaCerberus",
          "Quick start examples",
          "Genome examples"
        ],
        "type": "Text_excerpt",
        "value": "```bash\nconda activate metacerberus\nmetacerberus.py --prodigal lambda.fna --hmm KOFam_all --dir_out lambda_ko-only_dir\n```\n"
      },
      "source": "https://raw.githubusercontent.com/raw-lab/metacerberus/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Only KEGG/FOAM prokaryotic centric",
        "parent_header": [
          "Welcome to MetaCerberus",
          "Quick start examples",
          "Genome examples"
        ],
        "type": "Text_excerpt",
        "value": "```bash\nconda activate metacerberus\nmetacerberus.py --prodigal ecoli.fna --hmm KOFam_prokaryote --dir_out ecoli_ko-only_dir\n```\n"
      },
      "source": "https://raw.githubusercontent.com/raw-lab/metacerberus/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Only KEGG/FOAM eukaryotic centric",
        "parent_header": [
          "Welcome to MetaCerberus",
          "Quick start examples",
          "Genome examples"
        ],
        "type": "Text_excerpt",
        "value": "```bash\nconda activate metacerberus\nmetacerberus.py --fraggenescan human.fna --hmm KOFam_eukaryote --dir_out human_ko-only_dir\n```\n"
      },
      "source": "https://raw.githubusercontent.com/raw-lab/metacerberus/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Only Viral/Phage databases",
        "parent_header": [
          "Welcome to MetaCerberus",
          "Quick start examples",
          "Genome examples"
        ],
        "type": "Text_excerpt",
        "value": "```bash\nconda activate metacerberus\nmetacerberus.py --prodigal lambda.fna --hmm VOG, PHROG --dir_out lambda_vir-only_dir\n```\n- NOTE: You can pick any single database you want for your analysis including KOFam_all, COG, VOG, PHROG, CAZy or specific KO databases for eukaryotes and prokaryotes (KOFam_eukaryote or KOFam_prokaryote).\n"
      },
      "source": "https://raw.githubusercontent.com/raw-lab/metacerberus/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Custom HMM",
        "parent_header": [
          "Welcome to MetaCerberus",
          "Quick start examples",
          "Genome examples"
        ],
        "type": "Text_excerpt",
        "value": "```bash\nconda activate metacerberus\nmetacerberus.py --prodigal lambda.fna --hmm Custom.hmm --dir_out lambda_vir-only_dir\n```\n  "
      },
      "source": "https://raw.githubusercontent.com/raw-lab/metacerberus/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Bacterial, Archaea and Bacteriophage metagenomes/metatranscriptomes",
        "parent_header": [
          "Welcome to MetaCerberus",
          "Quick start examples",
          "Nanopore data"
        ],
        "type": "Text_excerpt",
        "value": "```bash\nconda activate metacerberus\nmetacerberus.py --prodigal [input_folder] --illumina --meta --dir_out [out_folder] \n```\n"
      },
      "source": "https://raw.githubusercontent.com/raw-lab/metacerberus/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Eukaryotes and Viruses metagenomes/metatranscriptomes",
        "parent_header": [
          "Welcome to MetaCerberus",
          "Quick start examples",
          "PacBio data"
        ],
        "type": "Text_excerpt",
        "value": "```bash\nconda activate metacerberus\nmetacerberus.py --fraggenescan [input_folder] --illumina --meta --dir_out [out_folder] \n```\n"
      },
      "source": "https://raw.githubusercontent.com/raw-lab/metacerberus/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Microbial, Archaea and Bacteriophage metagenomes/metatranscriptomes",
        "parent_header": [
          "Welcome to MetaCerberus",
          "Quick start examples",
          "PacBio data"
        ],
        "type": "Text_excerpt",
        "value": "```bash\nconda activate metacerberus\nmetacerberus.py --prodigal [input_folder]  --pacbio --meta --dir_out [out_folder]\n```\n\n#### Eukaryotes and Viruses metagenomes/metatranscriptomes\n\n```bash\nconda activate metacerberus\nmetacerberus.py --fraggenescan [input_folder]  --pacbio --meta --dir_out [out_folder]\n```\n"
      },
      "source": "https://raw.githubusercontent.com/raw-lab/metacerberus/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "SUPER (both methods)",
        "parent_header": [
          "Welcome to MetaCerberus",
          "Quick start examples"
        ],
        "type": "Text_excerpt",
        "value": "```bash\nconda activate metacerberus\nmetacerberus.py --super [input_folder]  --pacbio/--nanopore/--illumina --meta --dir_out [out_folder]\n```\n\n- Note: Fraggenescan will work for prokaryotes and viruses/bacteriophage but prodigal will not work well for eukaryotes. \n"
      },
      "source": "https://raw.githubusercontent.com/raw-lab/metacerberus/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Example Metadata sheet",
        "parent_header": [
          "Welcome to MetaCerberus",
          "MetaCerberus databases",
          "Custom Database"
        ],
        "type": "Text_excerpt",
        "value": "| ID | Function |\n| ---- | --- |\n| HMM1 | Sugarase | \n| HMM2 | Coffease | \n\n"
      },
      "source": "https://raw.githubusercontent.com/raw-lab/metacerberus/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "For example (class.tsv):",
        "parent_header": [
          "Welcome to MetaCerberus",
          "MetaCerberus Options",
          "GAGE / PathView"
        ],
        "type": "Text_excerpt",
        "value": "| Sample  |   Class      |\n| ------- | -------------|\n| 1A      | rhizobium    |\n| 1B      | non-rhizobium|\n\nThe output is saved under the step_10-visualizeData/combined/pathview folder. Also, at least 4 samples need to be used for this type of analysis.  \n  \nGAGE and PathView also require internet access to be able to download information from a database. MetaCerberus will save a bash script 'run_pathview.sh' in the step_10-visualizeData/combined/pathview directory along with the KO Counts tsv files and the class file for running manualy in case MetaCerberus was run on a cluster without access to the internet.\n"
      },
      "source": "https://raw.githubusercontent.com/raw-lab/metacerberus/main/README.md",
      "technique": "header_analysis"
    }
  ]
}