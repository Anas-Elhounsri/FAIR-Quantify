{
  "application_domain": [
    {
      "confidence": 42.47,
      "result": {
        "type": "String",
        "value": "Computer Vision"
      },
      "technique": "supervised_classification"
    }
  ],
  "citation": [
    {
      "confidence": 1,
      "result": {
        "format": "bibtex",
        "type": "File_dump",
        "value": "@misc{kaczmarzyk2022evaluating,\n      title={Evaluating histopathology transfer learning with ChampKit},\n      author={Jakub R. Kaczmarzyk and Tahsin M. Kurc and Shahira Abousamra and Rajarsi Gupta and Joel H. Saltz and Peter K. Koo},\n      year={2022},\n      eprint={2206.06862},\n      archivePrefix={arXiv},\n      primaryClass={q-bio.QM},\n      url={https://arxiv.org/abs/2206.06862}\n}\n"
      },
      "source": "https://raw.githubusercontent.com/SBU-BMI/champkit/main/CITATION",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Citations",
        "type": "Text_excerpt",
        "value": "If you find ChampKit useful, please consider citing our paper and the papers corresponding to any datasets you use.\n\n```bibtex\n@article{kaczmarzyk2023champkit,\n    title={ChampKit: a framework for rapid evaluation of deep neural networks for patch-based histopathology classification},\n    journal={Computer Methods and Programs in Biomedicine},\n    pages={107631},\n    year= {2023},\n    issn= {0169-2607},\n    doi={https://doi.org/10.1016/j.cmpb.2023.107631},\n    url={https://www.sciencedirect.com/science/article/pii/S0169260723002961},\n    author={Jakub R. Kaczmarzyk and Rajarsi Gupta and Tahsin M. Kurc and Shahira Abousamra and Joel H. Saltz and Peter K. Koo},\n}\n```\n\n<details><summary>Task 1 (tumor versus non-tumor classification)</summary>\n\n```bibtex\n@inproceedings{veeling2018rotation,\n    title={Rotation equivariant CNNs for digital pathology},\n    author={Veeling, Bastiaan S and Linmans, Jasper and Winkens, Jim and Cohen, Taco and Welling, Max},\n    booktitle={International Conference on Medical Image Computing and Computer-Assisted Intervention},\n    pages={210--218},\n    year={2018},\n    organization={Springer},\n    url={https://doi.org/10.1007/978-3-030-00934-2_24}\n}\n```\n\n```bibtex\n@article{bejnordi2017diagnostic,\n    title={Diagnostic assessment of deep learning algorithms for detection of lymph node metastases in women with breast cancer},\n    author={Bejnordi, Babak Ehteshami and Veta, Mitko and Van Diest, Paul Johannes and Van Ginneken, Bram and Karssemeijer, Nico and Litjens, Geert and Van Der Laak, Jeroen AWM and Hermsen, Meyke and Manson, Quirine F and Balkenhol, Maschenka and others},\n    journal={JAMA},\n    volume={318},\n    number={22},\n    pages={2199--2210},\n    year={2017},\n    publisher={American Medical Association}\n}\n```\n</details>\n\n\n<details><summary>Task 2 (tumor-infiltrating lymphocyte detection)</summary>\n\n```bibtex\n@article{abousamra2022deep,\n    author={Abousamra, Shahira and Gupta, Rajarsi and Hou, Le and Batiste, Rebecca and Zhao, Tianhao and Shankar, Anand and Rao, Arvind and Chen, Chao and Samaras, Dimitris and Kurc, Tahsin and Saltz, Joel},\n    title={Deep Learning-Based Mapping of Tumor Infiltrating Lymphocytes in Whole Slide Images of 23 Types of Cancer},\n    journal={Frontiers in Oncology},\n    volume={11},\n    year={2022},\n    doi={10.3389/fonc.2021.806603},\n    issn={2234-943X},\n    url={https://doi.org/10.3389/fonc.2021.806603}\n}\n```\n\n```bibtex\n@article{saltz2018spatial,\n    title={Spatial organization and molecular correlation of tumor-infiltrating lymphocytes using deep learning on pathology images},\n    author={Saltz, Joel and Gupta, Rajarsi and Hou, Le and Kurc, Tahsin and Singh, Pankaj and Nguyen, Vu and Samaras, Dimitris and Shroyer, Kenneth R and Zhao, Tianhao and Batiste, Rebecca and Van Arnam, John},\n    journal={Cell Reports},\n    volume={23},\n    number={1},\n    pages={181--193},\n    year={2018},\n    publisher={Elsevier},\n    url={https://doi.org/10.1016/j.celrep.2018.03.086},\n    doi={10.1016/j.celrep.2018.03.086}\n}\n```\n\n</details>\n\n\n<details><summary>Tasks 3-5 (microsatellite instability detection)</summary>\n\n```bibtex\n@article{kather2019deep,\n    title={Deep learning can predict microsatellite instability directly from histology in gastrointestinal cancer},\n    author={Kather, Jakob Nikolas and Pearson, Alexander T and Halama, Niels and J{\\\"a}ger, Dirk and Krause, Jeremias and Loosen, Sven H and Marx, Alexander and Boor, Peter and Tacke, Frank and Neumann, Ulf Peter and others},\n    journal=\"Nature Medicine\",\n    year=\"2019\",\n    month=\"Jul\",\n    day=\"01\",\n    volume=\"25\",\n    number=\"7\",\n    pages=\"1054--1056\",\n    issn=\"1546-170X\",\n    doi=\"10.1038/s41591-019-0462-y\",\n    url=\"https://doi.org/10.1038/s41591-019-0462-y\"\n}\n```\n</details>\n\n\n<details><summary>Task 6 (precancerous versus benign colorectal polyp classification)</summary>\n\n```bibtex\n@inproceedings{wei2021petri,\n    title={A Petri Dish for Histopathology Image Analysis},\n    author={Wei, Jerry and Suriawinata, Arief and Ren, Bing and Liu, Xiaoying and Lisovsky, Mikhail and Vaickus, Louis and Brown, Charles and Baker, Michael and Tomita, Naofumi and Torresani, Lorenzo and Wei, Jason and Hassanpour, Saeed},\n    booktitle={International Conference on Artificial Intelligence in Medicine},\n    pages={11--24},\n    year={2021},\n    organization={Springer},\n    url={https://doi.org/10.1007/978-3-030-77211-6_2},\n    doi={10.1007/978-3-030-77211-6_2}\n}\n```\n</details>\n"
      },
      "source": "https://raw.githubusercontent.com/SBU-BMI/champkit/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "author": "Jakub R. Kaczmarzyk and Rajarsi Gupta and Tahsin M. Kurc and Shahira Abousamra and Joel H. Saltz and Peter K. Koo",
        "doi": "https://doi.org/10.1016/j.cmpb.2023.107631",
        "format": "bibtex",
        "title": "ChampKit: a framework for rapid evaluation of deep neural networks for patch-based histopathology classification",
        "type": "Text_excerpt",
        "url": "https://www.sciencedirect.com/science/article/pii/S0169260723002961",
        "value": "@article{kaczmarzyk2023champkit,\n    author = {Jakub R. Kaczmarzyk and Rajarsi Gupta and Tahsin M. Kurc and Shahira Abousamra and Joel H. Saltz and Peter K. Koo},\n    url = {https://www.sciencedirect.com/science/article/pii/S0169260723002961},\n    doi = {https://doi.org/10.1016/j.cmpb.2023.107631},\n    issn = {0169-2607},\n    year = {2023},\n    pages = {107631},\n    journal = {Computer Methods and Programs in Biomedicine},\n    title = {ChampKit: a framework for rapid evaluation of deep neural networks for patch-based histopathology classification},\n}"
      },
      "source": "https://raw.githubusercontent.com/SBU-BMI/champkit/main/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "author": "Veeling, Bastiaan S and Linmans, Jasper and Winkens, Jim and Cohen, Taco and Welling, Max",
        "format": "bibtex",
        "title": "Rotation equivariant CNNs for digital pathology",
        "type": "Text_excerpt",
        "url": "https://doi.org/10.1007/978-3-030-00934-2_24",
        "value": "@inproceedings{veeling2018rotation,\n    url = {https://doi.org/10.1007/978-3-030-00934-2_24},\n    organization = {Springer},\n    year = {2018},\n    pages = {210--218},\n    booktitle = {International Conference on Medical Image Computing and Computer-Assisted Intervention},\n    author = {Veeling, Bastiaan S and Linmans, Jasper and Winkens, Jim and Cohen, Taco and Welling, Max},\n    title = {Rotation equivariant CNNs for digital pathology},\n}"
      },
      "source": "https://raw.githubusercontent.com/SBU-BMI/champkit/main/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "author": "Bejnordi, Babak Ehteshami and Veta, Mitko and Van Diest, Paul Johannes and Van Ginneken, Bram and Karssemeijer, Nico and Litjens, Geert and Van Der Laak, Jeroen AWM and Hermsen, Meyke and Manson, Quirine F and Balkenhol, Maschenka and others",
        "format": "bibtex",
        "title": "Diagnostic assessment of deep learning algorithms for detection of lymph node metastases in women with breast cancer",
        "type": "Text_excerpt",
        "value": "@article{bejnordi2017diagnostic,\n    publisher = {American Medical Association},\n    year = {2017},\n    pages = {2199--2210},\n    number = {22},\n    volume = {318},\n    journal = {JAMA},\n    author = {Bejnordi, Babak Ehteshami and Veta, Mitko and Van Diest, Paul Johannes and Van Ginneken, Bram and Karssemeijer, Nico and Litjens, Geert and Van Der Laak, Jeroen AWM and Hermsen, Meyke and Manson, Quirine F and Balkenhol, Maschenka and others},\n    title = {Diagnostic assessment of deep learning algorithms for detection of lymph node metastases in women with breast cancer},\n}"
      },
      "source": "https://raw.githubusercontent.com/SBU-BMI/champkit/main/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "author": "Abousamra, Shahira and Gupta, Rajarsi and Hou, Le and Batiste, Rebecca and Zhao, Tianhao and Shankar, Anand and Rao, Arvind and Chen, Chao and Samaras, Dimitris and Kurc, Tahsin and Saltz, Joel",
        "doi": "10.3389/fonc.2021.806603",
        "format": "bibtex",
        "title": "Deep Learning-Based Mapping of Tumor Infiltrating Lymphocytes in Whole Slide Images of 23 Types of Cancer",
        "type": "Text_excerpt",
        "url": "https://doi.org/10.3389/fonc.2021.806603",
        "value": "@article{abousamra2022deep,\n    url = {https://doi.org/10.3389/fonc.2021.806603},\n    issn = {2234-943X},\n    doi = {10.3389/fonc.2021.806603},\n    year = {2022},\n    volume = {11},\n    journal = {Frontiers in Oncology},\n    title = {Deep Learning-Based Mapping of Tumor Infiltrating Lymphocytes in Whole Slide Images of 23 Types of Cancer},\n    author = {Abousamra, Shahira and Gupta, Rajarsi and Hou, Le and Batiste, Rebecca and Zhao, Tianhao and Shankar, Anand and Rao, Arvind and Chen, Chao and Samaras, Dimitris and Kurc, Tahsin and Saltz, Joel},\n}"
      },
      "source": "https://raw.githubusercontent.com/SBU-BMI/champkit/main/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "author": "Saltz, Joel and Gupta, Rajarsi and Hou, Le and Kurc, Tahsin and Singh, Pankaj and Nguyen, Vu and Samaras, Dimitris and Shroyer, Kenneth R and Zhao, Tianhao and Batiste, Rebecca and Van Arnam, John",
        "doi": "10.1016/j.celrep.2018.03.086",
        "format": "bibtex",
        "title": "Spatial organization and molecular correlation of tumor-infiltrating lymphocytes using deep learning on pathology images",
        "type": "Text_excerpt",
        "url": "https://doi.org/10.1016/j.celrep.2018.03.086",
        "value": "@article{saltz2018spatial,\n    doi = {10.1016/j.celrep.2018.03.086},\n    url = {https://doi.org/10.1016/j.celrep.2018.03.086},\n    publisher = {Elsevier},\n    year = {2018},\n    pages = {181--193},\n    number = {1},\n    volume = {23},\n    journal = {Cell Reports},\n    author = {Saltz, Joel and Gupta, Rajarsi and Hou, Le and Kurc, Tahsin and Singh, Pankaj and Nguyen, Vu and Samaras, Dimitris and Shroyer, Kenneth R and Zhao, Tianhao and Batiste, Rebecca and Van Arnam, John},\n    title = {Spatial organization and molecular correlation of tumor-infiltrating lymphocytes using deep learning on pathology images},\n}"
      },
      "source": "https://raw.githubusercontent.com/SBU-BMI/champkit/main/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "author": "Kather, Jakob Nikolas and Pearson, Alexander T and Halama, Niels and J{\\\"a}ger, Dirk and Krause, Jeremias and Loosen, Sven H and Marx, Alexander and Boor, Peter and Tacke, Frank and Neumann, Ulf Peter and others",
        "doi": "10.1038/s41591-019-0462-y",
        "format": "bibtex",
        "title": "Deep learning can predict microsatellite instability directly from histology in gastrointestinal cancer",
        "type": "Text_excerpt",
        "url": "https://doi.org/10.1038/s41591-019-0462-y",
        "value": "@article{kather2019deep,\n    url = {https://doi.org/10.1038/s41591-019-0462-y},\n    doi = {10.1038/s41591-019-0462-y},\n    issn = {1546-170X},\n    pages = {1054--1056},\n    number = {7},\n    volume = {25},\n    day = {01},\n    month = {Jul},\n    year = {2019},\n    journal = {Nature Medicine},\n    author = {Kather, Jakob Nikolas and Pearson, Alexander T and Halama, Niels and J{\\\"a}ger, Dirk and Krause, Jeremias and Loosen, Sven H and Marx, Alexander and Boor, Peter and Tacke, Frank and Neumann, Ulf Peter and others},\n    title = {Deep learning can predict microsatellite instability directly from histology in gastrointestinal cancer},\n}"
      },
      "source": "https://raw.githubusercontent.com/SBU-BMI/champkit/main/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "author": "Wei, Jerry and Suriawinata, Arief and Ren, Bing and Liu, Xiaoying and Lisovsky, Mikhail and Vaickus, Louis and Brown, Charles and Baker, Michael and Tomita, Naofumi and Torresani, Lorenzo and Wei, Jason and Hassanpour, Saeed",
        "doi": "10.1007/978-3-030-77211-6_2",
        "format": "bibtex",
        "title": "A Petri Dish for Histopathology Image Analysis",
        "type": "Text_excerpt",
        "url": "https://doi.org/10.1007/978-3-030-77211-6_2",
        "value": "@inproceedings{wei2021petri,\n    doi = {10.1007/978-3-030-77211-6_2},\n    url = {https://doi.org/10.1007/978-3-030-77211-6_2},\n    organization = {Springer},\n    year = {2021},\n    pages = {11--24},\n    booktitle = {International Conference on Artificial Intelligence in Medicine},\n    author = {Wei, Jerry and Suriawinata, Arief and Ren, Bing and Liu, Xiaoying and Lisovsky, Mikhail and Vaickus, Louis and Brown, Charles and Baker, Michael and Tomita, Naofumi and Torresani, Lorenzo and Wei, Jason and Hassanpour, Saeed},\n    title = {A Petri Dish for Histopathology Image Analysis},\n}"
      },
      "source": "https://raw.githubusercontent.com/SBU-BMI/champkit/main/README.md",
      "technique": "regular_expression"
    }
  ],
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/SBU-BMI/champkit"
      },
      "technique": "GitHub_API"
    }
  ],
  "contributing_guidelines": [
    {
      "confidence": 1,
      "result": {
        "type": "File_dump",
        "value": "# How to contribute\n\nThanks for reading this, because everyone can help improve this project.\n\nWe encourage everyone to report any bugs, suggest improvements, and create pull requests. \nPlease use the GitHub issues and pull requests features for this.\n\n# Before reporting a bug or suggesting an enhancement\n\n- Check if an issue already exists.\n- Make sure you are using the latest version of the code.\n\n# Report a bug \n\nWe want to help, and it helps tremendously if you give details about your system and setup. \nWhen reporting a bug (or other problem), please include the following:\n\n- Version of ChampKit you are using (`git` commit would be ideal).\n- Operating system and version.\n- Did you install the ChampKit dependencies with conda/mamba? [yes/no]\n- If you did not install ChampKit dependencies, please provide details of your Python version and packages.\n- Describe the issue.\n\n# Making a pull request\n\nPlease make all pull requests via GitHub. We welcome changes and enhancements.\n\n# Community and behavioral expectations\n\n- Be respectful to all members of the community.\n- Be constructive with your feedback.\n- Discrimination, abuse, bullying, initimidation, trolling and unwanted sexual advances will not be tolerated.\n- Be a decent human being.\n"
      },
      "source": "https://raw.githubusercontent.com/SBU-BMI/champkit/main/.github/CONTRIBUTING.md",
      "technique": "file_exploration"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2022-06-06T18:18:31Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2024-05-10T13:00:59Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "Benchmarking toolkit for patch-based histopathology image classification."
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 0.9035303408363615,
      "result": {
        "original_header": "ChampKit",
        "type": "Text_excerpt",
        "value": "[![Overview of ChampKit](assets/figure-overview.webp)](assets/figure-overview.webp?raw=true)\n<sub>_ChampKit_: Comprehensive Histopathology Assessment of Model Predictions toolKit.</sub> \nA benchmarking toolkit for patch-based image classification in histopathology. \n"
      },
      "source": "https://raw.githubusercontent.com/SBU-BMI/champkit/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.807301793625733,
      "result": {
        "original_header": "Reproducing our manuscript",
        "type": "Text_excerpt",
        "value": "1. Get the ChampKit code.\n    ```bash\n    git clone https://github.com/kaczmarj/champkit\n    cd champkit\n    git checkout 51be0b36608a4380fac58bc593039fed041073a3\n    ```\n2. Install software dependencies. See [Software environment](#software-environment) for details.\n    BASH2*\n3. Install datasets. Almost all of the datasets can be downloaded automatically. The Task 6 dataset (MHIST) needs to be downloaded manually. Please go to https://bmirds.github.io/MHIST/#accessing-dataset and complete the registration form. You will receive an automated email with download links. Please download the files `images.zip` and `annotations.csv` and move them to `data/task6_precancer_vs_benign_polyps/`. After you have done this, run the following script to take care of the rest. This script will download approximately 75 GB of data.\n    BASH3*\n    See [Download and setup datasets](#download-and-setup-datasets) for details.\n4. Run experiments. We use Weights & Biases (W&B) sweeps to run and log the experiments. See [`sweeps/sweep_neurips_db.yml`](sweeps/sweep_neurips_db.yml) for the configuration. Please create an account on https://wandb.ai/ if you do not have one, and login on your machine with `python -m wandb login` (activate the champkit conda environment first).\n    - Initialize the W&B sweep:\n        BASH4*\n    - The command above will output a string like `USER/PROJECT/SWEEPID`. Use this in the next command.\n    - Start an agent:\n        BASH5*\n        There are 42 training runs in this sweep. One can start multiple agents to go through the experiments faster. Each agent will poll W&B for the next experiment to run. If you have more agents running, the experiments will be done sooner. Please see [Running multiple experiments](#running-multiple-experiments) for more information.\n    - The sweep requires at least 12 GB of GPU memory per agent. For the manuscript, we used Quadro RTX 8000 GPUs with 48 GB of video memory each.\n5. Evaluate trained models. The following command will evaluate the best model for each run in the sweep (best = lowest validation loss). Results will be printed as they are calculated, and all results are saved to a CSV. The values in this CSV should be very similar to the values reported in the manuscript.\n    BASH6*\n \n"
      },
      "source": "https://raw.githubusercontent.com/SBU-BMI/champkit/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9943505381145272,
      "result": {
        "original_header": "Using other datasets",
        "type": "Text_excerpt",
        "value": "ChampKit allows for integration with custom datasets that are framed as a single-task patch-level (binary or multi-class) classification.\nCustom datasets must be organized in an ImageNet-like directory structure, in which the top-level directory contains directories `train`, `val`, and `test`, and each of those contains sub-directories of the\ndifferent classes (e.g., `tumor-positive`, `tumor-negative`), where the corresponding patch-level images are located.\nImages can be of any size and will be resized during training and evaluation \u2013 the size is configurable. Put the dataset in the `data/` directory, and consider adding a `classmap.txt` file to indicate the order of the labels. In the example below, class 0 is tumor-negative, and class 1 is tumor-positive.\n```\ntumor-negative\ntumor-positive\n```\n \n"
      },
      "source": "https://raw.githubusercontent.com/SBU-BMI/champkit/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9792363319899912,
      "result": {
        "original_header": "Using other models",
        "type": "Text_excerpt",
        "value": "We use the excellent [`timm`](https://rwightman.github.io/pytorch-image-models/) package to have access to many models. Newly published models tend to be added to `timm` quickly, but there might be cases where you want to use a model that `timm` does not have. In those cases, please add a PyTorch implementation of your model to [`models.py`](models.py). See that file for examples of custom models or custom pretrained weights. Be sure to register your model with `timm` with the decorator `@timm.models.register_model`. This makes it possible to use the model with `timm.create_model(MODEL_NAME)`.\n \n"
      },
      "source": "https://raw.githubusercontent.com/SBU-BMI/champkit/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.977700326963034,
      "result": {
        "original_header": "Frequently asked questions",
        "type": "Text_excerpt",
        "value": "1. How do I get help?\n    - If you have read through this document and still have questions, we encourage you to [create a new issue](https://github.com/kaczmarj/champkit/issues/new/choose). You could also email jakub.kaczmarzyk@stonybrookmedicine.edu, but we would prefer to have these discussions be public. If you have a question, others likely have similar questions!\n2. How do I make a change to ChampKit?\n    - Please use GitHub pull requests to propose changes.\n3. I want to add a dataset to ChampKit.\n    - We are always on the hunt for more patch-based histopathology image classification datasets. If you use a new dataset, please let us know. If it is publicly available, we would love to incorporate it into ChampKit.\n4. How do I use a new dataset?\n    - You can use ChampKit with any single-task, binary/multiclass image classification dataset. The dataset directories should be organized in ImageNet style. Please see [Using other datasets](#using-other-datasets) for more information.\n5. How do I train and evaluate models?\n    - Use `train.py` to train models. See `python train.py --help` for all options.\n    - Use `validate.py` to evaluate models. See `python validate.py --help` for all options.\n    - While this is not strictly required, we use Weights & Biases to run multiple experiments. Please see the sweeps in the `sweeps/` directory for examples of configurations.\n6. I want to evaluate multiple training runs of the same model, but the result is always the same. Help!?\n    - The `train.py` was written (originally by Ross Wightman) to reproduce training results when using the same seed. If you want to train multiple runs of a model, use different `--seed` values in `train.py`. The default is `--seed=42`.\n7. How do I benchmark transfer learning from my favorite self-supervised histology model?\n    - ChampKit includes a self-supervised model from [Ciga et al. (2022)](https://github.com/ozanciga/self-supervised-histopathology). If you want to use a different model, it will have to be added to ChampKit. In general, code will have to be added to `models.py` that downloads the weights and loads them into a PyTorch network. The architecture will have to be implemented if it does not exist in `timm`. Pull requests are welcome! We are happy to work with you to add models to ChampKit.\n8. Why do you want me to use `python -m wandb` instead of `wandb`?\n    - Using `python -m wandb` ensures that you use the wandb command installed in the champkit python environment (assuming the champkit conda environment is activated). If you use `wandb` directly, it is possible that this points to a different python environment than champkit. For example, if one had previously installed wandb with `pip install --user wandb`, the wandb executable would be in `~/.local/bin/wandb` and might be used instead of the wandb in the champkit environment.\n    - In general, using `python -m PROGRAM` is better practice than using `PROGRAM` directly, because `python -m PROGRAM` guarantees we use `PROGRAM` installed in the current python environment. Using `PROGRAM` on its own relies on the `$PATH` variable, and it is possible that there exist multiple `PROGRAM` installations, one of which could appear in `$PATH` before the one we _think_ we are using.\n9. What version of ChampKit am I using?\n    - Use the command `git describe` to find the version and/or commit of the repository. Each change in this repository is associated with a different version and/or commit.\n \n"
      },
      "source": "https://raw.githubusercontent.com/SBU-BMI/champkit/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8672706138657172,
      "result": {
        "original_header": "Uninstalling ChampKit",
        "type": "Text_excerpt",
        "value": "We hope you enjoyed using ChampKit. To uninstall ChampKit and all datasets, remove this directory and the `champkit` conda environment.\n```\nconda deactivate\nconda env remove --name champkit\n```\n \n"
      },
      "source": "https://raw.githubusercontent.com/SBU-BMI/champkit/main/README.md",
      "technique": "supervised_classification"
    }
  ],
  "download": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Download and setup datasets",
        "parent_header": [
          "Installation"
        ],
        "type": "Text_excerpt",
        "value": "ChampKit includes scripts that download and process all included datasets, except MHIST.\nTo access the MHIST dataset, please complete the form at https://bmirds.github.io/MHIST/.\nYou will receive an email with links to the dataset (check spam folder if you don't see it).\nPlease download `images.zip` and `annotations.csv` and place them in `data/task6_precancer_vs_benign_polyps/`.\n\nAfter the MHIST dataset is downloaded, please run the following code to download and setup all of the datasets.\n\nThis can take _a long time_ (2+ hours). One can run the `setup.sh` scripts in parallel, and that might speed things up.\n\n```bash\nconda activate champkit\nbash data/task1_tumor_notumor/setup.sh\nbash data/task2_tils/setup.sh\nbash data/task3_msi_crc_ffpe/setup.sh\nbash data/task4_msi_crc_frozen/setup.sh\nbash data/task5_msi_stad_ffpe/setup.sh\nbash data/task6_precancer_vs_benign_polyps/setup.sh\n```\n\nThese are the different tasks and datasets.\nPlease cite the papers for the datasets you use ([Citations](#citations)).\n\n- Task 1: Tumor versus non-tumor (https://zenodo.org/record/2546921)\n- Task 2: Tumor-infiltrating lymphocyte detection (https://zenodo.org/record/6604094)\n- Task 3: Microsatellite instability detection in colorectal carcinoma (FFPE) (https://zenodo.org/record/2530835)\n- Task 4: Microsatellite instability detection in colorectal carcinoma (frozen) (https://zenodo.org/record/2532612)\n- Task 5: Microsatellite instability detection in stomach adenocarcinoma (FFPE) (https://zenodo.org/record/2530835)\n- Task 6: Precancerous versus benign colorectal polyps (https://bmirds.github.io/MHIST/)\n\n"
      },
      "source": "https://raw.githubusercontent.com/SBU-BMI/champkit/main/README.md",
      "technique": "header_analysis"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/SBU-BMI/champkit/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 4
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/SBU-BMI/champkit/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "SBU-BMI/champkit"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "ChampKit"
      },
      "source": "https://raw.githubusercontent.com/SBU-BMI/champkit/main/README.md",
      "technique": "regular_expression"
    }
  ],
  "has_script_file": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/SBU-BMI/champkit/main/setup.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/SBU-BMI/champkit/main/data/task5_msi_stad_ffpe/setup.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/SBU-BMI/champkit/main/data/task4_msi_crc_frozen/setup.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/SBU-BMI/champkit/main/data/task2_tils/setup.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/SBU-BMI/champkit/main/data/task1_tumor_notumor/setup.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/SBU-BMI/champkit/main/data/task6_precancer_vs_benign_polyps/setup.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/SBU-BMI/champkit/main/data/task3_msi_crc_ffpe/setup.sh"
      },
      "technique": "file_exploration"
    }
  ],
  "images": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/SBU-BMI/champkit/main/assets/figure-overview.webp"
      },
      "source": "https://raw.githubusercontent.com/SBU-BMI/champkit/main/README.md",
      "technique": "regular_expression"
    }
  ],
  "installation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Installation",
        "type": "Text_excerpt",
        "value": "ChampKit requires software and datasets. The next two subsections explain how to install these.\nIf you experience any difficulty, please [submit a new issue](https://github.com/kaczmarj/champkit/issues/new/choose).\n"
      },
      "source": "https://raw.githubusercontent.com/SBU-BMI/champkit/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Software environment",
        "parent_header": [
          "Installation"
        ],
        "type": "Text_excerpt",
        "value": "We use conda to manage Python environments. If you don't have conda, we recommend installing it with [Miniforge](https://github.com/conda-forge/miniforge).\nThen, create the conda environment:\n\n```\nconda env create -f environment.yml -n champkit\nconda activate champkit\n```\n\nWe have tested the software on several x86-64 Linux systems, including Debian bookworm/sid, Red Hat 8.5, and Ubuntu 20.04\nWe have not tested this on Windows, macOS, or non-x86-64 architectures. While we did not test the Windows Subsystem for Linux (WSL), we anticipate that ChampKit will work in that environment (and we encourage you to try!).\nChampKit is tested with CUDA version 11.3, which requires NVIDIA driver `>=450.80.02`.\n"
      },
      "source": "https://raw.githubusercontent.com/SBU-BMI/champkit/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Download and setup datasets",
        "parent_header": [
          "Installation"
        ],
        "type": "Text_excerpt",
        "value": "ChampKit includes scripts that download and process all included datasets, except MHIST.\nTo access the MHIST dataset, please complete the form at https://bmirds.github.io/MHIST/.\nYou will receive an email with links to the dataset (check spam folder if you don't see it).\nPlease download `images.zip` and `annotations.csv` and place them in `data/task6_precancer_vs_benign_polyps/`.\n\nAfter the MHIST dataset is downloaded, please run the following code to download and setup all of the datasets.\n\nThis can take _a long time_ (2+ hours). One can run the `setup.sh` scripts in parallel, and that might speed things up.\n\n```bash\nconda activate champkit\nbash data/task1_tumor_notumor/setup.sh\nbash data/task2_tils/setup.sh\nbash data/task3_msi_crc_ffpe/setup.sh\nbash data/task4_msi_crc_frozen/setup.sh\nbash data/task5_msi_stad_ffpe/setup.sh\nbash data/task6_precancer_vs_benign_polyps/setup.sh\n```\n\nThese are the different tasks and datasets.\nPlease cite the papers for the datasets you use ([Citations](#citations)).\n\n- Task 1: Tumor versus non-tumor (https://zenodo.org/record/2546921)\n- Task 2: Tumor-infiltrating lymphocyte detection (https://zenodo.org/record/6604094)\n- Task 3: Microsatellite instability detection in colorectal carcinoma (FFPE) (https://zenodo.org/record/2530835)\n- Task 4: Microsatellite instability detection in colorectal carcinoma (frozen) (https://zenodo.org/record/2532612)\n- Task 5: Microsatellite instability detection in stomach adenocarcinoma (FFPE) (https://zenodo.org/record/2530835)\n- Task 6: Precancerous versus benign colorectal polyps (https://bmirds.github.io/MHIST/)\n\n"
      },
      "source": "https://raw.githubusercontent.com/SBU-BMI/champkit/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 0.9315894369936799,
      "result": {
        "original_header": "ChampKit",
        "type": "Text_excerpt",
        "value": "This toolkit is meant to be fully reproducible. Please start by installing the software environment.\nThen download the datasets. \nIf you face any problems, please [submit a new issue](https://github.com/kaczmarj/champkit/issues/new/choose)! \n"
      },
      "source": "https://raw.githubusercontent.com/SBU-BMI/champkit/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9994511475516568,
      "result": {
        "original_header": "Reproducing our manuscript",
        "type": "Text_excerpt",
        "value": "To reproduce our [paper](https://doi.org/10.1016/j.cmpb.2023.107631), please follow the steps below. Ideally, we would include a script that reproduces the paper from start to finish, but unfortunately there are some steps that must be done manually. \n1. Get the ChampKit code.\n    ```bash\n    git clone https://github.com/kaczmarj/champkit\n    cd champkit\n    git checkout 51be0b36608a4380fac58bc593039fed041073a3\n    ```\n2. Install software dependencies. See [Software environment](#software-environment) for details.\n    BASH2*\n3. Install datasets. Almost all of the datasets can be downloaded automatically. The Task 6 dataset (MHIST) needs to be downloaded manually. Please go to https://bmirds.github.io/MHIST/#accessing-dataset and complete the registration form. You will receive an automated email with download links. Please download the files `images.zip` and `annotations.csv` and move them to `data/task6_precancer_vs_benign_polyps/`. After you have done this, run the following script to take care of the rest. This script will download approximately 75 GB of data.\n    BASH3*\n    See [Download and setup datasets](#download-and-setup-datasets) for details.\n4. Run experiments. We use Weights & Biases (W&B) sweeps to run and log the experiments. See [`sweeps/sweep_neurips_db.yml`](sweeps/sweep_neurips_db.yml) for the configuration. Please create an account on https://wandb.ai/ if you do not have one, and login on your machine with `python -m wandb login` (activate the champkit conda environment first).\n    - Initialize the W&B sweep:\n        BASH4*\n    - The command above will output a string like `USER/PROJECT/SWEEPID`. Use this in the next command.\n    - Start an agent:\n        BASH5*\n        There are 42 training runs in this sweep. One can start multiple agents to go through the experiments faster. Each agent will poll W&B for the next experiment to run. If you have more agents running, the experiments will be done sooner. Please see [Running multiple experiments](#running-multiple-experiments) for more information.\n    - The sweep requires at least 12 GB of GPU memory per agent. For the manuscript, we used Quadro RTX 8000 GPUs with 48 GB of video memory each.\n5. Evaluate trained models. The following command will evaluate the best model for each run in the sweep (best = lowest validation loss). Results will be printed as they are calculated, and all results are saved to a CSV. The values in this CSV should be very similar to the values reported in the manuscript.\n    BASH6*\n \n"
      },
      "source": "https://raw.githubusercontent.com/SBU-BMI/champkit/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9999999999376996,
      "result": {
        "original_header": "Frequently asked questions",
        "type": "Text_excerpt",
        "value": "1. How do I get help?\n    - If you have read through this document and still have questions, we encourage you to [create a new issue](https://github.com/kaczmarj/champkit/issues/new/choose). You could also email jakub.kaczmarzyk@stonybrookmedicine.edu, but we would prefer to have these discussions be public. If you have a question, others likely have similar questions!\n2. How do I make a change to ChampKit?\n    - Please use GitHub pull requests to propose changes.\n3. I want to add a dataset to ChampKit.\n    - We are always on the hunt for more patch-based histopathology image classification datasets. If you use a new dataset, please let us know. If it is publicly available, we would love to incorporate it into ChampKit.\n4. How do I use a new dataset?\n    - You can use ChampKit with any single-task, binary/multiclass image classification dataset. The dataset directories should be organized in ImageNet style. Please see [Using other datasets](#using-other-datasets) for more information.\n5. How do I train and evaluate models?\n    - Use `train.py` to train models. See `python train.py --help` for all options.\n    - Use `validate.py` to evaluate models. See `python validate.py --help` for all options.\n    - While this is not strictly required, we use Weights & Biases to run multiple experiments. Please see the sweeps in the `sweeps/` directory for examples of configurations.\n6. I want to evaluate multiple training runs of the same model, but the result is always the same. Help!?\n    - The `train.py` was written (originally by Ross Wightman) to reproduce training results when using the same seed. If you want to train multiple runs of a model, use different `--seed` values in `train.py`. The default is `--seed=42`.\n7. How do I benchmark transfer learning from my favorite self-supervised histology model?\n    - ChampKit includes a self-supervised model from [Ciga et al. (2022)](https://github.com/ozanciga/self-supervised-histopathology). If you want to use a different model, it will have to be added to ChampKit. In general, code will have to be added to `models.py` that downloads the weights and loads them into a PyTorch network. The architecture will have to be implemented if it does not exist in `timm`. Pull requests are welcome! We are happy to work with you to add models to ChampKit.\n8. Why do you want me to use `python -m wandb` instead of `wandb`?\n    - Using `python -m wandb` ensures that you use the wandb command installed in the champkit python environment (assuming the champkit conda environment is activated). If you use `wandb` directly, it is possible that this points to a different python environment than champkit. For example, if one had previously installed wandb with `pip install --user wandb`, the wandb executable would be in `~/.local/bin/wandb` and might be used instead of the wandb in the champkit environment.\n    - In general, using `python -m PROGRAM` is better practice than using `PROGRAM` directly, because `python -m PROGRAM` guarantees we use `PROGRAM` installed in the current python environment. Using `PROGRAM` on its own relies on the `$PATH` variable, and it is possible that there exist multiple `PROGRAM` installations, one of which could appear in `$PATH` before the one we _think_ we are using.\n9. What version of ChampKit am I using?\n    - Use the command `git describe` to find the version and/or commit of the repository. Each change in this repository is associated with a different version and/or commit.\n \n"
      },
      "source": "https://raw.githubusercontent.com/SBU-BMI/champkit/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9999998021204899,
      "result": {
        "original_header": "Uninstalling ChampKit",
        "type": "Text_excerpt",
        "value": "We hope you enjoyed using ChampKit. To uninstall ChampKit and all datasets, remove this directory and the `champkit` conda environment.\n```\nconda deactivate\nconda env remove --name champkit\n```\n \n"
      },
      "source": "https://raw.githubusercontent.com/SBU-BMI/champkit/main/README.md",
      "technique": "supervised_classification"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/SBU-BMI/champkit/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "benchmark, benchmarking, deep-learning, histopathology, image-classification, pytorch"
      },
      "technique": "GitHub_API"
    }
  ],
  "license": [
    {
      "confidence": 1,
      "result": {
        "name": "Apache License 2.0",
        "spdx_id": "Apache-2.0",
        "type": "License",
        "url": "https://api.github.com/licenses/apache-2.0",
        "value": "https://api.github.com/licenses/apache-2.0"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "type": "File_dump",
        "value": "                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright 2022 Jakub Kaczmarzyk\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n"
      },
      "source": "https://raw.githubusercontent.com/SBU-BMI/champkit/main/LICENSE",
      "technique": "file_exploration"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "champkit"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "Organization",
        "value": "SBU-BMI"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 85820,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Shell",
        "size": 15132,
        "type": "Programming_language",
        "value": "Shell"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/SBU-BMI/champkit/main/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "related_papers": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://arxiv.org/abs/2206.06862"
      },
      "source": "https://raw.githubusercontent.com/SBU-BMI/champkit/main/README.md",
      "technique": "regular_expression"
    }
  ],
  "releases": [
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "kaczmarj",
          "type": "User"
        },
        "date_created": "2022-06-16T10:41:17Z",
        "date_published": "2022-06-16T10:42:28Z",
        "description": "This release fixes a bug in which the files for task 1 were not included in this repository. While preparing our manuscript, we used a private GitHub repository, and after making the manuscript available, we moved the files from the private repository to this public one. There was a line in the `.gitignore` to ignore the entire task1 directory. This is fixed now.",
        "html_url": "https://github.com/SBU-BMI/champkit/releases/tag/v0.2.0",
        "name": "ChampKit version 0.2.0",
        "release_id": 69604689,
        "tag": "v0.2.0",
        "tarball_url": "https://api.github.com/repos/SBU-BMI/champkit/tarball/v0.2.0",
        "type": "Release",
        "url": "https://api.github.com/repos/SBU-BMI/champkit/releases/69604689",
        "value": "https://api.github.com/repos/SBU-BMI/champkit/releases/69604689",
        "zipball_url": "https://api.github.com/repos/SBU-BMI/champkit/zipball/v0.2.0"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "kaczmarj",
          "type": "User"
        },
        "date_created": "2022-06-14T14:09:20Z",
        "date_published": "2022-06-14T14:11:07Z",
        "description": "We are proud to introduce ChampKit version 0.1.0.",
        "html_url": "https://github.com/SBU-BMI/champkit/releases/tag/v0.1.0",
        "name": "ChampKit version 0.1.0",
        "release_id": 69406913,
        "tag": "v0.1.0",
        "tarball_url": "https://api.github.com/repos/SBU-BMI/champkit/tarball/v0.1.0",
        "type": "Release",
        "url": "https://api.github.com/repos/SBU-BMI/champkit/releases/69406913",
        "value": "https://api.github.com/repos/SBU-BMI/champkit/releases/69406913",
        "zipball_url": "https://api.github.com/repos/SBU-BMI/champkit/zipball/v0.1.0"
      },
      "technique": "GitHub_API"
    }
  ],
  "run": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Running multiple experiments",
        "type": "Text_excerpt",
        "value": "[Weights & Biases](https://wandb.ai/) (W&B) tracks experiments and facilitates running\nhyperparameter searches via sweeps. We use sweeps to train multiple models on multiple\ndatasets, with and without pretraining. W&B requires a (free) account (https://wandb.ai/).\nPlease make an account, and then login on the machine where you will be running the sweep.\n\n```\nconda activate champkit\npython -m wandb login\n```\n\nAfter logging in, initialize the sweep with\n\n```bash\npython -m wandb sweep sweeps/sweep_neurips_db.yml\n```\n\nThis will print `USER/PROJECT/SWEEPID`, which you will use in the next command.\nNow that we ran `python -m wandb sweep`, wandb is waiting us to run \"agents\" that will run through\nall of the combinations in the sweep configuration. When an agent is ready to run a new\njob, it will ask W&B which combination to run next. You can run multiple agents at once.\n\nThe following command will run one agent for this sweep using one GPU (with ID=0).\n\n```\nCUDA_VISIBLE_DEVICES=0 python -m wandb agent USER/PROJECT/SWEEPID\n```\n\nIn practice, I ([@kaczmarj](https://github.com/kaczmarj/)) like to run multiple agents on multiple GPUs in `screen` sessions.\nThe `screen` command runs a program in the background and will keep running it if you log out.\n\n```bash\nfor device in 0 1 2; do\n    CUDA_VISIBLE_DEVICES=$device screen -dmS champkit-$device python -m wandb agent USER/PROJECT/SWEEPID\ndone\n```\n"
      },
      "source": "https://raw.githubusercontent.com/SBU-BMI/champkit/main/README.md",
      "technique": "header_analysis"
    }
  ],
  "somef_missing_categories": [
    "acknowledgement",
    "requirements",
    "contact",
    "contributors",
    "documentation",
    "usage",
    "faq",
    "support",
    "identifier",
    "has_build_file",
    "executable_example"
  ],
  "somef_provenance": {
    "date": "2024-10-04 00:56:40",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 37
      },
      "technique": "GitHub_API"
    }
  ]
}