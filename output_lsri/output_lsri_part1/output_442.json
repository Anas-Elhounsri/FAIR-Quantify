{
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/fmfi-compbio/warpstr"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2022-06-16T15:03:37Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2023-08-22T20:29:55Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "Determining tandem repeat lengths using raw nanopore signals."
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "4.2 Summaries",
        "parent_header": [
          "WarpSTR",
          "4 Output"
        ],
        "type": "Text_excerpt",
        "value": "In the `summaries` directory of each locus there is a myriad of optional visualizations:\n\n- alleles.svg - Summarized predictions of repeat lengths in 1 or 2 groups and for WarpSTR and basecall.\n- collapsed_predictions.svg - Complex repeat structure counts, only for WarpSTR.\n- collapsed_predictions_strand.svg - As above, but further split by strand.\n- complex_genotypes.svg - Summarized complex repeat structure counts in 1 or 2 groups.\n- predictions_cost.svg - Scatterplot of state-wise cost and allele lengths.\n- predictions_phase.svg - Violinplots of repeat lengths in the first and second phase.\n- predictions_strand.svg - Violinplots of repeat lengths as split by strand.\n"
      },
      "source": "https://raw.githubusercontent.com/fmfi-compbio/warpstr/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 0.9975879363327267,
      "result": {
        "original_header": "WarpSTR",
        "type": "Text_excerpt",
        "value": "WarpSTR is an alignment-free algorithm for analysing STR alleles using nanopore sequencing raw reads. The method uses guppy basecalling annotation output for the extraction of region of interest, and dynamic time warping based state automata for calling raw signal data. The tool can be configured to account for complex motifs containing interruptions and other variations such as substitutions or ambiguous bases. \n"
      },
      "source": "https://raw.githubusercontent.com/fmfi-compbio/warpstr/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9623961840010979,
      "result": {
        "original_header": "4 Output",
        "type": "Text_excerpt",
        "value": "The upper path for output is given in the .yaml configuration file as `output` element. Each locus has the separate output - a new subdirectory of this upper path with locus name is created, where the output is stored. \nThe output structure for one locus is as follows:\n```bash\nalignments/         # contains alignments of template flanks with reads\nexpected_signals/   # contains template flanks as sequences and expected signals\nfast5/              # signals extracted as encompasssing the locus, stored as signle .fast5 files\npredictions/        # contains visualizations of automaton alignments and basecalled sequences (see below)\nsummaries/          # contains visualizations produced in the last summarizing phase (see below)\noverview.csv        # .csv file with read information and output\n```\n \n"
      },
      "source": "https://raw.githubusercontent.com/fmfi-compbio/warpstr/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9392161440857276,
      "result": {
        "original_header": "4.1 Predictions",
        "type": "Text_excerpt",
        "value": "In the `predictions` directory of each locus there would be a large variety of outputted files in other subdirectories. \nIn **basecalls** subdirectory are output files related to basecalling, such as `all.fasta` containing basecalled sequences of all reads encompassing the locus as given by SAM/BAM, `basecalls_all.fasta` containing only reads in which flanks were found. This file is further split per strand into `basecalls_reverse.fasta` and `basecalls_template.fasta`. In case of running muscle for MSA - multiple sequence alignment (controlled by advanced_params config), there would be `msa_all.fasta` file with MSA. In case of running summarizing, there would be `group1.fasta` and `group2.fasta` files where would be basecalled sequences split into groups as summarized by the last step of WarpSTR. In such case MSA output would be also created only for basecalled sequences of each group. \nIn `complex_repeat_units.csv` file there is counter for each repeat structure of the complex STR locus. Each row denote a read, and in columns are counts for repeat structures. \nIn **sequences** subdirectory there is analogous information as in **basecalls** subdirectory, but the information is not produced from the basecalled sequences but from sequences as given by WarpSTR. \nIn **DTW_alignments** subdirectory there are visualized alignments of STR signal with automaton (in both stages). Visualizations are truncated to first 2000 values.\n \n"
      },
      "source": "https://raw.githubusercontent.com/fmfi-compbio/warpstr/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9949431477423016,
      "result": {
        "original_header": "5 WarpSTR steps",
        "type": "Text_excerpt",
        "value": "WarpSTR pipeline steps are toggleable in the config file, i.e. you can skip them, by turning them to False:\n```yaml\nsingle_read_extraction: True   # Extracts reads mapped to the locus and stores them in single .fast5 format\nguppy_annotation:       True   # Annotates .fast5 files with mapping between basecalled sequence and the signal\nexp_signal_generation:  True   # Generates expected signals for flanks and repeats\ntr_region_extraction:   True   # Finds tandem repeat region in read using alignment of basecalled sequence and reference repeat sequence\ntr_region_calling:      True   # Uses state automata with DTW alignment to find the number of repeats for each signal\ngenotyping:             True   # Predicts the final allele lengths from the predicted repeat numbers of each read \n```\n \n"
      },
      "source": "https://raw.githubusercontent.com/fmfi-compbio/warpstr/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9356574799438215,
      "result": {
        "original_header": "5.1 Extraction of locus reads",
        "type": "Text_excerpt",
        "value": "In the output directory (given by `output` element) the state of the locus output subdirectory after running this step would be:\n```tree\n{locus_name}\n\u251c\u2500\u2500 fast5\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 {run_id}\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 {read_name1}.fast5\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 {read_name2}.fast5\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 ...\n\u2514\u2500\u2500 overview.csv - index of extracted reads with `name`,`run_id`,`reverse` values for each read\n```\n \n"
      },
      "source": "https://raw.githubusercontent.com/fmfi-compbio/warpstr/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8497615856424979,
      "result": {
        "original_header": "Skipping this step",
        "type": "Text_excerpt",
        "value": "If you have already single .fast5s ready for the locus and want to skip this step, you should simulate the outcome of the first step: \n1. Create the subdirectory in the output directory with the same as the name of the locus in the config.\n2. In the locus subdir create the `fast5/run_id` directory, where you copy single .fast5 reads (See above the output example)\n3. In the locus subdir create `overview.csv` file where for each read signal there should be a row with three columns: `name`,`run_id`,`reverse`, Where `name` is the name as the read_name, and `reverse` having either True or False value, denoting the strand. \nFor example, the overview.csv for the above case would be:\n```csv\nread_name,run_id,reverse\nread_name1,run_id,False\nread_name2,run_id,True\n...\n```\nThen, do not forget to turn off the step in the config file:\n```yaml\nsingle_read_extraction: False   # Extracts reads mapped to the locus and stores them in single .fast5 format\n```\n \n"
      },
      "source": "https://raw.githubusercontent.com/fmfi-compbio/warpstr/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9360020151416155,
      "result": {
        "original_header": "5.2 Extraction of STR regions",
        "type": "Text_excerpt",
        "value": "In this step, reads are basecalled again so they would be annotated with the mapping between basecalls and signal values. This mapping is then used to localize the STR region in signals. \nThe state of the locus output directory after running this step would be:\n```tree\n{locus_name}\n\u251c\u2500\u2500 fast5\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 {run_id}\n\u2502       \u251c\u2500\u2500 annot\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u251c\u2500\u2500 {read_name1}.fast5\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u251c\u2500\u2500 {read_name2}.fast5\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u2514\u2500\u2500 ...\n\u2514\u2500\u2500 overview.csv - index of extracted reads with `name`,`run_id`,`reverse` values for each read.\nIn addition, there would be 'l_start_raw', 'r_end_raw' values, corresponding to signal positions, where starts the left flank and ends the right flank.\n```\n \n#### Skipping this step \nIf you have already .fast5 signals with localized STR regions, you again must simulate the output of this step. The other option is to use our script `prepare_caller_only.py`. It requires two things: \n`--config CONFIG` - the same as you would use further. The important thing is to set the `output` and `loci`\n`--file CSV` - .csv file with one row for .fast5 signal, and these required columns: \n"
      },
      "source": "https://raw.githubusercontent.com/fmfi-compbio/warpstr/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9625349296178117,
      "result": {
        "original_header": "Important notes",
        "type": "Text_excerpt",
        "value": "- The `l_start_raw` and `r_end_raw` can be set approximately, 100-200 positions off should pose no problem for the correct result.\n- The `l_start_raw` and `r_end_raw` must correspond to the flank positions, i.e. the flank length must be set to the same value in the config for `loci`.\n- We currently do not support direct input of signal values of STR for STR calling.\n \n"
      },
      "source": "https://raw.githubusercontent.com/fmfi-compbio/warpstr/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/fmfi-compbio/warpstr/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 1
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/fmfi-compbio/warpstr/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "fmfi-compbio/warpstr"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "WarpSTR"
      },
      "source": "https://raw.githubusercontent.com/fmfi-compbio/warpstr/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "has_build_file": [
    {
      "confidence": 1,
      "result": {
        "format": "dockerfile",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/fmfi-compbio/warpstr/master/Dockerfile"
      },
      "source": "https://raw.githubusercontent.com/fmfi-compbio/warpstr/master/Dockerfile",
      "technique": "file_exploration"
    }
  ],
  "has_script_file": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/fmfi-compbio/warpstr/master/run_test_case.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/fmfi-compbio/warpstr/master/src/guppy_annotate/wrapper.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/fmfi-compbio/warpstr/master/src/guppy_annotate/guppy_annotate.sh"
      },
      "technique": "file_exploration"
    }
  ],
  "installation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "1 Installation",
        "parent_header": [
          "WarpSTR"
        ],
        "type": "Text_excerpt",
        "value": "WarpSTR can be installed using conda or pipenv. To install conda, please follow [the official guide](https://conda.io/projects/conda/en/latest/user-guide/install/index.html). To install pipenv, simple `pip install pipenv` should suffice.\n\nWarpSTR was tested in Ubuntu 20.04 and Ubuntu 22.04. Used Python version is 3.7.\n"
      },
      "source": "https://raw.githubusercontent.com/fmfi-compbio/warpstr/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "1.a) Installing using conda",
        "parent_header": [
          "WarpSTR",
          "1 Installation"
        ],
        "type": "Text_excerpt",
        "value": "Clone this repository. Then, create the conda environment:\n\n```bash\nconda env create -f conda_req.yaml\n```\n\nAfter installation, it is required to activate conda environment:\n\n```bash\nconda activate warpstr\n```\n"
      },
      "source": "https://raw.githubusercontent.com/fmfi-compbio/warpstr/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "1.b) Installing using pipenv",
        "parent_header": [
          "WarpSTR",
          "1 Installation"
        ],
        "type": "Text_excerpt",
        "value": "Clone this repository. The pipenv environment can be installed from Pipfile.lock as follows:\n\n```bash\npipenv sync\n```\n\nAfter installation, it is required to activate the environment:\n\n```bash\npipenv shell\n```\n"
      },
      "source": "https://raw.githubusercontent.com/fmfi-compbio/warpstr/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 0.9804806396392931,
      "result": {
        "original_header": "WarpSTR",
        "type": "Text_excerpt",
        "value": "See our preprint at: <https://www.biorxiv.org/content/10.1101/2022.11.05.515275v1> \nSee below for some quick steps how to install and run WarpSTR, or refer to more detailed [documentation](https://fmfi-compbio.github.io/warpstr/).\n \n"
      },
      "source": "https://raw.githubusercontent.com/fmfi-compbio/warpstr/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9229732901622574,
      "result": {
        "original_header": "4 Output",
        "type": "Text_excerpt",
        "value": "Some output files are optional and can be controlled by the .yaml config file.\n \n"
      },
      "source": "https://raw.githubusercontent.com/fmfi-compbio/warpstr/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.971600534592475,
      "result": {
        "original_header": "5.1 Extraction of locus reads",
        "type": "Text_excerpt",
        "value": "Here, .BAM and multi-fast5 files are required. The following config elements must be set: \n"
      },
      "source": "https://raw.githubusercontent.com/fmfi-compbio/warpstr/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9953798695211697,
      "result": {
        "original_header": "Skipping this step",
        "type": "Text_excerpt",
        "value": "If you have already single .fast5s ready for the locus and want to skip this step, you should simulate the outcome of the first step: \n"
      },
      "source": "https://raw.githubusercontent.com/fmfi-compbio/warpstr/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9725856245856686,
      "result": {
        "original_header": "5.2 Extraction of STR regions",
        "type": "Text_excerpt",
        "value": "Requires executable Guppy basecaller (and completed previous pipeline step). \nIf you have already .fast5 signals with localized STR regions, you again must simulate the output of this step. The other option is to use our script `prepare_caller_only.py`. It requires two things: \n`--config CONFIG` - the same as you would use further. The important thing is to set the `output` and `loci`\n`--file CSV` - .csv file with one row for .fast5 signal, and these required columns: \nThe example case is in the repository in `test/test_caller_only`. To run, provide the reference_path (!!!) there in the config, and run using:\n```bash\npython prepare_caller_only.py --config test/test_caller_only/config_caller_only.yaml --file test/test_caller_only/example.csv\n```\nThis creates a simulated output of the previous step in the `test/test_caller_only/Human_STR_1108232`. Then you can run WarpSTR:\n```bash\npython WarpSTR.py test/test_caller_only/config_caller_only.yaml\n```\n \n"
      },
      "source": "https://raw.githubusercontent.com/fmfi-compbio/warpstr/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9999990884771426,
      "result": {
        "original_header": "6 Additional information",
        "type": "Text_excerpt",
        "value": "Newer .fast5 files are usually VBZ compressed, therefore VBZ plugin for HD5 is required to be installed, so WarpSTR can handle such files. See `https://github.com/nanoporetech/vbz_compression`.\n \n"
      },
      "source": "https://raw.githubusercontent.com/fmfi-compbio/warpstr/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "invocation": [
    {
      "confidence": 0.9271340876391683,
      "result": {
        "original_header": "5.2 Extraction of STR regions",
        "type": "Text_excerpt",
        "value": "The example case is in the repository in `test/test_caller_only`. To run, provide the reference_path (!!!) there in the config, and run using:\n```bash\npython prepare_caller_only.py --config test/test_caller_only/config_caller_only.yaml --file test/test_caller_only/example.csv\n```\nThis creates a simulated output of the previous step in the `test/test_caller_only/Human_STR_1108232`. Then you can run WarpSTR:\n```bash\npython WarpSTR.py test/test_caller_only/config_caller_only.yaml\n```\n \n"
      },
      "source": "https://raw.githubusercontent.com/fmfi-compbio/warpstr/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/fmfi-compbio/warpstr/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ""
      },
      "technique": "GitHub_API"
    }
  ],
  "license": [
    {
      "confidence": 1,
      "result": {
        "name": "Other",
        "spdx_id": "NOASSERTION",
        "type": "License",
        "url": null,
        "value": null
      },
      "technique": "GitHub_API"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "warpstr"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "Organization",
        "value": "fmfi-compbio"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 125526,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Shell",
        "size": 3020,
        "type": "Programming_language",
        "value": "Shell"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Dockerfile",
        "size": 652,
        "type": "Programming_language",
        "value": "Dockerfile"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/fmfi-compbio/warpstr/master/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "releases": [
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "xsitarcik",
          "type": "User"
        },
        "date_created": "2023-09-11T10:53:27Z",
        "date_published": "2023-09-11T10:54:03Z",
        "description": "Fixed plotting for complex homozygous alleles",
        "html_url": "https://github.com/fmfi-compbio/warpstr/releases/tag/v0.3.2",
        "release_id": 120621658,
        "tag": "v0.3.2",
        "tarball_url": "https://api.github.com/repos/fmfi-compbio/warpstr/tarball/v0.3.2",
        "type": "Release",
        "url": "https://api.github.com/repos/fmfi-compbio/warpstr/releases/120621658",
        "value": "https://api.github.com/repos/fmfi-compbio/warpstr/releases/120621658",
        "zipball_url": "https://api.github.com/repos/fmfi-compbio/warpstr/zipball/v0.3.2"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "xsitarcik",
          "type": "User"
        },
        "date_created": "2023-08-30T07:21:45Z",
        "date_published": "2023-08-30T07:22:54Z",
        "description": "Fixed lowercase characters found in reference fasta or in config",
        "html_url": "https://github.com/fmfi-compbio/warpstr/releases/tag/v0.3.1",
        "release_id": 119183383,
        "tag": "v0.3.1",
        "tarball_url": "https://api.github.com/repos/fmfi-compbio/warpstr/tarball/v0.3.1",
        "type": "Release",
        "url": "https://api.github.com/repos/fmfi-compbio/warpstr/releases/119183383",
        "value": "https://api.github.com/repos/fmfi-compbio/warpstr/releases/119183383",
        "zipball_url": "https://api.github.com/repos/fmfi-compbio/warpstr/zipball/v0.3.1"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "xsitarcik",
          "type": "User"
        },
        "date_created": "2022-12-14T13:57:58Z",
        "date_published": "2022-12-14T14:00:08Z",
        "description": "- added script for simulating previous steps of pipeline\r\n- simplified conda reqs\r\n- added pipenv\r\n",
        "html_url": "https://github.com/fmfi-compbio/warpstr/releases/tag/v0.3.0",
        "release_id": 86031640,
        "tag": "v0.3.0",
        "tarball_url": "https://api.github.com/repos/fmfi-compbio/warpstr/tarball/v0.3.0",
        "type": "Release",
        "url": "https://api.github.com/repos/fmfi-compbio/warpstr/releases/86031640",
        "value": "https://api.github.com/repos/fmfi-compbio/warpstr/releases/86031640",
        "zipball_url": "https://api.github.com/repos/fmfi-compbio/warpstr/zipball/v0.3.0"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "xsitarcik",
          "type": "User"
        },
        "date_created": "2022-11-25T15:01:11Z",
        "date_published": "2022-11-25T15:04:54Z",
        "description": "- Based on issue #2 \r\n- Test data with 10 reads for one locus were added. Input test data are stored in `test/test_input` and config file is `test/config.yaml`. Sadly, the test case is not completely independent, as it is required to provide a path to the reference genome and path to Guppy basecaller. \r\n- Added wrapper  `bash run_test_case.sh` for test_case. Run the wrapper script when in WarpSTR directory (and with activated conda environment), which will prompt you to provide the required paths and run the WarpSTR for you. Output files will be then stored in `test/test_output/` as given in the config file.",
        "html_url": "https://github.com/fmfi-compbio/warpstr/releases/tag/v0.2.0",
        "release_id": 84195331,
        "tag": "v0.2.0",
        "tarball_url": "https://api.github.com/repos/fmfi-compbio/warpstr/tarball/v0.2.0",
        "type": "Release",
        "url": "https://api.github.com/repos/fmfi-compbio/warpstr/releases/84195331",
        "value": "https://api.github.com/repos/fmfi-compbio/warpstr/releases/84195331",
        "zipball_url": "https://api.github.com/repos/fmfi-compbio/warpstr/zipball/v0.2.0"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "xsitarcik",
          "type": "User"
        },
        "date_created": "2022-11-09T07:35:19Z",
        "date_published": "2022-11-09T07:46:10Z",
        "description": "WarpSTR tool as corresponding to the initial preprint version on biorxiv.",
        "html_url": "https://github.com/fmfi-compbio/warpstr/releases/tag/v0.1.0",
        "release_id": 82506395,
        "tag": "v0.1.0",
        "tarball_url": "https://api.github.com/repos/fmfi-compbio/warpstr/tarball/v0.1.0",
        "type": "Release",
        "url": "https://api.github.com/repos/fmfi-compbio/warpstr/releases/82506395",
        "value": "https://api.github.com/repos/fmfi-compbio/warpstr/releases/82506395",
        "zipball_url": "https://api.github.com/repos/fmfi-compbio/warpstr/zipball/v0.1.0"
      },
      "technique": "GitHub_API"
    }
  ],
  "run": [
    {
      "confidence": 1,
      "result": {
        "original_header": "2 Running the test case",
        "parent_header": [
          "WarpSTR"
        ],
        "type": "Text_excerpt",
        "value": "In `test/test_input` there is a small test dataset with 10 reads for one locus. There is also the template for config file required by WarpSTR, `test/config_template.yaml`. You can check whether WarpSTR works correctly simply by running:\n\n```bash\nbash run_test_case.sh\n```\n\nWhen running this wrapper script, the script will prompt you to provide the required paths and run the WarpSTR for you using the test data. Output files will be then stored in `test/test_output/` as given in the config file. The script should take approximately 3-5 minutes and at the end, you should see something like:\n\n```text\nResults stored in overview file XY\nAllele lengths as given by WarpSTR: (44, 40)\n```\n"
      },
      "source": "https://raw.githubusercontent.com/fmfi-compbio/warpstr/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "3 Running WarpSTR",
        "parent_header": [
          "WarpSTR"
        ],
        "type": "Text_excerpt",
        "value": "Running WarpSTR is simple as it requires only the path to the configuration file:\n\n```bash\npython WarpSTR.py example/config.yaml\n```\n\nWarpSTR consists of multiple complex steps doing the following:\n\n1. extracting reads encompassing the locus coordinates - requires BAM mapping files and multi .fast5.\n2. extracting STR regions from reads - requires Guppy basecaller.\n3. determining the alelle length for reads.\n4. genotyping alelle lengths and determining zygosity.\n\nIf you want to run a whole WarpSTR pipeline then continue reading, else skip to the [WarpSTR steps](#5-warpstr-steps).\n"
      },
      "source": "https://raw.githubusercontent.com/fmfi-compbio/warpstr/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "3.1 Config file",
        "parent_header": [
          "WarpSTR",
          "3 Running WarpSTR"
        ],
        "type": "Text_excerpt",
        "value": "In the input configuration file (see `example/config.yaml` for an example) you must set the following elements:\n\n- `reference_path` - path to the fasta file - the reference genome, the same which was used for mapping basecalled reads.\n- `guppy_config` - path to the executable Guppy basecaller and info about the sequencing (flowcell and kit).\n- `output` - path to the directory, when WarpSTR will produce output results.\n- `loci` - loci information, see [below](#32-loci-information).\n- `inputs` - input data, see [below](#33-input-data).\n\nThere are also many advanced parameters that are optional to set. List of all parameters are found in `example/advanced_params.yaml`. To set values for those parameters, just copy the elements to your main config and change valeus to your desired values. In other case, default values for those parameters are taken.\n"
      },
      "source": "https://raw.githubusercontent.com/fmfi-compbio/warpstr/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "3.2 Loci information",
        "parent_header": [
          "WarpSTR",
          "3 Running WarpSTR"
        ],
        "type": "Text_excerpt",
        "value": "Information about loci, that are subjects for analysis by WarpSTR, must be described in the config file. An example is described `example/config.yaml`. Each locus must be defined by name and genomic coordinates (these must match with the reference), and either motif or sequence:\n\n```yaml\nname: HD\ncoord: chr4:3,074,878-3,074,967\nmotif: AGC,CGC\n# sequence: (AGC)AACAGCCGCCAC(CGC)\n```\n\nThe `motif` element is recommended for beginners, as the input sequence for WarpSTR state automata is automatically created. In this element, possible repeat units should be provided.\n\nThe second way is to configure the input sequence for automata by yourself in the `sequence` element of the locus. This is not a trivial task, so it is recommended for more advanced users. The other possibility is to use automatic configuration and then modify it by hand. See the preprint for the information about the state automata.\n"
      },
      "source": "https://raw.githubusercontent.com/fmfi-compbio/warpstr/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "3.3 Input data",
        "parent_header": [
          "WarpSTR",
          "3 Running WarpSTR"
        ],
        "type": "Text_excerpt",
        "value": "Required input data are .fast5 files and .bam mapping files. In configuration file, the user is required to provide the path to the upper level path, in the `inputs` element. WarpSTR presumes that your data can come from multiple sequencing runs, but are of the same sample, and thus should be analyzed together, see [documentation](https://fmfi-compbio.github.io/warpstr/) in that case.\n\nThe simple case is like in the test case:\n\n```bash\ntest_input/\n\u2514\u2500\u2500 test_run1\n    \u251c\u2500\u2500 fast5s\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 batch_0.fast5\n    \u2514\u2500\u2500 mapping\n        \u251c\u2500\u2500 mapping.bam\n        \u2514\u2500\u2500 mapping.bam.bai\n```\n\nThe names `test_run1` and `test_input` are then used in the configuration file for the `inputs` element:\n\n```yaml\ninputs:                       \n  - path: test/test_input\n    runs: test_run1\n```\n\nNames of subdirectories such as `fast5s` and `mapping` are not important, but .fast5 files and .bam files must have the correct extension.\n"
      },
      "source": "https://raw.githubusercontent.com/fmfi-compbio/warpstr/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "somef_missing_categories": [
    "citation",
    "acknowledgement",
    "download",
    "requirements",
    "contact",
    "contributors",
    "documentation",
    "usage",
    "faq",
    "support",
    "identifier",
    "executable_example"
  ],
  "somef_provenance": {
    "date": "2024-10-04 00:45:34",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 11
      },
      "technique": "GitHub_API"
    }
  ]
}