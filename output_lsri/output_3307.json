{
  "application_domain": [
    {
      "confidence": 31.11,
      "result": {
        "type": "String",
        "value": "Computer Vision"
      },
      "technique": "supervised_classification"
    }
  ],
  "citation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "References",
        "parent_header": [
          "Deep H3 Loop Prediction"
        ],
        "type": "Text_excerpt",
        "value": "1. Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun, \"Identity Mappings in Deep \n   Residual Networks,\" *ECCV*, 2016.\n   [arXiv:1603.05027](https://arxiv.org/abs/1603.05027)\n2. S. Wang, S. Sun, Z. Li, R. Zhang and J. Xu, \"Accurate De Novo Prediction of \n   Protein Contact Map by Ultra-Deep Learning Model\", *PLOS Computational \n   Biology*, vol. 13, no. 1, p. e1005324, 2017. Available:\n   [10.1371/journal.pcbi.1005324.](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005324)\n3. K. He, X. Zhang, S. Ren, and J. Sun, \u201cDeep Residual Learning for Image Recognition,\u201d \n   2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2016.\n   [arXix:1512.03385](https://arxiv.org/abs/1512.03385)\n4. J. Yang, I. Anishchenko, H. Park, Z. Peng, S. Ovchinnikov and D. Baker, \n   \u201cImproved protein structure prediction using predicted interresidue orientations.,\u201d \n   Proceedings of the National Academy of Sciences, 2020. \n   [PNAS](https://www.pnas.org/content/117/3/1496.short)\n5. B. D. Weitzner, D. Kuroda, N. Marze, J. Xu and J. J. Gray, \u201cBlind prediction \n   performance of RosettaAntibody 3.0: grafting, relaxation, kinematic loop modeling, \n   and full CDR optimization.,\u201d Proteins: Structure, Function, and Bioinformatics, \n   vol. 82, no. 8, pp. 1611\u20131623, 2014.\n   [Wiley](https://onlinelibrary.wiley.com/doi/full/10.1002/prot.24534)\n\n"
      },
      "source": "https://raw.githubusercontent.com/Graylab/deepH3-distances-orientations/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/Graylab/deepH3-distances-orientations"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2020-01-29T19:44:22Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2024-06-27T16:02:15Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 0.9407923495741949,
      "result": {
        "original_header": "Deep H3 Loop Prediction",
        "type": "Text_excerpt",
        "value": "**Note: We no longer recommend the use of DeepH3 for antibody modeling. Instead, we encourage you to try the new [DeepAb](https://github.com/RosettaCommons/DeepAb).** \nA deep residual network architecture to predict probability distributions of \ninter-residue distances and angles for CDR H3 loops in antibodies. This work is protected by https://creativecommons.org/licenses/by-nc/3.0/. Please cite: \n* Ruffolo JA, Guerra C, Mahajan SP, Sulam J, & Gray JJ, \"Geometric Potentials from Deep Learning Improve Prediction of CDR H3 Loop Structures,\" *bioRXiv* 2020. [doi:10.1101/2020.02.09.940254](https://doi.org/10.1101/2020.02.09.940254) \nResNet part of the code is re-implemented from https://github.com/KaimingHe/resnet-1k-layers which was based on \\\nhttps://github.com/facebook/fb.resnet.torch. Network architecture is based on that of Wang et al. ([RaptorX-Contact](https://github.com/j3xugit/RaptorX-Contact)), and geometric descriptors based on Yang et al. ([trRosetta](https://github.com/gjoni/trRosetta)) (references below).\n \n"
      },
      "source": "https://raw.githubusercontent.com/Graylab/deepH3-distances-orientations/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9203704485069111,
      "result": {
        "original_header": "Trained Model",
        "type": "Text_excerpt",
        "value": "Model trained on ~ 1400 antibodies from the SAbDab Database is available in\ndeeph3/models/\n \n"
      },
      "source": "https://raw.githubusercontent.com/Graylab/deepH3-distances-orientations/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8847022629905175,
      "result": {
        "original_header": "Training",
        "type": "Text_excerpt",
        "value": "By default, structures are selected from SAbDab with paired VH/VL chains, a resolution of 3 A or better, and at most 99% sequence identity (ie, the set used in our [original preprint](https://doi.org/10.1101/2020.02.09.940254).) \nNote that you can skip this step since the [model described in our paper is available in this archive](deeph3/models/fully_trained_model.p)\n \n"
      },
      "source": "https://raw.githubusercontent.com/Graylab/deepH3-distances-orientations/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9645507916375416,
      "result": {
        "original_header": "Prediction",
        "type": "Text_excerpt",
        "value": "Output is in the form of a pickle file (\\[fasta_file_basename\\].p) containing the predicted distance and orientation distributions. \n"
      },
      "source": "https://raw.githubusercontent.com/Graylab/deepH3-distances-orientations/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9858606843800238,
      "result": {
        "original_header": "Generating Constraints",
        "type": "Text_excerpt",
        "value": "Output will go to `output_dir/` as a file (for example) `1a0q.constraints` to use in Rosetta as `-constraint_file deeph3/output_dir/1a0q.constraints`. In turn, that file references a set of data files with spline parameters in `output_dir/1a0q.histograms/`. \n"
      },
      "source": "https://raw.githubusercontent.com/Graylab/deepH3-distances-orientations/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/Graylab/deepH3-distances-orientations/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 9
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/Graylab/deepH3-distances-orientations/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "Graylab/deepH3-distances-orientations"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "Deep H3 Loop Prediction"
      },
      "source": "https://raw.githubusercontent.com/Graylab/deepH3-distances-orientations/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "installation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Requirements and Setup",
        "parent_header": [
          "Deep H3 Loop Prediction"
        ],
        "type": "Text_excerpt",
        "value": "torch, tensorboard (2.1 or higher), biopython (see [requirements.txt](requirements.txt) for the complete list). Install with:\n```\npip3 install -r requirements.txt [--user]\n```\n\nBe sure that your PYTHONPATH environment variable has the deepH3-distances-orientations/ directory. On linux, use the\nfollowing command:\n```\nexport PYTHONPATH=\"$PYTHONPATH:/absolute/path/to/deepH3-distances-orientations\"\n```\n"
      },
      "source": "https://raw.githubusercontent.com/Graylab/deepH3-distances-orientations/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 0.915877200475022,
      "result": {
        "original_header": "Deep H3 Loop Prediction",
        "type": "Text_excerpt",
        "value": "**Note: We no longer recommend the use of DeepH3 for antibody modeling. Instead, we encourage you to try the new [DeepAb](https://github.com/RosettaCommons/DeepAb).** \n"
      },
      "source": "https://raw.githubusercontent.com/Graylab/deepH3-distances-orientations/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9953786997700942,
      "result": {
        "original_header": "Training",
        "type": "Text_excerpt",
        "value": "To train a model using a non-redundant set of bound and unbound antibodies \ndownloaded from SAbDab, run:\n```\ncd deeph3\npython3 train.py \n``` \n"
      },
      "source": "https://raw.githubusercontent.com/Graylab/deepH3-distances-orientations/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9271993661497526,
      "result": {
        "original_header": "Prediction",
        "type": "Text_excerpt",
        "value": "Other arguments can be listed using the `--help` or `-h` option.\n \n"
      },
      "source": "https://raw.githubusercontent.com/Graylab/deepH3-distances-orientations/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8116672563466616,
      "result": {
        "original_header": "Training",
        "type": "Text_excerpt",
        "value": "Note that you can skip this step since the [model described in our paper is available in this archive](deeph3/models/fully_trained_model.p)\n \n"
      },
      "source": "https://raw.githubusercontent.com/Graylab/deepH3-distances-orientations/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9588233261831183,
      "result": {
        "original_header": "Generating Constraints",
        "type": "Text_excerpt",
        "value": "To generate constraint files to use in Rosetta, run:\n```\ncd deeph3\npython3 generate_constraints.py [--fasta_file [fasta file path] --model [model file path]]\n```\nThe fasta file must have the following format:\nBASH2* \n"
      },
      "source": "https://raw.githubusercontent.com/Graylab/deepH3-distances-orientations/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "invocation": [
    {
      "confidence": 0.8960687006884549,
      "result": {
        "original_header": "Training",
        "type": "Text_excerpt",
        "value": "To train a model using a non-redundant set of bound and unbound antibodies \ndownloaded from SAbDab, run:\n```\ncd deeph3\npython3 train.py \n``` \n"
      },
      "source": "https://raw.githubusercontent.com/Graylab/deepH3-distances-orientations/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8887633083320252,
      "result": {
        "original_header": "Prediction",
        "type": "Text_excerpt",
        "value": "To predict the binned distance and angle matrices for a given antibody sequence (in a fasta file), run:\n```\ncd deeph3\npython3 predict.py [--fasta_file [fasta file path] --model [model file path]]\n```\nThe fasta file must have the following format:\nBASH2* \n"
      },
      "source": "https://raw.githubusercontent.com/Graylab/deepH3-distances-orientations/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9296113690176773,
      "result": {
        "original_header": "Generating Constraints",
        "type": "Text_excerpt",
        "value": "To generate constraint files to use in Rosetta, run:\n```\ncd deeph3\npython3 generate_constraints.py [--fasta_file [fasta file path] --model [model file path]]\n```\nThe fasta file must have the following format:\nBASH2* \n"
      },
      "source": "https://raw.githubusercontent.com/Graylab/deepH3-distances-orientations/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/Graylab/deepH3-distances-orientations/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ""
      },
      "technique": "GitHub_API"
    }
  ],
  "license": [
    {
      "confidence": 1,
      "result": {
        "name": "Other",
        "spdx_id": "NOASSERTION",
        "type": "License",
        "url": null,
        "value": null
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "type": "File_dump",
        "value": "Creative Commons Legal Code\n\nAttribution-NonCommercial 3.0 Unported\n\n    CREATIVE COMMONS CORPORATION IS NOT A LAW FIRM AND DOES NOT PROVIDE\n    LEGAL SERVICES. DISTRIBUTION OF THIS LICENSE DOES NOT CREATE AN\n    ATTORNEY-CLIENT RELATIONSHIP. CREATIVE COMMONS PROVIDES THIS\n    INFORMATION ON AN \"AS-IS\" BASIS. CREATIVE COMMONS MAKES NO WARRANTIES\n    REGARDING THE INFORMATION PROVIDED, AND DISCLAIMS LIABILITY FOR\n    DAMAGES RESULTING FROM ITS USE.\n\nLicense\n\nTHE WORK (AS DEFINED BELOW) IS PROVIDED UNDER THE TERMS OF THIS CREATIVE\nCOMMONS PUBLIC LICENSE (\"CCPL\" OR \"LICENSE\"). THE WORK IS PROTECTED BY\nCOPYRIGHT AND/OR OTHER APPLICABLE LAW. ANY USE OF THE WORK OTHER THAN AS\nAUTHORIZED UNDER THIS LICENSE OR COPYRIGHT LAW IS PROHIBITED.\n\nBY EXERCISING ANY RIGHTS TO THE WORK PROVIDED HERE, YOU ACCEPT AND AGREE\nTO BE BOUND BY THE TERMS OF THIS LICENSE. TO THE EXTENT THIS LICENSE MAY\nBE CONSIDERED TO BE A CONTRACT, THE LICENSOR GRANTS YOU THE RIGHTS\nCONTAINED HERE IN CONSIDERATION OF YOUR ACCEPTANCE OF SUCH TERMS AND\nCONDITIONS.\n\n1. Definitions\n\n a. \"Adaptation\" means a work based upon the Work, or upon the Work and\n    other pre-existing works, such as a translation, adaptation,\n    derivative work, arrangement of music or other alterations of a\n    literary or artistic work, or phonogram or performance and includes\n    cinematographic adaptations or any other form in which the Work may be\n    recast, transformed, or adapted including in any form recognizably\n    derived from the original, except that a work that constitutes a\n    Collection will not be considered an Adaptation for the purpose of\n    this License. For the avoidance of doubt, where the Work is a musical\n    work, performance or phonogram, the synchronization of the Work in\n    timed-relation with a moving image (\"synching\") will be considered an\n    Adaptation for the purpose of this License.\n b. \"Collection\" means a collection of literary or artistic works, such as\n    encyclopedias and anthologies, or performances, phonograms or\n    broadcasts, or other works or subject matter other than works listed\n    in Section 1(f) below, which, by reason of the selection and\n    arrangement of their contents, constitute intellectual creations, in\n    which the Work is included in its entirety in unmodified form along\n    with one or more other contributions, each constituting separate and\n    independent works in themselves, which together are assembled into a\n    collective whole. A work that constitutes a Collection will not be\n    considered an Adaptation (as defined above) for the purposes of this\n    License.\n c. \"Distribute\" means to make available to the public the original and\n    copies of the Work or Adaptation, as appropriate, through sale or\n    other transfer of ownership.\n d. \"Licensor\" means the individual, individuals, entity or entities that\n    offer(s) the Work under the terms of this License.\n e. \"Original Author\" means, in the case of a literary or artistic work,\n    the individual, individuals, entity or entities who created the Work\n    or if no individual or entity can be identified, the publisher; and in\n    addition (i) in the case of a performance the actors, singers,\n    musicians, dancers, and other persons who act, sing, deliver, declaim,\n    play in, interpret or otherwise perform literary or artistic works or\n    expressions of folklore; (ii) in the case of a phonogram the producer\n    being the person or legal entity who first fixes the sounds of a\n    performance or other sounds; and, (iii) in the case of broadcasts, the\n    organization that transmits the broadcast.\n f. \"Work\" means the literary and/or artistic work offered under the terms\n    of this License including without limitation any production in the\n    literary, scientific and artistic domain, whatever may be the mode or\n    form of its expression including digital form, such as a book,\n    pamphlet and other writing; a lecture, address, sermon or other work\n    of the same nature; a dramatic or dramatico-musical work; a\n    choreographic work or entertainment in dumb show; a musical\n    composition with or without words; a cinematographic work to which are\n    assimilated works expressed by a process analogous to cinematography;\n    a work of drawing, painting, architecture, sculpture, engraving or\n    lithography; a photographic work to which are assimilated works\n    expressed by a process analogous to photography; a work of applied\n    art; an illustration, map, plan, sketch or three-dimensional work\n    relative to geography, topography, architecture or science; a\n    performance; a broadcast; a phonogram; a compilation of data to the\n    extent it is protected as a copyrightable work; or a work performed by\n    a variety or circus performer to the extent it is not otherwise\n    considered a literary or artistic work.\n g. \"You\" means an individual or entity exercising rights under this\n    License who has not previously violated the terms of this License with\n    respect to the Work, or who has received express permission from the\n    Licensor to exercise rights under this License despite a previous\n    violation.\n h. \"Publicly Perform\" means to perform public recitations of the Work and\n    to communicate to the public those public recitations, by any means or\n    process, including by wire or wireless means or public digital\n    performances; to make available to the public Works in such a way that\n    members of the public may access these Works from a place and at a\n    place individually chosen by them; to perform the Work to the public\n    by any means or process and the communication to the public of the\n    performances of the Work, including by public digital performance; to\n    broadcast and rebroadcast the Work by any means including signs,\n    sounds or images.\n i. \"Reproduce\" means to make copies of the Work by any means including\n    without limitation by sound or visual recordings and the right of\n    fixation and reproducing fixations of the Work, including storage of a\n    protected performance or phonogram in digital form or other electronic\n    medium.\n\n2. Fair Dealing Rights. Nothing in this License is intended to reduce,\nlimit, or restrict any uses free from copyright or rights arising from\nlimitations or exceptions that are provided for in connection with the\ncopyright protection under copyright law or other applicable laws.\n\n3. License Grant. Subject to the terms and conditions of this License,\nLicensor hereby grants You a worldwide, royalty-free, non-exclusive,\nperpetual (for the duration of the applicable copyright) license to\nexercise the rights in the Work as stated below:\n\n a. to Reproduce the Work, to incorporate the Work into one or more\n    Collections, and to Reproduce the Work as incorporated in the\n    Collections;\n b. to create and Reproduce Adaptations provided that any such Adaptation,\n    including any translation in any medium, takes reasonable steps to\n    clearly label, demarcate or otherwise identify that changes were made\n    to the original Work. For example, a translation could be marked \"The\n    original work was translated from English to Spanish,\" or a\n    modification could indicate \"The original work has been modified.\";\n c. to Distribute and Publicly Perform the Work including as incorporated\n    in Collections; and,\n d. to Distribute and Publicly Perform Adaptations.\n\nThe above rights may be exercised in all media and formats whether now\nknown or hereafter devised. The above rights include the right to make\nsuch modifications as are technically necessary to exercise the rights in\nother media and formats. Subject to Section 8(f), all rights not expressly\ngranted by Licensor are hereby reserved, including but not limited to the\nrights set forth in Section 4(d).\n\n4. Restrictions. The license granted in Section 3 above is expressly made\nsubject to and limited by the following restrictions:\n\n a. You may Distribute or Publicly Perform the Work only under the terms\n    of this License. You must include a copy of, or the Uniform Resource\n    Identifier (URI) for, this License with every copy of the Work You\n    Distribute or Publicly Perform. You may not offer or impose any terms\n    on the Work that restrict the terms of this License or the ability of\n    the recipient of the Work to exercise the rights granted to that\n    recipient under the terms of the License. You may not sublicense the\n    Work. You must keep intact all notices that refer to this License and\n    to the disclaimer of warranties with every copy of the Work You\n    Distribute or Publicly Perform. When You Distribute or Publicly\n    Perform the Work, You may not impose any effective technological\n    measures on the Work that restrict the ability of a recipient of the\n    Work from You to exercise the rights granted to that recipient under\n    the terms of the License. This Section 4(a) applies to the Work as\n    incorporated in a Collection, but this does not require the Collection\n    apart from the Work itself to be made subject to the terms of this\n    License. If You create a Collection, upon notice from any Licensor You\n    must, to the extent practicable, remove from the Collection any credit\n    as required by Section 4(c), as requested. If You create an\n    Adaptation, upon notice from any Licensor You must, to the extent\n    practicable, remove from the Adaptation any credit as required by\n    Section 4(c), as requested.\n b. You may not exercise any of the rights granted to You in Section 3\n    above in any manner that is primarily intended for or directed toward\n    commercial advantage or private monetary compensation. The exchange of\n    the Work for other copyrighted works by means of digital file-sharing\n    or otherwise shall not be considered to be intended for or directed\n    toward commercial advantage or private monetary compensation, provided\n    there is no payment of any monetary compensation in connection with\n    the exchange of copyrighted works.\n c. If You Distribute, or Publicly Perform the Work or any Adaptations or\n    Collections, You must, unless a request has been made pursuant to\n    Section 4(a), keep intact all copyright notices for the Work and\n    provide, reasonable to the medium or means You are utilizing: (i) the\n    name of the Original Author (or pseudonym, if applicable) if supplied,\n    and/or if the Original Author and/or Licensor designate another party\n    or parties (e.g., a sponsor institute, publishing entity, journal) for\n    attribution (\"Attribution Parties\") in Licensor's copyright notice,\n    terms of service or by other reasonable means, the name of such party\n    or parties; (ii) the title of the Work if supplied; (iii) to the\n    extent reasonably practicable, the URI, if any, that Licensor\n    specifies to be associated with the Work, unless such URI does not\n    refer to the copyright notice or licensing information for the Work;\n    and, (iv) consistent with Section 3(b), in the case of an Adaptation,\n    a credit identifying the use of the Work in the Adaptation (e.g.,\n    \"French translation of the Work by Original Author,\" or \"Screenplay\n    based on original Work by Original Author\"). The credit required by\n    this Section 4(c) may be implemented in any reasonable manner;\n    provided, however, that in the case of a Adaptation or Collection, at\n    a minimum such credit will appear, if a credit for all contributing\n    authors of the Adaptation or Collection appears, then as part of these\n    credits and in a manner at least as prominent as the credits for the\n    other contributing authors. For the avoidance of doubt, You may only\n    use the credit required by this Section for the purpose of attribution\n    in the manner set out above and, by exercising Your rights under this\n    License, You may not implicitly or explicitly assert or imply any\n    connection with, sponsorship or endorsement by the Original Author,\n    Licensor and/or Attribution Parties, as appropriate, of You or Your\n    use of the Work, without the separate, express prior written\n    permission of the Original Author, Licensor and/or Attribution\n    Parties.\n d. For the avoidance of doubt:\n\n     i. Non-waivable Compulsory License Schemes. In those jurisdictions in\n        which the right to collect royalties through any statutory or\n        compulsory licensing scheme cannot be waived, the Licensor\n        reserves the exclusive right to collect such royalties for any\n        exercise by You of the rights granted under this License;\n    ii. Waivable Compulsory License Schemes. In those jurisdictions in\n        which the right to collect royalties through any statutory or\n        compulsory licensing scheme can be waived, the Licensor reserves\n        the exclusive right to collect such royalties for any exercise by\n        You of the rights granted under this License if Your exercise of\n        such rights is for a purpose or use which is otherwise than\n        noncommercial as permitted under Section 4(b) and otherwise waives\n        the right to collect royalties through any statutory or compulsory\n        licensing scheme; and,\n   iii. Voluntary License Schemes. The Licensor reserves the right to\n        collect royalties, whether individually or, in the event that the\n        Licensor is a member of a collecting society that administers\n        voluntary licensing schemes, via that society, from any exercise\n        by You of the rights granted under this License that is for a\n        purpose or use which is otherwise than noncommercial as permitted\n        under Section 4(c).\n e. Except as otherwise agreed in writing by the Licensor or as may be\n    otherwise permitted by applicable law, if You Reproduce, Distribute or\n    Publicly Perform the Work either by itself or as part of any\n    Adaptations or Collections, You must not distort, mutilate, modify or\n    take other derogatory action in relation to the Work which would be\n    prejudicial to the Original Author's honor or reputation. Licensor\n    agrees that in those jurisdictions (e.g. Japan), in which any exercise\n    of the right granted in Section 3(b) of this License (the right to\n    make Adaptations) would be deemed to be a distortion, mutilation,\n    modification or other derogatory action prejudicial to the Original\n    Author's honor and reputation, the Licensor will waive or not assert,\n    as appropriate, this Section, to the fullest extent permitted by the\n    applicable national law, to enable You to reasonably exercise Your\n    right under Section 3(b) of this License (right to make Adaptations)\n    but not otherwise.\n\n5. Representations, Warranties and Disclaimer\n\nUNLESS OTHERWISE MUTUALLY AGREED TO BY THE PARTIES IN WRITING, LICENSOR\nOFFERS THE WORK AS-IS AND MAKES NO REPRESENTATIONS OR WARRANTIES OF ANY\nKIND CONCERNING THE WORK, EXPRESS, IMPLIED, STATUTORY OR OTHERWISE,\nINCLUDING, WITHOUT LIMITATION, WARRANTIES OF TITLE, MERCHANTIBILITY,\nFITNESS FOR A PARTICULAR PURPOSE, NONINFRINGEMENT, OR THE ABSENCE OF\nLATENT OR OTHER DEFECTS, ACCURACY, OR THE PRESENCE OF ABSENCE OF ERRORS,\nWHETHER OR NOT DISCOVERABLE. SOME JURISDICTIONS DO NOT ALLOW THE EXCLUSION\nOF IMPLIED WARRANTIES, SO SUCH EXCLUSION MAY NOT APPLY TO YOU.\n\n6. Limitation on Liability. EXCEPT TO THE EXTENT REQUIRED BY APPLICABLE\nLAW, IN NO EVENT WILL LICENSOR BE LIABLE TO YOU ON ANY LEGAL THEORY FOR\nANY SPECIAL, INCIDENTAL, CONSEQUENTIAL, PUNITIVE OR EXEMPLARY DAMAGES\nARISING OUT OF THIS LICENSE OR THE USE OF THE WORK, EVEN IF LICENSOR HAS\nBEEN ADVISED OF THE POSSIBILITY OF SUCH DAMAGES.\n\n7. Termination\n\n a. This License and the rights granted hereunder will terminate\n    automatically upon any breach by You of the terms of this License.\n    Individuals or entities who have received Adaptations or Collections\n    from You under this License, however, will not have their licenses\n    terminated provided such individuals or entities remain in full\n    compliance with those licenses. Sections 1, 2, 5, 6, 7, and 8 will\n    survive any termination of this License.\n b. Subject to the above terms and conditions, the license granted here is\n    perpetual (for the duration of the applicable copyright in the Work).\n    Notwithstanding the above, Licensor reserves the right to release the\n    Work under different license terms or to stop distributing the Work at\n    any time; provided, however that any such election will not serve to\n    withdraw this License (or any other license that has been, or is\n    required to be, granted under the terms of this License), and this\n    License will continue in full force and effect unless terminated as\n    stated above.\n\n8. Miscellaneous\n\n a. Each time You Distribute or Publicly Perform the Work or a Collection,\n    the Licensor offers to the recipient a license to the Work on the same\n    terms and conditions as the license granted to You under this License.\n b. Each time You Distribute or Publicly Perform an Adaptation, Licensor\n    offers to the recipient a license to the original Work on the same\n    terms and conditions as the license granted to You under this License.\n c. If any provision of this License is invalid or unenforceable under\n    applicable law, it shall not affect the validity or enforceability of\n    the remainder of the terms of this License, and without further action\n    by the parties to this agreement, such provision shall be reformed to\n    the minimum extent necessary to make such provision valid and\n    enforceable.\n d. No term or provision of this License shall be deemed waived and no\n    breach consented to unless such waiver or consent shall be in writing\n    and signed by the party to be charged with such waiver or consent.\n e. This License constitutes the entire agreement between the parties with\n    respect to the Work licensed here. There are no understandings,\n    agreements or representations with respect to the Work not specified\n    here. Licensor shall not be bound by any additional provisions that\n    may appear in any communication from You. This License may not be\n    modified without the mutual written agreement of the Licensor and You.\n f. The rights granted under, and the subject matter referenced, in this\n    License were drafted utilizing the terminology of the Berne Convention\n    for the Protection of Literary and Artistic Works (as amended on\n    September 28, 1979), the Rome Convention of 1961, the WIPO Copyright\n    Treaty of 1996, the WIPO Performances and Phonograms Treaty of 1996\n    and the Universal Copyright Convention (as revised on July 24, 1971).\n    These rights and subject matter take effect in the relevant\n    jurisdiction in which the License terms are sought to be enforced\n    according to the corresponding provisions of the implementation of\n    those treaty provisions in the applicable national law. If the\n    standard suite of rights granted under applicable copyright law\n    includes additional rights not granted under this License, such\n    additional rights are deemed to be included in the License; this\n    License is not intended to restrict the license of any rights under\n    applicable law.\n\n\nCreative Commons Notice\n\n    Creative Commons is not a party to this License, and makes no warranty\n    whatsoever in connection with the Work. Creative Commons will not be\n    liable to You or any party on any legal theory for any damages\n    whatsoever, including without limitation any general, special,\n    incidental or consequential damages arising in connection to this\n    license. Notwithstanding the foregoing two (2) sentences, if Creative\n    Commons has expressly identified itself as the Licensor hereunder, it\n    shall have all rights and obligations of Licensor.\n\n    Except for the limited purpose of indicating to the public that the\n    Work is licensed under the CCPL, Creative Commons does not authorize\n    the use by either party of the trademark \"Creative Commons\" or any\n    related trademark or logo of Creative Commons without the prior\n    written consent of Creative Commons. Any permitted use will be in\n    compliance with Creative Commons' then-current trademark usage\n    guidelines, as may be published on its website or otherwise made\n    available upon request from time to time. For the avoidance of doubt,\n    this trademark restriction does not form part of the License.\n\n    Creative Commons may be contacted at http://creativecommons.org/.\n"
      },
      "source": "https://raw.githubusercontent.com/Graylab/deepH3-distances-orientations/master/LICENSE",
      "technique": "file_exploration"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "deepH3-distances-orientations"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "Organization",
        "value": "Graylab"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 103542,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Graylab/deepH3-distances-orientations/master/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "related_papers": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://arxiv.org/abs/1603.05027](https://arxiv.org/abs/1603.05027)\n2. S. Wang, S. Sun, Z. Li, R. Zhang and J. Xu, \"Accurate De Novo Prediction of \n   Protein Contact Map by Ultra-Deep Learning Model\", *PLOS Computational \n   Biology*, vol. 13, no. 1, p. e1005324, 2017. Available:\n   [10.1371/journal.pcbi.1005324.](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005324)\n3. K. He, X. Zhang, S. Ren, and J. Sun, \u201cDeep Residual Learning for Image Recognition,\u201d \n   2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2016.\n   [arXix:1512.03385](https://arxiv.org/abs/1512.03385)\n4. J. Yang, I. Anishchenko, H. Park, Z. Peng, S. Ovchinnikov and D. Baker, \n   \u201cImproved protein structure prediction using predicted interresidue orientations.,\u201d \n   Proceedings of the National Academy of Sciences, 2020. \n   [PNAS](https://www.pnas.org/content/117/3/1496.short)\n5. B. D. Weitzner, D. Kuroda, N. Marze, J. Xu and J. J. Gray, \u201cBlind prediction \n   performance of RosettaAntibody 3.0: grafting, relaxation, kinematic loop modeling, \n   and full CDR optimization.,\u201d Proteins: Structure, Function, and Bioinformatics, \n   vol. 82, no. 8, pp. 1611\u20131623, 2014.\n   [Wiley](https://onlinelibrary.wiley.com/doi/full/10.1002/prot.24534)\n"
      },
      "source": "https://raw.githubusercontent.com/Graylab/deepH3-distances-orientations/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://arxiv.org/abs/1512.03385"
      },
      "source": "https://raw.githubusercontent.com/Graylab/deepH3-distances-orientations/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://arxiv.org/abs/1603.05027"
      },
      "source": "https://raw.githubusercontent.com/Graylab/deepH3-distances-orientations/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "releases": [
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "jjgray",
          "type": "User"
        },
        "date_created": "2020-03-31T03:58:09Z",
        "date_published": "2020-04-08T18:58:59Z",
        "description": "Submitted revised proceedings paper.",
        "html_url": "https://github.com/Graylab/deepH3-distances-orientations/releases/tag/2a3e8a4",
        "name": "0.2",
        "release_id": 25334452,
        "tag": "2a3e8a4",
        "tarball_url": "https://api.github.com/repos/Graylab/deepH3-distances-orientations/tarball/2a3e8a4",
        "type": "Release",
        "url": "https://api.github.com/repos/Graylab/deepH3-distances-orientations/releases/25334452",
        "value": "https://api.github.com/repos/Graylab/deepH3-distances-orientations/releases/25334452",
        "zipball_url": "https://api.github.com/repos/Graylab/deepH3-distances-orientations/zipball/2a3e8a4"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "jjgray",
          "type": "User"
        },
        "date_created": "2020-02-25T03:19:51Z",
        "date_published": "2020-02-26T22:43:28Z",
        "description": "Submitted proceedings paper and preprint",
        "html_url": "https://github.com/Graylab/deepH3-distances-orientations/releases/tag/9addbbd",
        "name": "0.1",
        "release_id": 24020206,
        "tag": "9addbbd",
        "tarball_url": "https://api.github.com/repos/Graylab/deepH3-distances-orientations/tarball/9addbbd",
        "type": "Release",
        "url": "https://api.github.com/repos/Graylab/deepH3-distances-orientations/releases/24020206",
        "value": "https://api.github.com/repos/Graylab/deepH3-distances-orientations/releases/24020206",
        "zipball_url": "https://api.github.com/repos/Graylab/deepH3-distances-orientations/zipball/9addbbd"
      },
      "technique": "GitHub_API"
    }
  ],
  "requirements": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Requirements and Setup",
        "parent_header": [
          "Deep H3 Loop Prediction"
        ],
        "type": "Text_excerpt",
        "value": "torch, tensorboard (2.1 or higher), biopython (see [requirements.txt](requirements.txt) for the complete list). Install with:\n```\npip3 install -r requirements.txt [--user]\n```\n\nBe sure that your PYTHONPATH environment variable has the deepH3-distances-orientations/ directory. On linux, use the\nfollowing command:\n```\nexport PYTHONPATH=\"$PYTHONPATH:/absolute/path/to/deepH3-distances-orientations\"\n```\n"
      },
      "source": "https://raw.githubusercontent.com/Graylab/deepH3-distances-orientations/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "somef_missing_categories": [
    "acknowledgement",
    "run",
    "download",
    "contact",
    "contributors",
    "documentation",
    "usage",
    "faq",
    "support",
    "identifier",
    "has_build_file",
    "executable_example"
  ],
  "somef_provenance": {
    "date": "2024-10-06 12:19:55",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 34
      },
      "technique": "GitHub_API"
    }
  ]
}