{
  "application_domain": [
    {
      "confidence": 13.86,
      "result": {
        "type": "String",
        "value": "Computer Vision"
      },
      "technique": "supervised_classification"
    }
  ],
  "citation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Citation",
        "parent_header": [
          "EnAET"
        ],
        "type": "Text_excerpt",
        "value": "If you use any part of this code in your research, please cite our [paper](https://ieeexplore.ieee.org/document/9301261):   \n```\n@ARTICLE{EnAET,\n  author={X. {Wang} and D. {Kihara} and J. {Luo} and G. -J. {Qi}},\n  journal={IEEE Transactions on Image Processing}, \n  title={EnAET: A Self-Trained framework for Semi-Supervised and Supervised Learning with Ensemble Transformations}, \n  year={2020},\n  volume={},\n  number={},\n  pages={1-1},\n  doi={10.1109/TIP.2020.3044220}}\n```\n"
      },
      "source": "https://raw.githubusercontent.com/maple-research-lab/EnAET/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "author": "X. {Wang} and D. {Kihara} and J. {Luo} and G. -J. {Qi}",
        "doi": "10.1109/TIP.2020.3044220",
        "format": "bibtex",
        "title": "EnAET: A Self-Trained framework for Semi-Supervised and Supervised Learning with Ensemble Transformations",
        "type": "Text_excerpt",
        "value": "@article{EnAET,\n    doi = {10.1109/TIP.2020.3044220},\n    pages = {1-1},\n    number = {},\n    volume = {},\n    year = {2020},\n    title = {EnAET: A Self-Trained framework for Semi-Supervised and Supervised Learning with Ensemble Transformations},\n    journal = {IEEE Transactions on Image Processing},\n    author = {X. {Wang} and D. {Kihara} and J. {Luo} and G. -J. {Qi}},\n}"
      },
      "source": "https://raw.githubusercontent.com/maple-research-lab/EnAET/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/maple-research-lab/EnAET"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2019-11-20T15:42:27Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2024-01-04T16:39:47Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "EnAET: Self-Trained Ensemble AutoEncoding Transformations for Semi-Supervised Learning"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Introduction",
        "parent_header": [
          "EnAET"
        ],
        "type": "Text_excerpt",
        "value": "Deep neural networks have been successfully applied to many real-world applications. However, these successes rely heavily on large amounts of labeled data, which is expensive to obtain. Recently, Auto-Encoding Transformation (AET) and MixMatch have been proposed and achieved state-of-the-art results for unsupervised and semi-supervised learning, respectively. In this study, we train an Ensemble of Auto-Encoding Transformations (EnAET) to learn from both labeled and unlabeled data based on the embedded representations by decoding both spatial and non-spatial transformations. This distinguishes EnAET from conventional semi-supervised methods that focus on improving prediction consistency and confidence by different models on both unlabeled and labeled examples. In contrast, we propose to explore the role of self-supervised representations in semi-supervised learning under a rich family of transformations. Experiment results on CIFAR-10, CIFAR-100, SVHN and STL10 demonstrate that the proposed EnAET outperforms the state-of-the-art semi-supervised methods by significant margins. In particular, we apply the proposed method to extremely challenging scenarios with only 10 images per class, and show that EnAET can achieve an error rate of 9.35% on CIFAR-10 and 16.92% on SVHN. In addition, EnAET achieves the best result when compared with fully supervised learning using all labeled data with the same network architecture. The performance on CIFAR-10, CIFAR-100 and SVHN with a smaller network is even more competitive than the state-of-the-art of supervised learning methods based on a larger network. We also set a new performance record with an error rate of 1.99% on CIFAR-10 and 4.52% on STL10. \n"
      },
      "source": "https://raw.githubusercontent.com/maple-research-lab/EnAET/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 0.9160722204429047,
      "result": {
        "original_header": "EnAET",
        "type": "Text_excerpt",
        "value": "Codes and all training records for paper: \n> [EnAET: Self-Trained Ensemble AutoEncoding Transformations forSemi-Supervised Learning](https://arxiv.org/abs/1911.09265)\n \n"
      },
      "source": "https://raw.githubusercontent.com/maple-research-lab/EnAET/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9838162379763064,
      "result": {
        "original_header": "Overall Framework",
        "type": "Text_excerpt",
        "value": "<p align=\"center\">\n  <img src=\"figures/EnAET.jpg\" alt=\"EnAET\" width=\"80%\">\n</p> \nThe overall framework of EnAET.For each image x, we apply five different transformations: Projective,Affine,Similarity,Euclidean,CCBS(Color+Contrast+Brightness+Sharpness).    \nThe network is split into three parts: an representation encoder E, a classifier C, and a set of decoders D_k each for a type of transformation t_k. The original input x and all its transformed counterparts t_{k}(x) are fed through the network.  The original and transformed images have a Siamese encoder E and classifier C with shared weights.\n \n"
      },
      "source": "https://raw.githubusercontent.com/maple-research-lab/EnAET/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/maple-research-lab/EnAET/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "faq": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Possible problems and solution",
        "parent_header": [
          "EnAET",
          "Environment SetUp"
        ],
        "type": "Text_excerpt",
        "value": "I always use git to manage my project. From my experience, sometimes the code can't work because of pytorch version and cuda version. When you see any errors during installment, usually it's pytorch version problem. Please come to [PyTorch](https://pytorch.org/) to download the suitable pytorch version for you.\n\n"
      },
      "source": "https://raw.githubusercontent.com/maple-research-lab/EnAET/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 6
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/maple-research-lab/EnAET/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "maple-research-lab/EnAET"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "EnAET"
      },
      "source": "https://raw.githubusercontent.com/maple-research-lab/EnAET/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "has_script_file": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/maple-research-lab/EnAET/master/scripts/run_cifar100_large.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/maple-research-lab/EnAET/master/scripts/run_cifar10_large.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/maple-research-lab/EnAET/master/scripts/ablation.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/maple-research-lab/EnAET/master/scripts/run_svhn_large.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/maple-research-lab/EnAET/master/scripts/run_stl10.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/maple-research-lab/EnAET/master/scripts/run_cifar10.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/maple-research-lab/EnAET/master/scripts/run_svhn.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/maple-research-lab/EnAET/master/scripts/run_cifar100.sh"
      },
      "technique": "file_exploration"
    }
  ],
  "images": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/maple-research-lab/EnAET/master/figures/algorithm.png"
      },
      "source": "https://raw.githubusercontent.com/maple-research-lab/EnAET/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/maple-research-lab/EnAET/master/figures/combine-spatial.jpg"
      },
      "source": "https://raw.githubusercontent.com/maple-research-lab/EnAET/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/maple-research-lab/EnAET/master/figures/combine.jpg"
      },
      "source": "https://raw.githubusercontent.com/maple-research-lab/EnAET/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/maple-research-lab/EnAET/master/Records/cifar10/label250/Accuracy_top1.svg"
      },
      "source": "https://raw.githubusercontent.com/maple-research-lab/EnAET/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/maple-research-lab/EnAET/master/Records/cifar100/label10000/Accuracy_top1.svg"
      },
      "source": "https://raw.githubusercontent.com/maple-research-lab/EnAET/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/maple-research-lab/EnAET/master/Records/SVHN/label100/Accuracy_top1.svg"
      },
      "source": "https://raw.githubusercontent.com/maple-research-lab/EnAET/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/maple-research-lab/EnAET/master/figures/cifar10_cmp.png"
      },
      "source": "https://raw.githubusercontent.com/maple-research-lab/EnAET/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/maple-research-lab/EnAET/master/figures/cifar100_cmp.png"
      },
      "source": "https://raw.githubusercontent.com/maple-research-lab/EnAET/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/maple-research-lab/EnAET/master/figures/svhn_cmp.png"
      },
      "source": "https://raw.githubusercontent.com/maple-research-lab/EnAET/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/maple-research-lab/EnAET/master/figures/stl10_cmp.png"
      },
      "source": "https://raw.githubusercontent.com/maple-research-lab/EnAET/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/maple-research-lab/EnAET/master/figures/large_semi.png"
      },
      "source": "https://raw.githubusercontent.com/maple-research-lab/EnAET/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/maple-research-lab/EnAET/master/figures/small_fully.png"
      },
      "source": "https://raw.githubusercontent.com/maple-research-lab/EnAET/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/maple-research-lab/EnAET/master/figures/large_fully.png"
      },
      "source": "https://raw.githubusercontent.com/maple-research-lab/EnAET/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "installation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "For Beginer",
        "parent_header": [
          "EnAET",
          "Environment SetUp"
        ],
        "type": "Text_excerpt",
        "value": "In order to have a same environment to run my code, you have two options.\n"
      },
      "source": "https://raw.githubusercontent.com/maple-research-lab/EnAET/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "1 Installing with pip3",
        "parent_header": [
          "EnAET",
          "Environment SetUp",
          "For Beginer"
        ],
        "type": "Text_excerpt",
        "value": "```\npip3 install -r requirements.txt --user\n```\nI strongly suggest you do not use this way because it will possible violate your own python configurations and dependencies.\n"
      },
      "source": "https://raw.githubusercontent.com/maple-research-lab/EnAET/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "2 Installing with anaconda",
        "parent_header": [
          "EnAET",
          "Environment SetUp",
          "For Beginer"
        ],
        "type": "Text_excerpt",
        "value": "```\nconda create -n EnAET python=3.6.7\nconda activate EnAET\npip install -r requirements.txt \n```\nEach time when you want to run my code, simply activate the environment by\n```\nconda activate EnAET\nconda deactivate(If you want to exit) \n```"
      },
      "source": "https://raw.githubusercontent.com/maple-research-lab/EnAET/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "For expert",
        "parent_header": [
          "EnAET",
          "Environment SetUp"
        ],
        "type": "Text_excerpt",
        "value": "In order to save time for you to download so many dependencies which may not be used in this project. I prepared a simple and clean dependecy list for expert. Please use pip or conda environment to run:\n```\npip3 install -r min_requirements.txt --user\n```\n"
      },
      "source": "https://raw.githubusercontent.com/maple-research-lab/EnAET/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/maple-research-lab/EnAET/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ""
      },
      "technique": "GitHub_API"
    }
  ],
  "license": [
    {
      "confidence": 1,
      "result": {
        "name": "MIT License",
        "spdx_id": "MIT",
        "type": "License",
        "url": "https://api.github.com/licenses/mit",
        "value": "https://api.github.com/licenses/mit"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "type": "File_dump",
        "value": "MIT License\n\nCopyright (c) 2019 Xiao Wang\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
      },
      "source": "https://raw.githubusercontent.com/maple-research-lab/EnAET/master/LICENSE",
      "technique": "file_exploration"
    }
  ],
  "logo": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/maple-research-lab/EnAET/master/figures/EnAET.jpg"
      },
      "source": "https://raw.githubusercontent.com/maple-research-lab/EnAET/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "EnAET"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "Organization",
        "value": "maple-research-lab"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 337954,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Shell",
        "size": 13997,
        "type": "Programming_language",
        "value": "Shell"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/maple-research-lab/EnAET/master/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "related_papers": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://arxiv.org/abs/1911.09265"
      },
      "source": "https://raw.githubusercontent.com/maple-research-lab/EnAET/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "run": [
    {
      "confidence": 1,
      "result": {
        "original_header": "All command parameters Meaning",
        "parent_header": [
          "EnAET",
          "Running"
        ],
        "type": "Text_excerpt",
        "value": "```\npython3 main.py -h\n```\n"
      },
      "source": "https://raw.githubusercontent.com/maple-research-lab/EnAET/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "CIFAR-10",
        "parent_header": [
          "EnAET",
          "Running",
          "Running Command"
        ],
        "type": "Text_excerpt",
        "value": "```\npython3 main.py --mode=0 -F=tmp_data/cifar --choose=0 --lr=0.002 --lr1=0.1 --batch_size=128 --num_workers=4 --type=0 --KL_Lambda=1.0 --lambda=10.0 --lambda1=7.5 --lambda2=5.0 --lambda3=2.0 --lambda4=0.5 --max_lambda=1 --max_lambda1=0.75 --max_lambda2=0.5 --max_lambda3=0.2 --max_lambda4=0.05 --portion=0.005 --beta=75 --mix_mode=1  --Mixmatch_warm=50 --dataset=cifar10\n```\nThis is for running cifar-10 with 250 labels. When you want to test with different number of labeled data, simply change the --portion.           \nHere I found an interesting thing is that you can only achieve around 91.7% accuracy if you used pytorch higher version. Personally, I suspect this decrease comes from the initialization of network. To solve this, simply update --Mixmatch_warm=200, you will also have the same performance as reported in the paper. For reference, I also keep the training records in the \"Records\" directory.\nSimple instructions for all the parameters used here.\n```\npython3 main.py -h\n--mode default:0, default mode to run\n-F training data path(Automatically download to this path)\n--choose use gpu id \n--lr default:0.002 learning rate for Adam optimizer for main backbone network\n--lr1 default:0.1 learning rate for SGD optimizer for AET regularization network\n--batch_size default:128 (Actually 256 is better, but one gpu can't support)\n--num_workers default:16 number of data loading workers for pytorch dataloader\n--type default:0 0:Wide ResNet-28-2, 1:Wide ResNet-28-2-Large\n--KL_Lambda default:1.0 hyper parameter for KL divergence to control consistency in the framework\n--lambda: warm factor for projective transformation AET regularization\n--lambda1: warm factor for affine transformation AET regularization\n--lambda2: warm factor for similarity transformation AET regularization\n--lambda3: warm factor for euclidean transformation AET regularization\n--lambda4: warm factor for CCBS transformation AET regularization\n--max_lambda: hyper-parameter for projective transformation in AET regularization.\n--max_lambda1: hyper-parameter for affine transformation in AET regularization.\n--max_lambda2: hyper-parameter for similarity transformation in AET regularization.\n--max_lambda3: hyper-parameter for eculidean transformation in AET regularization.\n--max_lambda4: hyper-parameter for CCBS transformation in AET regularization.\n--portion: specify the portion of data used as labeled data\n--beta: hyper parameter for the consistency loss in MixMatch part\n--mix_mode: default:1 specify to use Mosaic augmentation in MixMatch or not\n--Mixmatch_warm: warm factor for MixMatch beta hyper parameter\n--dataset: specify the dataset you will use for training\n```\nWhen you want to run with \"Wide Resnet-28-2-Large\", which requires 4 gpus:    \nsimply change two parameters: --type=1 --choose=0,1,2,3\n```\npython3 main.py --mode=0 -F=tmp_data/cifar --choose=0,1,2,3 --lr=0.002 --lr1=0.1 --batch_size=128 --num_workers=4 --type=1 --KL_Lambda=1.0 --lambda=10.0 --lambda1=7.5 --lambda2=5.0 --lambda3=2.0 --lambda4=0.5 --max_lambda=1 --max_lambda1=0.75 --max_lambda2=0.5 --max_lambda3=0.2 --max_lambda4=0.05 --portion=0.08 --beta=75 --mix_mode=1  --Mixmatch_warm=50 --dataset=cifar10\n```\nThis is for running cifar-10 with 4,000 labels.\n"
      },
      "source": "https://raw.githubusercontent.com/maple-research-lab/EnAET/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "CIFAR100",
        "parent_header": [
          "EnAET",
          "Running",
          "Running Command"
        ],
        "type": "Text_excerpt",
        "value": "Simply change --dataset --portion --beta(follow MixMatch setting)\n```\npython3 main.py --mode=0 -F=tmp_data/cifar --choose=0 --lr=0.002 --lr1=0.1 --batch_size=128 --num_workers=4 --type=0 --KL_Lambda=1.0 --lambda=10.0 --lambda1=7.5 --lambda2=5.0 --lambda3=2.0 --lambda4=0.5 --max_lambda=1 --max_lambda1=0.75 --max_lambda2=0.5 --max_lambda3=0.2 --max_lambda4=0.05 --portion=0.2 --beta=150 --mix_mode=1  --Mixmatch_warm=50 --dataset=cifar100\n```\nThis is the command for running CIFAR100 with 10,000 labels.   \nWhen you want to run with \"Wide Resnet-28-2-Large\", which requires 4 gpus:    \nSimply change --type=1 --choose=0,1,2,3:\n```\npython3 main.py --mode=0 -F=tmp_data/cifar --choose=0,1,2,3 --lr=0.002 --lr1=0.1 --batch_size=128 --num_workers=4 --type=1 --KL_Lambda=1.0 --lambda=10.0 --lambda1=7.5 --lambda2=5.0 --lambda3=2.0 --lambda4=0.5 --max_lambda=1 --max_lambda1=0.75 --max_lambda2=0.5 --max_lambda3=0.2 --max_lambda4=0.05 --portion=0.2 --beta=150 --mix_mode=1  --Mixmatch_warm=50 --dataset=cifar100\n```\nThis is the command for running CIFAR100 with 10,000 labels.\n"
      },
      "source": "https://raw.githubusercontent.com/maple-research-lab/EnAET/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "SVHN",
        "parent_header": [
          "EnAET",
          "Running",
          "Running Command"
        ],
        "type": "Text_excerpt",
        "value": "Simply change --dataset --portion --beta(follow MixMatch setting) -F (change to a different saving path for data)\n```\npython3 main.py --mode=0 -F=tmp_data/SVHN --choose=0 --lr=0.002 --lr1=0.1 --batch_size=128 --num_workers=4 --type=0 --KL_Lambda=1.0 --lambda=10.0 --lambda1=7.5 --lambda2=5.0 --lambda3=2.0 --lambda4=0.5 --max_lambda=1 --max_lambda1=0.75 --max_lambda2=0.5 --max_lambda3=0.2 --max_lambda4=0.05 --portion=0.00342 --beta=250 --mix_mode=1  --Mixmatch_warm=50 --dataset=SVHN\n```\nThis is the command for running SVHN with 250 labels.   \nWhen you want to run with \"Wide Resnet-28-2-Large\", which requires 4 gpus:    \nSimply change --type=1 --choose=0,1,2,3\n``` \npython3 main.py --mode=0 -F=tmp_data/SVHN --choose=0,1,2,3 --lr=0.002 --lr1=0.1 --batch_size=128 --num_workers=4 --type=1 --KL_Lambda=1.0 --lambda=10.0 --lambda1=7.5 --lambda2=5.0 --lambda3=2.0 --lambda4=0.5 --max_lambda=1 --max_lambda1=0.75 --max_lambda2=0.5 --max_lambda3=0.2 --max_lambda4=0.05 --portion=0.01367 --beta=250 --mix_mode=1  --Mixmatch_warm=50 --dataset=SVHN\n```\nThis is the command for running SVHN with 1,000 labels. \n"
      },
      "source": "https://raw.githubusercontent.com/maple-research-lab/EnAET/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "STL10",
        "parent_header": [
          "EnAET",
          "Running",
          "Running Command"
        ],
        "type": "Text_excerpt",
        "value": "Simply change --dataset --portion --beta(follow MixMatch setting) --choose -F (change to a different saving path for data)\n```\npython3 main.py --mode=0 -F=tmp_data/STL10  --choose=0,1,2,3,4,5,6,7 --lr=0.002 --lr1=0.1 --batch_size=128 --num_workers=4 --type=0 --KL_Lambda=1.0 --lambda=10.0 --lambda1=7.5 --lambda2=5.0 --lambda3=2.0 --lambda4=0.5 --max_lambda=1 --max_lambda1=0.75 --max_lambda2=0.5 --max_lambda3=0.2 --max_lambda4=0.05 --portion=0.2 --beta=50 --mix_mode=1  --Mixmatch_warm=500 --dataset=STL10\n```\nThis is the command for running STL10 with 1,000 labels, which requires 8 gpus(2080Ti).\n\nMore training bash scripts which we used is saved in \"scripts\" dir. "
      },
      "source": "https://raw.githubusercontent.com/maple-research-lab/EnAET/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Results and Visualization",
        "parent_header": [
          "EnAET",
          "Running"
        ],
        "type": "Text_excerpt",
        "value": "All the training results will be kept in a subdirectory under \"train_log\" dirctory. \"train.log\" keeps the record of training accuracy, AET loss, MixMatch loss, KL loss, total loss and so on. \"val.log\" keeps the record of model's performance on all the training dataset. \"test.log\" keeps the record of model's performance on all the testing dataset. \"trainlabel.log\" keeps the record of student model's performance on testing dataset.   \nAll records for visualization will be kept in the \"Tensorboard\" directory of current subdirrectory. Simply run \n```\ntensorboard --logdir=Tensorboard --port=9000 --bind_all\n```\nThen you can see the result in [server_ip]:9000 in browser.\n"
      },
      "source": "https://raw.githubusercontent.com/maple-research-lab/EnAET/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Training Records",
        "parent_header": [
          "EnAET",
          "Running"
        ],
        "type": "Text_excerpt",
        "value": "We keep all the training records in \"Records\" directory. For someone want to reproduce our results, I believe it's a very good reference to make sure you are in the correct path.\n"
      },
      "source": "https://raw.githubusercontent.com/maple-research-lab/EnAET/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Resume your training",
        "parent_header": [
          "EnAET",
          "Running"
        ],
        "type": "Text_excerpt",
        "value": "Compared to before, you should specify the -M=[model_path] --resume=1 --start_epoch=[previous_stop_epoch]     \nFor example(with cifar-100 10,000 labels):\n```\npython3 main.py --mode=0 -F=tmp_data/cifar --choose=0 --lr=0.002 --lr1=0.1 --batch_size=128 --num_workers=4 --type=0 --KL_Lambda=1.0 --lambda=10.0 --lambda1=7.5 --lambda2=5.0 --lambda3=2.0 --lambda4=0.5 --max_lambda=1 --max_lambda1=0.75 --max_lambda2=0.5 --max_lambda3=0.2 --max_lambda4=0.05 --portion=0.2 --beta=150 --mix_mode=1  --Mixmatch_warm=50 --dataset=cifar100 --resume=1 -M=[model_path] --start_epoch=292\n```\nHere I will save the checkpoint.pth.tar model under model sub dir of your current log directory (which described before). Please check train.log to make sure your resume step.\n"
      },
      "source": "https://raw.githubusercontent.com/maple-research-lab/EnAET/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "CIFAR-10 250 Labels",
        "parent_header": [
          "EnAET",
          "Running",
          "Resume your training"
        ],
        "type": "Text_excerpt",
        "value": "![Accuracy](Records/cifar10/label250/Accuracy_top1.svg)\nGreen line is the training accuracy on trainset(250 labeled images), blue is the validation set(which is not actually used for validation, it's actually the whole unlabelled data+labeled data in training set), grey is the testing set performance, yellow is the student model's performance on testing set. More details related to loss please check in \"Records\" directory.\n"
      },
      "source": "https://raw.githubusercontent.com/maple-research-lab/EnAET/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "CIFAR-100 10000 Labels",
        "parent_header": [
          "EnAET",
          "Running",
          "Resume your training"
        ],
        "type": "Text_excerpt",
        "value": "![Accuracy](Records/cifar100/label10000/Accuracy_top1.svg)\n"
      },
      "source": "https://raw.githubusercontent.com/maple-research-lab/EnAET/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "SVHN 100 Labels",
        "parent_header": [
          "EnAET",
          "Running",
          "Resume your training"
        ],
        "type": "Text_excerpt",
        "value": "![Accuracy](Records/SVHN/label100/Accuracy_top1.svg)\nI choose this becuase it is very interesting to illustrate how transformation help the learning to become better step by step.\n"
      },
      "source": "https://raw.githubusercontent.com/maple-research-lab/EnAET/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "somef_missing_categories": [
    "acknowledgement",
    "download",
    "requirements",
    "contact",
    "contributors",
    "documentation",
    "support",
    "identifier",
    "has_build_file",
    "executable_example"
  ],
  "somef_provenance": {
    "date": "2024-10-06 11:17:49",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 81
      },
      "technique": "GitHub_API"
    }
  ],
  "usage": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Spatial Transformation",
        "parent_header": [
          "EnAET",
          "Transformation Example"
        ],
        "type": "Text_excerpt",
        "value": "<p align=\"center\">\n  <img src=\"figures/combine-spatial.jpg\" alt=\"Spatial\" width=\"80%\">\n</p>\nThe images are original, projective transformation,  affine transformation,  similarity transformation, euclidean transformation.\n"
      },
      "source": "https://raw.githubusercontent.com/maple-research-lab/EnAET/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Non-Spatial Transformation",
        "parent_header": [
          "EnAET",
          "Transformation Example"
        ],
        "type": "Text_excerpt",
        "value": "<p align=\"center\">\n  <img src=\"figures/combine.jpg\" alt=\"Non-spatial\" width=\"80%\">\n</p>\nThe  images  are  original,    color   transformation,    contrast   transformation,    brightness   transformation,   sharpen   transformation,   color+contrast,color+contrast+brightness, color+contrast+brightness+sharpen\n\n"
      },
      "source": "https://raw.githubusercontent.com/maple-research-lab/EnAET/master/README.md",
      "technique": "header_analysis"
    }
  ]
}