{
  "acknowledgement": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Acknowledgements",
        "parent_header": [
          "Fixed-Point GAN <img src=\"https://img.shields.io/badge/Patent-Pending-yellow\"/>"
        ],
        "type": "Text_excerpt",
        "value": "This is a patent-pending technology. This research has been supported partially by ASU and Mayo Clinic through a Seed Grant and an Innovation Grant, and partially by NIH under Award Number R01HL128785. The content is solely the responsibility of the authors and does not necessarily represent the official views of NIH. This repository has been built upon [yunjey/stargan](https://github.com/yunjey/stargan).\n"
      },
      "source": "https://raw.githubusercontent.com/jlianglab/Fixed-Point-GAN/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "application_domain": [
    {
      "confidence": 67.8,
      "result": {
        "type": "String",
        "value": "Computer Vision"
      },
      "technique": "supervised_classification"
    }
  ],
  "citation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Citation",
        "parent_header": [
          "Fixed-Point GAN <img src=\"https://img.shields.io/badge/Patent-Pending-yellow\"/>"
        ],
        "type": "Text_excerpt",
        "value": "Please cite this work as following:\n\n```\n@inproceedings{siddiquee2019learning,\n  title={Learning Fixed Points in Generative Adversarial Networks: From Image-to-Image Translation to Disease Detection and Localization},\n  author={Rahman Siddiquee, Md Mahfuzur and Zhou, Zongwei and Tajbakhsh, Nima and Feng, Ruibin and Gotway, Michael B and Bengio, Yoshua and Liang, Jianming},\n  booktitle={Proceedings of the IEEE International Conference on Computer Vision},\n  pages={191--200},\n  year={2019}\n}\n```\n"
      },
      "source": "https://raw.githubusercontent.com/jlianglab/Fixed-Point-GAN/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "author": "Rahman Siddiquee, Md Mahfuzur and Zhou, Zongwei and Tajbakhsh, Nima and Feng, Ruibin and Gotway, Michael B and Bengio, Yoshua and Liang, Jianming",
        "format": "bibtex",
        "title": "Learning Fixed Points in Generative Adversarial Networks: From Image-to-Image Translation to Disease Detection and Localization",
        "type": "Text_excerpt",
        "value": "@inproceedings{siddiquee2019learning,\n    year = {2019},\n    pages = {191--200},\n    booktitle = {Proceedings of the IEEE International Conference on Computer Vision},\n    author = {Rahman Siddiquee, Md Mahfuzur and Zhou, Zongwei and Tajbakhsh, Nima and Feng, Ruibin and Gotway, Michael B and Bengio, Yoshua and Liang, Jianming},\n    title = {Learning Fixed Points in Generative Adversarial Networks: From Image-to-Image Translation to Disease Detection and Localization},\n}"
      },
      "source": "https://raw.githubusercontent.com/jlianglab/Fixed-Point-GAN/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/mahfuzmohammad/Fixed-Point-GAN"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2019-10-22T00:57:09Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2024-04-09T01:36:04Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "Official implementation of Fixed-Point GAN - ICCV 2019"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 0.9875338303595798,
      "result": {
        "original_header": "Fixed-Point GAN <img src=\"https://img.shields.io/badge/Patent-Pending-yellow\"/>",
        "type": "Text_excerpt",
        "value": "This repository provides the official PyTorch implementation of Fixed-Point GAN. Fixed-Point GAN introduces fixed-point translation which dramatically reduces artifacts in image-to-image translation and introduces a novel method for disease detection and localization using image-level annotation only. \n<img src=\"images/image-to-image_translation_example.png\" alt=\"Example of image-to-image translation\"/>\n<img src=\"images/disease_detection_localization_example.png\" alt=\"Example of disease detection and localization\"/>\n \n"
      },
      "source": "https://raw.githubusercontent.com/jlianglab/Fixed-Point-GAN/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9967912870437913,
      "result": {
        "original_header": "Abstract",
        "type": "Text_excerpt",
        "value": "Generative adversarial networks (GANs) have ushered in a revolution in image-to-image translation. The development and proliferation of GANs raises an interesting question: can we train a GAN to remove an object, if present, from an image while otherwise preserving the image? Specifically, can a GAN \"virtually heal\" anyone by turning his medical image, with an unknown health status (diseased or healthy), into a healthy one, so that diseased regions could be revealed by subtracting those two images? Such a task requires a GAN to identify a minimal subset of target pixels for domain translation, an ability that we call fixed-point translation, which no GAN is equipped with yet. Therefore, we propose a new GAN, called Fixed-Point GAN, trained by (1) supervising same-domain translation through a conditional identity loss, and (2) regularizing cross-domain translation through revised adversarial, domain classification, and cycle consistency loss. Based on fixed-point translation, we further derive a novel framework for disease detection and localization using only image-level annotation. Qualitative and quantitative evaluations demonstrate that the proposed method outperforms the state of the art in multi-domain image-to-image translation and that it surpasses predominant weakly-supervised localization methods in both disease detection and localization.\n \n"
      },
      "source": "https://raw.githubusercontent.com/jlianglab/Fixed-Point-GAN/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "download": [
    {
      "confidence": 1,
      "result": {
        "original_header": "2. Downloading the dataset",
        "parent_header": [
          "Fixed-Point GAN <img src=\"https://img.shields.io/badge/Patent-Pending-yellow\"/>",
          "Usage"
        ],
        "type": "Text_excerpt",
        "value": "To download the CelebA dataset:\n\n```bash\n$ bash download.sh celeba\n```\n\nTo download the processed BRATS 2013 synthetic dataset:\n\n```bash\n$ bash download.sh brats\n```\n"
      },
      "source": "https://raw.githubusercontent.com/jlianglab/Fixed-Point-GAN/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/jlianglab/Fixed-Point-GAN/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 22
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/mahfuzmohammad/Fixed-Point-GAN/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "mahfuzmohammad/Fixed-Point-GAN"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "Fixed-Point GAN "
      },
      "source": "https://raw.githubusercontent.com/jlianglab/Fixed-Point-GAN/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "has_script_file": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/jlianglab/Fixed-Point-GAN/master/download.sh"
      },
      "technique": "file_exploration"
    }
  ],
  "images": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "http://raw.githubusercontent.com/jlianglab/Fixed-Point-GAN/master/images/image-to-image_translation_example.png"
      },
      "source": "https://raw.githubusercontent.com/jlianglab/Fixed-Point-GAN/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "http://raw.githubusercontent.com/jlianglab/Fixed-Point-GAN/master/images/disease_detection_localization_example.png"
      },
      "source": "https://raw.githubusercontent.com/jlianglab/Fixed-Point-GAN/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/mahfuzmohammad/Fixed-Point-GAN/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ""
      },
      "technique": "GitHub_API"
    }
  ],
  "license": [
    {
      "confidence": 1,
      "result": {
        "name": "Other",
        "spdx_id": "NOASSERTION",
        "type": "License",
        "url": null,
        "value": null
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "type": "File_dump",
        "value": "Copyright 2019 Arizona Board of Regents for and on behalf of Arizona State University, a body corporate \nPatent Pending in the United States of America\n\nLICENSE\n=======\n\nArizona Board of Regents, for and on behalf of Arizona State University, a body corporate (\u201cLicensor\u201d) offers its \u201cLearning Fixed Points in Generative Adversarial Networks: From Image-to-Image Translation to Disease Detection and Localization\u201d project (Tech ID no. M19-117L) (the \u201cWork\u201d) solely for non-commercial use under the following terms and conditions:\n1. Definitions.\n   \"License\" means the terms and conditions for use, reproduction, and distribution of the Work set forth in this document.\n   \"You\" (or \"Your\") shall mean an individual or entity exercising permissions granted by this License.\n   \"Source\" form means the preferred form for making modifications, including but not limited to software source code, documentation source, and configuration files.\n   \"Object\" form means any form resulting from mechanical transformation or translation of a Source form, including but not limited to compiled object code, generated documentation, and conversions to other media types.\n   \"Work\" shall mean the work(s) of authorship, whether in Source or Object form, made available under the License, as identified above.\n   \"Derivative Works\" means any work, whether in Source or Object form, that incorporates, is based on, or is otherwise derived from the Work or from any other Derivative Work authorized under this License and whereby such work constitutes, as a whole, a separate original work of authorship. For the purposes of this License, Derivative Works do not include works that remain separable from, or merely link (or bind by name) to the interfaces of, the Work and Derivative Works thereof.\n   \"Contribution\" shall mean any work of authorship, including the original version of the Work and any modifications or additions to that Work that is intentionally submitted to Licensor for inclusion in the Work by the copyright owner of the submission or by an individual authorized to submit on behalf of the copyright owner. For the purposes of this definition, \"submitted\" means any form of electronic, verbal, or written communication sent to the Licensor or its representatives, including but not limited to communication on electronic mailing lists, source code control systems, and issue tracking systems that are managed by, or on behalf of, the Licensor for the purpose of discussing and improving the Work, but excluding communication that is conspicuously marked or otherwise designated in writing by the copyright owner as \"Not a Contribution.\"\n   \"Contributor\" shall mean Licensor and any individual or entity on behalf of whom a Contribution has been received by Licensor and subsequently incorporated within the Work.\n\n2. Grant of Copyright License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, revocable (as stated in this section) right to perform any or all of the following actions solely for academic and other non-commercial research purposes: reproduce, prepare Derivative Works of, publicly display, publicly perform, sublicense, and distribute the Work and such Derivative Works in Source or Object. Any person or entity wishing to make a commercial use of the Work or a Derivative Work must enter into a separate written agreement with the Licensor and, in the case of a Derivative Work, any other applicable copyright owner of that Derivative Work. For the avoidance of doubt, no licenses to use the Work for commercial or for-profit purposes are granted hereunder. If Licensor determines in its sole discretion that You have exceeded the scope or otherwise breached the terms of the License granted herein, it shall have the right to terminate the License in addition to all other remedies available to it under common law, by statute, and in equity.\n\n3. Grant of Patent License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, revocable (as stated in this section) right to make, have made, use, and import the Work solely for academic and other non-commercial research purposes; provided that such license applies only to those patent claims licensable by such Contributor that are necessarily infringed by their Contribution(s) alone or by combination of their Contribution(s) with the Work. Any person or entity wishing to make a commercial use of the Work or a Derivative Work must enter into a separate written agreement with the Licensor and, in the case of a Derivative Work, any other applicable patent owner with claims pertaining to that Derivative Work. For the avoidance of doubt, no licenses to use the Work for commercial or for-profit purposes are granted hereunder. If You institute patent litigation against any individual or entity (including a cross-claim or counterclaim in a lawsuit) alleging that the Work or a Contribution incorporated within the Work constitutes direct or contributory patent infringement, then any patent licenses granted to You under this License for that Work or such Contribution shall terminate as of the date such litigation is filed. If Licensor determines in its sole discretion that You have exceeded the scope or otherwise breached the terms of the License granted herein, it shall have the right to terminate the License in addition to all other remedies available to it under common law, by statute, and in equity.\n\n4. Redistribution. You may reproduce and distribute copies of the Work or Derivative Works thereof in any medium, with or without modifications, and in Source or Object form, provided that You meet the following conditions:\n   (a) The reproduction and distribution is only for academic or other non-commercial research purposes;\n   (b) You must give any other recipients of the Work or Derivative Works a copy of this License;\n   (c) You must cause any modified files to carry prominent notices stating that You changed the files and include in a NOTICE text file a description of Your changes; \n   (d) You must retain, in the Source form of any Derivative Work that You distribute, all copyright, patent, trademark, and attribution notices from the Source form of the Work, except for notices that do not pertain to any portion of the Derivative Work;\n   (e) If the Work includes a \"NOTICE\" text file as part of its distribution, then any Derivative Work that You distribute must include a readable copy of the attribution notices contained within such NOTICE file, except for notices that do not pertain to any part of the Derivative Work, in at least one of the following places: within a NOTICE text file distributed as part of the Derivative Work; within the Source form or documentation, if provided along with the Derivative Work; or, within a display generated by the Derivative Work, if and wherever such third-party notices normally appear. The contents of the NOTICE file are for informational purposes only and do not modify the License. You may add Your own attribution notices within Derivative Works that You distribute, alongside or as an addendum to the NOTICE text from the Work, provided that such additional attribution notices cannot be construed as modifying the License. You may add Your own copyright statement to Your modifications and may provide additional or different license terms and conditions for use, reproduction, or distribution of Your modifications, or for any such Derivative Works as a whole, provided Your use, reproduction, and distribution of the Work otherwise complies with all the terms and conditions stated in this License.\n\n5. Submission of Contributions. Unless You explicitly state otherwise, any Contribution intentionally submitted for inclusion in the Work by You to the Licensor shall be under the terms and conditions of this License, without any additional terms or conditions.  Notwithstanding the above, nothing herein shall supersede or modify the terms of any separate agreement you may have executed or may execute with Licensor regarding such Contributions.\n\n6. Trademarks. This License does not grant permission to use the trade names, trademarks, service marks, or product names of the Licensor. Pursuant to nominative fair use principles, you may merely identify Licensor as the original author of the Work.\n\n7. Disclaimer of Warranty. Unless required by applicable law or agreed to in writing, Licensor provides the Work (and each Contributor provides its Contributions) on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND.  LICENSOR HEREBY DISCLAIMS ALL WARRANTIES, WHETHER EXPRESS, IMPLIED, STATUTORY OR OTHER (INCLUDING ALL WARRANTIES ARISING FROM COURSE OF DEALING, USAGE OR TRADE PRACTICE), AND SPECIFICALLY DISCLAIMS ALL IMPLIED WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, TITLE AND NON-INFRINGEMENT. WITHOUT LIMITING THE FOREGOING, LICENSOR MAKES NO WARRANTY OF ANY KIND THAT THE WORK, OR ANY OTHER LICENSOR OR THIRD-PARTY GOODS, SERVICES, TECHNOLOGIES OR MATERIALS (INCLUDING ANY SOFTWARE OR HARDWARE), OR ANY PRODUCTS OR RESULTS OF THE USE OF ANY OF THEM, WILL MEET YOUR OR ANY OTHER PERSONS' REQUIREMENTS, OPERATE WITHOUT INTERRUPTION, ACHIEVE ANY INTENDED RESULT, BE COMPATIBLE OR WORK WITH ANY OTHER GOODS, SERVICES, TECHNOLOGIES OR MATERIALS (INCLUDING ANY SOFTWARE, HARDWARE, SYSTEM OR NETWORK), OR BE SECURE, ACCURATE, COMPLETE, FREE OF HARMFUL CODE OR ERROR FREE. ALL OPEN-SOURCE COMPONENTS AND OTHER THIRD-PARTY MATERIALS ARE PROVIDED \"AS IS\" AND ANY REPRESENTATION OR WARRANTY OF OR CONCERNING ANY OF THEM IS STRICTLY BETWEEN YOU AND THE THIRD-PARTY OWNER OR DISTRIBUTOR OF SUCH OPEN-SOURCE COMPONENTS AND THIRD-PARTY MATERIALS. You are solely responsible for determining the appropriateness of using or redistributing the Work and assume any risks associated with Your exercise of permissions under this License.\n\n8. Limitation of Liability. UNLESS REQUIRED BY APPLICABLE LAW OR OTHERWISE AGREED IN WRITING, IN NO EVENT WILL LICENSOR OR ANY CONTRIBUTOR BE LIABLE FOR DAMAGES UNDER OR IN CONNECTION WITH THIS LICENSE OR ITS SUBJECT MATTER UNDER ANY LEGAL OR EQUITABLE THEORY, INCLUDING BREACH OF CONTRACT, TORT (INCLUDING NEGLIGENCE), STRICT LIABILITY AND OTHERWISE, FOR ANY (a) INCREASED COSTS, DIMINUTION IN VALUE OR LOST BUSINESS, PRODUCTION, REVENUES OR PROFITS, (b) LOSS OF GOODWILL OR REPUTATION, (c) USE, INABILITY TO USE, LOSS, INTERRUPTION, DELAY OR RECOVERY OF ANY LICENSED SOFTWARE[ OR OPEN-SOURCE COMPONENTS OR OTHER THIRD-PARTY MATERIALS], (d) LOSS, DAMAGE, CORRUPTION OR RECOVERY OF DATA, OR BREACH OF DATA OR SYSTEM SECURITY, (e) COST OF REPLACEMENT GOODS OR SERVICES, OR (e) CONSEQUENTIAL, INCIDENTAL, INDIRECT, EXEMPLARY, SPECIAL, ENHANCED OR PUNITIVE DAMAGES, IN EACH CASE REGARDLESS OF WHETHER SUCH PERSONS WERE ADVISED OF THE POSSIBILITY OF SUCH LOSSES OR DAMAGES OR SUCH LOSSES OR DAMAGES WERE OTHERWISE FORESEEABLE, AND NOTWITHSTANDING THE FAILURE OF ANY AGREED OR OTHER REMEDY OF ITS ESSENTIAL PURPOSE\n\n9. PyTorch Library. The Work includes and is implemented on the PyTorch library. The PyTorch library is offered under the BSD License as follows:\n\nFrom PyTorch:\n\nCopyright (c) 2016-     Facebook, Inc            (Adam Paszke)\nCopyright (c) 2014-     Facebook, Inc            (Soumith Chintala)\nCopyright (c) 2011-2014 Idiap Research Institute (Ronan Collobert)\nCopyright (c) 2012-2014 Deepmind Technologies    (Koray Kavukcuoglu)\nCopyright (c) 2011-2012 NEC Laboratories America (Koray Kavukcuoglu)\nCopyright (c) 2011-2013 NYU                      (Clement Farabet)\nCopyright (c) 2006-2010 NEC Laboratories America (Ronan Collobert, Leon Bottou, Iain Melvin, Jason Weston)\nCopyright (c) 2006      Idiap Research Institute (Samy Bengio)\nCopyright (c) 2001-2004 Idiap Research Institute (Ronan Collobert, Samy Bengio, Johnny Mariethoz)\n\nFrom Caffe2:\n\nCopyright (c) 2016-present, Facebook Inc. All rights reserved.\n\nAll contributions by Facebook:\nCopyright (c) 2016 Facebook Inc.\n \nAll contributions by Google:\nCopyright (c) 2015 Google Inc.\nAll rights reserved.\n \nAll contributions by Yangqing Jia:\nCopyright (c) 2015 Yangqing Jia\nAll rights reserved.\n \nAll contributions from Caffe:\nCopyright(c) 2013, 2014, 2015, the respective contributors\nAll rights reserved.\n \nAll other contributions:\nCopyright(c) 2015, 2016 the respective contributors\nAll rights reserved.\n \nCaffe2 uses a copyright model similar to Caffe: each contributor holds\ncopyright over their contributions to Caffe2. The project versioning records\nall such contribution and copyright details. If a contributor wants to further\nmark their specific copyright on a particular contribution, they should\nindicate their copyright solely in the commit message of the change when it is\ncommitted.\n\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n\n1. Redistributions of source code must retain the above copyright\n   notice, this list of conditions and the following disclaimer.\n\n2. Redistributions in binary form must reproduce the above copyright\n   notice, this list of conditions and the following disclaimer in the\n   documentation and/or other materials provided with the distribution.\n\n3. Neither the names of Facebook, Deepmind Technologies, NYU, NEC Laboratories America\n   and IDIAP Research Institute nor the names of its contributors may be\n   used to endorse or promote products derived from this software without\n   specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\nARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE\nLIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\nCONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\nSUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\nINTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\nCONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\nARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\nPOSSIBILITY OF SUCH DAMAGE.\n"
      },
      "source": "https://raw.githubusercontent.com/jlianglab/Fixed-Point-GAN/master/LICENSE",
      "technique": "file_exploration"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "Fixed-Point-GAN"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "User",
        "value": "mahfuzmohammad"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 35966,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Shell",
        "size": 1494,
        "type": "Programming_language",
        "value": "Shell"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/jlianglab/Fixed-Point-GAN/master/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "related_papers": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://arxiv.org/abs/1908.06965"
      },
      "source": "https://raw.githubusercontent.com/jlianglab/Fixed-Point-GAN/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "somef_missing_categories": [
    "installation",
    "run",
    "requirements",
    "contact",
    "contributors",
    "documentation",
    "faq",
    "support",
    "identifier",
    "has_build_file",
    "executable_example"
  ],
  "somef_provenance": {
    "date": "2024-10-06 08:22:41",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 98
      },
      "technique": "GitHub_API"
    }
  ],
  "usage": [
    {
      "confidence": 1,
      "result": {
        "original_header": "0. Cloning the repository",
        "parent_header": [
          "Fixed-Point GAN <img src=\"https://img.shields.io/badge/Patent-Pending-yellow\"/>",
          "Usage"
        ],
        "type": "Text_excerpt",
        "value": "```bash\n$ git clone https://github.com/mahfuzmohammad/Fixed-Point-GAN.git\n$ cd Fixed-Point-GAN/\n```\n"
      },
      "source": "https://raw.githubusercontent.com/jlianglab/Fixed-Point-GAN/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "1. Creating python environment",
        "parent_header": [
          "Fixed-Point GAN <img src=\"https://img.shields.io/badge/Patent-Pending-yellow\"/>",
          "Usage"
        ],
        "type": "Text_excerpt",
        "value": "```bash\n$ conda env create -f conda_env/conda_env_pytorch0.2.yml\n$ source activate pytorch0.2\n$ cat conda_env/pip_pytorch0.2.txt | xargs -n 1 pip install\n```\n"
      },
      "source": "https://raw.githubusercontent.com/jlianglab/Fixed-Point-GAN/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "3. Training",
        "parent_header": [
          "Fixed-Point GAN <img src=\"https://img.shields.io/badge/Patent-Pending-yellow\"/>",
          "Usage"
        ],
        "type": "Text_excerpt",
        "value": "Training on CelebA dataset\n\n```bash\n$ python main.py --mode train --dataset CelebA --image_size 128 --c_dim 5 \\\n                 --sample_dir celeba/samples \\\n                 --log_dir celeba/logs \\\n                 --model_save_dir celeba/models \\\n                 --result_dir celeba/results \\\n                 --selected_attrs Black_Hair Blond_Hair Brown_Hair Male Young --lambda_id 10\n```\n\nTraining on BRATS dataset\n\n```bash\n$ python main.py --mode train --dataset BRATS --crop_size 256 --image_size 256 --c_dim 1 \\\n                 --image_dir data/brats/syn \\\n                 --sample_dir brats_syn_256_lambda0.1/samples \\\n                 --log_dir brats_syn_256_lambda0.1/logs \\\n                 --model_save_dir brats_syn_256_lambda0.1/models \\\n                 --result_dir brats_syn_256_lambda0.1/results \\\n                 --batch_size 8 --num_workers 4 --lambda_id 0.1 --num_iters 300000\n```\n"
      },
      "source": "https://raw.githubusercontent.com/jlianglab/Fixed-Point-GAN/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "4. Testing",
        "parent_header": [
          "Fixed-Point GAN <img src=\"https://img.shields.io/badge/Patent-Pending-yellow\"/>",
          "Usage"
        ],
        "type": "Text_excerpt",
        "value": "Testing on CelebA dataset\n\n```bash\n$ python main.py --mode test --dataset CelebA --image_size 128 --c_dim 5 \\\n                 --sample_dir celeba/samples \\\n                 --log_dir celeba/logs \\\n                 --model_save_dir celeba/models \\\n                 --result_dir celeba/results \\\n                 --selected_attrs Black_Hair Blond_Hair Brown_Hair Male Young --lambda_id 10\n```\n\nTesting on BRATS dataset\n\n```bash\n$ python main.py --mode test_brats --dataset BRATS --crop_size 256 --image_size 256 --c_dim 1 \\\n                 --image_dir data/brats/syn \\\n                 --sample_dir brats_syn_256_lambda0.1/samples \\\n                 --log_dir brats_syn_256_lambda0.1/logs \\\n                 --model_save_dir brats_syn_256_lambda0.1/models \\\n                 --result_dir brats_syn_256_lambda0.1/results \\\n                 --batch_size 16 --num_workers 4 --lambda_id 0.1 --test_iters 300000\n```\n"
      },
      "source": "https://raw.githubusercontent.com/jlianglab/Fixed-Point-GAN/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "5. Testing using pretrained models",
        "parent_header": [
          "Fixed-Point GAN <img src=\"https://img.shields.io/badge/Patent-Pending-yellow\"/>",
          "Usage"
        ],
        "type": "Text_excerpt",
        "value": "Testing on CelebA dataset using pretrained models\n\n```bash\n$ bash download.sh pretrained_celeba_128\n$ python main.py --mode test --dataset CelebA --image_size 128 --c_dim 5 \\\n                 --sample_dir celeba/samples \\\n                 --log_dir celeba/logs \\\n                 --model_save_dir pretrained_models/celeba \\\n                 --result_dir celeba/results \\\n                 --selected_attrs Black_Hair Blond_Hair Brown_Hair Male Young --lambda_id 10\n```\n\nTesting on BRATS dataset using pretrained models\n\n```bash\n$ bash download.sh pretrained_brats_256\n$ python main.py --mode test_brats --dataset BRATS --crop_size 256 --image_size 256 --c_dim 1 \\\n                 --image_dir data/brats/syn --sample_dir brats_syn_256_lambda0.1/samples \\\n                 --log_dir brats_syn_256_lambda0.1/logs \\\n                 --model_save_dir pretrained_models/brats_syn_256_lambda0.1 \\\n                 --result_dir brats_syn_256_lambda0.1/results \\\n                 --batch_size 16 --num_workers 4 --lambda_id 0.1 --test_iters 300000\n$ python brats_auc.py\n```\n"
      },
      "source": "https://raw.githubusercontent.com/jlianglab/Fixed-Point-GAN/master/README.md",
      "technique": "header_analysis"
    }
  ]
}