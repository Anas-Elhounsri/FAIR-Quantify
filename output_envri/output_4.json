{
  "application_domain": [
    {
      "confidence": 29.49,
      "result": {
        "type": "String",
        "value": "Computer Vision"
      },
      "technique": "supervised_classification"
    }
  ],
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/akhilvreddy/Rutgers-ECE491"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2023-01-21T18:40:55Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2024-06-24T15:48:54Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "Independent Study"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Introduction",
        "parent_header": [
          "Special Problems, ECE491"
        ],
        "type": "Text_excerpt",
        "value": "The main goal of this research is to recover signals in the presence of Speckle Noise. The way this can be done is using Machine Learning, Autoencoders, and algorithms based off that. My approach, code, algorithms, and process will be outlined below.\n"
      },
      "source": "https://raw.githubusercontent.com/akhilvreddy/ECE491-SpecialProblems/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Motivation",
        "parent_header": [
          "Special Problems, ECE491",
          "Introduction"
        ],
        "type": "Text_excerpt",
        "value": "There are a wide range of computational imaging systems that illuminate the object of interest\nby coherent light. Examples of such imaging systems are synthetic aperture radar (SAR) and\ndigital holography. These systems all suffer from a very particular type of noise referred to as\nspeckle noise. Speckle noise is very different and than typical additive noise, since it is\nmultiplicative. Most solutions to tackle speckle noise seem to be heuristic. The main motivation\nfor this work is the recent paper by Prof. Jalali and her collaborators that looks into such\nsystems from a theoretical perspective and shows that compressed sensing in the presence of\nspeckle noise is possible. However, the results of that paper are mainly theoretical. In this\nproject, we are interested in taking advantage of powerful tools from machine learning, such as\nauto encoders, to implement algorithms that recover a signal in the presence of speckle noise.\n"
      },
      "source": "https://raw.githubusercontent.com/akhilvreddy/ECE491-SpecialProblems/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Concepts / Tools being used",
        "parent_header": [
          "Special Problems, ECE491",
          "Introduction"
        ],
        "type": "Text_excerpt",
        "value": "The problem of signal recovery from noisy samples that are corrupted by speckle noise is\ninherently very complex mathematically. To be successful in this project, I need to understand\nthose concepts and then, based on the results of that paper and other prior work on application\nof compressed sensing, implement a proper recovery algorithm.\n\nMost of my coding will be done in Python3 and the main libraries that I will be using are Numpy,\nNumba, and PyTorch. Numba is going to be used for a wide variety of operations such as\nspeeding up calculations and will translate the code to be easily-compilable. Numpy is the basic\nmathematical calculation library that I will be using to work with doing operations on vectors.\nPyTorch is the biggest library that I will use since it is the main machine learning tool that I have.\nI\u2019ll be using that to train and use neural networks that I have to make. Also, PyTorch is an\nimportant skill to learn as an ECE undergraduate because of its wide use and doing this project\nwould help me.\n"
      },
      "source": "https://raw.githubusercontent.com/akhilvreddy/ECE491-SpecialProblems/main/README.md",
      "technique": "header_analysis"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/akhilvreddy/ECE491-SpecialProblems/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "executable_example": [
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/akhilvreddy/ECE491-SpecialProblems/main/Autoencoder%20Final%20Notebook.ipynb"
      },
      "source": "https://raw.githubusercontent.com/akhilvreddy/ECE491-SpecialProblems/main/Autoencoder%20Final%20Notebook.ipynb",
      "technique": "file_exploration"
    }
  ],
  "faq": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Motivation",
        "parent_header": [
          "Special Problems, ECE491",
          "Introduction"
        ],
        "type": "Text_excerpt",
        "value": "There are a wide range of computational imaging systems that illuminate the object of interest\nby coherent light. Examples of such imaging systems are synthetic aperture radar (SAR) and\ndigital holography. These systems all suffer from a very particular type of noise referred to as\nspeckle noise. Speckle noise is very different and than typical additive noise, since it is\nmultiplicative. Most solutions to tackle speckle noise seem to be heuristic. The main motivation\nfor this work is the recent paper by Prof. Jalali and her collaborators that looks into such\nsystems from a theoretical perspective and shows that compressed sensing in the presence of\nspeckle noise is possible. However, the results of that paper are mainly theoretical. In this\nproject, we are interested in taking advantage of powerful tools from machine learning, such as\nauto encoders, to implement algorithms that recover a signal in the presence of speckle noise.\n"
      },
      "source": "https://raw.githubusercontent.com/akhilvreddy/ECE491-SpecialProblems/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Concepts / Tools being used",
        "parent_header": [
          "Special Problems, ECE491",
          "Introduction"
        ],
        "type": "Text_excerpt",
        "value": "The problem of signal recovery from noisy samples that are corrupted by speckle noise is\ninherently very complex mathematically. To be successful in this project, I need to understand\nthose concepts and then, based on the results of that paper and other prior work on application\nof compressed sensing, implement a proper recovery algorithm.\n\nMost of my coding will be done in Python3 and the main libraries that I will be using are Numpy,\nNumba, and PyTorch. Numba is going to be used for a wide variety of operations such as\nspeeding up calculations and will translate the code to be easily-compilable. Numpy is the basic\nmathematical calculation library that I will be using to work with doing operations on vectors.\nPyTorch is the biggest library that I will use since it is the main machine learning tool that I have.\nI\u2019ll be using that to train and use neural networks that I have to make. Also, PyTorch is an\nimportant skill to learn as an ECE undergraduate because of its wide use and doing this project\nwould help me.\n"
      },
      "source": "https://raw.githubusercontent.com/akhilvreddy/ECE491-SpecialProblems/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Thesis",
        "parent_header": [
          "Special Problems, ECE491"
        ],
        "type": "Text_excerpt",
        "value": "The use of advanced signal processing techniques, such as denoising combined with machine learning algorithms can significantly improve the accuracy of signal recovery from noisy image samples of lungs with pneumonia, leading to more accurate diagnosis and treatment of the disease.\n"
      },
      "source": "https://raw.githubusercontent.com/akhilvreddy/ECE491-SpecialProblems/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "The problem",
        "parent_header": [
          "Special Problems, ECE491"
        ],
        "type": "Text_excerpt",
        "value": "Speckle noise is a type of noise that is commonly found in images acquired from optical imaging systems, such as laser imaging, ultrasound imaging and synthetic aperture radar (SAR) imaging. It is characterized by a granular or \"salt-and-pepper\" appearance, with small bright or dark spots scattered throughout the image.\n\n<p align=\"center\">\n  <img \n    width=\"544\"\n    height=\"308\"\n    src=\"https://user-images.githubusercontent.com/101938119/213531959-61496e6f-abce-4d1b-a72d-9b925ac867f8.png\"\n  >\n</p>\n\n> Our goal here is to get from an image that looks like the one on the right.\n\nIt is caused by the constructive and destructive interference of light waves scattered by small, randomly distributed scatterers within the imaging system. The scattered waves combine to create a speckled pattern on the image. There can be different variations of noise disturbances such as multiplicative noise and additive nosie.\n\nSpeckle noise can be a significant problem in certain imaging applications, as it can reduce image quality, make it difficult to detect small features, and limit the ability to extract useful information from the image. Getting rid of it can be difficult but can prove to be very useful. As the thesis mentions, it can \"[lead] to more accurate diagnosis and treatment of the disease\".\n\n"
      },
      "source": "https://raw.githubusercontent.com/akhilvreddy/ECE491-SpecialProblems/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Graphical Depiction",
        "parent_header": [
          "Special Problems, ECE491"
        ],
        "type": "Text_excerpt",
        "value": "In this case, we are talking about images and images having speckle noise, but I would first like to show speckle noise's effect on signals. Since images can be represented as vectors, this would be a good way to visualize what is happening. Since I am going to be converting the image we are working with to patches and then later to a vector, it is good to see what changes happen to a single vector. \n\nThe noise formula is modeled by the following: $$\\textbf{y} = AX_o\\textbf{w} + \\textbf{z}$$\n\nHere is what all the variables are: \n- $\\textbf{y}$ : This is the final measurement of the signal we end up with, and is the one that we see. \n- $A$ : This is a multiplicative constant (can be in the form of a matrix).\n- $X_o$ : This is the original signal in the form of a matrix. The signal elements are on the diagonal of a square matrix.\n- $\\textbf{w}$ : The speckle noise, this is the main issue we are dealing with. \n- $\\textbf{z}$ : This is the white gaussian additive noise. \n"
      },
      "source": "https://raw.githubusercontent.com/akhilvreddy/ECE491-SpecialProblems/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Test vector",
        "parent_header": [
          "Special Problems, ECE491",
          "Graphical Depiction"
        ],
        "type": "Text_excerpt",
        "value": "We can generate random values for speckle noise, additive white gaussian noise, and the original signal to see a sample comparison between $X_o$ and $y$. \n\nWe can take $w$ as some random multiplicative values, ranging between 0.8-1.2 because we don't want too much difference, but just enough to see. \nWe can take $X_o$ as the matrix of the array [5.4, 7.65, 9.4, 3.4] as spread along its diagonal. This was randomly generated.\nWe can take $z$ as a guassian random distributed noise:\nIgnoring $A$ for now, we can just set it equal to 1.\n\nHere, I am converting all of the lists to python vectors so that we can do operations on them.\n\nThe way to do this in python is the following: \n\n- Let's assume that the randomly generated vector is a column vector (5x1). \n\n```\nimport numpy as np\n\n# Generate a 5x1 vector (this can be our Xo - original vector) \nx = np.random.rand(5, 1)\nprint(\"Original Vector:\")\nprint(x)\n\n# Generate multiplicative constant in the form of a matrix (must be 5x5 because of our conditions) with random values between 0.1 and 1.9\nA_matrix = np.random.uniform(low=0.1, high=1.9, size=(5, 5))\nx = x * A_matrix\nprint(\"Vector with multiplicative constant included\")\nprint(x)\n\n\n# Generate multiplicative noise (this is the speckle part)\nmultiplicative_noise = 0.5\nx = x * (1 + multiplicative_noise * np.random.randn(5, 1))\nprint(\"Vector with multiplicative noise:\")\nprint(x)\n\n# Generate additive noise\nadditive_noise = 0.1\nx = x + additive_noise * np.random.randn(5, 1)\nprint(\"Vector with additive noise:\")\nprint(x)\n```\n"
      },
      "source": "https://raw.githubusercontent.com/akhilvreddy/ECE491-SpecialProblems/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Test Images",
        "parent_header": [
          "Special Problems, ECE491"
        ],
        "type": "Text_excerpt",
        "value": "As aforementioned, I used 4 very high quality images of lungs with pneumonia. Here is one of them - they all look pretty similar from a third person perspective. \n\n<p align=\"center\">\n  <img \n    src=\"https://github.com/akhilvreddy/ECE491-SpecialProblems/blob/main/Training%20Images/im2_pn_normal.jpeg\"\n  >\n</p>\n\nIf you look closely, the image has a black border on all sides. Since each pixel can inlfuence the model, we would like to remove the border. This is what I did to remove the border from the image: \n\n``` \nimport cv2\n# Load the image\nimage = cv2.imread(\"image.jpg\")\n\n# Define the border color (black)\nlower = [0, 0, 0]\nupper = [0, 0, 0]\n\n# Create a mask for the border color\nmask = cv2.inRange(image, lower, upper)\n\n# Remove the border color\nimage_without_border = cv2.bitwise_not(image, image, mask=mask)\n```\n\nAnother way to do this is using the properies of python. \n\n``` \nImage1 = img[:, 1:]\nImage1 = Image1[:, :-1]\n```\n"
      },
      "source": "https://raw.githubusercontent.com/akhilvreddy/ECE491-SpecialProblems/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Image Patches",
        "parent_header": [
          "Special Problems, ECE491",
          "Test Images"
        ],
        "type": "Text_excerpt",
        "value": "Before moving further in the program, we would need to convert the testing images that I have into smaller patches. There are two reasons that we would have to do this. \n\n- **Computational Power.** The main reason to change to patches is because the machines we are using cannot handle/support that much computation. Even after running our code with many patches from a singular high quality image, it took my machine (lenovo with i5) about 17.5 minutes to run the autoencoder model. Having to run multiple of models for multiple high quality images would be too much. GPU would be needed for this case. \n\n- **Efficiency.** Making patches like this is decreasing computational power for a similar accuracy. We would want to do this if we are working without funding / low budget. \n"
      },
      "source": "https://raw.githubusercontent.com/akhilvreddy/ECE491-SpecialProblems/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Test patches",
        "parent_header": [
          "Special Problems, ECE491",
          "Test Images"
        ],
        "type": "Text_excerpt",
        "value": "Given an image like the one above, we can get *n* number of patches from that specific image using the *sklearn* library. \n\n```\nfrom sklearn.feature_extraction import image\n\n# Load the image\nimage = ...\n\n# Define the patch size (e.g. (64, 64))\npatch_size = (64, 64)\n\n# Extract the patches\npatches = image.extract_patches_2d(image, patch_size)\n\n# convert from 4d array down to 3d array for better use\npatches = patches.reshape(-1, patch_size[0], patch_size[1])\n\nprint(patches)\n```\n\n> imported our test images into this code segment\n> \n> [[[174 201 231],[174 201 231]],[[173 200 230],[173 200 230]]] is the output I got after running the code\n\nIf we wanted to go the other way around (patches back to the image), *sklearn* has a library to do that as well. \n\n```\nfrom sklearn.feature_extraction import image\n\n# Load the patches\npatches = ...\n\n# Reconstruct the image\nimage = image.reconstruct_from_patches_2d(patches, (height, width))\n```\n"
      },
      "source": "https://raw.githubusercontent.com/akhilvreddy/ECE491-SpecialProblems/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Autoencoders",
        "parent_header": [
          "Special Problems, ECE491",
          "Tackling the problem"
        ],
        "type": "Text_excerpt",
        "value": "Autoencoders can be used to remove the noise and distortions from the images by training the network to reconstruct the original, noise-free image from the noisy input image. Autoencoders don't have a specific defintion but they are capable of reducing the data dimensions by ignoring noise in the data. It will then expand the data out agian to the dimensions of the initial dataset. There are usually four components inside an autoencoder, all of these combined make it up.\n- Encoder  \n  * In which the model learns how to reduce the input dimensions and compress the input data into an encoded representation.\n- Bottleneck \n   * The layer that contains the compressed representation of the input data. This is the lowest possible dimensions of the input data.\n- Decoder\n  * In which the model learns how to reconstruct the data from the encoded representation to be as close to the original input as possible.\n- Reconstruction Loss\n  * the method that measures measure how well the decoder is performing and how close the output is to the original input.\n\nHere is an image depicting the way autoencoders work. This image shows a one-layer design, but a lot of autoencoders can have many more than a single layer.\n\n<p align=\"center\">\n  <img \n    width=\"464\"\n    height=\"328\"\n    src=\"https://github.com/akhilvreddy/ECE491/blob/main/ourimage.png\"\n  >\n</p>\n\nAutoencoders are the biggest tools that allow us to solve inverse problems. The way we are going to solve the vector equation is by trying to inverse it, kind of like an algebraic equation, but we cannot do the same elementary operations for a vector equation involving matrices. \n"
      },
      "source": "https://raw.githubusercontent.com/akhilvreddy/ECE491-SpecialProblems/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Recovery Algorithms",
        "parent_header": [
          "Special Problems, ECE491",
          "Tackling the problem"
        ],
        "type": "Text_excerpt",
        "value": "Recovery Algorithms are basically a set of instructions or steps that are used to restore or recover data that has been lost, deleted, or damaged. In this case, our images are going to be hit with speckle noise and we would want to recover the original, clean image from this. One of the ways to get the signal (or image in this case) back from speckle noise is by Projected Gradient Descent. The cost function in this case would be \n"
      },
      "source": "https://raw.githubusercontent.com/akhilvreddy/ECE491-SpecialProblems/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Recovery using Generative Functions (GFs)",
        "parent_header": [
          "Special Problems, ECE491",
          "Tackling the problem",
          "Recovery Algorithms"
        ],
        "type": "Text_excerpt",
        "value": "Recovery using generative functions refers to the process of using generative models to recover or generate data that has been lost, corrupted, or never existed in the first place. Generative models are a class of machine learning models that are trained to generate new data that is similar to the training data.\n"
      },
      "source": "https://raw.githubusercontent.com/akhilvreddy/ECE491-SpecialProblems/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Projected Gradient Descent (PGD)",
        "parent_header": [
          "Special Problems, ECE491",
          "Tackling the problem",
          "Recovery Algorithms"
        ],
        "type": "Text_excerpt",
        "value": "This is one of the ways we reduce the cost function step-by-step to drive closer to the solution everytime. Understading the pseudo-code is very important before coding it up. \n\n* We are assuming that the result is **x<sub>t</sub>**.\n\n```\nXo = diag(xo)    //initalize the matrix\nBo = A(Xo)^2(A^T)\n\nfor t = 1:T do \n  for i = 1:n do\n  \n  s(t, i) = *some algorithmic step*\n  \n  end \n  \n  x_t = pi*c_r*s_t\n  Xt = diag(xt)\n  Bt = A(X_t)^2(A^T)\nend\n```\n\nLet's unpack this alogrithm. The first two lines should be pretty self-explanatory - we are just setting up the basic matrix and constants in order to do the first iteration calcuations.\n\nThe nested for loops is where we get into the meat of the algorithm. For the inner-most loop, we are trying to find values of s_(t,i). Since t stays the same for a single loop, we get n specific values of the s vector. \n\nAfter exiting that loop, we set all the values of the x_t vector to a specific constant times those values. \n\nThe X_t matrix gets updated from this everytime. \n\nBy running through both of these for-loops we are inching closer towards an answer everytime. The main line that is getting us to reduce our cost-function is: \n\n<p align=\"center\">\n  <img \n    width=\"508\"\n    height=\"48\"\n    src=\"https://github.com/akhilvreddy/ECE491/blob/main/pic2.png\"\n  >\n</p>\n"
      },
      "source": "https://raw.githubusercontent.com/akhilvreddy/ECE491-SpecialProblems/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Putting our Images into Python",
        "parent_header": [
          "Special Problems, ECE491",
          "Starting with the Autoencoder class"
        ],
        "type": "Text_excerpt",
        "value": "As aforementioned, we start by importing our image into python from our desktop. We need to divide by 255 because we want to normalize it. After normalization, we output the image and as you can see, it looks pretty much the same as what we had above. Thsi is because if you divide every pixel value by the same value, you are going to get the same image, just scaled down in value. \n```\n# inputting the image from \ninput_img = \"im1_pn_normal.jpeg\"\n\n#saving the images that we have into vector variables\nimg = cv2.imread(input_img,0)\n\n# the following command will help us understand what the image will look like (vectorized)\nimg = img/255\n# this is going to show us the dimensions of the image  (we can make adjustments based off this)\n```\n\nWe can now output this image using the following command:\n```\nplt.imshow(img,cmap='gray')\n```\n<p align=\"center\">\n  <img \n    src=\"https://github.com/akhilvreddy/ECE491-SpecialProblems/blob/main/Reference%20Images/img1_matplotliboutput.png\"\n  >\n</p>\n"
      },
      "source": "https://raw.githubusercontent.com/akhilvreddy/ECE491-SpecialProblems/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Patches in Numpy",
        "parent_header": [
          "Special Problems, ECE491",
          "Starting with the Autoencoder class"
        ],
        "type": "Text_excerpt",
        "value": "Above, we have the patches from our image. Here, we would want to convert it to a numpy patch tensor so that we can do calculations and manipulations with it. Especially since we are going to be feeding these into our autoencoder. \n```\npatchtensor = torch.from_numpy(patch)\nprint(patchtensor.data.shape)\ntype(patchtensor)\n```\n\n> torch.Size([10000, 8, 8]) (notice how size stays the same)\n> torch.Tensor (torch.Tensor is the type now)\n\nWith everything settled, we would want to now ready the data (patches) for training. \n```\n# DataLoader is used to load the dataset for training\npatchloader = torch.utils.data.DataLoader(dataset = patchtensor, batch_size = 32, shuffle = True)\n```\n"
      },
      "source": "https://raw.githubusercontent.com/akhilvreddy/ECE491-SpecialProblems/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Choosing our Autoencoder size",
        "parent_header": [
          "Special Problems, ECE491",
          "Starting with the Autoencoder class"
        ],
        "type": "Text_excerpt",
        "value": "This is probably the most difficult and important step of the whole process. Since choosing the size and dimensions have the most direct impact on the quality and efficacy of the autoencoder. I'll outline some of the sizes I have chosen. \n"
      },
      "source": "https://raw.githubusercontent.com/akhilvreddy/ECE491-SpecialProblems/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "The first attempt:",
        "parent_header": [
          "Special Problems, ECE491",
          "Starting with the Autoencoder class",
          "Choosing our Autoencoder size"
        ],
        "type": "Text_excerpt",
        "value": "256 (16 x 16) ==> 196 (14 x 14) ==> 144 (12 x 12) ==> 100 (10 x 10) ==> 64 (8 x 8) ==> 36 (6 x 6) ==> 25 (5 x 5)\n\n\n25 (5 x 5) ==> 36 (6 x 6) ==> 64 (8 x 8) ==> 100 (10 x 10) ==> 144 (12 x 12) ==> 196 (14 x 14) ==> 256 (16 x 16)\n  \nThese were the dimensions I used for the first time I did the autoenocder class and this brought in not the best results. The issue that happend with this is that the MSE was not as good as we wanted it to be, it was kind of all over the place. Here is what it looked like: \n\n<p align=\"center\">\n  <img \n    src=\"https://github.com/akhilvreddy/ECE491-SpecialProblems/blob/main/Reference%20Images/imgw_firstmse.png\"\n  >\n</p>\n\nAs you can see, this is not a great reduction in MSE so we can do better. \n"
      },
      "source": "https://raw.githubusercontent.com/akhilvreddy/ECE491-SpecialProblems/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "The second attempt:",
        "parent_header": [
          "Special Problems, ECE491",
          "Starting with the Autoencoder class",
          "Choosing our Autoencoder size"
        ],
        "type": "Text_excerpt",
        "value": "1024 (32 x 32) ==> 625 (25 x 25) ==> 400 (20 x 20) ==> 225 (15 x 15) ==> 144 (12 x 12) ==> 121 (11 x 11) ==> 100 (10 x 10)\n\n\n100 (10 x 10) ==> 121 (11 x 11) ==> 144 (12 x 12) ==> 225 (15 x 15) ==> 400 (20 x 20) ==> 625 (25 x 25) ==> 1024 (32 x 32)\n\nThis was better, but still not the best. Here is a snippet of how this is inputted into python: \n\n```\ntorch.nn.Linear(k * k, 2000), \ntorch.nn.ReLU(),\ntorch.nn.Linear(2000, 1000),\ntorch.nn.ReLU(),\ntorch.nn.Linear(1000, 500),\ntorch.nn.ReLU(),\ntorch.nn.Linear(500, 200),\ntorch.nn.ReLU(),\ntorch.nn.Linear(200, 100),\n ```\n \nEach Linear command is followed by a ReLU command. The ReLU activation function is commonly used in neural networks to introduce non-linearity and improve the model's ability to learn complex, non-linear relationships in the data and hence having linear commands followed by the ReLU commands help the model really understand the data.\n"
      },
      "source": "https://raw.githubusercontent.com/akhilvreddy/ECE491-SpecialProblems/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "The third attempt:",
        "parent_header": [
          "Special Problems, ECE491",
          "Starting with the Autoencoder class",
          "Choosing our Autoencoder size"
        ],
        "type": "Text_excerpt",
        "value": "After not much of a decrease in MSE, I decided there were other ways to fix the issues that I was having. Going to the bottle-neck need not to be uniform and I used this fact to my ability.\n\n1024 (32 x 32) ==> 625 (25 x 25) ==> 400 (20 x 20) ==> 225 (15 x 15) ==> 144 (12 x 12) ==> 121 (11 x 11) ==> 100 (10 x 10)\n\n\n100 (10 x 10) ==> 121 (11 x 11) ==> 144 (12 x 12) ==> 225 (15 x 15) ==> 400 (20 x 20) ==> 625 (25 x 25) ==> 1024 (32 x 32)\n\nHere is the MSE we got by doing the above: \n\n<p align=\"center\">\n  <img \n    src=\"https://github.com/akhilvreddy/ECE491-SpecialProblems/blob/main/Reference%20Images/imgy_secondmse.png\"\n  >\n</p>\n"
      },
      "source": "https://raw.githubusercontent.com/akhilvreddy/ECE491-SpecialProblems/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Building the end to end Autoencoder class",
        "parent_header": [
          "Special Problems, ECE491",
          "Starting with the Autoencoder class"
        ],
        "type": "Text_excerpt",
        "value": "```\n# Creating a PyTorch class\n# 28*28 ==> 9 ==> 28*28 # change these values\nclass AE(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        # Building an linear encoder with Linear\n        # layer followed by Relu activation function\n        # 784 ==> 9\n\n        #grow first and then shrink\n        self.encoder = torch.nn.Sequential(\n            torch.nn.Linear(k * k, 2000),  # change these values, these are not big enough ## change the 32^2 to maybe 2048\n            torch.nn.ReLU(),\n            torch.nn.Linear(2000, 1000),\n            torch.nn.ReLU(),\n            torch.nn.Linear(1000, 500),\n            torch.nn.ReLU(),\n            torch.nn.Linear(500, 200),\n            torch.nn.ReLU(),\n            torch.nn.Linear(200, 100),\n        )\n    \n        '''\n        what can we do with the compressed form of the nn?\n        can we take this nn and put it somewhere else so that it can work as transfer of data with much less information\n        '''\n\n        # Building an linear decoder with Linear\n        # layer followed by Relu activation function\n        # The Sigmoid activation function\n        # outputs the value between 0 and 1\n        # 9 ==> 784\n        self.decoder = torch.nn.Sequential(\n            torch.nn.Linear(100, 200),\n            torch.nn.ReLU(),\n            torch.nn.Linear(200, 500),\n            torch.nn.ReLU(),\n            torch.nn.Linear(500, 1000),\n            torch.nn.ReLU(),\n            torch.nn.Linear(1000, 2000),\n            torch.nn.ReLU(),\n            torch.nn.Linear(2000, k * k),\n            torch.nn.ReLU()\n        )\n\n    def forward(self, x):\n        encoded = self.encoder(x)\n        decoded = self.decoder(encoded)\n        return decoded\n\n```\n"
      },
      "source": "https://raw.githubusercontent.com/akhilvreddy/ECE491-SpecialProblems/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Using our model",
        "parent_header": [
          "Special Problems, ECE491",
          "Starting with the Autoencoder class"
        ],
        "type": "Text_excerpt",
        "value": "```\n# Model Initialization\nmodel = AE()\n\n# Validation using MSE Loss function\nloss_function = torch.nn.MSELoss()\n\n# Using an Adam Optimizer with lr = 0.1\noptimizer = torch.optim.Adam(model.parameters(),lr = 0.0001, weight_decay = 1e-8)\n```\nWhat is happening here is that we are making an instance of our Autoencoder class, kind of like in an OOP language like java. After that, we set up our MSE calculations in a variable called *loss_function* which comes from PyTorch's MSELoss() class. \n\nThis line of code creates an optimizer object, which will be used to update the parameters of a model during training. The optimizer used here is the Adam optimizer, which is a popular choice for training neural networks. The Adam optimizer uses a combination of gradient descent and adaptive learning rate techniques to adjust the model's parameters.\n\nThe first argument passed to the Adam function is the parameters of the model, so the optimizer will update the parameters of the model object. The second argument is the learning rate (lr), which is set to 0.0001. This value determines the step size at which the optimizer makes updates to the model's parameters. A smaller learning rate means that the optimizer will make smaller updates, while a larger learning rate means that the optimizer will make larger updates.\n\nThe third argument is weight_decay, which is set to 1e-8. It helps to prevent overfitting by adding an L2 penalty on the weights of the model during optimization.\n\nLearning rate of 0.0001 and weight decay of 1e-8 are reasonable default values to start with for most problems.\n"
      },
      "source": "https://raw.githubusercontent.com/akhilvreddy/ECE491-SpecialProblems/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Training the Autoencoder model to our specific data",
        "parent_header": [
          "Special Problems, ECE491",
          "Starting with the Autoencoder class"
        ],
        "type": "Text_excerpt",
        "value": "This is the most important part of the whole project - it is everything coming together and training the AE model so that we can get reconstructed images. \n```\nepochs = 300 #change the epoch value to be larger\noutputs = []\nlosses = []\nfor epoch in range(epochs):\n#     print(epoch)\n    for image in patchloader:\n        image = image.reshape(-1, k*k)# Reshaping the image to (-1, 784)\n        image = image.float()\n\n    # Output of Autoencoder\n        reconstructed = model(image)\n\n    # Calculating the loss function\n        loss = loss_function(reconstructed, image)\n\n    # The gradients are set to zero,\n    # the gradient is computed and stored.\n    # .step() performs parameter update\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n    # Storing the losses in a list for plotting\n        losses.append(loss)\n        outputs.append((epochs, image, reconstructed))\n    print('epoch [{}/{}], loss:{:.8f}'\n          .format(epoch + 1, epochs, loss.data.detach().numpy()))\n```\nThe outermost loop is running for a total of 300 epochs, which is the value assigned to the variable epochs. An epoch is a full training pass through all the training data.\n\nThe innermost loop is iterating through a data loader object called patchloader, which is presumably an object that loads the images that will be used as input to the autoencoder. For each image in the patchloader, the code reshapes the image to a 2D tensor of shape (-1, k*k) and converts the image to a float data type.\n\nThe autoencoder model is then applied to the image, and the output is assigned to the variable reconstructed. The loss function is then calculated by comparing the reconstructed image to the original image. The loss function used here is the mean squared error.\n\nThe gradients are then set to zero, the gradient is computed and stored by the backward() method, and the step() method updates the model parameters using the optimizer.\n\nAt each iteration of the inner loop, the loss is appended to the losses list and the output and reconstructed image are appended to the outputs list.\n\nFinally, the code prints out the current epoch number, the total number of epochs, and the value of the loss at that point in the training.\n"
      },
      "source": "https://raw.githubusercontent.com/akhilvreddy/ECE491-SpecialProblems/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "MSE Outputs",
        "parent_header": [
          "Special Problems, ECE491",
          "Starting with the Autoencoder class"
        ],
        "type": "Text_excerpt",
        "value": "Here is the output that we get from the model running above. It is worth to note that this took my machine 17 and a half minutes to run. This is important to think about for scalability. If it takes a decent laptop running i5 17.5 minutes, to train huge AI models, it would require a lot of CPU and GPU processing power which would cost a lot. \n```\nepoch [1/300], loss:0.06043266\nepoch [2/300], loss:0.07363702\nepoch [3/300], loss:0.06667658\nepoch [4/300], loss:0.06946521\nepoch [5/300], loss:0.05480300\nepoch [6/300], loss:0.09153187\nepoch [7/300], loss:0.09710239\nepoch [8/300], loss:0.07143620\nepoch [9/300], loss:0.05849411\n...\nepoch [291/300], loss:0.00412072\nepoch [292/300], loss:0.00621012\nepoch [293/300], loss:0.00533406\nepoch [294/300], loss:0.00514319\nepoch [295/300], loss:0.00585328\nepoch [296/300], loss:0.00399428\nepoch [297/300], loss:0.00497398\nepoch [298/300], loss:0.00542437\nepoch [299/300], loss:0.00350400\nepoch [300/300], loss:0.00568663\n```\nThis is the output of the training loop, which shows the value of the loss function at the end of each epoch. The loss function is a measure of how well the autoencoder is able to reconstruct the input images. A lower loss value indicates that the autoencoder is performing well and is able to accurately reconstruct the input images.\n\nIt is clear from the output that the loss is decreasing as the training progresses. In the beginning, the loss is high around 0.06 and by the end, it is around 0.0055. And this decrease in loss indicates that the model is learning and improving with each epoch.\n\nIt is also worth noting that the loss fluctuates, which is normal. There will be some variations in the loss values between different epochs, but overall, the loss is decreasing as the training progresses.\n"
      },
      "source": "https://raw.githubusercontent.com/akhilvreddy/ECE491-SpecialProblems/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Viewing our MSE",
        "parent_header": [
          "Special Problems, ECE491",
          "Starting with the Autoencoder class"
        ],
        "type": "Text_excerpt",
        "value": "```\nl = []\nfor j in range(len(losses)):\n    a = losses[j].detach().numpy()\n    l.append(a)\n\n# Defining the Plot Style\nplt.plot(l)\nplt.style.use('fivethirtyeight')\nplt.xlabel('Iterations')\nplt.ylabel('Loss')\n```\n\nThis code is plotting the training loss over the course of the training process.\n\nThe first loop iterates through the losses list, which contains the loss values at the end of each iteration of the training loop. For each value in the losses list, the code converts the value to a numpy array and appends it to a new list l.\n\nThe next part of the code is using the matplotlib library to plot the data in the l list. The plt.plot(l) function plots the values in the l list on the y-axis, and the x-axis is determined by the index of the values in the list.\n\nThis plot will show how the loss changes over time and will help to monitor the training progress and identify if the model is overfitting or underfitting.\n\nHere is what a good version of what a loss model would look like: \n\n<p align=\"center\">\n  <img \n    src=\"https://github.com/akhilvreddy/ECE491-SpecialProblems/blob/main/Reference%20Images/imgz_idealloss.png\"\n  >\n</p>\n"
      },
      "source": "https://raw.githubusercontent.com/akhilvreddy/ECE491-SpecialProblems/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Viewing our reconstructed image:",
        "parent_header": [
          "Special Problems, ECE491",
          "Starting with the Autoencoder class"
        ],
        "type": "Text_excerpt",
        "value": "```\n# print(reconstructed.shape)\nfor i, item in enumerate(reconstructed):\n    item = item.reshape(-1, k, k)\n    plt.imshow(item[0].detach().numpy(),cmap='gray',vmin=0, vmax=1)\n#     plt.show()\n```\n\nHere is what one the reconstructed patches look like:\n\n<p align=\"center\">\n  <img \n    src=\"https://github.com/akhilvreddy/ECE491-SpecialProblems/blob/main/Reference%20Images/imgx_reconstructedpatch.png\"\n  >\n</p>\n\nWe can also stitch them together using the method we talked about [above](https://github.com/akhilvreddy/ECE491-SpecialProblems/blob/main/README.md#test-patches). Here is what the code would look like: \n```\nimage = image.reconstruct_from_patches_2d(patches, (height, width))\n```\n"
      },
      "source": "https://raw.githubusercontent.com/akhilvreddy/ECE491-SpecialProblems/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Final Thoughts",
        "parent_header": [
          "Special Problems, ECE491"
        ],
        "type": "Text_excerpt",
        "value": "In conclusion, Autoencoders are a powerful tool for unsupervised feature learning and dimensionality reduction. They can be used in a wide range of applications, such as image and speech recognition, natural language processing, and anomaly detection.\n\nIn this research paper, we have discussed the basic principles of autoencoders and how they work. We have also demonstrated how to implement an autoencoder in Pytorch, a popular deep learning framework. We have trained the autoencoder on a dataset of images and analyzed the results. The loss function decreased as the training progressed, and the output of the autoencoder was able to reconstruct the input images with high accuracy.\n\nWe have also discussed some of the limitations of autoencoders, such as overfitting and the need for a large amount of data. However, these limitations can be overcome by using techniques such as regularization, denoising, and variational autoencoders.\n\nIn summary, autoencoders are a versatile and powerful tool for machine learning and have many potential applications. Further research in this field could lead to new and improved methods for unsupervised feature learning and dimensionality reduction.\n\nI would like to thank Professor Jalali and my TA Mengyu Zhao for helping me and advising me through this project.\n\n\n\n"
      },
      "source": "https://raw.githubusercontent.com/akhilvreddy/ECE491-SpecialProblems/main/README.md",
      "technique": "header_analysis"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 0
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/akhilvreddy/Rutgers-ECE491/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "akhilvreddy/Rutgers-ECE491"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "Special Problems, ECE491"
      },
      "source": "https://raw.githubusercontent.com/akhilvreddy/ECE491-SpecialProblems/main/README.md",
      "technique": "regular_expression"
    }
  ],
  "images": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://user-images.githubusercontent.com/101938119/213531959-61496e6f-abce-4d1b-a72d-9b925ac867f8.png"
      },
      "source": "https://raw.githubusercontent.com/akhilvreddy/ECE491-SpecialProblems/main/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/akhilvreddy/ECE491-SpecialProblems/main/Training%20Images/im2_pn_normal.jpeg"
      },
      "source": "https://raw.githubusercontent.com/akhilvreddy/ECE491-SpecialProblems/main/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/akhilvreddy/ECE491/main/ourimage.png"
      },
      "source": "https://raw.githubusercontent.com/akhilvreddy/ECE491-SpecialProblems/main/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/akhilvreddy/ECE491/main/pic2.png"
      },
      "source": "https://raw.githubusercontent.com/akhilvreddy/ECE491-SpecialProblems/main/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/akhilvreddy/ECE491-SpecialProblems/main/Reference%20Images/img1_matplotliboutput.png"
      },
      "source": "https://raw.githubusercontent.com/akhilvreddy/ECE491-SpecialProblems/main/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/akhilvreddy/ECE491-SpecialProblems/main/Reference%20Images/img2_firstpatch.png"
      },
      "source": "https://raw.githubusercontent.com/akhilvreddy/ECE491-SpecialProblems/main/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/akhilvreddy/ECE491-SpecialProblems/main/Reference%20Images/imgw_firstmse.png"
      },
      "source": "https://raw.githubusercontent.com/akhilvreddy/ECE491-SpecialProblems/main/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/akhilvreddy/ECE491-SpecialProblems/main/Reference%20Images/imgy_secondmse.png"
      },
      "source": "https://raw.githubusercontent.com/akhilvreddy/ECE491-SpecialProblems/main/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/akhilvreddy/ECE491-SpecialProblems/main/Reference%20Images/imgz_idealloss.png"
      },
      "source": "https://raw.githubusercontent.com/akhilvreddy/ECE491-SpecialProblems/main/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/akhilvreddy/ECE491-SpecialProblems/main/Reference%20Images/imgx_reconstructedpatch.png"
      },
      "source": "https://raw.githubusercontent.com/akhilvreddy/ECE491-SpecialProblems/main/README.md",
      "technique": "regular_expression"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/akhilvreddy/Rutgers-ECE491/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ""
      },
      "technique": "GitHub_API"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "Rutgers-ECE491"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "User",
        "value": "akhilvreddy"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Jupyter Notebook",
        "size": 301591,
        "type": "Programming_language",
        "value": "Jupyter Notebook"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 10963,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/akhilvreddy/ECE491-SpecialProblems/main/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "requirements": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Dependencies",
        "parent_header": [
          "Special Problems, ECE491",
          "Starting with the Autoencoder class"
        ],
        "type": "Text_excerpt",
        "value": "As you can see in the main jupyter notebook, we have a couple of dependencies for this program. \n```\nfrom sklearn.datasets import load_sample_image\nfrom sklearn.feature_extraction import image\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport cv2\n```\n\n- Scikit-learn (sklearn) is a popular Python library for machine learning. It offers a wide range of tools for tasks such as classification, regression, clustering, and model selection, and it is built on top of other popular Python libraries such as NumPy and Matplotlib. It provides a consistent interface to various machine learning models, making it easy to switch between them and to perform common tasks such as feature extraction, model selection, and evaluation. I have used it through the program, especially in my autoencoder class. \n- NumPy is a Python library that provides support for large multi-dimensional arrays and matrices of numerical data, as well as a large collection of mathematical functions to operate on these arrays. It is a fundamental package for scientific computing with Python. \n- OpenCV (Open Source Computer Vision Library) is a library of programming functions mainly aimed at real-time computer vision. It provides a number of features such as image processing, video analysis, object detection, and machine learning.\n- Matplotlib is a plotting library for the Python programming language and its numerical mathematics extension NumPy. It provides an object-oriented API for embedding plots into applications using general-purpose GUI toolkits like Tkinter, wxPython, Qt, or GTK. It provides a high-level interface for drawing attractive and informative statistical graphics.\n\nAll of these libraries together help us get to our final goal - a fully working autoencoder method which stores the *MSE (mean squared error)*. \n"
      },
      "source": "https://raw.githubusercontent.com/akhilvreddy/ECE491-SpecialProblems/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "More dependencies",
        "parent_header": [
          "Special Problems, ECE491",
          "Starting with the Autoencoder class"
        ],
        "type": "Text_excerpt",
        "value": "Moving on to the real Machine Learning part, we would want to import *PyTorch* so that we can use it's ability to make NNs.\n```\nimport torch\nfrom torchvision import datasets\nfrom torchvision import transforms\n```\n"
      },
      "source": "https://raw.githubusercontent.com/akhilvreddy/ECE491-SpecialProblems/main/README.md",
      "technique": "header_analysis"
    }
  ],
  "somef_missing_categories": [
    "installation",
    "citation",
    "acknowledgement",
    "run",
    "download",
    "contact",
    "contributors",
    "documentation",
    "license",
    "support",
    "identifier",
    "has_build_file"
  ],
  "somef_provenance": {
    "date": "2024-10-03 22:51:18",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 1
      },
      "technique": "GitHub_API"
    }
  ],
  "usage": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Putting our Images into Python",
        "parent_header": [
          "Special Problems, ECE491",
          "Starting with the Autoencoder class"
        ],
        "type": "Text_excerpt",
        "value": "As aforementioned, we start by importing our image into python from our desktop. We need to divide by 255 because we want to normalize it. After normalization, we output the image and as you can see, it looks pretty much the same as what we had above. Thsi is because if you divide every pixel value by the same value, you are going to get the same image, just scaled down in value. \n```\n# inputting the image from \ninput_img = \"im1_pn_normal.jpeg\"\n\n#saving the images that we have into vector variables\nimg = cv2.imread(input_img,0)\n\n# the following command will help us understand what the image will look like (vectorized)\nimg = img/255\n# this is going to show us the dimensions of the image  (we can make adjustments based off this)\n```\n\nWe can now output this image using the following command:\n```\nplt.imshow(img,cmap='gray')\n```\n<p align=\"center\">\n  <img \n    src=\"https://github.com/akhilvreddy/ECE491-SpecialProblems/blob/main/Reference%20Images/img1_matplotliboutput.png\"\n  >\n</p>\n"
      },
      "source": "https://raw.githubusercontent.com/akhilvreddy/ECE491-SpecialProblems/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Getting the patches",
        "parent_header": [
          "Special Problems, ECE491",
          "Starting with the Autoencoder class"
        ],
        "type": "Text_excerpt",
        "value": "As aforementioned, we wanted to use patch images for certain capacity reasons. Here is how we do it in the program.\n```\nk = 8\nN = 10000\npatch = image.extract_patches_2d(img, (k, k), max_patches = N, random_state=None) # change the max_patches number as well as random_state # change around the random_state value\npatch.shape\n```\n\n> (10000, 8, 8) is the output (patches size)\n\nOut of all those patches we would want to see one of them, and to make sure that they look pretty much the same throughout, we would want \n```\nimport random\nplt.imshow(255*patch[random.randint(0,N)],cmap='gray')\n```\n\n> This command really shows us the power of *matplotlib* in python.\n\n<p align=\"center\">\n  <img \n    src=\"https://github.com/akhilvreddy/ECE491-SpecialProblems/blob/main/Reference%20Images/img2_firstpatch.png\"\n  >\n</p>\n\n> We do not know exactly where and which part of the image this patch comes from, but we can definitely feel that this is a patch from the image above.\n"
      },
      "source": "https://raw.githubusercontent.com/akhilvreddy/ECE491-SpecialProblems/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Patches in Numpy",
        "parent_header": [
          "Special Problems, ECE491",
          "Starting with the Autoencoder class"
        ],
        "type": "Text_excerpt",
        "value": "Above, we have the patches from our image. Here, we would want to convert it to a numpy patch tensor so that we can do calculations and manipulations with it. Especially since we are going to be feeding these into our autoencoder. \n```\npatchtensor = torch.from_numpy(patch)\nprint(patchtensor.data.shape)\ntype(patchtensor)\n```\n\n> torch.Size([10000, 8, 8]) (notice how size stays the same)\n> torch.Tensor (torch.Tensor is the type now)\n\nWith everything settled, we would want to now ready the data (patches) for training. \n```\n# DataLoader is used to load the dataset for training\npatchloader = torch.utils.data.DataLoader(dataset = patchtensor, batch_size = 32, shuffle = True)\n```\n"
      },
      "source": "https://raw.githubusercontent.com/akhilvreddy/ECE491-SpecialProblems/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Choosing our Autoencoder size",
        "parent_header": [
          "Special Problems, ECE491",
          "Starting with the Autoencoder class"
        ],
        "type": "Text_excerpt",
        "value": "This is probably the most difficult and important step of the whole process. Since choosing the size and dimensions have the most direct impact on the quality and efficacy of the autoencoder. I'll outline some of the sizes I have chosen. \n"
      },
      "source": "https://raw.githubusercontent.com/akhilvreddy/ECE491-SpecialProblems/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "The first attempt:",
        "parent_header": [
          "Special Problems, ECE491",
          "Starting with the Autoencoder class",
          "Choosing our Autoencoder size"
        ],
        "type": "Text_excerpt",
        "value": "256 (16 x 16) ==> 196 (14 x 14) ==> 144 (12 x 12) ==> 100 (10 x 10) ==> 64 (8 x 8) ==> 36 (6 x 6) ==> 25 (5 x 5)\n\n\n25 (5 x 5) ==> 36 (6 x 6) ==> 64 (8 x 8) ==> 100 (10 x 10) ==> 144 (12 x 12) ==> 196 (14 x 14) ==> 256 (16 x 16)\n  \nThese were the dimensions I used for the first time I did the autoenocder class and this brought in not the best results. The issue that happend with this is that the MSE was not as good as we wanted it to be, it was kind of all over the place. Here is what it looked like: \n\n<p align=\"center\">\n  <img \n    src=\"https://github.com/akhilvreddy/ECE491-SpecialProblems/blob/main/Reference%20Images/imgw_firstmse.png\"\n  >\n</p>\n\nAs you can see, this is not a great reduction in MSE so we can do better. \n"
      },
      "source": "https://raw.githubusercontent.com/akhilvreddy/ECE491-SpecialProblems/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "The second attempt:",
        "parent_header": [
          "Special Problems, ECE491",
          "Starting with the Autoencoder class",
          "Choosing our Autoencoder size"
        ],
        "type": "Text_excerpt",
        "value": "1024 (32 x 32) ==> 625 (25 x 25) ==> 400 (20 x 20) ==> 225 (15 x 15) ==> 144 (12 x 12) ==> 121 (11 x 11) ==> 100 (10 x 10)\n\n\n100 (10 x 10) ==> 121 (11 x 11) ==> 144 (12 x 12) ==> 225 (15 x 15) ==> 400 (20 x 20) ==> 625 (25 x 25) ==> 1024 (32 x 32)\n\nThis was better, but still not the best. Here is a snippet of how this is inputted into python: \n\n```\ntorch.nn.Linear(k * k, 2000), \ntorch.nn.ReLU(),\ntorch.nn.Linear(2000, 1000),\ntorch.nn.ReLU(),\ntorch.nn.Linear(1000, 500),\ntorch.nn.ReLU(),\ntorch.nn.Linear(500, 200),\ntorch.nn.ReLU(),\ntorch.nn.Linear(200, 100),\n ```\n \nEach Linear command is followed by a ReLU command. The ReLU activation function is commonly used in neural networks to introduce non-linearity and improve the model's ability to learn complex, non-linear relationships in the data and hence having linear commands followed by the ReLU commands help the model really understand the data.\n"
      },
      "source": "https://raw.githubusercontent.com/akhilvreddy/ECE491-SpecialProblems/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "The third attempt:",
        "parent_header": [
          "Special Problems, ECE491",
          "Starting with the Autoencoder class",
          "Choosing our Autoencoder size"
        ],
        "type": "Text_excerpt",
        "value": "After not much of a decrease in MSE, I decided there were other ways to fix the issues that I was having. Going to the bottle-neck need not to be uniform and I used this fact to my ability.\n\n1024 (32 x 32) ==> 625 (25 x 25) ==> 400 (20 x 20) ==> 225 (15 x 15) ==> 144 (12 x 12) ==> 121 (11 x 11) ==> 100 (10 x 10)\n\n\n100 (10 x 10) ==> 121 (11 x 11) ==> 144 (12 x 12) ==> 225 (15 x 15) ==> 400 (20 x 20) ==> 625 (25 x 25) ==> 1024 (32 x 32)\n\nHere is the MSE we got by doing the above: \n\n<p align=\"center\">\n  <img \n    src=\"https://github.com/akhilvreddy/ECE491-SpecialProblems/blob/main/Reference%20Images/imgy_secondmse.png\"\n  >\n</p>\n"
      },
      "source": "https://raw.githubusercontent.com/akhilvreddy/ECE491-SpecialProblems/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Building the end to end Autoencoder class",
        "parent_header": [
          "Special Problems, ECE491",
          "Starting with the Autoencoder class"
        ],
        "type": "Text_excerpt",
        "value": "```\n# Creating a PyTorch class\n# 28*28 ==> 9 ==> 28*28 # change these values\nclass AE(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        # Building an linear encoder with Linear\n        # layer followed by Relu activation function\n        # 784 ==> 9\n\n        #grow first and then shrink\n        self.encoder = torch.nn.Sequential(\n            torch.nn.Linear(k * k, 2000),  # change these values, these are not big enough ## change the 32^2 to maybe 2048\n            torch.nn.ReLU(),\n            torch.nn.Linear(2000, 1000),\n            torch.nn.ReLU(),\n            torch.nn.Linear(1000, 500),\n            torch.nn.ReLU(),\n            torch.nn.Linear(500, 200),\n            torch.nn.ReLU(),\n            torch.nn.Linear(200, 100),\n        )\n    \n        '''\n        what can we do with the compressed form of the nn?\n        can we take this nn and put it somewhere else so that it can work as transfer of data with much less information\n        '''\n\n        # Building an linear decoder with Linear\n        # layer followed by Relu activation function\n        # The Sigmoid activation function\n        # outputs the value between 0 and 1\n        # 9 ==> 784\n        self.decoder = torch.nn.Sequential(\n            torch.nn.Linear(100, 200),\n            torch.nn.ReLU(),\n            torch.nn.Linear(200, 500),\n            torch.nn.ReLU(),\n            torch.nn.Linear(500, 1000),\n            torch.nn.ReLU(),\n            torch.nn.Linear(1000, 2000),\n            torch.nn.ReLU(),\n            torch.nn.Linear(2000, k * k),\n            torch.nn.ReLU()\n        )\n\n    def forward(self, x):\n        encoded = self.encoder(x)\n        decoded = self.decoder(encoded)\n        return decoded\n\n```\n"
      },
      "source": "https://raw.githubusercontent.com/akhilvreddy/ECE491-SpecialProblems/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Using our model",
        "parent_header": [
          "Special Problems, ECE491",
          "Starting with the Autoencoder class"
        ],
        "type": "Text_excerpt",
        "value": "```\n# Model Initialization\nmodel = AE()\n\n# Validation using MSE Loss function\nloss_function = torch.nn.MSELoss()\n\n# Using an Adam Optimizer with lr = 0.1\noptimizer = torch.optim.Adam(model.parameters(),lr = 0.0001, weight_decay = 1e-8)\n```\nWhat is happening here is that we are making an instance of our Autoencoder class, kind of like in an OOP language like java. After that, we set up our MSE calculations in a variable called *loss_function* which comes from PyTorch's MSELoss() class. \n\nThis line of code creates an optimizer object, which will be used to update the parameters of a model during training. The optimizer used here is the Adam optimizer, which is a popular choice for training neural networks. The Adam optimizer uses a combination of gradient descent and adaptive learning rate techniques to adjust the model's parameters.\n\nThe first argument passed to the Adam function is the parameters of the model, so the optimizer will update the parameters of the model object. The second argument is the learning rate (lr), which is set to 0.0001. This value determines the step size at which the optimizer makes updates to the model's parameters. A smaller learning rate means that the optimizer will make smaller updates, while a larger learning rate means that the optimizer will make larger updates.\n\nThe third argument is weight_decay, which is set to 1e-8. It helps to prevent overfitting by adding an L2 penalty on the weights of the model during optimization.\n\nLearning rate of 0.0001 and weight decay of 1e-8 are reasonable default values to start with for most problems.\n"
      },
      "source": "https://raw.githubusercontent.com/akhilvreddy/ECE491-SpecialProblems/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Training the Autoencoder model to our specific data",
        "parent_header": [
          "Special Problems, ECE491",
          "Starting with the Autoencoder class"
        ],
        "type": "Text_excerpt",
        "value": "This is the most important part of the whole project - it is everything coming together and training the AE model so that we can get reconstructed images. \n```\nepochs = 300 #change the epoch value to be larger\noutputs = []\nlosses = []\nfor epoch in range(epochs):\n#     print(epoch)\n    for image in patchloader:\n        image = image.reshape(-1, k*k)# Reshaping the image to (-1, 784)\n        image = image.float()\n\n    # Output of Autoencoder\n        reconstructed = model(image)\n\n    # Calculating the loss function\n        loss = loss_function(reconstructed, image)\n\n    # The gradients are set to zero,\n    # the gradient is computed and stored.\n    # .step() performs parameter update\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n    # Storing the losses in a list for plotting\n        losses.append(loss)\n        outputs.append((epochs, image, reconstructed))\n    print('epoch [{}/{}], loss:{:.8f}'\n          .format(epoch + 1, epochs, loss.data.detach().numpy()))\n```\nThe outermost loop is running for a total of 300 epochs, which is the value assigned to the variable epochs. An epoch is a full training pass through all the training data.\n\nThe innermost loop is iterating through a data loader object called patchloader, which is presumably an object that loads the images that will be used as input to the autoencoder. For each image in the patchloader, the code reshapes the image to a 2D tensor of shape (-1, k*k) and converts the image to a float data type.\n\nThe autoencoder model is then applied to the image, and the output is assigned to the variable reconstructed. The loss function is then calculated by comparing the reconstructed image to the original image. The loss function used here is the mean squared error.\n\nThe gradients are then set to zero, the gradient is computed and stored by the backward() method, and the step() method updates the model parameters using the optimizer.\n\nAt each iteration of the inner loop, the loss is appended to the losses list and the output and reconstructed image are appended to the outputs list.\n\nFinally, the code prints out the current epoch number, the total number of epochs, and the value of the loss at that point in the training.\n"
      },
      "source": "https://raw.githubusercontent.com/akhilvreddy/ECE491-SpecialProblems/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "MSE Outputs",
        "parent_header": [
          "Special Problems, ECE491",
          "Starting with the Autoencoder class"
        ],
        "type": "Text_excerpt",
        "value": "Here is the output that we get from the model running above. It is worth to note that this took my machine 17 and a half minutes to run. This is important to think about for scalability. If it takes a decent laptop running i5 17.5 minutes, to train huge AI models, it would require a lot of CPU and GPU processing power which would cost a lot. \n```\nepoch [1/300], loss:0.06043266\nepoch [2/300], loss:0.07363702\nepoch [3/300], loss:0.06667658\nepoch [4/300], loss:0.06946521\nepoch [5/300], loss:0.05480300\nepoch [6/300], loss:0.09153187\nepoch [7/300], loss:0.09710239\nepoch [8/300], loss:0.07143620\nepoch [9/300], loss:0.05849411\n...\nepoch [291/300], loss:0.00412072\nepoch [292/300], loss:0.00621012\nepoch [293/300], loss:0.00533406\nepoch [294/300], loss:0.00514319\nepoch [295/300], loss:0.00585328\nepoch [296/300], loss:0.00399428\nepoch [297/300], loss:0.00497398\nepoch [298/300], loss:0.00542437\nepoch [299/300], loss:0.00350400\nepoch [300/300], loss:0.00568663\n```\nThis is the output of the training loop, which shows the value of the loss function at the end of each epoch. The loss function is a measure of how well the autoencoder is able to reconstruct the input images. A lower loss value indicates that the autoencoder is performing well and is able to accurately reconstruct the input images.\n\nIt is clear from the output that the loss is decreasing as the training progresses. In the beginning, the loss is high around 0.06 and by the end, it is around 0.0055. And this decrease in loss indicates that the model is learning and improving with each epoch.\n\nIt is also worth noting that the loss fluctuates, which is normal. There will be some variations in the loss values between different epochs, but overall, the loss is decreasing as the training progresses.\n"
      },
      "source": "https://raw.githubusercontent.com/akhilvreddy/ECE491-SpecialProblems/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Viewing our MSE",
        "parent_header": [
          "Special Problems, ECE491",
          "Starting with the Autoencoder class"
        ],
        "type": "Text_excerpt",
        "value": "```\nl = []\nfor j in range(len(losses)):\n    a = losses[j].detach().numpy()\n    l.append(a)\n\n# Defining the Plot Style\nplt.plot(l)\nplt.style.use('fivethirtyeight')\nplt.xlabel('Iterations')\nplt.ylabel('Loss')\n```\n\nThis code is plotting the training loss over the course of the training process.\n\nThe first loop iterates through the losses list, which contains the loss values at the end of each iteration of the training loop. For each value in the losses list, the code converts the value to a numpy array and appends it to a new list l.\n\nThe next part of the code is using the matplotlib library to plot the data in the l list. The plt.plot(l) function plots the values in the l list on the y-axis, and the x-axis is determined by the index of the values in the list.\n\nThis plot will show how the loss changes over time and will help to monitor the training progress and identify if the model is overfitting or underfitting.\n\nHere is what a good version of what a loss model would look like: \n\n<p align=\"center\">\n  <img \n    src=\"https://github.com/akhilvreddy/ECE491-SpecialProblems/blob/main/Reference%20Images/imgz_idealloss.png\"\n  >\n</p>\n"
      },
      "source": "https://raw.githubusercontent.com/akhilvreddy/ECE491-SpecialProblems/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Viewing our reconstructed image:",
        "parent_header": [
          "Special Problems, ECE491",
          "Starting with the Autoencoder class"
        ],
        "type": "Text_excerpt",
        "value": "```\n# print(reconstructed.shape)\nfor i, item in enumerate(reconstructed):\n    item = item.reshape(-1, k, k)\n    plt.imshow(item[0].detach().numpy(),cmap='gray',vmin=0, vmax=1)\n#     plt.show()\n```\n\nHere is what one the reconstructed patches look like:\n\n<p align=\"center\">\n  <img \n    src=\"https://github.com/akhilvreddy/ECE491-SpecialProblems/blob/main/Reference%20Images/imgx_reconstructedpatch.png\"\n  >\n</p>\n\nWe can also stitch them together using the method we talked about [above](https://github.com/akhilvreddy/ECE491-SpecialProblems/blob/main/README.md#test-patches). Here is what the code would look like: \n```\nimage = image.reconstruct_from_patches_2d(patches, (height, width))\n```\n"
      },
      "source": "https://raw.githubusercontent.com/akhilvreddy/ECE491-SpecialProblems/main/README.md",
      "technique": "header_analysis"
    }
  ]
}