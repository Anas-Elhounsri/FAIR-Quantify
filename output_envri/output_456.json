{
  "application_domain": [
    {
      "confidence": 25.1,
      "result": {
        "type": "String",
        "value": "Computer Vision"
      },
      "technique": "supervised_classification"
    },
    {
      "confidence": 43.04,
      "result": {
        "type": "String",
        "value": "Reinforcement Learning"
      },
      "technique": "supervised_classification"
    }
  ],
  "citation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "How to cite this work?",
        "parent_header": [
          "*SMPyBandits*"
        ],
        "type": "Text_excerpt",
        "value": "If you use this package for your own work, please consider citing it with [this piece of BibTeX](SMPyBandits.bib):\n\n\n```bibtex\n@misc{SMPyBandits,\n    title =   {{SMPyBandits: an Open-Source Research Framework for Single and Multi-Players Multi-Arms Bandits (MAB) Algorithms in Python}},\n    author =  {Lilian Besson},\n    year =    {2018},\n    url =     {https://github.com/SMPyBandits/SMPyBandits/},\n    howpublished = {Online at: \\url{github.com/SMPyBandits/SMPyBandits}},\n    note =    {Code at https://github.com/SMPyBandits/SMPyBandits/, documentation at https://smpybandits.github.io/}\n}\n```\n\nI also wrote a small paper to present *SMPyBandits*, and I will send it to [JMLR MLOSS](http://jmlr.org/mloss/).\nThe paper can be consulted [here on my website](https://perso.crans.org/besson/articles/SMPyBandits.pdf).\n\n> A DOI will arrive as soon as possible! I tried to publish [a paper](docs/paper/paper.md) on both [JOSS](http://joss.theoj.org/) and [MLOSS](http://mloss.org/software/).\n"
      },
      "source": "https://raw.githubusercontent.com/SMPyBandits/SMPyBandits/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "author": "Lilian Besson",
        "format": "bibtex",
        "title": "{SMPyBandits: an Open-Source Research Framework for Single and Multi-Players Multi-Arms Bandits (MAB) Algorithms in Python}",
        "type": "Text_excerpt",
        "url": "https://github.com/SMPyBandits/SMPyBandits/",
        "value": "@misc{SMPyBandits,\n    note = {Code at https://github.com/SMPyBandits/SMPyBandits/, documentation at https://smpybandits.github.io/},\n    howpublished = {Online at: \\url{github.com/SMPyBandits/SMPyBandits}},\n    url = {https://github.com/SMPyBandits/SMPyBandits/},\n    year = {2018},\n    author = {Lilian Besson},\n    title = {{SMPyBandits: an Open-Source Research Framework for Single and Multi-Players Multi-Arms Bandits (MAB) Algorithms in Python}},\n}"
      },
      "source": "https://raw.githubusercontent.com/SMPyBandits/SMPyBandits/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "code_of_conduct": [
    {
      "confidence": 1,
      "result": {
        "type": "File_dump",
        "value": "# Contributor Covenant Code of Conduct\n\n## Our Pledge\n\nIn the interest of fostering an open and welcoming environment, we as\ncontributors and maintainers pledge to making participation in our project and\nour community a harassment-free experience for everyone, regardless of age, body\nsize, disability, ethnicity, gender identity and expression, level of experience,\neducation, socio-economic status, nationality, personal appearance, race,\nreligion, or sexual identity and orientation.\n\n## Our Standards\n\nExamples of behavior that contributes to creating a positive environment\ninclude:\n\n* Using welcoming and inclusive language\n* Being respectful of differing viewpoints and experiences\n* Gracefully accepting constructive criticism\n* Focusing on what is best for the community\n* Showing empathy towards other community members\n\nExamples of unacceptable behavior by participants include:\n\n* The use of sexualized language or imagery and unwelcome sexual attention or\n  advances\n* Trolling, insulting/derogatory comments, and personal or political attacks\n* Public or private harassment\n* Publishing others' private information, such as a physical or electronic\n  address, without explicit permission\n* Other conduct which could reasonably be considered inappropriate in a\n  professional setting\n\n## Our Responsibilities\n\nProject maintainers are responsible for clarifying the standards of acceptable\nbehavior and are expected to take appropriate and fair corrective action in\nresponse to any instances of unacceptable behavior.\n\nProject maintainers have the right and responsibility to remove, edit, or\nreject comments, commits, code, wiki edits, issues, and other contributions\nthat are not aligned to this Code of Conduct, or to ban temporarily or\npermanently any contributor for other behaviors that they deem inappropriate,\nthreatening, offensive, or harmful.\n\n## Scope\n\nThis Code of Conduct applies both within project spaces and in public spaces\nwhen an individual is representing the project or its community. Examples of\nrepresenting a project or community include using an official project e-mail\naddress, posting via an official social media account, or acting as an appointed\nrepresentative at an online or offline event. Representation of a project may be\nfurther defined and clarified by project maintainers.\n\n## Enforcement\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be\nreported by contacting the project team at `naereen at crans dot org`.\nAll complaints will be reviewed and investigated and will result in a response that\nis deemed necessary and appropriate to the circumstances. The project team is\nobligated to maintain confidentiality with regard to the reporter of an incident.\nFurther details of specific enforcement policies may be posted separately.\n\nProject maintainers who do not follow or enforce the Code of Conduct in good\nfaith may face temporary or permanent repercussions as determined by other\nmembers of the project's leadership.\n\n## Attribution\n\nThis Code of Conduct is adapted from the [Contributor Covenant][homepage], version 1.4,\navailable at https://www.contributor-covenant.org/version/1/4/code-of-conduct.html\n\n[homepage]: https://www.contributor-covenant.org\n\n"
      },
      "source": "https://raw.githubusercontent.com/SMPyBandits/SMPyBandits/master/.github/CODE_OF_CONDUCT.md",
      "technique": "file_exploration"
    }
  ],
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/SMPyBandits/SMPyBandits"
      },
      "technique": "GitHub_API"
    }
  ],
  "contributing_guidelines": [
    {
      "confidence": 1,
      "result": {
        "type": "File_dump",
        "value": "# On Github Issues and Pull Requests\n\nFound a bug? Have a new feature to suggest? Want to contribute changes to the codebase? Make sure to read this first.\n\nYou can read this [document to learn how to do your first contributions](https://github.com/firstcontributions/first-contributions#first-contributions) (\ud83c\uddeb\ud83c\uddf7 aussi [disponible en fran\u00e7ais](https://github.com/firstcontributions/first-contributions/blob/master/translations/README.fr.md)).\n\n## Bug reporting\n\nYour code doesn't work, and you have determined that the issue lies with SMPyBandits? Follow these steps to report a bug.\n\n1. Your bug may already be fixed. Make sure to update to the current SMPyBandits master branch. To easily update SMPyBandits: `pip install git+git://github.com/SMPyBandits/SMPyBandits.git --upgrade`\n\n2. Search for similar issues. Make sure to delete `is:open` on the issue search to find solved tickets as well. It's possible somebody has encountered this bug already. Still having a problem? Open an issue on Github to let us know.\n\n3. Make sure you provide us with useful information about your configuration: what OS are you using? Which version of Python? (3, [no one should use Python 2](https://pythonclock.org/) anymore...) etc\n\n4. Provide us with a script to reproduce the issue. This script should be runnable as-is. I recommend that you use Github Gists to post your code. Any issue that cannot be reproduced is likely to be closed.\n\n5. If possible, take a stab at fixing the bug yourself --if you can!\n\nThe more information you provide, the easier it is for us to validate that there is a bug and the faster we'll be able to take action. If you want your issue to be resolved quickly, following the steps above is crucial.\n\n---\n\n## Requesting a Feature\n\nYou can also use Github issues to request features you would like to see in SMPyBandits, or changes in the SMPyBandits API.\n\n1. Provide a clear and detailed explanation of the feature you want and why it's important to add. Keep in mind that I want features that will be useful to my research. Any other requests for features will probably stay unanswered.\n\n2. Provide code snippets demonstrating the API you have in mind and illustrating the use cases of your feature (eg. for a new algorithm, give a reference to the research article). Of course, you don't need to write any real code at this point!\n\n3. After discussing the feature you may choose to attempt a Pull Request. If you're at all able, start writing some code. I always have more work to do than time to do it. If you can write some code then that will speed the process along.\n\n\n---\n\n## Requests for Contributions\n\n[This is the file](https://github.com/SMPyBandits/SMPyBandits/tree/master/TODO.md) where I list current issues and features to be added. If you want to start contributing to SMPyBandits, this is the place to start.\n\n---\n\n## Pull Requests\n\n**Where should I submit my pull request?**\n\n1. **SMPyBandits improvements and bugfixes** go to the [SMPyBandits `master` branch](https://github.com/SMPyBandits/SMPyBandits/tree/master).\n\nPlease note that PRs that are primarily about **code style** (as opposed to fixing bugs, improving docs, or adding new functionality) will likely be rejected.\n\nHere's a quick guide to submitting your improvements:\n\n1. If your PR introduces a change in functionality, make sure you start by writing a design doc and share it on a SMPyBandits issue.\n\n2. Write the code (or get others to write it). This is the hard part!\n\n3. Make sure any new function or class you introduce has proper docstrings. Make sure any code you touch still has up-to-date docstrings and documentation. I don't care about docstring style, just useful docstrings.\n\n4. Write examples, and try your code in some non-trivial bandit problems.\n\n5. I use PEP8 syntax conventions, but I am not dogmatic when it comes to line length. Make sure your lines stay reasonably sized, though. To make your life easier, I recommend running a PEP8 linter:\n    - Install PEP8 packages: `pip install pep8 pytest-pep8 autopep8`\n    - Run a standalone PEP8 check: `py.test --pep8 -m pep8`\n    - You can automatically fix some PEP8 error by running: `autopep8 -i --select <errors> <FILENAME>` for example: `autopep8 -i --select E128 Policies/newAlgorithm.py`\n\n6. When committing, use appropriate, descriptive commit messages.\n\n7. Update the documentation. If introducing new functionality, make sure you include code snippets demonstrating the usage of your new feature.\n\n8. Submit your PR. If your changes have been approved in a previous discussion, and if you have complete (and passing) unit tests as well as proper docstrings/documentation, your PR is likely to be merged promptly.\n\n---\n\n## Adding new examples\n\nEven if you don't contribute to the SMPyBandits source code, if you have an application of SMPyBandits that is concise and powerful, please consider adding it to my collection of examples, as a notebook.\n[Existing notebooks](https://github.com/SMPyBandits/SMPyBandits/tree/master/notebooks) show idiomatic SMPyBandits code: make sure to keep your own script in the same spirit.\n"
      },
      "source": "https://raw.githubusercontent.com/SMPyBandits/SMPyBandits/master/.github/CONTRIBUTING.md",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Contributing?",
        "parent_header": [
          "*SMPyBandits*"
        ],
        "type": "Text_excerpt",
        "value": "> I don't except issues or pull requests on this project, but you are welcome to.\n\nContributions (issues, questions, pull requests) are of course welcome, but this project is and will stay a personal environment designed for quick research experiments, and will never try to be an industry-ready module for applications of Multi-Armed Bandits algorithms.\nIf you want to contribute, please have a look to the [CONTRIBUTING.md](.github/CONTRIBUTING.md) file, and if you want to be more seriously involved, read the [CODE_OF_CONDUCT.md](.github/CODE_OF_CONDUCT.md) file.\n\n- You are welcome to [submit an issue](https://github.com/SMPyBandits/SMPyBandits/issues/new), if it was not previously answered,\n- If you have interesting example of use of SMPyBandits, please share it! ([Jupyter Notebooks](https://www.jupyter.org/) are preferred). And fill a pull request to [add it to the notebooks examples](notebooks/).\n"
      },
      "source": "https://raw.githubusercontent.com/SMPyBandits/SMPyBandits/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2016-11-17T13:27:49Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2024-09-27T08:55:51Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "\ud83d\udd2c Research Framework for Single and Multi-Players \ud83c\udfb0 Multi-Arms Bandits (MAB) Algorithms, implementing all the state-of-the-art algorithms for single-player (UCB, KL-UCB, Thompson...) and multi-player (MusicalChair, MEGA, rhoRand, MCTop/RandTopM etc).. Available on PyPI: https://pypi.org/project/SMPyBandits/ and documentation on"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 0.9701537444432584,
      "result": {
        "original_header": "*SMPyBandits*",
        "type": "Text_excerpt",
        "value": "This repository contains the code of [Lilian Besson's](https://perso.crans.org/besson/) numerical environment, written in [Python (2 or 3)](https://www.python.org/), for numerical simulations on :slot_machine: *single*-player and *multi*-players [Multi-Armed Bandits (MAB)](https://en.wikipedia.org/wiki/Multi-armed_bandit) algorithms. \n- A complete Sphinx-generated documentation is on [SMPyBandits.GitHub.io](https://smpybandits.github.io/).\n- You can also browse online the results of extensive benchmarks, powered by [Airspeed Velocity](https://asv.readthedocs.io/en/stable/using.html), on [this page](https://perso.crans.org/besson/phd/SMPyBandits-benchmarks/) (code on [SMPyBandits-benchmarks](https://github.com/Naereen/SMPyBandits-benchmarks/)).\n \n"
      },
      "source": "https://raw.githubusercontent.com/SMPyBandits/SMPyBandits/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.98279162838876,
      "result": {
        "original_header": "Quick presentation",
        "type": "Text_excerpt",
        "value": "It contains the most complete collection of single-player (classical) bandit algorithms on the Internet ([over 65!](https://smpybandits.github.io/docs/Policies.html)), as well as implementation of all the state-of-the-art [multi-player algorithms](https://smpybandits.github.io/MultiPlayers.html#policies-designed-to-be-used-in-the-multi-players-setting). \nI follow very actively the latest publications related to Multi-Armed Bandits (MAB) research, and usually implement quite quickly the new algorithms (see for instance, [Exp3++](https://smpybandits.github.io/docs/Policies.Exp3PlusPlus.html), [CORRAL](https://smpybandits.github.io/docs/Policies.CORRAL.html) and [SparseUCB](https://smpybandits.github.io/docs/Policies.SparseUCB.html) were each introduced by articles ([for Exp3++](https://arxiv.org/pdf/1702.06103), [for CORRAL](https://arxiv.org/abs/1612.06246v2), [for SparseUCB](https://arxiv.org/abs/1706.01383)) presented at COLT in July 2017, [LearnExp](https://smpybandits.github.io/docs/Policies.LearnExp.html) comes from a [NIPS 2017 paper](https://arxiv.org/abs/1702.04825), and [kl-UCB++](https://smpybandits.github.io/docs/Policies.klUCBPlusPlus.html) from an [ALT 2017 paper](https://hal.inria.fr/hal-01475078).).\nMore recent examples are [klUCBswitch](https://smpybandits.github.io/docs/Policies.klUCBswitch.html) from [a paper from May 2018](https://arxiv.org/abs/1805.05071), and also [MusicalChairNoSensing](https://smpybandits.github.io/docs/Policies.MusicalChairNoSensing.html) from [a paper from August 2018](https://arxiv.org/abs/1808.08416). \n- Classical MAB have a lot of applications, from clinical trials, A/B testing, game tree exploration, and online content recommendation (my framework does *not* implement contextual bandit - yet).\n- [Multi-player MAB](MultiPlayers.md) have applications in Cognitive Radio, and my framework implements [all the collision models](https://smpybandits.github.io/docs/Environment.CollisionModels.html) found in the literature, as well as all the algorithms from the last 10 years or so ([`rhoRand`](https://smpybandits.github.io/docs/PoliciesMultiPlayers.rhoRand.html) from 2009, [`MEGA`](https://smpybandits.github.io/docs/Policies.MEGA.html) from 2015, [`MusicalChair`](https://smpybandits.github.io/docs/Policies.MusicalChair.html), and our state-of-the-art algorithms [`RandTopM`](https://smpybandits.github.io/docs/PoliciesMultiPlayers.RandTopM.html) and [`MCTopM`](https://smpybandits.github.io/docs/PoliciesMultiPlayers.MCTopM.html), along with very recent algorithms [`SIC-MMAB`](https://smpybandits.github.io/docs/Policies.SIC_MMAB.html) from [arXiv:1809.08151](https://arxiv.org/abs/1809.08151) and [`MusicalChairNoSensing`](https://smpybandits.github.io/docs/Policies.MusicalChairNoSensing.html) from [arXiv:1808.08416](https://arxiv.org/abs/1808.08416)).\n- I'm working on adding a clean support for non-stationary MAB problem, and I will soon implement all state-of-the-art algorithms for these problems. \nWith this numerical framework, simulations can run on a single CPU or a multi-core machine, and summary plots are automatically saved as high-quality PNG, PDF and EPS (ready for being used in research article).\nMaking new simulations is very easy, one only needs to write a configuration script and basically no code! See [these examples](https://github.com/SMPyBandits/SMPyBandits/search?l=Python&q=configuration&type=&utf8=%E2%9C%93) (files named `configuration_*.py`). \nA complete [Sphinx](http://sphinx-doc.org/) documentation for each algorithms and every piece of code (included constants in the configurations!) is available here: [SMPyBandits.GitHub.io](https://smpybandits.github.io/). (I will use [ReadTheDocs](https://readthedocs.org/) for this project, but I won't use any *continuous integration*, don't even think of it!) \n\n> [I (Lilian Besson)](https://perso.crans.org/besson/) have [started my PhD](https://perso.crans.org/besson/phd/) in October 2016, and this is a part of my **on going** research since December 2016.\n>\n> I launched the [documentation](https://smpybandits.github.io/) on March 2017, I wrote my first research articles using this framework in 2017 and decided to (finally) open-source my project in February 2018.\n> [![Commits of https://github.com/SMPyBandits/SMPyBandits/](https://badgen.net/github/commits/SMPyBandits/SMPyBandits)](https://github.com/SMPyBandits/SMPyBandits/commits/master) / [![Date of last commit of https://github.com/SMPyBandits/SMPyBandits/](https://badgen.net/github/last-commit/SMPyBandits/SMPyBandits)](https://github.com/SMPyBandits/SMPyBandits/commits/master)\n> [![Issues of https://github.com/SMPyBandits/SMPyBandits/](https://badgen.net/github/issues/SMPyBandits/SMPyBandits)](https://GitHub.com/SMPyBandits/SMPyBandits/issues) : [![Open issues of https://github.com/SMPyBandits/SMPyBandits/](https://badgen.net/github/open-issues/SMPyBandits/SMPyBandits)](https://github.com/SMPyBandits/SMPyBandits/issues?q=is%3Aopen+is%3Aissue) / [![Closed issues of https://github.com/SMPyBandits/SMPyBandits/](https://badgen.net/github/closed-issues/SMPyBandits/SMPyBandits)](https://github.com/SMPyBandits/SMPyBandits/issues?q=is%3Aclosed+is%3Aissue) \n"
      },
      "source": "https://raw.githubusercontent.com/SMPyBandits/SMPyBandits/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.846779342582566,
      "result": {
        "original_header": "1st article, about <a href=\"Aggregation.md\">**policy aggregation algorithm (aka model selection)**</a>",
        "type": "Text_excerpt",
        "value": "I designed and added the [`Aggregator`](https://smpybandits.github.io/docs/Policies.Aggregator.html) policy, in order to test its validity and performance. \nIt is a \"simple\" **voting algorithm to combine multiple bandit algorithms into one**.\nBasically, it behaves like a simple MAB bandit just based on empirical means (even simpler than UCB), where *arms* are the child algorithms `A_1 .. A_N`, each running in \"parallel\". \n"
      },
      "source": "https://raw.githubusercontent.com/SMPyBandits/SMPyBandits/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9480201878800125,
      "result": {
        "original_header": "4th article, about <a href=\"NonStationaryBandits.md\">**Piece-Wise Stationary Multi-Armed Bandits**</a>",
        "type": "Text_excerpt",
        "value": "> **For more details**, refer to this file: [`NonStationaryBandits.md`](NonStationaryBandits.md) and [this research article](https://hal.inria.fr/hal-02006471). \n"
      },
      "source": "https://raw.githubusercontent.com/SMPyBandits/SMPyBandits/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9850050380294704,
      "result": {
        "original_header": "2nd article, about <a href=\"MultiPlayers.md\">**Multi-players Multi-Armed Bandits**</a>",
        "type": "Text_excerpt",
        "value": "There is another point of view: instead of comparing different single-player policies on the same problem, we can make them play against each other, in a multi-player setting.\nThe basic difference is about **collisions** : at each time `t`, if two or more user chose to sense the same channel, there is a *collision*. Collisions can be handled in different way from the base station point of view, and from each player point of view. \n"
      },
      "source": "https://raw.githubusercontent.com/SMPyBandits/SMPyBandits/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9065621774596483,
      "result": {
        "original_header": "3rd article, using <a href=\"DoublingTrick.md\">**Doubling Trick for Multi-Armed Bandits**</a>",
        "type": "Text_excerpt",
        "value": "I studied what Doubling Trick can and can't do to obtain efficient anytime version of non-anytime optimal Multi-Armed Bandits algorithms. \n"
      },
      "source": "https://raw.githubusercontent.com/SMPyBandits/SMPyBandits/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9572341840993549,
      "result": {
        "original_header": "4th article, about <a href=\"NonStationaryBandits.md\">**Piece-Wise Stationary Multi-Armed Bandits**</a>",
        "type": "Text_excerpt",
        "value": "With Emilie Kaufmann, we studied the Generalized Likelihood Ratio Test (GLRT) for sub-Bernoulli distributions, and proposed the B-GLRT algorithm for change-point detection for piece-wise stationary one-armed bandit problems. We combined the B-GLRT with the kl-UCB multi-armed bandit algorithm and proposed the GLR-klUCB algorithm for piece-wise stationary multi-armed bandit problems. We prove finite-time guarantees for the B-GLRT and the GLR-klUCB algorithm, and we illustrate its performance with extensive numerical experiments. \n"
      },
      "source": "https://raw.githubusercontent.com/SMPyBandits/SMPyBandits/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9916237220795695,
      "result": {
        "original_header": "<a href=\"https://smpybandits.github.io/docs/Policies.html\">Single-player Policies</a>",
        "type": "Text_excerpt",
        "value": "- More than 65 algorithms, including all known variants of the [`UCB`](https://smpybandits.github.io/docs/Policies.UCB.html), [kl-UCB](https://smpybandits.github.io/docs//Policies.klUCB.html), [`MOSS`](https://smpybandits.github.io/docs/Policies.MOSS.html) and [Thompson Sampling](https://smpybandits.github.io/docs/Policies.Thompson.html) algorithms, as well as other less known algorithms ([`OCUCB`](https://smpybandits.github.io/docs/Policies.OCUCB.html), [`BESA`](https://smpybandits.github.io/docs/Policies.OCUCB.html), [`OSSB`](https://smpybandits.github.io/docs/Policies.OSSB.html) etc).\n- For instance, [`SparseWrapper`](https://smpybandits.github.io/docs/Policies.SparseWrapper.html#module-Policies.SparseWrapper) is a generalization of [the SparseUCB from this article](https://arxiv.org/pdf/1706.01383/).\n- Implementation of very recent Multi-Armed Bandits algorithms, e.g., [`kl-UCB++`](https://smpybandits.github.io/docs/Policies.klUCBPlusPlus.html) (from [this article](https://hal.inria.fr/hal-01475078)), [`UCB-dagger`](https://smpybandits.github.io/docs/Policies.UCBdagger.html) (from [this article](https://arxiv.org/pdf/1507.07880)),  or [`MOSS-anytime`](https://smpybandits.github.io/docs/Policies.MOSSAnytime.html) (from [this article](http://proceedings.mlr.press/v48/degenne16.pdf)).\n- Experimental policies: [`BlackBoxOpt`](https://smpybandits.github.io/docs/Policies.BlackBoxOpt.html) or [`UnsupervisedLearning`](https://smpybandits.github.io/docs/Policies.UnsupervisedLearning.html) (using Gaussian processes to learn the arms distributions).\n \n"
      },
      "source": "https://raw.githubusercontent.com/SMPyBandits/SMPyBandits/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.996197194330518,
      "result": {
        "original_header": "Other remarks",
        "type": "Text_excerpt",
        "value": "- Everything here is done in an imperative, object oriented style. The API of the Arms, Policy and MultiPlayersPolicy classes is documented [in this file (`API.md`)](API.md).\n- The code is [clean](logs/main_pylint_log.txt), valid for both [Python 2](logs/main_pylint_log.txt) and [Python 3](logs/main_pylint3_log.txt).\n- Some piece of code come from the [pymaBandits](http://mloss.org/software/view/415/) project, but most of them were refactored. Thanks to the initial project!\n- [G.Varoquaux](http://gael-varoquaux.info/)'s [joblib](https://joblib.readthedocs.io/) is used for the [`Evaluator`](https://smpybandits.github.io/docs/Environment.Evaluator.html) and [`EvaluatorMultiPlayers`](https://smpybandits.github.io/docs/Environment.EvaluatorMultiPlayers.html) classes, so the simulations are easily parallelized on multi-core machines. (Put `n_jobs = -1` or `PARALLEL = True` in the config file to use all your CPU cores, as it is by default).\n \n"
      },
      "source": "https://raw.githubusercontent.com/SMPyBandits/SMPyBandits/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/SMPyBandits/SMPyBandits/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "executable_example": [
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/SMPyBandits/SMPyBandits/master/notebooks/Experiments_of_statistical_tests_for_piecewise_stationary_bandit.ipynb"
      },
      "source": "https://raw.githubusercontent.com/SMPyBandits/SMPyBandits/master/notebooks/Experiments_of_statistical_tests_for_piecewise_stationary_bandit.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/SMPyBandits/SMPyBandits/master/notebooks/Visualizing_detection_of_change_points_for_nonstationary_problems.ipynb"
      },
      "source": "https://raw.githubusercontent.com/SMPyBandits/SMPyBandits/master/notebooks/Visualizing_detection_of_change_points_for_nonstationary_problems.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/SMPyBandits/SMPyBandits/master/notebooks/Unsupervised_Learning_for_Bandit_problem.ipynb"
      },
      "source": "https://raw.githubusercontent.com/SMPyBandits/SMPyBandits/master/notebooks/Unsupervised_Learning_for_Bandit_problem.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/SMPyBandits/SMPyBandits/master/notebooks/Do_we_even_need_UCB.ipynb"
      },
      "source": "https://raw.githubusercontent.com/SMPyBandits/SMPyBandits/master/notebooks/Do_we_even_need_UCB.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/SMPyBandits/SMPyBandits/master/notebooks/Exploring_different_doubling_tricks_for_different_kinds_of_regret_bounds.ipynb"
      },
      "source": "https://raw.githubusercontent.com/SMPyBandits/SMPyBandits/master/notebooks/Exploring_different_doubling_tricks_for_different_kinds_of_regret_bounds.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/SMPyBandits/SMPyBandits/master/notebooks/Testing_cython_numba_for_base_functions.ipynb"
      },
      "source": "https://raw.githubusercontent.com/SMPyBandits/SMPyBandits/master/notebooks/Testing_cython_numba_for_base_functions.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/SMPyBandits/SMPyBandits/master/notebooks/Lai_Robbins_Lower_Bound_for_Doubling_Trick_with_Restarting_Algorithms.ipynb"
      },
      "source": "https://raw.githubusercontent.com/SMPyBandits/SMPyBandits/master/notebooks/Lai_Robbins_Lower_Bound_for_Doubling_Trick_with_Restarting_Algorithms.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/SMPyBandits/SMPyBandits/master/notebooks/Easily_creating_MAB_problems.ipynb"
      },
      "source": "https://raw.githubusercontent.com/SMPyBandits/SMPyBandits/master/notebooks/Easily_creating_MAB_problems.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/SMPyBandits/SMPyBandits/master/notebooks/BlackBox_Bayesian_Optimization_for_Bandit_problems.ipynb"
      },
      "source": "https://raw.githubusercontent.com/SMPyBandits/SMPyBandits/master/notebooks/BlackBox_Bayesian_Optimization_for_Bandit_problems.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/SMPyBandits/SMPyBandits/master/notebooks/Demonstrations_of_Single-Player_Simulations_for_Non-Stationary-Bandits.ipynb"
      },
      "source": "https://raw.githubusercontent.com/SMPyBandits/SMPyBandits/master/notebooks/Demonstrations_of_Single-Player_Simulations_for_Non-Stationary-Bandits.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/SMPyBandits/SMPyBandits/master/notebooks/Example_of_a_small_Multi-Player_Simulation__with_Centralized_Algorithms.ipynb"
      },
      "source": "https://raw.githubusercontent.com/SMPyBandits/SMPyBandits/master/notebooks/Example_of_a_small_Multi-Player_Simulation__with_Centralized_Algorithms.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/SMPyBandits/SMPyBandits/master/notebooks/Example_of_a_small_Single-Player_Simulation.ipynb"
      },
      "source": "https://raw.githubusercontent.com/SMPyBandits/SMPyBandits/master/notebooks/Example_of_a_small_Single-Player_Simulation.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/SMPyBandits/SMPyBandits/master/notebooks/Example_of_a_small_Multi-Player_Simulation__with_rhoRand_and_Selfish_Algorithms.ipynb"
      },
      "source": "https://raw.githubusercontent.com/SMPyBandits/SMPyBandits/master/notebooks/Example_of_a_small_Multi-Player_Simulation__with_rhoRand_and_Selfish_Algorithms.ipynb",
      "technique": "file_exploration"
    }
  ],
  "faq": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Arms and problems",
        "parent_header": [
          "*SMPyBandits*",
          "Other interesting things"
        ],
        "type": "Text_excerpt",
        "value": "- My framework mainly targets stochastic bandits, with arms following [`Bernoulli`](https://smpybandits.github.io/docs/Arms.Bernoulli.html), bounded (truncated) or unbounded [`Gaussian`](https://smpybandits.github.io/docs/Arms.Gaussian.html), [`Exponential`](https://smpybandits.github.io/docs/Arms.Exponential.html), [`Gamma`](https://smpybandits.github.io/docs/Arms.Gamma.html) or [`Poisson`](https://smpybandits.github.io/docs/Arms.Poisson.html) distributions, and more.\n- The default configuration is to use a fixed problem for N repetitions (e.g. 1000 repetitions, use [`MAB.MAB`](https://smpybandits.github.io/docs/Environment.MAB.html#Environment.MAB.MAB)), but there is also a perfect support for \"Bayesian\" problems where the mean vector \u00b51,\u2026,\u00b5K change *at every repetition* (see [`MAB.DynamicMAB`](https://smpybandits.github.io/docs/Environment.MAB.html#Environment.MAB.DynamicMAB)).\n- There is also a good support for Markovian problems, see [`MAB.MarkovianMAB`](https://smpybandits.github.io/docs/Environment.MAB.html#Environment.MAB.MarkovianMAB), even though I didn't implement any policies tailored for Markovian problems.\n- I'm actively working on adding a very clean support for non-stationary MAB problems, and [`MAB.PieceWiseStationaryMAB`](https://smpybandits.github.io/docs/Environment.MAB.html#Environment.MAB.PieceWiseStationaryMAB) is already working well. Use it with policies designed for piece-wise stationary problems, like [Discounted-Thompson](https://smpybandits.github.io/docs/Policies.DiscountedThompson.html), one of the [CD-UCB](https://smpybandits.github.io/docs/Policies.CD_UCB.html) algorithms, [M-UCB](https://smpybandits.github.io/docs/Policies.Monitored_UCB.html), [SlidingWindowUCB](https://smpybandits.github.io/docs/Policies.SlidingWindowUCB.html) or [Discounted-UCB](https://smpybandits.github.io/docs/Policies.DiscountedUCB.html), or [SW-UCB#](https://smpybandits.github.io/docs/Policies.SWHash_UCB.html).\n\n----\n"
      },
      "source": "https://raw.githubusercontent.com/SMPyBandits/SMPyBandits/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 57
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/SMPyBandits/SMPyBandits/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "SMPyBandits/SMPyBandits"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "SMPyBandits"
      },
      "source": "https://raw.githubusercontent.com/SMPyBandits/SMPyBandits/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "has_script_file": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/SMPyBandits/SMPyBandits/master/notebooks/symlinks.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/SMPyBandits/SMPyBandits/master/.github/issues/open_local_cache.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/SMPyBandits/SMPyBandits/master/.github/issues/update_local_cache.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/SMPyBandits/SMPyBandits/master/other_scripts/run_all_doctest.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/SMPyBandits/SMPyBandits/master/other_scripts/test_all.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/SMPyBandits/SMPyBandits/master/other_scripts/travis_install.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/SMPyBandits/SMPyBandits/master/other_scripts/run_test_simulations.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/SMPyBandits/SMPyBandits/master/other_scripts/fixes_html_in_doc.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/SMPyBandits/SMPyBandits/master/plots/remove_empty_folders.sh"
      },
      "technique": "file_exploration"
    }
  ],
  "images": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/SMPyBandits/SMPyBandits/master/logo_large.png"
      },
      "source": "https://raw.githubusercontent.com/SMPyBandits/SMPyBandits/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://ga-beacon.appspot.com/UA-38514290-17/raw.githubusercontent.com/SMPyBandits/SMPyBandits/README.md?pixel"
      },
      "source": "https://raw.githubusercontent.com/SMPyBandits/SMPyBandits/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://ga-beacon.appspot.com/UA-38514290-17/raw.githubusercontent.com/SMPyBandits/SMPyBandits/README.md?pixel"
      },
      "source": "https://raw.githubusercontent.com/SMPyBandits/SMPyBandits/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "invocation": [
    {
      "confidence": 0.8178914186438049,
      "result": {
        "original_header": "*SMPyBandits*",
        "type": "Text_excerpt",
        "value": "<img width=\"50%\" src=\"logo_large.png\" align=\"right\" alt=\"Logo, logo_large.png\"/> \n"
      },
      "source": "https://raw.githubusercontent.com/SMPyBandits/SMPyBandits/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/SMPyBandits/SMPyBandits/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "bandit-algorithms, cognitive-radio, internet-of-things, learning-theory, multi-arm-bandits, multi-armed-bandit, open-source, python, research, simulations"
      },
      "technique": "GitHub_API"
    }
  ],
  "license": [
    {
      "confidence": 1,
      "result": {
        "name": "MIT License",
        "spdx_id": "MIT",
        "type": "License",
        "url": "https://api.github.com/licenses/mit",
        "value": "https://api.github.com/licenses/mit"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "type": "File_dump",
        "value": "The MIT License (MIT)\n\nCopyright (c) 2016-2018 Lilian Besson (Naereen), https://GitHub.com/Naereen\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
      },
      "source": "https://raw.githubusercontent.com/SMPyBandits/SMPyBandits/master/LICENSE",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": ":scroll: License ? <a href=\"https://github.com/SMPyBandits/SMPyBandits/blob/master/LICENSE\"><img alt=\"GitHub license\" src=\"https://img.shields.io/github/license/SMPyBandits/SMPyBandits.svg\" /></a>",
        "parent_header": [
          "*SMPyBandits*"
        ],
        "type": "Text_excerpt",
        "value": "[MIT Licensed](https://lbesson.mit-license.org/) (file [LICENSE](LICENSE)).\n\n\u00a9 2016-2018 [Lilian Besson](https://GitHub.com/Naereen), with help [from contributors](https://github.com/SMPyBandits/SMPyBandits/graphs/contributors).\n\n[![Maintenance](https://img.shields.io/badge/Maintained%3F-yes-green.svg)](https://GitHub.com/SMPyBandits/SMPyBandits/graphs/commit-activity)\n[![Ask Me Anything !](https://img.shields.io/badge/Ask%20me-anything-1abc9c.svg)](https://GitHub.com/Naereen/ama)\n[![Analytics](https://ga-beacon.appspot.com/UA-38514290-17/github.com/SMPyBandits/SMPyBandits/README.md?pixel)](https://GitHub.com/SMPyBandits/SMPyBandits/)\n[![PyPI version](https://img.shields.io/pypi/v/smpybandits.svg)](https://pypi.org/project/SMPyBandits)\n[![PyPI implementation](https://img.shields.io/pypi/implementation/smpybandits.svg)](https://pypi.org/project/SMPyBandits)\n[![PyPI pyversions](https://img.shields.io/pypi/pyversions/smpybandits.svg?logo=python)](https://pypi.org/project/SMPyBandits)\n[![PyPI download](https://img.shields.io/pypi/dm/smpybandits.svg)](https://pypi.org/project/SMPyBandits)\n[![PyPI status](https://img.shields.io/pypi/status/smpybandits.svg)](https://pypi.org/project/SMPyBandits)\n[![Documentation Status](https://readthedocs.org/projects/smpybandits/badge/?version=latest)](https://SMPyBandits.ReadTheDocs.io/en/latest/?badge=latest)\n[![Build Status](https://travis-ci.org/SMPyBandits/SMPyBandits.svg?branch=master)](https://travis-ci.org/SMPyBandits/SMPyBandits)\n\n[![Stars of https://github.com/SMPyBandits/SMPyBandits/](https://badgen.net/github/stars/SMPyBandits/SMPyBandits)](https://GitHub.com/SMPyBandits/SMPyBandits/stargazers) [![Contributors of https://github.com/SMPyBandits/SMPyBandits/](https://badgen.net/github/contributors/SMPyBandits/SMPyBandits)](https://github.com/SMPyBandits/SMPyBandits/graphs/contributors) [![Watchers of https://github.com/SMPyBandits/SMPyBandits/](https://badgen.net/github/watchers/SMPyBandits/SMPyBandits)](https://GitHub.com/SMPyBandits/SMPyBandits/watchers) [![Forks of https://github.com/SMPyBandits/SMPyBandits/](https://badgen.net/github/forks/SMPyBandits/SMPyBandits)](https://github.com/SMPyBandits/SMPyBandits/network/members)\n\n[![Releases of https://github.com/SMPyBandits/SMPyBandits/](https://badgen.net/github/release/SMPyBandits/SMPyBandits)](https://github.com/SMPyBandits/SMPyBandits/releases)\n[![Commits of https://github.com/SMPyBandits/SMPyBandits/](https://badgen.net/github/commits/SMPyBandits/SMPyBandits)](https://github.com/SMPyBandits/SMPyBandits/commits/master) / [![Date of last commit of https://github.com/SMPyBandits/SMPyBandits/](https://badgen.net/github/last-commit/SMPyBandits/SMPyBandits)](https://github.com/SMPyBandits/SMPyBandits/commits/master)\n\n[![Issues of https://github.com/SMPyBandits/SMPyBandits/](https://badgen.net/github/issues/SMPyBandits/SMPyBandits)](https://GitHub.com/SMPyBandits/SMPyBandits/issues) : [![Open issues of https://github.com/SMPyBandits/SMPyBandits/](https://badgen.net/github/open-issues/SMPyBandits/SMPyBandits)](https://github.com/SMPyBandits/SMPyBandits/issues?q=is%3Aopen+is%3Aissue) / [![Closed issues of https://github.com/SMPyBandits/SMPyBandits/](https://badgen.net/github/closed-issues/SMPyBandits/SMPyBandits)](https://github.com/SMPyBandits/SMPyBandits/issues?q=is%3Aclosed+is%3Aissue)\n\n[![Pull requests of https://github.com/SMPyBandits/SMPyBandits/](https://badgen.net/github/prs/SMPyBandits/SMPyBandits)](https://GitHub.com/SMPyBandits/SMPyBandits/pulls) : [![Open pull requests of https://github.com/SMPyBandits/SMPyBandits/](https://badgen.net/github/open-prs/SMPyBandits/SMPyBandits)](https://GitHub.com/SMPyBandits/SMPyBandits/issues?q=is%3Aopen+is%3Apr) / [![Closed pull requests of https://github.com/SMPyBandits/SMPyBandits/](https://badgen.net/github/closed-prs/SMPyBandits/SMPyBandits)](https://GitHub.com/SMPyBandits/SMPyBandits/issues?q=is%3Aclose+is%3Apr)\n\n[![ForTheBadge uses-badges](http://ForTheBadge.com/images/badges/uses-badges.svg)](http://ForTheBadge.com)\n[![ForTheBadge uses-git](http://ForTheBadge.com/images/badges/uses-git.svg)](https://GitHub.com/)\n[![forthebadge made-with-python](http://ForTheBadge.com/images/badges/made-with-python.svg)](https://www.python.org/)\n[![ForTheBadge built-with-science](http://ForTheBadge.com/images/badges/built-with-science.svg)](https://GitHub.com/Naereen/)\n"
      },
      "source": "https://raw.githubusercontent.com/SMPyBandits/SMPyBandits/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "SMPyBandits"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "Organization",
        "value": "SMPyBandits"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Jupyter Notebook",
        "size": 36178456,
        "type": "Programming_language",
        "value": "Jupyter Notebook"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "TeX",
        "size": 3212044,
        "type": "Programming_language",
        "value": "TeX"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 2345592,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "C++",
        "size": 106499,
        "type": "Programming_language",
        "value": "C++"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Cython",
        "size": 64980,
        "type": "Programming_language",
        "value": "Cython"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "C",
        "size": 25835,
        "type": "Programming_language",
        "value": "C"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Makefile",
        "size": 23824,
        "type": "Programming_language",
        "value": "Makefile"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Shell",
        "size": 13683,
        "type": "Programming_language",
        "value": "Shell"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "HTML",
        "size": 5226,
        "type": "Programming_language",
        "value": "HTML"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Nix",
        "size": 2183,
        "type": "Programming_language",
        "value": "Nix"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Julia",
        "size": 685,
        "type": "Programming_language",
        "value": "Julia"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/SMPyBandits/SMPyBandits/master/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "related_documentation": [
    {
      "confidence": 1,
      "result": {
        "format": "readthedocs",
        "type": "Url",
        "value": "https://asv.readthedocs.io/"
      },
      "source": "https://raw.githubusercontent.com/SMPyBandits/SMPyBandits/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "format": "readthedocs",
        "type": "Url",
        "value": "https://joblib.readthedocs.io/"
      },
      "source": "https://raw.githubusercontent.com/SMPyBandits/SMPyBandits/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "related_papers": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://arxiv.org/abs/1808.08416"
      },
      "source": "https://raw.githubusercontent.com/SMPyBandits/SMPyBandits/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://arxiv.org/abs/1702.04825"
      },
      "source": "https://raw.githubusercontent.com/SMPyBandits/SMPyBandits/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://arxiv.org/pdf/1702.06103"
      },
      "source": "https://raw.githubusercontent.com/SMPyBandits/SMPyBandits/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://arxiv.org/pdf/1507.07880"
      },
      "source": "https://raw.githubusercontent.com/SMPyBandits/SMPyBandits/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://arxiv.org/abs/1809.08151"
      },
      "source": "https://raw.githubusercontent.com/SMPyBandits/SMPyBandits/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://arxiv.org/abs/1805.05071"
      },
      "source": "https://raw.githubusercontent.com/SMPyBandits/SMPyBandits/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://arxiv.org/abs/1706.01383"
      },
      "source": "https://raw.githubusercontent.com/SMPyBandits/SMPyBandits/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://arxiv.org/abs/1808.08416](https://arxiv.org/abs/1808.08416)).\n- I'm working on adding a clean support for non-stationary MAB problem, and I will soon implement all state-of-the-art algorithms for these problems.\n\nWith this numerical framework, simulations can run on a single CPU or a multi-core machine, and summary plots are automatically saved as high-quality PNG, PDF and EPS (ready for being used in research article).\nMaking new simulations is very easy, one only needs to write a configuration script and basically no code! See [these examples](https://github.com/SMPyBandits/SMPyBandits/search?l=Python&q=configuration&type=&utf8=%E2%9C%93) (files named `configuration_*.py`).\n\nA complete [Sphinx](http://sphinx-doc.org/) documentation for each algorithms and every piece of code (included constants in the configurations!) is available here: [SMPyBandits.GitHub.io](https://smpybandits.github.io/). (I will use [ReadTheDocs](https://readthedocs.org/) for this project, but I won't use any *continuous integration*, don't even think of it!)\n\n\n> [I (Lilian Besson)](https://perso.crans.org/besson/) have [started my PhD](https://perso.crans.org/besson/phd/) in October 2016, and this is a part of my **on going** research since December 2016.\n>\n> I launched the [documentation](https://smpybandits.github.io/) on March 2017, I wrote my first research articles using this framework in 2017 and decided to (finally) open-source my project in February 2018.\n> [![Commits of https://github.com/SMPyBandits/SMPyBandits/](https://badgen.net/github/commits/SMPyBandits/SMPyBandits)](https://github.com/SMPyBandits/SMPyBandits/commits/master) / [![Date of last commit of https://github.com/SMPyBandits/SMPyBandits/](https://badgen.net/github/last-commit/SMPyBandits/SMPyBandits)](https://github.com/SMPyBandits/SMPyBandits/commits/master)\n> [![Issues of https://github.com/SMPyBandits/SMPyBandits/](https://badgen.net/github/issues/SMPyBandits/SMPyBandits)](https://GitHub.com/SMPyBandits/SMPyBandits/issues) : [![Open issues of https://github.com/SMPyBandits/SMPyBandits/](https://badgen.net/github/open-issues/SMPyBandits/SMPyBandits)](https://github.com/SMPyBandits/SMPyBandits/issues?q=is%3Aopen+is%3Aissue) / [![Closed issues of https://github.com/SMPyBandits/SMPyBandits/](https://badgen.net/github/closed-issues/SMPyBandits/SMPyBandits)](https://github.com/SMPyBandits/SMPyBandits/issues?q=is%3Aclosed+is%3Aissue)\n\n----\n\n## How to cite this work?\nIf you use this package for your own work, please consider citing it with [this piece of BibTeX](SMPyBandits.bib):\n\n\n```bibtex\n@misc{SMPyBandits,\n    title =   {{SMPyBandits: an Open-Source Research Framework for Single and Multi-Players Multi-Arms Bandits (MAB) Algorithms in Python"
      },
      "source": "https://raw.githubusercontent.com/SMPyBandits/SMPyBandits/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://arxiv.org/abs/1612.06246v2"
      },
      "source": "https://raw.githubusercontent.com/SMPyBandits/SMPyBandits/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://arxiv.org/pdf/1706.01383/"
      },
      "source": "https://raw.githubusercontent.com/SMPyBandits/SMPyBandits/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://arxiv.org/abs/1809.08151](https://arxiv.org/abs/1809.08151) and [`MusicalChairNoSensing`](https://smpybandits.github.io/docs/Policies.MusicalChairNoSensing.html) from [https://arxiv.org/abs/1808.08416](https://arxiv.org/abs/1808.08416)).\n- I'm working on adding a clean support for non-stationary MAB problem, and I will soon implement all state-of-the-art algorithms for these problems.\n\nWith this numerical framework, simulations can run on a single CPU or a multi-core machine, and summary plots are automatically saved as high-quality PNG, PDF and EPS (ready for being used in research article).\nMaking new simulations is very easy, one only needs to write a configuration script and basically no code! See [these examples](https://github.com/SMPyBandits/SMPyBandits/search?l=Python&q=configuration&type=&utf8=%E2%9C%93) (files named `configuration_*.py`).\n\nA complete [Sphinx](http://sphinx-doc.org/) documentation for each algorithms and every piece of code (included constants in the configurations!) is available here: [SMPyBandits.GitHub.io](https://smpybandits.github.io/). (I will use [ReadTheDocs](https://readthedocs.org/) for this project, but I won't use any *continuous integration*, don't even think of it!)\n\n\n> [I (Lilian Besson)](https://perso.crans.org/besson/) have [started my PhD](https://perso.crans.org/besson/phd/) in October 2016, and this is a part of my **on going** research since December 2016.\n>\n> I launched the [documentation](https://smpybandits.github.io/) on March 2017, I wrote my first research articles using this framework in 2017 and decided to (finally) open-source my project in February 2018.\n> [![Commits of https://github.com/SMPyBandits/SMPyBandits/](https://badgen.net/github/commits/SMPyBandits/SMPyBandits)](https://github.com/SMPyBandits/SMPyBandits/commits/master) / [![Date of last commit of https://github.com/SMPyBandits/SMPyBandits/](https://badgen.net/github/last-commit/SMPyBandits/SMPyBandits)](https://github.com/SMPyBandits/SMPyBandits/commits/master)\n> [![Issues of https://github.com/SMPyBandits/SMPyBandits/](https://badgen.net/github/issues/SMPyBandits/SMPyBandits)](https://GitHub.com/SMPyBandits/SMPyBandits/issues) : [![Open issues of https://github.com/SMPyBandits/SMPyBandits/](https://badgen.net/github/open-issues/SMPyBandits/SMPyBandits)](https://github.com/SMPyBandits/SMPyBandits/issues?q=is%3Aopen+is%3Aissue) / [![Closed issues of https://github.com/SMPyBandits/SMPyBandits/](https://badgen.net/github/closed-issues/SMPyBandits/SMPyBandits)](https://github.com/SMPyBandits/SMPyBandits/issues?q=is%3Aclosed+is%3Aissue)\n\n----\n\n## How to cite this work?\nIf you use this package for your own work, please consider citing it with [this piece of BibTeX](SMPyBandits.bib):\n\n\n```bibtex\n@misc{SMPyBandits,\n    title =   {{SMPyBandits: an Open-Source Research Framework for Single and Multi-Players Multi-Arms Bandits (MAB) Algorithms in Python"
      },
      "source": "https://raw.githubusercontent.com/SMPyBandits/SMPyBandits/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "releases": [
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "Naereen",
          "type": "User"
        },
        "date_created": "2019-07-12T09:44:49Z",
        "date_published": "2019-07-12T09:48:41Z",
        "description": "It's been 6 months since the last release, and I didn't implement any new features.\r\nI have been using SMPyBandits a lot in the last few months, when I was writing my PhD thesis.\r\nI fixed a lot of small issues, but I didn't have the time to do more.\r\n\r\n## Roadmap for the next six months\r\n- I want to work on the [most important issues](https://github.com/SMPyBandits/SMPyBandits/issues)\r\n- I want to submit again a journal paper to [JMLR MLOSS](http://jmlr.org/mloss/)\r\n- I would like to see >= 100 stars!",
        "html_url": "https://github.com/SMPyBandits/SMPyBandits/releases/tag/v0.9.6",
        "name": "I finished my PhD thesis, and this version ships improvements on many small aspects",
        "release_id": 18574496,
        "tag": "v0.9.6",
        "tarball_url": "https://api.github.com/repos/SMPyBandits/SMPyBandits/tarball/v0.9.6",
        "type": "Release",
        "url": "https://api.github.com/repos/SMPyBandits/SMPyBandits/releases/18574496",
        "value": "https://api.github.com/repos/SMPyBandits/SMPyBandits/releases/18574496",
        "zipball_url": "https://api.github.com/repos/SMPyBandits/SMPyBandits/zipball/v0.9.6"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "Naereen",
          "type": "User"
        },
        "date_created": "2018-11-09T21:44:08Z",
        "date_published": "2018-11-09T21:46:07Z",
        "description": "Almost done for piece-wise stationary bandits.\r\nStill some issues to close, see:\r\n\r\n- `LM-DSEE` seems bugged, cf. #151\r\n- Fix `PieceWiseStationaryMAB` for best arm pull selections, cf. #153",
        "html_url": "https://github.com/SMPyBandits/SMPyBandits/releases/tag/v0.9.4",
        "name": "Almost done for piece-wise stationary bandits",
        "release_id": 13930003,
        "tag": "v0.9.4",
        "tarball_url": "https://api.github.com/repos/SMPyBandits/SMPyBandits/tarball/v0.9.4",
        "type": "Release",
        "url": "https://api.github.com/repos/SMPyBandits/SMPyBandits/releases/13930003",
        "value": "https://api.github.com/repos/SMPyBandits/SMPyBandits/releases/13930003",
        "zipball_url": "https://api.github.com/repos/SMPyBandits/SMPyBandits/zipball/v0.9.4"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "Naereen",
          "type": "User"
        },
        "date_created": "2018-09-28T12:52:01Z",
        "date_published": "2018-09-28T13:03:54Z",
        "description": "## Summary of the last 6 months\r\n\r\nI have opened this project since more than 6 months, I wrote [a companion research paper](https://perso.crans.org/besson/articles/SMPyBandits.pdf) to present it, its documentation is now handled automatically by [ReadTheDocs](https://readthedocs.org/projects/smpybandits/builds/) ([see it live here](https://smpybandits.readthedocs.io/en/latest/)), [Travis CI](https://travis-ci.org/SMPyBandits/SMPyBandits) is used to test every commit, etc.\r\n\r\nSMPyBandits has been used in more research articles, it received its first other contributor (thanks @guilgautier !), and many other cool things happened.\r\nI have kept SMPyBandits up-to-date with my (small and partial) point of view on the state-of-the-art research in classical or multi-player multi-armed bandit algorithms and heuristics.\r\n\r\nI met researchers in a [workshop in Rotterdam (Netherlands)](http://www.erim.eur.nl/e-code-erasmus-centre-for-optimization-of-digital-experiments/workshop-on-multi-armed-bandits-and-learning-algorithms/) and in a [workshop in Toulouse (France)](http://cimi.univ-toulouse.fr/optimisation/en/workshop-optimization-and-machine-learning) who knew my library and my work but didn't know me, and told me that they found this work useful.\r\nColleagues in Inria Lille has used SMPyBandits, [for teaching](http://odalricambrymmaillard.neowordpress.fr/) or [research](https://www.linkedin.com/in/julien-seznec-29364a104/), and I was happy to help them and learn from them.\r\n\r\n## Directions for next release\r\n- I want to stay as up-to-date as possible for multi-player MAB as my library is most surely the only one being open-source that implements these models and algorithms. I need to work on #145 and #139 mainly, in October and November. Maybe #120 but I won't have time for all.\r\n- I want to work on more general non-stationary problems, see #17 with for instance the algorithm from #100, or even harder models like #123, #124.\r\n- I need to finish my work on the documentation, mainly #138 (@guilgautier thanks the idea).\r\n- With more time, I want to work on #140, #135 too.\r\n\r\n## Disclaimers\r\nPlease keep in mind that this is only meant as a research framework: easy to interact with, easy to modify, and easy to do some small or medium-sized simulations and get nice figures for research paper.\r\n\r\nIt is not meant as an industry package for multi-armed bandits. If you want to use any MAB algorithms for real-world content optimization, you should rather implement them yourself to better suit your needs.\r\n\r\n## Please help and contribute!\r\nWith that being said, I am still excited to share this project on GitHub, now on [its own organization](https://github.com/SMPyBandits/) instead of my personal profile.\r\nIf you have any suggestion on how I could improve this project, I would be delighted to here them! Contributions like issues, pull requests, questions etc are welcome.",
        "html_url": "https://github.com/SMPyBandits/SMPyBandits/releases/tag/v0.9.3",
        "name": "Happy things! Not yet 1.0 but close!",
        "release_id": 13149565,
        "tag": "v0.9.3",
        "tarball_url": "https://api.github.com/repos/SMPyBandits/SMPyBandits/tarball/v0.9.3",
        "type": "Release",
        "url": "https://api.github.com/repos/SMPyBandits/SMPyBandits/releases/13149565",
        "value": "https://api.github.com/repos/SMPyBandits/SMPyBandits/releases/13149565",
        "zipball_url": "https://api.github.com/repos/SMPyBandits/SMPyBandits/zipball/v0.9.3"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "Naereen",
          "type": "User"
        },
        "date_created": "2018-02-21T18:17:38Z",
        "date_published": "2018-02-21T18:18:44Z",
        "description": "I finally open-sourced my research framework on multi-armed bandits \ud83c\udf89\r\nhttps://github.com/Naereen/AlgoBandits\r\n\r\nPlease keep in mind that this is only meant as a research framework:\r\neasy to interact with, easy to modify, and easy to do some small or\r\nmedium-sized simulations and get nice figures for research paper.\r\n\r\nIt is *not* meant as an industry package for multi-armed bandits. If you\r\nwant to use any MAB algorithms for real-world content optimization, you\r\nshould rather implement them yourself to better suit your needs.\r\n\r\nWith that being said, I am very excited to finally share this on GitHub.\r\nIf you have any suggestion on how I could improve this project, I would\r\nbe delighted to here them!  Contributions like issues, pull requests,\r\nquestions etc are welcome.",
        "html_url": "https://github.com/SMPyBandits/SMPyBandits/releases/tag/v0.9.1",
        "name": "First public version",
        "release_id": 9774811,
        "tag": "v0.9.1",
        "tarball_url": "https://api.github.com/repos/SMPyBandits/SMPyBandits/tarball/v0.9.1",
        "type": "Release",
        "url": "https://api.github.com/repos/SMPyBandits/SMPyBandits/releases/9774811",
        "value": "https://api.github.com/repos/SMPyBandits/SMPyBandits/releases/9774811",
        "zipball_url": "https://api.github.com/repos/SMPyBandits/SMPyBandits/zipball/v0.9.1"
      },
      "technique": "GitHub_API"
    }
  ],
  "run": [
    {
      "confidence": 1,
      "result": {
        "original_header": "<a href=\"How_to_run_the_code.md\">How to run the experiments ?</a>",
        "parent_header": [
          "*SMPyBandits*"
        ],
        "type": "Text_excerpt",
        "value": "> See this document: [`How_to_run_the_code.md`](How_to_run_the_code.md) for more details (or [this documentation page](How_to_run_the_code.html)).\n\nTL;DR: this short bash snippet shows how to clone the code, install the requirements for Python 3 (in a [virtualenv](https://virtualenv.pypa.io/en/stable/), and starts some simulation for N=100 repetitions of the default non-Bayesian Bernoulli-distributed problem, for K=9 arms, an horizon of T=10000 and on 4 CPUs (it should take about 20 minutes for each simulations):\n\n```bash\ncd /tmp/  # or wherever you want\ngit clone -c core.symlinks=true https://GitHub.com/SMPyBandits/SMPyBandits.git\ncd SMPyBandits\n# just be sure you have the latest virtualenv from Python 3\nsudo pip3 install --upgrade --force-reinstall virtualenv\n# create and active the virtualenv\nvirtualenv venv\n. venv/bin/activate\ntype pip  # check it is /tmp/SMPyBandits/venv/bin/pip\ntype python  # check it is /tmp/SMPyBandits/venv/bin/python\n# install the requirements in the virtualenv\npip install -r requirements_full.txt\n# run a single-player simulation!\nN=100 T=10000 K=9 N_JOBS=4 make single\n# run a multi-player simulation!\nN=100 T=10000 M=3 K=9 N_JOBS=4 make moremulti\n```\n\nYou can also install it directly with [`pip`](https://pip.pypa.io/) and from GitHub:\n\n```bash\ncd /tmp/ ; mkdir SMPyBandits ; cd SMPyBandits/\nvirtualenv venv\n. venv/bin/activate\ntype pip  # check it is /tmp/SMPyBandits/venv/bin/pip\ntype python  # check it is /tmp/SMPyBandits/venv/bin/python\npip install git+https://github.com/SMPyBandits/SMPyBandits.git#egg=SMPyBandits[full]\n```\n\n> - If speed matters to you and you want to use algorithms based on [kl-UCB](https://smpybandits.github.io/docs/Policies.klUCB.html), you should take the time to build and install the fast C implementation of the utilities KL functions. Default is to use [kullback.py](https://smpybandits.github.io/docs/Policies.kullback.html), but using [the C version from Policies/C/](Policies/C/) really speeds up the computations. Just follow the instructions, it should work well (you need `gcc` to be installed).\n> - And if speed matters, be sure that you have a working version of [Numba](https://numba.pydata.org/), it is used by many small functions to (try to automatically) speed up the computations.\n"
      },
      "source": "https://raw.githubusercontent.com/SMPyBandits/SMPyBandits/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Nix",
        "parent_header": [
          "*SMPyBandits*",
          "<a href=\"How_to_run_the_code.md\">How to run the experiments ?</a>"
        ],
        "type": "Text_excerpt",
        "value": "A pinned [Nix](https://nixos.org) environment is available for this experimental setup in the [`nix/pkgs/`](nix/pkgs) directory.\nFrom the root of the project:\n\n```bash \n$ nix-shell\nnix-shell$ jupyter_notebook \nnix-shell$ N=100 T=10000 K=9 N_JOBS=4 make single\n``` \n\nThe following one-liner lets you explore one of the example notebooks from any Nix-enabled machine, without cloning the repository:\n\n```bash\n$ nix-shell https://github.com/SMPYBandits/SMPyBandits/archive/master.tar.gz --run 'jupyter-notebook $EXAMPLE_NOTEBOOKS/Example_of_a_small_Multi-Player_Simulation__with_Centralized_Algorithms.ipynb' \n```\n\n----\n"
      },
      "source": "https://raw.githubusercontent.com/SMPyBandits/SMPyBandits/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": ":boom: Warning",
        "parent_header": [
          "*SMPyBandits*",
          "<a href=\"How_to_run_the_code.md\">How to run the experiments ?</a>"
        ],
        "type": "Text_excerpt",
        "value": "- This work is still **experimental** even if [it is well tested and stable](https://travis-ci.org/SMPyBandits/SMPyBandits)! It's [active research](https://github.com/SMPyBandits/SMPyBandits/graphs/contributors). It should be completely bug free and every single module/file should work perfectly (as [this pylint log](main_pylint_log.txt) and [this other one](main_pylint3_log.txt) says), but bugs are sometimes hard to spot so if you encounter any issue, [please fill a bug ticket](https://github.com/SMPyBandits/SMPyBandits/issues/new).\n- Whenever I add a new feature, I run experiments [to check that nothing is broken](https://travis-ci.org/SMPyBandits/SMPyBandits) (and [Travis CI](https://travis-ci.org/SMPyBandits/SMPyBandits) helps too). But *there is no unittest* (I don't have time). You would have to trust me :sunglasses:!\n- This project is NOT meant to be a library that you can use elsewhere, but a research tool.\n"
      },
      "source": "https://raw.githubusercontent.com/SMPyBandits/SMPyBandits/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "somef_missing_categories": [
    "installation",
    "acknowledgement",
    "download",
    "requirements",
    "contact",
    "contributors",
    "documentation",
    "usage",
    "support",
    "identifier",
    "has_build_file"
  ],
  "somef_provenance": {
    "date": "2024-10-04 00:54:49",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 386
      },
      "technique": "GitHub_API"
    }
  ]
}