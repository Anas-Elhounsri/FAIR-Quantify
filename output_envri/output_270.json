{
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/danamlewis/OpenHumansDataTools"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2017-02-09T04:05:26Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2023-08-23T09:24:39Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "tools to work with data downloaded from Open Humans research platform"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Tool `#4`: Examples and descriptions of the four data file types from Nightscout",
        "parent_header": [
          "OpenHumansDataTools"
        ],
        "type": "Text_excerpt",
        "value": "[NS-data-types.md](https://github.com/danamlewis/OpenHumansDataTools/blob/master/NS-data-types.md) attemps to explain the nuances and what is contained in each of the four data file types: profile, entries, device status, and treatments. \n\n"
      },
      "source": "https://raw.githubusercontent.com/danamlewis/OpenHumansDataTools/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Tool `#5`: Examples and descriptions of data structures from AndroidAPS uploader",
        "parent_header": [
          "OpenHumansDataTools"
        ],
        "type": "Text_excerpt",
        "value": "Project members who have used the AndroidAPS uploader will have a different series of data files available, although similar data will exist. Depending on what stage of use someone is at (e.g. in \"open loop\" or early objective stage vs. an advanced user), they may not have all of the files described below.\n\n**ApplicationInfo** - contains information about the version of AndroidAPS\n\n**APSData** - contains information about algorithm predictions, calculations, and decisions. This is similar to \"devicestatus\" from the Nightscout uploader.\n\n**BgReadings** - contains timestamps and BG value. This is similar to \"entries\" from the Nightscout uploader.\n\n**CarePortalEvents** - contains information the user or system has entered as a CarePortal event.\n\n**DeviceInfo** - contains information about the mobile device used\n\n**DisplayInfo** - contains information about the size of the display \n\n**Preferences** - contains information about the preferences used within AndroidAPS. [See the AndroidAPS documentation on preferences](https://androidaps.readthedocs.io/en/latest/Configuration/Preferences.html) for more details about what each of those indicate and the available setting options.\n\n**TemporaryBasals** - contains information about temporary basal rates that have been set. \n\n**TempTargets** - contains information about temporary targets that have been set.\n\n**Treatments** - contains information about bolus calculations, boluses (manual or SMB), profile changes, etc. \n"
      },
      "source": "https://raw.githubusercontent.com/danamlewis/OpenHumansDataTools/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 0.9480349813206594,
      "result": {
        "original_header": "OpenHumansDataTools",
        "type": "Text_excerpt",
        "value": "Tools to work with data downloaded from Open Humans research platform. \n"
      },
      "source": "https://raw.githubusercontent.com/danamlewis/OpenHumansDataTools/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9914310685432376,
      "result": {
        "original_header": "Tool `#2`: Unzip and convert json to csv, on data from OH from the AndroidAPS uploader type",
        "type": "Text_excerpt",
        "value": "[unzip-csvify-AAPS-OpenHumans-data.sh](unzip-csvify-AAPS-OpenHumans-data.sh) checks for the existence of AndroidAPS uploader data (under direct-sharing396 folder, which is the Open Humans designation for this uploader project), unzips the files, puts the BG and timestamp in a simplified csv file (similar to \"entries\" from the Nightscout uploader type), and converts the remaining files into csv as well. Each .zip file remains, and a folder with the file name is created with all converted json and .csv folders below (see picture below for example). \n \n"
      },
      "source": "https://raw.githubusercontent.com/danamlewis/OpenHumansDataTools/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8677705524380955,
      "result": {
        "original_header": "Tool `#6`: Pull ISF from device status",
        "type": "Text_excerpt",
        "value": "The [devicestatus-pull-isf-timestamp.sh](https://github.com/danamlewis/OpenHumansDataTools/blob/master/bin/devicestatus-pull-isf-timestamp.sh) script, when successful, pulls ISF and timestamp to enable further ISF analysis.  \n"
      },
      "source": "https://raw.githubusercontent.com/danamlewis/OpenHumansDataTools/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9847194326364037,
      "result": {
        "original_header": "Tool `#7`: Assess amount of looping data",
        "type": "Text_excerpt",
        "value": "There are two methods for assessing amounts of data. \n* You can use [howmuchBGdata.sh](https://github.com/danamlewis/OpenHumansDataTools/blob/master/bin/howmuchBGdata.sh) to see how much time worth of BG entries someone has. However, this doesn't necessarily represent time of looping data.\n* Or, you can use [howmuchdevicestatusdata.sh](https://github.com/danamlewis/OpenHumansDataTools/blob/master/bin/howmuchdevicestatusdata.sh) to see how much looping data (OpenAPS only for now; someone can add in Loop assessment later with same principle) someone has in the Data Commons. \nThe original output of `howmuchdevicestatusdata.sh` is a CSV. \n* Due to someone having multiple uploads, there may be multiple lines for a single person. You can use Excel to de-duplicate these.\n* Loop users (until someone updates the script to pull in loop/enacted/timestamp) will show up as 0. You may want to remove these before averaging to estimate the Data Commons' total looping data. \n"
      },
      "source": "https://raw.githubusercontent.com/danamlewis/OpenHumansDataTools/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9330173543576035,
      "result": {
        "original_header": "TODO for Tool 7:",
        "type": "Text_excerpt",
        "value": "1) add Loop/enacted/timestamp to also assess Loop users\n2) add a script version to include both BG and looping data in same output CSV)\n \n"
      },
      "source": "https://raw.githubusercontent.com/danamlewis/OpenHumansDataTools/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9363652237280222,
      "result": {
        "original_header": "Tool `#8`: Outcomes",
        "type": "Text_excerpt",
        "value": "This script ([outcomes.sh](https://github.com/danamlewis/OpenHumansDataTools/blob/master/bin/outcomes.sh)) assess the start/end of BG and looping data to calculate time spent low (default: <70 mg/dL), time in range (default: 70-180mg/dL), time spent high (default:>180mg/dL), amount of high readings, and the average glucose for the time frame where there is entries data and they are looping.  \n*Tl;dr - this analyzes the post-looping time frame.*\n \n"
      },
      "source": "https://raw.githubusercontent.com/danamlewis/OpenHumansDataTools/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.946627808956555,
      "result": {
        "original_header": "Tool `#9`: GV Demographics scripts",
        "type": "Text_excerpt",
        "value": "[This folder](https://github.com/danamlewis/OpenHumansDataTools/blob/master/bin/GV-demographics-scripts/) contains a variety of notebooks and other scripts for analyzing glucose variability and performing analysis of demographics, such as within the OpenAPS Data Commons. Note: This folder contains a separate license from the rest of this repository (which is MIT license), please make note of the license that applies to all files within this folder.  \nThese scripts were used within the paper, \"Large-Scale Data Analysis for Glucose Variability Outcomes with Open-Source Automated Insulin Delivery Systems\". [This paper is open access and can be read here](https://doi.org/10.3390/nu14091906). \n \n"
      },
      "source": "https://raw.githubusercontent.com/danamlewis/OpenHumansDataTools/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9955097408798466,
      "result": {
        "original_header": "Tool `#10`: GV Analytics for Pre and Post Analysis",
        "type": "Text_excerpt",
        "value": "[This folder](https://github.com/danamlewis/OpenHumansDataTools/tree/master/bin/GV-pre-post-analysis) contains multiple notebooks with scripts for analysing glucose variability for before/after a change, such as a new onset medication that someone wants to assess GV-related changes for following commencement. Note: This folder contains a separate license from the rest of this repository (which is MIT license), please make note of the license that applies to all files within this folder. \n \n"
      },
      "source": "https://raw.githubusercontent.com/danamlewis/OpenHumansDataTools/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9930061559402517,
      "result": {
        "original_header": "Tool `#11`: Python Scripts for Checking Between Different Versions of the OpenAPS Data Commons Dataset",
        "type": "Text_excerpt",
        "value": "There are two useful scripts that enable you to check between the latest version of the OpenAPS Data Commons dataset and the previous version you were working on. Running these two scripts allows you to generate a list of your current and/or the latest dataset and compare between them. This would then allow you to pull out only the files you didn't already have, saving you a lot of time by not downloading duplicate data that you may have already cleaned.\n \n"
      },
      "source": "https://raw.githubusercontent.com/danamlewis/OpenHumansDataTools/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9619813503820787,
      "result": {
        "original_header": "folder-contents.py",
        "type": "Text_excerpt",
        "value": "The first, [folder-contents.py](https://github.com/danamlewis/OpenHumansDataTools/blob/master/bin/folder-contents.py), looks through a folder containing an existing version of the OpenAPS Data Commons (or any OH) dataset and outputs a CSV file with a list of the projectmemberID and any of the projectmemberID's file within the sub-folders of various direct-sharing uploaders. To run this script, `python ~/bin/folder-contents.py` from within the data folder (e.g. \"OpenAPS Data Commons n=122\").  \n"
      },
      "source": "https://raw.githubusercontent.com/danamlewis/OpenHumansDataTools/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9167783263814306,
      "result": {
        "original_header": "match-file-names.py",
        "type": "Text_excerpt",
        "value": "The expected use of this script is to check a newer, bigger file as the first input file against the second input file. This will tell you whether the content exist (Yes) in the smaller, older file or not (No). This would aid you in determining which files to then pull from the newer, larger dataset to append to your cleaned, existing older/smaller dataset. \nNote that it's looking for member_ID and data_file in input-file-1; and project_member_id, file_basename in input-file-2. If your input files are differently formatted, adjust accordingly. \nThis is what the output CSV file looks like. I've also added conditional formatting after opening the CSV file to identify those files not found in the previous version of the dataset: \n"
      },
      "source": "https://raw.githubusercontent.com/danamlewis/OpenHumansDataTools/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "download": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Tool `#1`: Unzip, split if needed based on size, and convert json to csv, and do it on a full batch of downloaded data from OH.",
        "parent_header": [
          "OpenHumansDataTools"
        ],
        "type": "Text_excerpt",
        "value": "[Unzip-Zip-CSVify-OpenHumans-data.sh](https://github.com/danamlewis/OpenHumansDataTools/blob/master/bin/unzip-split-csvify-OpenHumans-data.sh) Note that this tool was designed for use with the OpenAPS and Nightscout Data Commons, which pulls in Nightscout data as json files to Open Humans. Any users will need to specify the data file types for use in the second \"for\" loop. (The first for loop is Nightscout specific based on the data type, and uses an alternative json to csv conversion - see tips for other installation requirements).\n\nSee [these tips for help, especially related to the first for loop if you will be using entries.json from Nightscout](https://gist.github.com/danamlewis/aab795a7ec0bdd3abbb08b1f9be79663).\n\nThis script calls `complex-json2csv` and `jsonsplit.sh`. Both tools are in a package ([see repo here](https://github.com/danamlewis/json)) which can be installed by npm ([see this](https://www.npmjs.com/package/complex-json2csv)).\n\nProgress output from the tool while running, with the script in current form, looks like:\n```\n########\n########_entries.json\n########_entries.csv\nStarting participant ########\nExtracted ########_profile.json; splitting it...\n.\nGrouping split records into valid json...\n-\nCreating CSV files...\n=\nParticipant ########: profile CSV files created:       1\nExtracted ########_treatments.json; splitting it...\n..............\nGrouping split records into valid json...\n--------------\nCreating CSV files...\n==============\nParticipant ########: treatments CSV files created:      14\nExtracted ########_devicestatus.json; splitting it...\n...................................\nGrouping split records into valid json...\n-----------------------------------\nCreating CSV files...\n===================================\nParticipant ########: devicestatus CSV files created:      35\n```\n"
      },
      "source": "https://raw.githubusercontent.com/danamlewis/OpenHumansDataTools/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Tool `#3`: Unzip, merge, and create output file from multiple data files from an OH download",
        "parent_header": [
          "OpenHumansDataTools"
        ],
        "type": "Text_excerpt",
        "value": "[Unzip-merge-output.sh](https://github.com/danamlewis/OpenHumansDataTools/blob/master/bin/unzip-merge-output.sh)\nNote that this tool was designed for use with the OpenAPS and Nightscout Data Commons, which pulls in Nightscout data as json files to Open Humans. Any users will need to specify the data file types for use in the second \"for\" loop, but can see this script as a template for taking various pieces of data from multiple files (i.e. timezone from devicestatus and BG data from entries) and creating one file, complete with headers, ready for data analysis.\n\nPer the headers for the file provided as an example in this script, if needed, I have formulas created in excel to calculate if data is from a control or intervention period or neither; the hour of day the data is from to calculate if it is day or nighttime; and also (once looping start date manually added to file) can calculate number of days looping and number of days of data in the upload to calculate the control/intervention time frames based on the project protocol.\n\n**Mock data in output file along with additional calculations for various variables as defined by a project protocol:**\n\n![Example output file with mock data and formulas embedded for calculating these other fields](https://github.com/danamlewis/OpenHumansDataTools/blob/master/Examples/Example%20output%20file%20from%20unzip-merge-output.png)\n"
      },
      "source": "https://raw.githubusercontent.com/danamlewis/OpenHumansDataTools/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/danamlewis/OpenHumansDataTools/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "executable_example": [
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/danamlewis/OpenHumansDataTools/master/bin/GV-pre-post-analysis/EPI-GV-shared.ipynb"
      },
      "source": "https://raw.githubusercontent.com/danamlewis/OpenHumansDataTools/master/bin/GV-pre-post-analysis/EPI-GV-shared.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/danamlewis/OpenHumansDataTools/master/bin/GV-pre-post-analysis/EPI-GV%20Meal%20Analysis-shared.ipynb"
      },
      "source": "https://raw.githubusercontent.com/danamlewis/OpenHumansDataTools/master/bin/GV-pre-post-analysis/EPI-GV%20Meal%20Analysis-shared.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/danamlewis/OpenHumansDataTools/master/bin/GV-pre-post-analysis/EPI-GV-autocorrelations.ipynb"
      },
      "source": "https://raw.githubusercontent.com/danamlewis/OpenHumansDataTools/master/bin/GV-pre-post-analysis/EPI-GV-autocorrelations.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/danamlewis/OpenHumansDataTools/master/bin/GV-Hypoglycemia/Hypoglycemic-Variability-HypoGV-Statistics.ipynb"
      },
      "source": "https://raw.githubusercontent.com/danamlewis/OpenHumansDataTools/master/bin/GV-Hypoglycemia/Hypoglycemic-Variability-HypoGV-Statistics.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/danamlewis/OpenHumansDataTools/master/bin/GV-Hypoglycemia/Hypoglycemic-Variability-HypoGV.ipynb"
      },
      "source": "https://raw.githubusercontent.com/danamlewis/OpenHumansDataTools/master/bin/GV-Hypoglycemia/Hypoglycemic-Variability-HypoGV.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/danamlewis/OpenHumansDataTools/master/bin/GV-demographics-scripts/demographics_EDA_shared.ipynb"
      },
      "source": "https://raw.githubusercontent.com/danamlewis/OpenHumansDataTools/master/bin/GV-demographics-scripts/demographics_EDA_shared.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/danamlewis/OpenHumansDataTools/master/bin/GV-demographics-scripts/glucose_data_store.ipynb"
      },
      "source": "https://raw.githubusercontent.com/danamlewis/OpenHumansDataTools/master/bin/GV-demographics-scripts/glucose_data_store.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/danamlewis/OpenHumansDataTools/master/bin/GV-demographics-scripts/Timeseries-analysis-for-CGM-data-shared.ipynb"
      },
      "source": "https://raw.githubusercontent.com/danamlewis/OpenHumansDataTools/master/bin/GV-demographics-scripts/Timeseries-analysis-for-CGM-data-shared.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/danamlewis/OpenHumansDataTools/master/bin/GV-demographics-scripts/clustering_glucose_data_shared.ipynb"
      },
      "source": "https://raw.githubusercontent.com/danamlewis/OpenHumansDataTools/master/bin/GV-demographics-scripts/clustering_glucose_data_shared.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/danamlewis/OpenHumansDataTools/master/bin/GV-demographics-scripts/Glucose%20and%20Demographics%20analysis-shared.ipynb"
      },
      "source": "https://raw.githubusercontent.com/danamlewis/OpenHumansDataTools/master/bin/GV-demographics-scripts/Glucose%20and%20Demographics%20analysis-shared.ipynb",
      "technique": "file_exploration"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 19
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/danamlewis/OpenHumansDataTools/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "danamlewis/OpenHumansDataTools"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "OpenHumansDataTools"
      },
      "source": "https://raw.githubusercontent.com/danamlewis/OpenHumansDataTools/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "has_script_file": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/danamlewis/OpenHumansDataTools/master/bin/devicestatustimestamp.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/danamlewis/OpenHumansDataTools/master/bin/howmuchdevicestatusdata.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/danamlewis/OpenHumansDataTools/master/bin/howmuchBGdata.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/danamlewis/OpenHumansDataTools/master/bin/outcomes.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/danamlewis/OpenHumansDataTools/master/bin/unzip-merge-output.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/danamlewis/OpenHumansDataTools/master/bin/unzip-split-csvify-OpenHumans-data.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/danamlewis/OpenHumansDataTools/master/bin/devicestatus-pull-isf-timestamp.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/danamlewis/OpenHumansDataTools/master/bin/unzip-csvify-AAPS-OpenHumans-data.sh"
      },
      "technique": "file_exploration"
    }
  ],
  "images": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/danamlewis/OpenHumansDataTools/master/Examples/Example%20output%20file%20from%20unzip-merge-output.png"
      },
      "source": "https://raw.githubusercontent.com/danamlewis/OpenHumansDataTools/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/danamlewis/OpenHumansDataTools/master/Examples/Example_devicestatus_pull_ISF_timestamp.png"
      },
      "source": "https://raw.githubusercontent.com/danamlewis/OpenHumansDataTools/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/danamlewis/OpenHumansDataTools/master/Examples/Example_command_line_devicestatustimestamp.sh.png"
      },
      "source": "https://raw.githubusercontent.com/danamlewis/OpenHumansDataTools/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/danamlewis/OpenHumansDataTools/master/Examples/Example_command_line_howmuchdevicestatusdata.sh.png"
      },
      "source": "https://raw.githubusercontent.com/danamlewis/OpenHumansDataTools/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/danamlewis/OpenHumansDataTools/master/Examples/Example_CSVoutput_howmuchdevicestatusdata.sh.png"
      },
      "source": "https://raw.githubusercontent.com/danamlewis/OpenHumansDataTools/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/danamlewis/OpenHumansDataTools/master/Examples/Example-output-folder-contents-py-script.png"
      },
      "source": "https://raw.githubusercontent.com/danamlewis/OpenHumansDataTools/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/danamlewis/OpenHumansDataTools/master/Examples/Example-output-match-file-names-py-script.png"
      },
      "source": "https://raw.githubusercontent.com/danamlewis/OpenHumansDataTools/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "installation": [
    {
      "confidence": 0.951502546139919,
      "result": {
        "original_header": "Tool `#6`: Pull ISF from device status",
        "type": "Text_excerpt",
        "value": "Requires `csvkit`, so do `sudo pip install csvkit` to install before running this script. Also, it assumes your NS data files are already in csv format, using tool #1 [Unzip-Zip-CSVify-OpenHumans-data.sh](https://github.com/danamlewis/OpenHumansDataTools/blob/master/bin/unzip-split-csvify-OpenHumans-data.sh). \n*Note: depending on your install of `six`, you may get an attribute error. \nFollowing [this rabbit hole about the error](https://github.com/wireservice/csvkit/issues/747), various combinations of solutions outlined in [this stack overflow article](https://stackoverflow.com/questions/29485741/unable-to-upgrade-python-six-package-in-mac-osx-10-10-2/29666702#29666702) may help.* \nThe [devicestatus-pull-isf-timestamp.sh](https://github.com/danamlewis/OpenHumansDataTools/blob/master/bin/devicestatus-pull-isf-timestamp.sh) script, when successful, pulls ISF and timestamp to enable further ISF analysis.  \n"
      },
      "source": "https://raw.githubusercontent.com/danamlewis/OpenHumansDataTools/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9224957749796776,
      "result": {
        "original_header": "Tool `#7`: Assess amount of looping data",
        "type": "Text_excerpt",
        "value": "Before running `howmuchdevicestatusdata.sh`, you'll need to first run [devicestatustimestamp.sh](https://github.com/danamlewis/OpenHumansDataTools/blob/master/bin/devicestatustimestamp.sh) to pull out the timestamp into a separate file. If you haven't, you'll need `csvkit` (see Tool #4 for details). **Also, both of these may need `chmod +x <filename>` before running on your machine.** \nOutput on the command line of `devicestatustimestamp.sh`:\n![Example from command line output of devicestatustimestamp.sh](https://github.com/danamlewis/OpenHumansDataTools/blob/master/Examples/Example_command_line_devicestatustimestamp.sh.png) \n"
      },
      "source": "https://raw.githubusercontent.com/danamlewis/OpenHumansDataTools/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9965449716990934,
      "result": {
        "original_header": "TODO for Tool 7:",
        "type": "Text_excerpt",
        "value": "1) add Loop/enacted/timestamp to also assess Loop users\n2) add a script version to include both BG and looping data in same output CSV)\n \n"
      },
      "source": "https://raw.githubusercontent.com/danamlewis/OpenHumansDataTools/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9856888380832426,
      "result": {
        "original_header": "Tool `#11`: Python Scripts for Checking Between Different Versions of the OpenAPS Data Commons Dataset",
        "type": "Text_excerpt",
        "value": "There are two useful scripts that enable you to check between the latest version of the OpenAPS Data Commons dataset and the previous version you were working on. Running these two scripts allows you to generate a list of your current and/or the latest dataset and compare between them. This would then allow you to pull out only the files you didn't already have, saving you a lot of time by not downloading duplicate data that you may have already cleaned.\n \n"
      },
      "source": "https://raw.githubusercontent.com/danamlewis/OpenHumansDataTools/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9217447109569502,
      "result": {
        "original_header": "match-file-names.py",
        "type": "Text_excerpt",
        "value": "To run this script:\n`python ~/bin/match-file/names.py Input-File-1-Larger-Newest.csv Input-File-2-Smaller-Older.csv` \n"
      },
      "source": "https://raw.githubusercontent.com/danamlewis/OpenHumansDataTools/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "invocation": [
    {
      "confidence": 0.8370371882457119,
      "result": {
        "original_header": "Tool `#6`: Pull ISF from device status",
        "type": "Text_excerpt",
        "value": "Output file looks like this:\n![Example of isf timestamp puller](https://github.com/danamlewis/OpenHumansDataTools/blob/master/Examples/Example_devicestatus_pull_ISF_timestamp.png)\n \n"
      },
      "source": "https://raw.githubusercontent.com/danamlewis/OpenHumansDataTools/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9570882344031548,
      "result": {
        "original_header": "match-file-names.py",
        "type": "Text_excerpt",
        "value": "To run this script:\n`python ~/bin/match-file/names.py Input-File-1-Larger-Newest.csv Input-File-2-Smaller-Older.csv` \n"
      },
      "source": "https://raw.githubusercontent.com/danamlewis/OpenHumansDataTools/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/danamlewis/OpenHumansDataTools/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ""
      },
      "technique": "GitHub_API"
    }
  ],
  "license": [
    {
      "confidence": 1,
      "result": {
        "name": "MIT License",
        "spdx_id": "MIT",
        "type": "License",
        "url": "https://api.github.com/licenses/mit",
        "value": "https://api.github.com/licenses/mit"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "type": "File_dump",
        "value": "MIT License\n\nCopyright (c) 2017 Dana Lewis\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
      },
      "source": "https://raw.githubusercontent.com/danamlewis/OpenHumansDataTools/master/LICENSE",
      "technique": "file_exploration"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "OpenHumansDataTools"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "User",
        "value": "danamlewis"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Jupyter Notebook",
        "size": 25518958,
        "type": "Programming_language",
        "value": "Jupyter Notebook"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Shell",
        "size": 17686,
        "type": "Programming_language",
        "value": "Shell"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 5045,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/danamlewis/OpenHumansDataTools/master/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "related_documentation": [
    {
      "confidence": 1,
      "result": {
        "format": "readthedocs",
        "type": "Url",
        "value": "https://androidaps.readthedocs.io/"
      },
      "source": "https://raw.githubusercontent.com/danamlewis/OpenHumansDataTools/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "somef_missing_categories": [
    "citation",
    "acknowledgement",
    "run",
    "requirements",
    "contact",
    "contributors",
    "documentation",
    "faq",
    "support",
    "identifier",
    "has_build_file"
  ],
  "somef_provenance": {
    "date": "2024-10-03 23:52:35",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 26
      },
      "technique": "GitHub_API"
    }
  ],
  "type": [
    {
      "confidence": 0.82,
      "result": {
        "type": "String",
        "value": "commandline-application"
      },
      "technique": "software_type_heuristics"
    }
  ],
  "usage": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Tool `#4`: Examples and descriptions of the four data file types from Nightscout",
        "parent_header": [
          "OpenHumansDataTools"
        ],
        "type": "Text_excerpt",
        "value": "[NS-data-types.md](https://github.com/danamlewis/OpenHumansDataTools/blob/master/NS-data-types.md) attemps to explain the nuances and what is contained in each of the four data file types: profile, entries, device status, and treatments. \n\n"
      },
      "source": "https://raw.githubusercontent.com/danamlewis/OpenHumansDataTools/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Tool `#5`: Examples and descriptions of data structures from AndroidAPS uploader",
        "parent_header": [
          "OpenHumansDataTools"
        ],
        "type": "Text_excerpt",
        "value": "Project members who have used the AndroidAPS uploader will have a different series of data files available, although similar data will exist. Depending on what stage of use someone is at (e.g. in \"open loop\" or early objective stage vs. an advanced user), they may not have all of the files described below.\n\n**ApplicationInfo** - contains information about the version of AndroidAPS\n\n**APSData** - contains information about algorithm predictions, calculations, and decisions. This is similar to \"devicestatus\" from the Nightscout uploader.\n\n**BgReadings** - contains timestamps and BG value. This is similar to \"entries\" from the Nightscout uploader.\n\n**CarePortalEvents** - contains information the user or system has entered as a CarePortal event.\n\n**DeviceInfo** - contains information about the mobile device used\n\n**DisplayInfo** - contains information about the size of the display \n\n**Preferences** - contains information about the preferences used within AndroidAPS. [See the AndroidAPS documentation on preferences](https://androidaps.readthedocs.io/en/latest/Configuration/Preferences.html) for more details about what each of those indicate and the available setting options.\n\n**TemporaryBasals** - contains information about temporary basal rates that have been set. \n\n**TempTargets** - contains information about temporary targets that have been set.\n\n**Treatments** - contains information about bolus calculations, boluses (manual or SMB), profile changes, etc. \n"
      },
      "source": "https://raw.githubusercontent.com/danamlewis/OpenHumansDataTools/master/README.md",
      "technique": "header_analysis"
    }
  ]
}