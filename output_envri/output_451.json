{
  "application_domain": [
    {
      "confidence": 22.76,
      "result": {
        "type": "String",
        "value": "Computer Vision"
      },
      "technique": "supervised_classification"
    }
  ],
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/hasnainnaeem/PlotPricePrediction"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2019-12-01T17:02:39Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2022-05-15T11:34:04Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "This repo contains the analysis & visualization of a dataset containing the prices & other attributes of plots in Pakistan. This contribution was made to a project at TUKL-NUST Research & Development Lab, during my internship."
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Description of Repo Files",
        "parent_header": [
          "Plot Price Prediction"
        ],
        "type": "Text_excerpt",
        "value": "- `PricePredictionModel-Rethought.ipyn` contains the implications of visualization & analysis along with the baseline results\nusing various ML models. Moreover, it describes the measures to validate & improve the dataset.\n- `/images` contains plots & other images used in `PricePredictionModel-Rethought.ipyn`.\n- `PlotPricePrediction-Visualization and Analysis.pptx` Presentation on this work.\n\n-------\n"
      },
      "source": "https://raw.githubusercontent.com/hasnainnaeem/PlotPricePrediction/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 0.9850405484311234,
      "result": {
        "original_header": "Plot Price Prediction",
        "type": "Text_excerpt",
        "value": "This repo contains the analysis & visualization of a dataset containing the prices & other attributes of plots in Pakistan. \nPlus, it contains results established using various classical machine learning algorithms as well as deep learning ANN models.\nThis contribution was made to a project at [TUKL-NUST Research & Development Lab.](https://tukl.seecs.nust.edu.pk/), \nduring my internship.\n \n"
      },
      "source": "https://raw.githubusercontent.com/hasnainnaeem/PlotPricePrediction/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9226589599421952,
      "result": {
        "original_header": "Observations and deductions from the Attribute Histograms",
        "type": "Text_excerpt",
        "value": "- **Most of variables are not continuous**. Variables are not suitable for predicting a continuous variable: price. So, binary attributes must be replaced with suitable continuous attributes. For example, **distance to bank, restaurant, school, and other places can be added to the dataset** instead of simply having a flag variable indicating their presence. \n- **Useless Attributes**: *Cemetery, hospital, restaurant, school and supermarket* are present in almost all the records. So, these will not be helpful in predictive models. To increase generalizability of the model during test and deployment phase, records with absence of these places should be added to the dataset. Moreover, replacing current values (1 or 0) with distances can help in better use of current dataset.\n    \n- **Remaining potential attributes**: *Area, bank, bus, mosque, department_store and park* may prove helpful in predictive models. Nonetheless, adding more attributes will help with getting better results. \n"
      },
      "source": "https://raw.githubusercontent.com/hasnainnaeem/PlotPricePrediction/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9653218344809745,
      "result": {
        "original_header": "Implications of scatter plots:",
        "type": "Text_excerpt",
        "value": "- Dataset points are very closely placed. So, most of the entries are from the same or nearly situated towns/colonies. \n- **To better predict price differences in cities, attributes which count to difference of prices in cities should present in the dataset. There is not even a single such attribute in the dataset.**\t\n    - Possible new attributes to differentiate cities can be can be population, presence of people of certain social class (can be differentiated on the basis of their income, job, etc), presence of industries, number of malls, number of cinemas, number of parks, etc. \n    - Presence of places should be counted within a certain radius around the plots - preferably dataset should be collected with different radius values, best one can be found during training. Dataset collection with different radius values does not need much effort, same scraping algorithm can be used multiple times with little changes.\n- Last but not the least, **to predict the price differences within the towns/colonies**, we need more attributes which count to differences in prices within same town, colony, or city. Currently, such attributes in the dataset are: area, bank, bus, mosque and park. Only area is a continuous variable here. Problems with the non-continuous variables are discussed earlier in \"Attributes Histograms\" section. \n"
      },
      "source": "https://raw.githubusercontent.com/hasnainnaeem/PlotPricePrediction/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9614757118492674,
      "result": {
        "original_header": "Correlation Matrix and Plots",
        "type": "Text_excerpt",
        "value": "\n```python\n# Run this to generate full correlation matrix. It needs significant processing and memory. \n# Chrome may become unresponsive due to the amount of output data\n# corr_matrix.style.background_gradient(cmap='coolwarm', axis=None)\n``` \n"
      },
      "source": "https://raw.githubusercontent.com/hasnainnaeem/PlotPricePrediction/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.991672650409269,
      "result": {
        "original_header": "Deductions from the correlations",
        "type": "Text_excerpt",
        "value": "- As expected, there is a strong correlation between the price and area.\n- Category variables do not have considerable correlation with the prices. Because, area and other attributes are not being considered in correlation calculation.\n- *Correlation of price with previously separated potential attributes (area, bank, bus, mosque, park) is insignificant*. **This points to possibility of defects in the dataset collection, selection of dataset attributes and default attribute values/types.** We can't certainly say that the correlation doesn't exist because there are other attributes affecting the price at the same time. For example, decrease in price is not significant due to absence of bank if the area of plot is high.\n    \n    **Presence of defects can be pointed out by** checking correlation between pair of attributes with the price. **For example**, *correlation between (mosque, area) and price should be checked*. One attribute in the pair should be area because it is most influential attribute in the dataset. \n"
      },
      "source": "https://raw.githubusercontent.com/hasnainnaeem/PlotPricePrediction/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/hasnainnaeem/PlotPricePrediction/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "executable_example": [
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/hasnainnaeem/PlotPricePrediction/master/PricePredictionModel-Rethought.ipynb"
      },
      "source": "https://raw.githubusercontent.com/hasnainnaeem/PlotPricePrediction/master/PricePredictionModel-Rethought.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/hasnainnaeem/PlotPricePrediction/master/PricePredictionModel-Original.ipynb"
      },
      "source": "https://raw.githubusercontent.com/hasnainnaeem/PlotPricePrediction/master/PricePredictionModel-Original.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/hasnainnaeem/PlotPricePrediction/master/.ipynb_checkpoints/PricePredictionModel-Rethought-checkpoint.ipynb"
      },
      "source": "https://raw.githubusercontent.com/hasnainnaeem/PlotPricePrediction/master/.ipynb_checkpoints/PricePredictionModel-Rethought-checkpoint.ipynb",
      "technique": "file_exploration"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 0
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/hasnainnaeem/PlotPricePrediction/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "hasnainnaeem/PlotPricePrediction"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "Plot Price Prediction"
      },
      "source": "https://raw.githubusercontent.com/hasnainnaeem/PlotPricePrediction/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "images": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/hasnainnaeem/PlotPricePrediction/master/./images/readme/output_13_1.png"
      },
      "source": "https://raw.githubusercontent.com/hasnainnaeem/PlotPricePrediction/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/hasnainnaeem/PlotPricePrediction/master/images/attribute_histogram_plots_without_removing_duplicates.png"
      },
      "source": "https://raw.githubusercontent.com/hasnainnaeem/PlotPricePrediction/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/hasnainnaeem/PlotPricePrediction/master/./images/readme/output_15_1.png"
      },
      "source": "https://raw.githubusercontent.com/hasnainnaeem/PlotPricePrediction/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/hasnainnaeem/PlotPricePrediction/master/./images/readme/output_16_1.png"
      },
      "source": "https://raw.githubusercontent.com/hasnainnaeem/PlotPricePrediction/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/hasnainnaeem/PlotPricePrediction/master/./images/readme/output_20_1.png"
      },
      "source": "https://raw.githubusercontent.com/hasnainnaeem/PlotPricePrediction/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/hasnainnaeem/PlotPricePrediction/master/./images/readme/output_24_1.png"
      },
      "source": "https://raw.githubusercontent.com/hasnainnaeem/PlotPricePrediction/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/hasnainnaeem/PlotPricePrediction/master/./images/readme/output_25_2.png"
      },
      "source": "https://raw.githubusercontent.com/hasnainnaeem/PlotPricePrediction/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/hasnainnaeem/PlotPricePrediction/master/./images/readme/output_28_1.png"
      },
      "source": "https://raw.githubusercontent.com/hasnainnaeem/PlotPricePrediction/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/hasnainnaeem/PlotPricePrediction/master/images/correlation_matrix_heatmap_without_categorical_region_variable.png"
      },
      "source": "https://raw.githubusercontent.com/hasnainnaeem/PlotPricePrediction/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/hasnainnaeem/PlotPricePrediction/master/images/correlation_matrix_without_categorical_region_variable.png"
      },
      "source": "https://raw.githubusercontent.com/hasnainnaeem/PlotPricePrediction/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/hasnainnaeem/PlotPricePrediction/master/./images/readme/output_75_0.png"
      },
      "source": "https://raw.githubusercontent.com/hasnainnaeem/PlotPricePrediction/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/hasnainnaeem/PlotPricePrediction/master/./images/readme/output_78_0.png"
      },
      "source": "https://raw.githubusercontent.com/hasnainnaeem/PlotPricePrediction/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/hasnainnaeem/PlotPricePrediction/master/images/comparison_of_model_results.png"
      },
      "source": "https://raw.githubusercontent.com/hasnainnaeem/PlotPricePrediction/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "installation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Imports &amp; Basic Setup",
        "parent_header": [
          "Notebook Preview"
        ],
        "type": "Text_excerpt",
        "value": "\n```python\n# Common imports\nimport sys\nimport os\nimport numpy as np\nimport pandas as pd\n\nimport seaborn as sns\n\n%matplotlib inline\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n# To plot pretty figures\nmpl.rc('axes', labelsize=14)\nmpl.rc('xtick', labelsize=12)\nmpl.rc('ytick', labelsize=12)\n\n# Define directory to save the figures\nPROJECT_ROOT_DIR = \".\"\nIMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\")\nos.makedirs(IMAGES_PATH, exist_ok=True)\n\n# function to save the figures\ndef save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n    print(\"Saving figure\", fig_id)\n    if tight_layout:\n        plt.tight_layout()\n    plt.savefig(path, format=fig_extension, dpi=resolution)\n\n# To get same results during each run\nnp.random.seed(42)\n\n# Ignoring useless warnings\nimport warnings\nwarnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")\n```\n\n\n```python\nimport sklearn\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras import losses\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras import regularizers\n```\n"
      },
      "source": "https://raw.githubusercontent.com/hasnainnaeem/PlotPricePrediction/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Dataset Setup",
        "parent_header": [
          "Notebook Preview"
        ],
        "type": "Text_excerpt",
        "value": "\n```python\ndf = pd.read_csv('dataset.csv')\ndf.shape\n```\n\n\n\n\n    (43628, 18)\n\n\n\n\n```python\ndf.info()\n```\n\n    <class 'pandas.core.frame.DataFrame'>\n    RangeIndex: 43628 entries, 0 to 43627\n    Data columns (total 18 columns):\n    id                  43628 non-null int64\n    disc                43628 non-null object\n    region              43628 non-null object\n    cityID              43628 non-null int64\n    area                43628 non-null float64\n    price               43628 non-null int64\n    Lat                 43628 non-null float64\n    Lng                 43628 non-null float64\n    bank                43628 non-null int64\n    mosque              43628 non-null int64\n    bus                 43628 non-null int64\n    park                43628 non-null int64\n    department_store    43628 non-null int64\n    school              43628 non-null int64\n    supermarket         43628 non-null int64\n    cemetary            43628 non-null int64\n    hospital            43628 non-null int64\n    restaurant          43628 non-null int64\n    dtypes: float64(3), int64(13), object(2)\n    memory usage: 6.0+ MB\n    \n\n\n```python\n# some region names end with comma, removing those commas\ndf['region'] = df['region'].str.strip(',')\ndf.shape\n```\n\n\n\n\n    (43628, 18)\n\n\n\n\n```python\ndef cleanData():\n    global df\n    # Removing outliers\n    indexNames = df[ (df['price'] >= 250000000 )].index\n    df.drop(indexNames , inplace=True)\n    print(df.shape)\n    indexNames = df[(df['price'] <= 10000)].index\n    df.drop(indexNames , inplace=True)\n    print(df.shape)\n    indexNames = df[(df['area']>= 1000)].index\n    df.drop(indexNames , inplace=True)\n    print(df.shape)\n    indexNames = df[(df['area'] <= 3 )].index\n    df.drop(indexNames , inplace=True)\n    print(df.shape)\n    \n    # Removing places with the same latitude and longitude\n    df.drop_duplicates(subset=['Lat','Lng'],keep='first',inplace = True)\n    print(df.shape)\n```\n\n\n```python\ncleanData()\ndf.head()\n```\n\n    (43591, 18)\n    (43591, 18)\n    (43590, 18)\n    (43587, 18)\n    (2158, 18)\n    \n\n\n\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>disc</th>\n      <th>region</th>\n      <th>cityID</th>\n      <th>area</th>\n      <th>price</th>\n      <th>Lat</th>\n      <th>Lng</th>\n      <th>bank</th>\n      <th>mosque</th>\n      <th>bus</th>\n      <th>park</th>\n      <th>department_store</th>\n      <th>school</th>\n      <th>supermarket</th>\n      <th>cemetary</th>\n      <th>hospital</th>\n      <th>restaurant</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>7 Marla Plot for Sale.</td>\n      <td>B-17</td>\n      <td>1</td>\n      <td>7.62400</td>\n      <td>2300000</td>\n      <td>33.669341</td>\n      <td>72.844890</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>41</td>\n      <td>5 Marla Residential Land for Sale in Islamabad...</td>\n      <td>Top City-1</td>\n      <td>1</td>\n      <td>5.44504</td>\n      <td>1000000</td>\n      <td>33.586108</td>\n      <td>72.866789</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>54</td>\n      <td>600 Square Yard Plot for Sale</td>\n      <td>F-16</td>\n      <td>1</td>\n      <td>21.60000</td>\n      <td>5500000</td>\n      <td>33.656936</td>\n      <td>72.888470</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>74</td>\n      <td>200 Square Yards Plot for Sale</td>\n      <td>Faisal Hills</td>\n      <td>1</td>\n      <td>7.20000</td>\n      <td>2185000</td>\n      <td>33.729388</td>\n      <td>73.093146</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>57</th>\n      <td>88</td>\n      <td>10 Marla Plot for Sale</td>\n      <td>Bahria Town</td>\n      <td>1</td>\n      <td>10.89200</td>\n      <td>9500000</td>\n      <td>33.692555</td>\n      <td>73.219032</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n\n\n\n\n```python\ndf.describe()\n# remaining dataset entries are 2158. \n```\n\n\n\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>cityID</th>\n      <th>area</th>\n      <th>price</th>\n      <th>Lat</th>\n      <th>Lng</th>\n      <th>bank</th>\n      <th>mosque</th>\n      <th>bus</th>\n      <th>park</th>\n      <th>department_store</th>\n      <th>school</th>\n      <th>supermarket</th>\n      <th>cemetary</th>\n      <th>hospital</th>\n      <th>restaurant</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>2158.000000</td>\n      <td>2158.000000</td>\n      <td>2158.000000</td>\n      <td>2.158000e+03</td>\n      <td>2158.000000</td>\n      <td>2158.000000</td>\n      <td>2158.000000</td>\n      <td>2158.000000</td>\n      <td>2158.000000</td>\n      <td>2158.000000</td>\n      <td>2158.000000</td>\n      <td>2158.000000</td>\n      <td>2158.000000</td>\n      <td>2158.000000</td>\n      <td>2158.000000</td>\n      <td>2158.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>27620.110287</td>\n      <td>1.963855</td>\n      <td>18.053462</td>\n      <td>1.529253e+07</td>\n      <td>32.572422</td>\n      <td>73.643578</td>\n      <td>0.863763</td>\n      <td>0.501854</td>\n      <td>0.246525</td>\n      <td>0.495366</td>\n      <td>0.401761</td>\n      <td>0.994903</td>\n      <td>0.995366</td>\n      <td>0.981928</td>\n      <td>0.988879</td>\n      <td>0.982854</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>18338.542450</td>\n      <td>0.999578</td>\n      <td>30.080210</td>\n      <td>2.349205e+07</td>\n      <td>1.114469</td>\n      <td>0.671395</td>\n      <td>0.343120</td>\n      <td>0.500112</td>\n      <td>0.431087</td>\n      <td>0.500094</td>\n      <td>0.490368</td>\n      <td>0.071230</td>\n      <td>0.067931</td>\n      <td>0.133244</td>\n      <td>0.104894</td>\n      <td>0.129844</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>3.267000</td>\n      <td>3.300000e+05</td>\n      <td>24.993758</td>\n      <td>67.307440</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>15779.500000</td>\n      <td>1.000000</td>\n      <td>7.623040</td>\n      <td>4.000000e+06</td>\n      <td>31.455539</td>\n      <td>73.043821</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>25207.500000</td>\n      <td>1.000000</td>\n      <td>10.890040</td>\n      <td>7.575000e+06</td>\n      <td>33.521323</td>\n      <td>73.218711</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>36617.250000</td>\n      <td>3.000000</td>\n      <td>21.780000</td>\n      <td>1.650000e+07</td>\n      <td>33.632623</td>\n      <td>74.284503</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>66744.000000</td>\n      <td>3.000000</td>\n      <td>784.080000</td>\n      <td>2.300000e+08</td>\n      <td>33.744962</td>\n      <td>74.499221</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n\n\n"
      },
      "source": "https://raw.githubusercontent.com/hasnainnaeem/PlotPricePrediction/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Linear Regression",
        "parent_header": [
          "Notebook Preview",
          "Predictive ML Models",
          "Making Predictions on Validation Set &amp; Custom Input"
        ],
        "type": "Text_excerpt",
        "value": "\n```python\nfrom sklearn.linear_model import LinearRegression\n\nlin_reg_model = LinearRegression()\nlin_reg_model.fit(X_train, Y_train)\n```\n\n\n\n\n    LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)\n\n\n"
      },
      "source": "https://raw.githubusercontent.com/hasnainnaeem/PlotPricePrediction/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Decision Tree Regression",
        "parent_header": [
          "Notebook Preview",
          "Predictive ML Models",
          "Making Predictions on Validation Set &amp; Custom Input"
        ],
        "type": "Text_excerpt",
        "value": "\n```python\nfrom sklearn.tree import DecisionTreeRegressor\n\ntree_reg_model = DecisionTreeRegressor(random_state=42)\ntree_reg_model.fit(X_train, Y_train)\n```\n\n\n\n\n    DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n                          max_leaf_nodes=None, min_impurity_decrease=0.0,\n                          min_impurity_split=None, min_samples_leaf=1,\n                          min_samples_split=2, min_weight_fraction_leaf=0.0,\n                          presort=False, random_state=42, splitter='best')\n\n\n"
      },
      "source": "https://raw.githubusercontent.com/hasnainnaeem/PlotPricePrediction/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Random Forest Regression",
        "parent_header": [
          "Notebook Preview",
          "Predictive ML Models",
          "Evaluating on Test Set"
        ],
        "type": "Text_excerpt",
        "value": "\n```python\nprice_predictions = forest_reg_model.predict(X_test)\nforest_reg_mse = mean_squared_error(price_predictions, Y_test)\nforest_reg_rmse = np.sqrt(forest_reg_mse)\nreduced_num, ten_count = countTens(forest_reg_rmse)\nprint(\"RMSE on test set using Random Forest Regression is: \" + str(reduced_num) + \" * 10^\" + str(ten_count))\n```\n\n    RMSE on test set using Random Forest Regression is: 1.4274739383490493 * 10^7\n    \n\n\n```python\n# evaluating the model tuned by grid-search\nprice_predictions = grid_search.predict(X_test)\nforest_reg_mse = mean_squared_error(price_predictions, Y_test)\nforest_reg_rmse = np.sqrt(forest_reg_mse)\nreduced_num, ten_count = countTens(forest_reg_rmse)\nprint(\"RMSE on test set using grid-search optimized Random Forest Regression is: \" + str(reduced_num) + \" * 10^\" + str(ten_count))\n```\n\n    RMSE on test set using grid-search optimized Random Forest Regression is: 1.42468066402298 * 10^7\n    \n\n#### Deep Learning Model 1\n\n\n```python\nmodel_1_mse = model_1.evaluate(X_test, Y_test)[0]\nmodel_1_rmse = np.sqrt(model_1_mse)\nreduced_num, ten_count = countTens(model_1_rmse)\nprint(\"RMSE on test set using Model 1 is: \" + str(reduced_num) + \" * 10^\" + str(ten_count))\n```\n\n    216/216 [==============================] - 0s 74us/sample - loss: 172750485673301.3438 - mean_squared_error: 172750480080896.0000\n    RMSE on test set using Model 1 is: 1.3143457903965048 * 10^7\n    \n\n\n```python\nplt.plot(hist.history['loss'])\nplt.plot(hist.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Val'], loc='upper right')\nplt.show()\n```\n\n\n    \n![png](./images/readme/output_75_0.png)\n    \n\n\n#### Deep Learning Model 2\n\n\n```python\nmodel_2_mse = model_2.evaluate(X_test, Y_test)[0]\nmodel_2_rmse = np.sqrt(model_2_mse)\nreduced_num, ten_count = countTens(model_2_rmse)\nprint(\"RMSE on test set using Model 2 is: \" + str(reduced_num) + \" * 10^\" + str(ten_count))\n```\n\n    216/216 [==============================] - 0s 83us/sample - loss: 141226298135893.3438 - mean_squared_error: 141226292543488.0000\n    RMSE on test set using Model 2 is: 1.1883867137253485 * 10^7\n    \n\n\n```python\nplt.plot(hist_2.history['loss'])\nplt.plot(hist_2.history['val_loss'])\nplt.title('Model loss 2')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Val'], loc='upper right')\nplt.show()\n\n# below figure doesn't show next 25 epochs. RMSE above was displayed after 25 more epoches (making total epochs = 300)\n```\n\n\n    \n![png](./images/readme/output_78_0.png)\n    \n\n"
      },
      "source": "https://raw.githubusercontent.com/hasnainnaeem/PlotPricePrediction/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Predictions on Custom Input",
        "parent_header": [
          "Notebook Preview",
          "Predictive ML Models",
          "Making Predictions on Validation Set &amp; Custom Input",
          "Deep Learning Model 2"
        ],
        "type": "Text_excerpt",
        "value": "\n```python\n#test_data = np.array([1,7.624,33.669341,72.84489,1,1,0,0,0,1,1,1,1,1])\ntest_data = np.array([1 ,43.560, 33.669341, 72.84489, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1])\nprint(model_1.predict(test_data.reshape(1,14), batch_size=1))\nprediction = model_1.predict(test_data.reshape(1,14), batch_size=1)\nprint(Y.at[1,\"price\"])\nprint(prediction - Y.at[1,\"price\"])\n```\n"
      },
      "source": "https://raw.githubusercontent.com/hasnainnaeem/PlotPricePrediction/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Predictions on Validation Set",
        "parent_header": [
          "Notebook Preview",
          "Predictive ML Models",
          "Making Predictions on Validation Set &amp; Custom Input",
          "Deep Learning Model 1"
        ],
        "type": "Text_excerpt",
        "value": "\n```python\npred_val = model_1.predict(X_val)\nmodel1_val_rmse = np.sqrt(mean_squared_error(Y_val, pred_val))\nreduced_num, ten_count = countTens(model1_val_rmse)\nprint(\"RMSE on validation set using model 1 is: \" + str(reduced_num) + \" * 10^\" + str(ten_count))\n```\n\n    RMSE on validation set using model 1 is: 1.5026939173212719 * 10^7\n    \n\n#### Deep Learning Model 2\n\n##### Predictions on Custom Input\n\n\n```python\n#test_data = np.array([1,7.624,33.669341,72.84489,1,1,0,0,0,1,1,1,1,1])\ntest_data = np.array([1 ,43.560, 33.669341, 72.84489, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1])\nprint(model_2.predict(test_data.reshape(1,14), batch_size=1))\nprediction = model_2.predict(test_data.reshape(1,14), batch_size=1)\nprint(Y.at[1,\"price\"])\nprint(prediction - Y.at[1,\"price\"])\n\n\n##### Predictions on Training Set\n\n\n```python\npred_val = model_2.predict(X_val)\nmodel2_val_rmse = np.sqrt(mean_squared_error(Y_val, pred_val))\nreduced_num, ten_count = countTens(model2_val_rmse)\nprint(\"RMSE on validation set using model 2 is: \" + str(reduced_num) + \" * 10^\" + str(ten_count))\n```\n\n    RMSE on validation set using model 2 is: 1.424891094928326 * 10^7\n    \n\n### Summary of Results\n\n**Note:** These are some baseline results. DL models were not fine-tuned by trying different hyper-parameters. Secondly, different configurations of DL models were not tried at all except for the given models. This work focused on dataset visualization & analysis.\n![Comparison of Results achieved using various ML Models](images/comparison_of_model_results.png)\n\n- Random Forests & Decision Trees performed comparable to Deep Learning models. This is because of the nature of the dataset. \n- Deeper DL models can be used for better results along with hyper-parameter tuning. But, significant improvements are not expected (as validated during some experiments) without improving the dataset.\n\n- **Future work** \n    - Work can be done on modifying the dataset according to the analysis given in this notebook. Suggested modifications can help with achieving better results using deep learning models.\n    - Deeper DL models can be tried, because moving from model 1 to model 2 showed some progress. Secondly, different layer configurations can be tried along with hyper-parameter tuning.\n\n## Conclusion\n\n- Dataset needs serious improvements. All the future work on this project depends on the dataset. Investing in the dataset can bring significant improvements in the results.\n- Most of suggested dataset improvements are not resource-extensive. Latitude & longitude of plots can be used to extract required attributes from the Google Maps. Cost-effective solution can be achieved through Node.js frameworks & Google Maps APIs.\n- Without dataset extension & improvement, hyper-parameter tuning & usage of deeper deep learning models may lead to better results.\n\n\n```python\n\n```\n"
      },
      "source": "https://raw.githubusercontent.com/hasnainnaeem/PlotPricePrediction/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 0.8531969743994872,
      "result": {
        "original_header": "Model 1 - Dense Layers",
        "type": "Text_excerpt",
        "value": "\n```python\nmodel_1.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_squared_error'])\n```\n \n"
      },
      "source": "https://raw.githubusercontent.com/hasnainnaeem/PlotPricePrediction/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8531969743994872,
      "result": {
        "original_header": "Model 2 - 3 Dense Layers",
        "type": "Text_excerpt",
        "value": "\n```python\nmodel_2.compile(optimizer='adam', loss='mean_squared_error',metrics=['mean_squared_error'])\n```\n \n"
      },
      "source": "https://raw.githubusercontent.com/hasnainnaeem/PlotPricePrediction/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9983227102930481,
      "result": {
        "original_header": "Random Forest Regressor",
        "type": "Text_excerpt",
        "value": "\n    RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n                          max_features='auto', max_leaf_nodes=None,\n                          min_impurity_decrease=0.0, min_impurity_split=None,\n                          min_samples_leaf=1, min_samples_split=2,\n                          min_weight_fraction_leaf=0.0, n_estimators=150,\n                          n_jobs=None, oob_score=False, random_state=42, verbose=0,\n                          warm_start=False) \n"
      },
      "source": "https://raw.githubusercontent.com/hasnainnaeem/PlotPricePrediction/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "invocation": [
    {
      "confidence": 0.8720049514282944,
      "result": {
        "original_header": "Histograms of Dataset Attributes",
        "type": "Text_excerpt",
        "value": "\n```python\ndf.hist(bins=50, figsize=(20,15))\nsave_fig(\"attribute_histogram_plots\")\nplt.show()\n``` \n"
      },
      "source": "https://raw.githubusercontent.com/hasnainnaeem/PlotPricePrediction/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8598224236423836,
      "result": {
        "original_header": "Location Scatter Plots",
        "type": "Text_excerpt",
        "value": "\n```python\ndf.plot(kind=\"scatter\", x=\"Lat\", y=\"Lng\")\nsave_fig(\"overall_scatter_plot\")\n\n``` \n```python\ndf.plot(kind=\"scatter\", x=\"Lng\", y=\"Lat\", alpha=1,\n    figsize=(10,7),\n    c=\"price\", cmap=plt.get_cmap(\"jet\"), colorbar=True,\n    sharex=False)\nplt.legend()\nsave_fig(\"housing_prices_scatterplot\")\n``` \n"
      },
      "source": "https://raw.githubusercontent.com/hasnainnaeem/PlotPricePrediction/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8402247803970845,
      "result": {
        "original_header": "Correlation Matrix and Plots",
        "type": "Text_excerpt",
        "value": "\n```python\ncorr_matrix = df.corr()\nplt.subplots(figsize=(12,9))\nsns.heatmap(corr_matrix, vmax=0.9, square=True)\nsave_fig(\"correlation_matrix_heatmap\")\n``` \n"
      },
      "source": "https://raw.githubusercontent.com/hasnainnaeem/PlotPricePrediction/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8350937729213439,
      "result": {
        "original_header": "Random Forest Regressor",
        "type": "Text_excerpt",
        "value": "\n```python\nfrom sklearn.ensemble import RandomForestRegressor\n\nforest_reg_model = RandomForestRegressor(n_estimators=150, random_state=42)\nforest_reg_model.fit(X_train, Y_train)\n``` \n\n```python\n# Using Grid Search for Optimal Hypyerparameters\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.ensemble import RandomForestRegressor\n\nparam_grid = [\n    {'n_estimators': [50, 70, 100, 150, 200], 'max_features': [2, 4, 6, 8, 10, 12]},\n    {'bootstrap': [False], 'n_estimators': [50, 70, 100, 150, 200], 'max_features': [2, 3, 4, 8, 10, 12]},\n  ]\n\nforest_reg_model = RandomForestRegressor(random_state=42)\ngrid_search = GridSearchCV(forest_reg_model, param_grid, cv=12,\n                           scoring='neg_mean_squared_error',\n                           return_train_score=True)\ngrid_search.fit(X_train, Y_train)\n```\n```python\nprice_predictions = grid_search.predict(X_train)\nforest_reg_mse = mean_squared_error(price_predictions, Y_train)\nforest_reg_rmse = np.sqrt(forest_reg_mse)\nreduced_num, ten_count = countTens(forest_reg_rmse)\nprint(\"RMSE on training set using Forest Tree Regression is: \" + str(reduced_num) + \" * 10^\" + str(ten_count))\n```\n \n"
      },
      "source": "https://raw.githubusercontent.com/hasnainnaeem/PlotPricePrediction/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/hasnainnaeem/PlotPricePrediction/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ""
      },
      "technique": "GitHub_API"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "PlotPricePrediction"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "User",
        "value": "hasnainnaeem"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Jupyter Notebook",
        "size": 2273432,
        "type": "Programming_language",
        "value": "Jupyter Notebook"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/hasnainnaeem/PlotPricePrediction/master/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "somef_missing_categories": [
    "citation",
    "acknowledgement",
    "run",
    "download",
    "requirements",
    "contact",
    "contributors",
    "documentation",
    "license",
    "usage",
    "faq",
    "support",
    "identifier",
    "has_build_file"
  ],
  "somef_provenance": {
    "date": "2024-10-04 00:50:44",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 0
      },
      "technique": "GitHub_API"
    }
  ],
  "type": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "notebook-application"
      },
      "technique": "software_type_heuristics"
    }
  ]
}