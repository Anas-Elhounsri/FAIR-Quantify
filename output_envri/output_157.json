{
  "application_domain": [
    {
      "confidence": 56.87,
      "result": {
        "type": "String",
        "value": "Computer Vision"
      },
      "technique": "supervised_classification"
    },
    {
      "confidence": 35.93,
      "result": {
        "type": "String",
        "value": "Reinforcement Learning"
      },
      "technique": "supervised_classification"
    }
  ],
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/mdelrosa/wireless-ml"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2019-04-02T02:12:34Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2022-09-25T05:33:56Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "Research on machine learning in wireless communications."
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 0.879786041469419,
      "result": {
        "original_header": "Code",
        "type": "Text_excerpt",
        "value": "- Mason:\n\t- As of 2019-05-06: Replicating results in Ali and Yangyu, \"Automatic Modulation Classification Using Deep Learning Based on Sparse Autoencdoers with Nonegativity Constraints.\" (detailed below).\n\t\t- Issues: Getting GNU radio Python dependency installed on Windows proving difficult. Needed to generate radioml dataset to train/validate network.\n \n"
      },
      "source": "https://raw.githubusercontent.com/mdelrosa/wireless-ml/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9841342841883748,
      "result": {
        "original_header": "Papers",
        "type": "Text_excerpt",
        "value": "Formatting of filenames for papers: XXXX_firstAuthorLastName_titleSummary (e.g., 2018_Dorner_DLOverAir) \n- Huang, Y., Li, S., Hou, Y. T., and Lou, W., \"GPF: A GPU-based design to achieve ~100us scheduling for 5G NR,\" MobiCom '18, Nov 2018.\n\t- **Summary**: Treats problem of resource-block/modulation coding scheme as hierarchical arrangement of sub-problems to make amenable to GPU-based solver.\n- O'Shea, T. J., Roy, T., and West, N., \"Approximating the void: Learning stochastic channel models from observation with variational generative adversarial networks,\" arXiv:1805.06350v2, May 2018.\n\t- **Summary**: Uses concept of adversarial networks (popularized by [Goodfellow 2014 paper](https://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf)) to simultaneously train a channel autoencoder and a channel model to allow for backpropagation/gradient calculation.\n- O'Shea, T. J., Roy, T., West, N., and Hilburn, B. C., \"Physical layer communications system design over-the-air using adversarial networks,\" \tarXiv:1803.03145 [eess.SP], Mar 2018.\n\t- **Summary**: Similar approach to [D\u00f6rner](https://github.com/mdelrosa/wireless-ml/blob/master/Papers/2018_Dorner_DLoverAir.pdf) (training encoder/decoder), but trains a network to approximate the channel rather than implementing transfer learning from an analytical model.\n- Corlay, V, et al, \"Multilevel MIMO Detection with Deep Learning,\" IEEE 2018 52nd Asilomar Conference, Oct 2018. [Link](https://ieeexplore.ieee.org/document/8645519)\n\t- **Summary**: Using a deep neural network (DNN) with a customized sigmoid function to reduce network complexity, the authors achieve near Maximimum-Likelihood decoder performance on decoding a MIMO channel.\n\t- **Methods**: Multi-level sigmoid function, DNN, random forest\n- S. D\u00f6rner et al, \"Deep Learning Based Communication Over the Air,\" IEEE, Feb 2018. ([Link](https://github.com/mdelrosa/wireless-ml/blob/master/Papers/2018_Dorner_DLoverAir.pdf), [Summary Slides](https://docs.google.com/presentation/d/122XdVg9kUqoCtVnBc7acemM5RyVIfHtDeRlXqwHdOQk/edit#slide=id.p))\n- A. Ali and F. Yangyu, \"Automatic Modulation Classification Using Deep Learning Based on Sparse Autoencdoers with Nonegativity Constraints,\" IEEE, Nov 2017. ([Link](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8038046))\n\t- **Summary**: Extends notion of stacked autoencoders (SAE) by leveraging sparsity ([see here](https://web.stanford.edu/class/cs294a/sparseAutoencoder.pdf) for explanation of sparsity in autoencoders) and nonnegativity constraints on the network's hidden layers. Compares performancec of SAE and SAE with extended maximum likelihood estimator to the autoencoder with nonnegativity constraint (ANC) in classifying signals from five different modulation schemes.\n\t- **Methods**: Stacked Autoencoders (greedy layer-wise training), Sparse Autoencoders, Cumulants (as signal features), KL Divergence (used to express sparsity constraint in loss function).\n\t- **Comments**:\n\t\t- KL Divergence normally used to measure/minimize difference between two probability distributions. Here, KL Divergence is used to minimizing discrepancy between a given hidden layer's average activation and the sparsity constraint.\n\t\t- No comments on runtime/viability as a real-time signal classification method. \n- S. Peng et al, \"Modulation Classification Based on Signal Constellation Diagrams and Deep Learning,\" IEEE Transactions on Neural Networks and Learning Systems. Mar 2019. ([Link](https://ieeexplore.ieee.org/document/8418751))\n\t- **Summary**: Performs signal modulation classification by applying image-like segmentation of constellation diagrams to make data compatible with well-established convolutional neural networks (CNN), including [AlexNet](https://medium.com/@smallfishbigsea/a-walk-through-of-alexnet-6cbd137a5637) and [GoogLeNet](https://ai.google/research/pubs/pub43022). Demonstrates DL-based classification accuracy exceeds that of other traditional classification methods (i.e., cumulant-based statistics).\n\t- **Methods**: Deep Learning, Convolutional Neural Networks, Image Processing. \n\t- **Upshot**: DL-based classification of most low-order modulation schemes (i.e., BPSK, ASK) is high, but accuracy for higher order schemes (e.g. 16/64 QAM) suffers (74.1%/68.3%, respectively). Additionally, DL/CNN approaches demand more computation time than traditional methods (see Table III). Does not seem like paper attempts classification on live, OTA data.\n- T. O'Shea, T. Roy, T. Charles, \"Over-the-Air Deep Learning Based Radio Signal Classification,\" IEEE Journal of Selected Topics in Signal Processing. Feb 2018. ([Link](https://ieeexplore.ieee.org/abstract/document/8267032), [Radioml Github](https://github.com/radioML))\n\t- **Summary**: Demonstrates residual neural network (RNN) which is capable of discerning different radio modulation schemes with better accuracy (?) than previously developed convolutional neural networks and other baseline methods. Applies RNN to OTA data and demonstrates feasibility of deep-learning based signal classification.\n\t- **Methods**: Deep Learning (residual neural networks, transfer learning). \n\t- **Upshot**: Transfer learning valuable but does not achieve equivalent accuracy/sensitivity compared to direct training when transfer learning data is small. Transfer learning can be made more valuable when simulation methods become more accurate, allowing for generation of synthetic data which accurately represents real-world data.\n- H. Mao et al, \"Resource Management with Deep Reinforcement Learning,\" HetNets, Nov 2016. ([Link](https://people.csail.mit.edu/alizadeh/papers/deeprm-hotnets16.pdf), [GitHub](https://github.com/hongzimao/deeprm))\n\t- **Summary**: Presents a deep reinforcement learning algorithm, \"DeepRM,\" which learns sensible online scheduling of multiple computational resources by minimizing average slowdown in each timestep. Demonstrates experimental performance gains over other scheduling algorithms.\n\t- **Methods**: Reinforcement learning (policy-gradient methods, REINFORCE). Deep Learning. \n\t- **Upshot**: Not strictly a wireless communications or deep learning application, but demonstrates discsussion of scheduling and online learning might prove useful in analogous wireless communications network application, such as cluster scheduleing/formation in 5G networks.\n- S. Jiang et al, \"VIA: Improving Internet Telephony Call Quality Using Predictive Relay Selection,\" SIGCOMM, Aug 2016. ([Link](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/08/via.pdf))\n\t- **Summary**: Uses machine learning to improve Quality of Experience (QoE) for VoIP by combining methods from overlay networks and reinforcement learning. Demonstrates theoretical and experimental reduction in metrics of Poor Network Rate (PNR), including round-trip time (RTT), packet loss, and jitter.\n\t- **Methods**: Reinforcement learning (multi-armed bandit, Upper-confidence bound, epsilon-greedy). Overlay networks.\n\t- **Upshot**: Not strictly a wireless communications or deep learning application, but demonstrates methods which might prove applicable. \n- Generally better at NP hard problems\n\t- 1:\n\t\t- \"Most fertile ground\" in resource allocation\n\t\t- Channel information provided to operator too low resolution temporally/spatially\n\t\t- What do we do in the case of missing/outdated data?\n\t\t\t- Objective function: maximize data rate for everyone\n\t\t- What is the state of the art for deep learning in resource allocation in the context of stale/limited data?\n\t- 2:\n\t\t- If I want better resource allocation, then how do I design the pilots to get the desired information from UEs?\n\t- Figure out if this is a fertile research direction for the next 2-3 years (minimum)\n\t- Look-up later: basic understanding of how channel state information is provided\n\t\t- Anticipate\n\t- For encoding/decoding: \n- Chatrooms talking about wireless comms research/machine learning?\n- Setup Slack\n- Trouble with machine learning: tends to be unstructured\n\t- Already have good classic approaches for feature extraction. Machine-learning \n\t- In order to make it effective, need to apply domain knowledge\n\t- AWGN is well-understood, so machine learning not well-suited. But what about colored noise? Impulses? (What )\n\t- Good thing about machine learning: only require one architecture which needs its weights updated\n\t\t- Less hardware-specific; different specifications can be implemented by software update instead of changing out processor\n \n"
      },
      "source": "https://raw.githubusercontent.com/mdelrosa/wireless-ml/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/mdelrosa/wireless-ml/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "executable_example": [
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/mdelrosa/wireless-ml/master/code/fading-vgan/fading-vgan.ipynb"
      },
      "source": "https://raw.githubusercontent.com/mdelrosa/wireless-ml/master/code/fading-vgan/fading-vgan.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/mdelrosa/wireless-ml/master/code/fading-vgan/.ipynb_checkpoints/fading-vgan-checkpoint.ipynb"
      },
      "source": "https://raw.githubusercontent.com/mdelrosa/wireless-ml/master/code/fading-vgan/.ipynb_checkpoints/fading-vgan-checkpoint.ipynb",
      "technique": "file_exploration"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 4
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/mdelrosa/wireless-ml/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "mdelrosa/wireless-ml"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "wireless-ml"
      },
      "source": "https://raw.githubusercontent.com/mdelrosa/wireless-ml/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/mdelrosa/wireless-ml/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ""
      },
      "technique": "GitHub_API"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "wireless-ml"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "User",
        "value": "mdelrosa"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Jupyter Notebook",
        "size": 49465,
        "type": "Programming_language",
        "value": "Jupyter Notebook"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/mdelrosa/wireless-ml/master/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "related_papers": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://arxiv.org/abs/1803.03145 [eess.SP], Mar 2018.\n\t- **Summary**: Similar approach to [D\u00f6rner](https://github.com/mdelrosa/wireless-ml/blob/master/Papers/2018_Dorner_DLoverAir.pdf) (training encoder/decoder), but trains a network to approximate the channel rather than implementing transfer learning from an analytical model.\n- Corlay, V, et al, \"Multilevel MIMO Detection with Deep Learning,\" IEEE 2018 52nd Asilomar Conference, Oct 2018. [Link](https://ieeexplore.ieee.org/document/8645519)\n\t- **Summary**: Using a deep neural network (DNN) with a customized sigmoid function to reduce network complexity, the authors achieve near Maximimum-Likelihood decoder performance on decoding a MIMO channel.\n\t- **Methods**: Multi-level sigmoid function, DNN, random forest\n- S. D\u00f6rner et al, \"Deep Learning Based Communication Over the Air,\" IEEE, Feb 2018. ([Link](https://github.com/mdelrosa/wireless-ml/blob/master/Papers/2018_Dorner_DLoverAir.pdf), [Summary Slides](https://docs.google.com/presentation/d/122XdVg9kUqoCtVnBc7acemM5RyVIfHtDeRlXqwHdOQk/edit#slide=id.p))\n- A. Ali and F. Yangyu, \"Automatic Modulation Classification Using Deep Learning Based on Sparse Autoencdoers with Nonegativity Constraints,\" IEEE, Nov 2017. ([Link](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8038046))\n\t- **Summary**: Extends notion of stacked autoencoders (SAE) by leveraging sparsity ([see here](https://web.stanford.edu/class/cs294a/sparseAutoencoder.pdf) for explanation of sparsity in autoencoders) and nonnegativity constraints on the network's hidden layers. Compares performancec of SAE and SAE with extended maximum likelihood estimator to the autoencoder with nonnegativity constraint (ANC) in classifying signals from five different modulation schemes.\n\t- **Methods**: Stacked Autoencoders (greedy layer-wise training), Sparse Autoencoders, Cumulants (as signal features), KL Divergence (used to express sparsity constraint in loss function).\n\t- **Comments**:\n\t\t- KL Divergence normally used to measure/minimize difference between two probability distributions. Here, KL Divergence is used to minimizing discrepancy between a given hidden layer's average activation and the sparsity constraint.\n\t\t- No comments on runtime/viability as a real-time signal classification method. \n- S. Peng et al, \"Modulation Classification Based on Signal Constellation Diagrams and Deep Learning,\" IEEE Transactions on Neural Networks and Learning Systems. Mar 2019. ([Link](https://ieeexplore.ieee.org/document/8418751))\n\t- **Summary**: Performs signal modulation classification by applying image-like segmentation of constellation diagrams to make data compatible with well-established convolutional neural networks (CNN), including [AlexNet](https://medium.com/@smallfishbigsea/a-walk-through-of-alexnet-6cbd137a5637) and [GoogLeNet](https://ai.google/research/pubs/pub43022). Demonstrates DL-based classification accuracy exceeds that of other traditional classification methods (i.e., cumulant-based statistics).\n\t- **Methods**: Deep Learning, Convolutional Neural Networks, Image Processing. \n\t- **Upshot**: DL-based classification of most low-order modulation schemes (i.e., BPSK, ASK) is high, but accuracy for higher order schemes (e.g. 16/64 QAM) suffers (74.1%/68.3%, respectively). Additionally, DL/CNN approaches demand more computation time than traditional methods (see Table III). Does not seem like paper attempts classification on live, OTA data.\n- T. O'Shea, T. Roy, T. Charles, \"Over-the-Air Deep Learning Based Radio Signal Classification,\" IEEE Journal of Selected Topics in Signal Processing. Feb 2018. ([Link](https://ieeexplore.ieee.org/abstract/document/8267032), [Radioml Github](https://github.com/radioML))\n\t- **Summary**: Demonstrates residual neural network (RNN) which is capable of discerning different radio modulation schemes with better accuracy (?) than previously developed convolutional neural networks and other baseline methods. Applies RNN to OTA data and demonstrates feasibility of deep-learning based signal classification.\n\t- **Methods**: Deep Learning (residual neural networks, transfer learning). \n\t- **Upshot**: Transfer learning valuable but does not achieve equivalent accuracy/sensitivity compared to direct training when transfer learning data is small. Transfer learning can be made more valuable when simulation methods become more accurate, allowing for generation of synthetic data which accurately represents real-world data.\n- H. Mao et al, \"Resource Management with Deep Reinforcement Learning,\" HetNets, Nov 2016. ([Link](https://people.csail.mit.edu/alizadeh/papers/deeprm-hotnets16.pdf), [GitHub](https://github.com/hongzimao/deeprm))\n\t- **Summary**: Presents a deep reinforcement learning algorithm, \"DeepRM,\" which learns sensible online scheduling of multiple computational resources by minimizing average slowdown in each timestep. Demonstrates experimental performance gains over other scheduling algorithms.\n\t- **Methods**: Reinforcement learning (policy-gradient methods, REINFORCE). Deep Learning. \n\t- **Upshot**: Not strictly a wireless communications or deep learning application, but demonstrates discsussion of scheduling and online learning might prove useful in analogous wireless communications network application, such as cluster scheduleing/formation in 5G networks.\n- S. Jiang et al, \"VIA: Improving Internet Telephony Call Quality Using Predictive Relay Selection,\" SIGCOMM, Aug 2016. ([Link](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/08/via.pdf))\n\t- **Summary**: Uses machine learning to improve Quality of Experience (QoE) for VoIP by combining methods from overlay networks and reinforcement learning. Demonstrates theoretical and experimental reduction in metrics of Poor Network Rate (PNR), including round-trip time (RTT), packet loss, and jitter.\n\t- **Methods**: Reinforcement learning (multi-armed bandit, Upper-confidence bound, epsilon-greedy). Overlay networks.\n\t- **Upshot**: Not strictly a wireless communications or deep learning application, but demonstrates methods which might prove applicable.\n\n- Generally better at NP hard problems\n\t- 1:\n\t\t- \"Most fertile ground\" in resource allocation\n\t\t- Channel information provided to operator too low resolution temporally/spatially\n\t\t- What do we do in the case of missing/outdated data?\n\t\t\t- Objective function: maximize data rate for everyone\n\t\t- What is the state of the art for deep learning in resource allocation in the context of stale/limited data?\n\t- 2:\n\t\t- If I want better resource allocation, then how do I design the pilots to get the desired information from UEs?\n\t- Figure out if this is a fertile research direction for the next 2-3 years (minimum)\n\t- Look-up later: basic understanding of how channel state information is provided\n\t\t- Anticipate\n\t- For encoding/decoding: \n- Chatrooms talking about wireless comms research/machine learning?\n- Setup Slack\n- Trouble with machine learning: tends to be unstructured\n\t- Already have good classic approaches for feature extraction. Machine-learning \n\t- In order to make it effective, need to apply domain knowledge\n\t- AWGN is well-understood, so machine learning not well-suited. But what about colored noise? Impulses? (What )\n\t- Good thing about machine learning: only require one architecture which needs its weights updated\n\t\t- Less hardware-specific; different specifications can be implemented by software update instead of changing out processor"
      },
      "source": "https://raw.githubusercontent.com/mdelrosa/wireless-ml/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://arxiv.org/abs/1805.06350v2, May 2018.\n\t- **Summary**: Uses concept of adversarial networks (popularized by [Goodfellow 2014 paper](https://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf)) to simultaneously train a channel autoencoder and a channel model to allow for backpropagation/gradient calculation.\n- O'Shea, T. J., Roy, T., West, N., and Hilburn, B. C., \"Physical layer communications system design over-the-air using adversarial networks,\" \thttps://arxiv.org/abs/1803.03145 [eess.SP], Mar 2018.\n\t- **Summary**: Similar approach to [D\u00f6rner](https://github.com/mdelrosa/wireless-ml/blob/master/Papers/2018_Dorner_DLoverAir.pdf) (training encoder/decoder), but trains a network to approximate the channel rather than implementing transfer learning from an analytical model.\n- Corlay, V, et al, \"Multilevel MIMO Detection with Deep Learning,\" IEEE 2018 52nd Asilomar Conference, Oct 2018. [Link](https://ieeexplore.ieee.org/document/8645519)\n\t- **Summary**: Using a deep neural network (DNN) with a customized sigmoid function to reduce network complexity, the authors achieve near Maximimum-Likelihood decoder performance on decoding a MIMO channel.\n\t- **Methods**: Multi-level sigmoid function, DNN, random forest\n- S. D\u00f6rner et al, \"Deep Learning Based Communication Over the Air,\" IEEE, Feb 2018. ([Link](https://github.com/mdelrosa/wireless-ml/blob/master/Papers/2018_Dorner_DLoverAir.pdf), [Summary Slides](https://docs.google.com/presentation/d/122XdVg9kUqoCtVnBc7acemM5RyVIfHtDeRlXqwHdOQk/edit#slide=id.p))\n- A. Ali and F. Yangyu, \"Automatic Modulation Classification Using Deep Learning Based on Sparse Autoencdoers with Nonegativity Constraints,\" IEEE, Nov 2017. ([Link](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8038046))\n\t- **Summary**: Extends notion of stacked autoencoders (SAE) by leveraging sparsity ([see here](https://web.stanford.edu/class/cs294a/sparseAutoencoder.pdf) for explanation of sparsity in autoencoders) and nonnegativity constraints on the network's hidden layers. Compares performancec of SAE and SAE with extended maximum likelihood estimator to the autoencoder with nonnegativity constraint (ANC) in classifying signals from five different modulation schemes.\n\t- **Methods**: Stacked Autoencoders (greedy layer-wise training), Sparse Autoencoders, Cumulants (as signal features), KL Divergence (used to express sparsity constraint in loss function).\n\t- **Comments**:\n\t\t- KL Divergence normally used to measure/minimize difference between two probability distributions. Here, KL Divergence is used to minimizing discrepancy between a given hidden layer's average activation and the sparsity constraint.\n\t\t- No comments on runtime/viability as a real-time signal classification method. \n- S. Peng et al, \"Modulation Classification Based on Signal Constellation Diagrams and Deep Learning,\" IEEE Transactions on Neural Networks and Learning Systems. Mar 2019. ([Link](https://ieeexplore.ieee.org/document/8418751))\n\t- **Summary**: Performs signal modulation classification by applying image-like segmentation of constellation diagrams to make data compatible with well-established convolutional neural networks (CNN), including [AlexNet](https://medium.com/@smallfishbigsea/a-walk-through-of-alexnet-6cbd137a5637) and [GoogLeNet](https://ai.google/research/pubs/pub43022). Demonstrates DL-based classification accuracy exceeds that of other traditional classification methods (i.e., cumulant-based statistics).\n\t- **Methods**: Deep Learning, Convolutional Neural Networks, Image Processing. \n\t- **Upshot**: DL-based classification of most low-order modulation schemes (i.e., BPSK, ASK) is high, but accuracy for higher order schemes (e.g. 16/64 QAM) suffers (74.1%/68.3%, respectively). Additionally, DL/CNN approaches demand more computation time than traditional methods (see Table III). Does not seem like paper attempts classification on live, OTA data.\n- T. O'Shea, T. Roy, T. Charles, \"Over-the-Air Deep Learning Based Radio Signal Classification,\" IEEE Journal of Selected Topics in Signal Processing. Feb 2018. ([Link](https://ieeexplore.ieee.org/abstract/document/8267032), [Radioml Github](https://github.com/radioML))\n\t- **Summary**: Demonstrates residual neural network (RNN) which is capable of discerning different radio modulation schemes with better accuracy (?) than previously developed convolutional neural networks and other baseline methods. Applies RNN to OTA data and demonstrates feasibility of deep-learning based signal classification.\n\t- **Methods**: Deep Learning (residual neural networks, transfer learning). \n\t- **Upshot**: Transfer learning valuable but does not achieve equivalent accuracy/sensitivity compared to direct training when transfer learning data is small. Transfer learning can be made more valuable when simulation methods become more accurate, allowing for generation of synthetic data which accurately represents real-world data.\n- H. Mao et al, \"Resource Management with Deep Reinforcement Learning,\" HetNets, Nov 2016. ([Link](https://people.csail.mit.edu/alizadeh/papers/deeprm-hotnets16.pdf), [GitHub](https://github.com/hongzimao/deeprm))\n\t- **Summary**: Presents a deep reinforcement learning algorithm, \"DeepRM,\" which learns sensible online scheduling of multiple computational resources by minimizing average slowdown in each timestep. Demonstrates experimental performance gains over other scheduling algorithms.\n\t- **Methods**: Reinforcement learning (policy-gradient methods, REINFORCE). Deep Learning. \n\t- **Upshot**: Not strictly a wireless communications or deep learning application, but demonstrates discsussion of scheduling and online learning might prove useful in analogous wireless communications network application, such as cluster scheduleing/formation in 5G networks.\n- S. Jiang et al, \"VIA: Improving Internet Telephony Call Quality Using Predictive Relay Selection,\" SIGCOMM, Aug 2016. ([Link](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/08/via.pdf))\n\t- **Summary**: Uses machine learning to improve Quality of Experience (QoE) for VoIP by combining methods from overlay networks and reinforcement learning. Demonstrates theoretical and experimental reduction in metrics of Poor Network Rate (PNR), including round-trip time (RTT), packet loss, and jitter.\n\t- **Methods**: Reinforcement learning (multi-armed bandit, Upper-confidence bound, epsilon-greedy). Overlay networks.\n\t- **Upshot**: Not strictly a wireless communications or deep learning application, but demonstrates methods which might prove applicable.\n\n- Generally better at NP hard problems\n\t- 1:\n\t\t- \"Most fertile ground\" in resource allocation\n\t\t- Channel information provided to operator too low resolution temporally/spatially\n\t\t- What do we do in the case of missing/outdated data?\n\t\t\t- Objective function: maximize data rate for everyone\n\t\t- What is the state of the art for deep learning in resource allocation in the context of stale/limited data?\n\t- 2:\n\t\t- If I want better resource allocation, then how do I design the pilots to get the desired information from UEs?\n\t- Figure out if this is a fertile research direction for the next 2-3 years (minimum)\n\t- Look-up later: basic understanding of how channel state information is provided\n\t\t- Anticipate\n\t- For encoding/decoding: \n- Chatrooms talking about wireless comms research/machine learning?\n- Setup Slack\n- Trouble with machine learning: tends to be unstructured\n\t- Already have good classic approaches for feature extraction. Machine-learning \n\t- In order to make it effective, need to apply domain knowledge\n\t- AWGN is well-understood, so machine learning not well-suited. But what about colored noise? Impulses? (What )\n\t- Good thing about machine learning: only require one architecture which needs its weights updated\n\t\t- Less hardware-specific; different specifications can be implemented by software update instead of changing out processor"
      },
      "source": "https://raw.githubusercontent.com/mdelrosa/wireless-ml/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "requirements": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Dependencies",
        "parent_header": [
          "wireless-ml",
          "Code"
        ],
        "type": "Text_excerpt",
        "value": "For dataset generation, [radioML dataset repo](https://github.com/radioML/dataset), which requires [gnuradio](https://www.gnuradio.org/doc/sphinx/). [Installation of gnuradio](http://www.gcndevelopment.com/gnuradio/documentation.htm) on Windows is not straightforward, but using of Anaconda might simplify process.\n"
      },
      "source": "https://raw.githubusercontent.com/mdelrosa/wireless-ml/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "somef_missing_categories": [
    "installation",
    "citation",
    "acknowledgement",
    "run",
    "download",
    "contact",
    "contributors",
    "documentation",
    "license",
    "usage",
    "faq",
    "support",
    "identifier",
    "has_build_file"
  ],
  "somef_provenance": {
    "date": "2024-10-03 23:30:00",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 7
      },
      "technique": "GitHub_API"
    }
  ],
  "type": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "notebook-application"
      },
      "technique": "software_type_heuristics"
    }
  ]
}