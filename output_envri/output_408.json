{
  "application_domain": [
    {
      "confidence": 54.66,
      "result": {
        "type": "String",
        "value": "Computer Vision"
      },
      "technique": "supervised_classification"
    }
  ],
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/Cvrane/ChartReader"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2020-05-20T18:14:53Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2024-09-29T04:24:01Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "Fully automated end-to-end framework to extract data from bar plots and other figures in scientific research papers using modules such as OpenCV, AWS-Rekognition."
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 0.9922746136044666,
      "result": {
        "original_header": "ChartReader",
        "type": "Text_excerpt",
        "value": "Fully automated end-to-end framework to extract data from bar plots and other figures in scientific research papers using modules such as OpenCV, AWS-Rekognition for text detection in images.\n \n"
      },
      "source": "https://raw.githubusercontent.com/Cvrane/ChartReader/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8823133798494365,
      "result": {
        "original_header": "Training phase:",
        "type": "Text_excerpt",
        "value": "pretrained models VGG-19, ResNet152V2, InceptionV3, EfficientNetB3 are used to train the images, and is run on the test images to classify the images to 13 different types such as Bar chart, Line graph, Pie chart etc. \nThe accuracy is calculated using stratified five-fold cross validation. The accuracy of the models are given below in the table. We see that the accuracy is around 84% for all the models used to train the data. The following are the training accuracy and loss curves captured during the training phase for each fold of cross validation. \n"
      },
      "source": "https://raw.githubusercontent.com/Cvrane/ChartReader/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9657971609826494,
      "result": {
        "original_header": "Axes Detection (Accuracy: 80.22%) [1006/1254 correct]",
        "type": "Text_excerpt",
        "value": "1. Firstly, the image is converted into black and white image, then the max-continuous ones along each row and each column are obtained.\n2. Next, for all columns, the maximum value of the max-continuous 1s is picked.\n3. A certain threshold (=10) is assumed, and the first column where the max-continuous 1s falls in the region [max - threshold, max + threshold] is the y-axis.\n4. Similar approach is followed for the x-axis, but the last row is picked where the max-continuous 1s fall in the region [max - threshold, max + threshold] \n\nWe experimented with threshold values of 0, 5, 10, 12 and found that threshold value of 10 gives better results for axes detection. Table below shows the accuracy of axes detection with varying threshold values. \n"
      },
      "source": "https://raw.githubusercontent.com/Cvrane/ChartReader/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9815626469628143,
      "result": {
        "original_header": "Results",
        "type": "Text_excerpt",
        "value": "Both x and y axes are detected correctly for 1006 images out of 1254 images (test data set). Below are some of the failed cases in axes detection. \n"
      },
      "source": "https://raw.githubusercontent.com/Cvrane/ChartReader/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.981937605322259,
      "result": {
        "original_header": "Text detection",
        "type": "Text_excerpt",
        "value": "Amazon Rekognition is used to detect text in the image. [DetectText](https://docs.aws.amazon.com/rekognition/latest/dg/API_DetectText.html) API is used for detecting text. Only the text with confidence >= 80 are considered.\n \n"
      },
      "source": "https://raw.githubusercontent.com/Cvrane/ChartReader/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.975711970654028,
      "result": {
        "original_header": "Double-pass algorithm for text detection",
        "type": "Text_excerpt",
        "value": "To improve text detection, double-pass algorithm is employed.\n1. Text detection using detect_text AWS Rekognition API, and considered only the text boxes for which confidence >= 80\n2. Fill the polygons corresponding to these text with white color\n3. Run text detection (2nd pass) on the new image, and consider only the ones with confidence >= 80 \n"
      },
      "source": "https://raw.githubusercontent.com/Cvrane/ChartReader/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9505242970935379,
      "result": {
        "original_header": "Bounding Box calculation",
        "type": "Text_excerpt",
        "value": "There is an [issue](https://forums.aws.amazon.com/thread.jspa?threadID=325482&tstart=0) with bounding box for vertical text or text with an angle. Therefore, bounding box is calculated from the polygon coordinates (or vertices) from the AWS Rekognition output. \n \n"
      },
      "source": "https://raw.githubusercontent.com/Cvrane/ChartReader/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9397306597918339,
      "result": {
        "original_header": "X-labels:",
        "type": "Text_excerpt",
        "value": "1. Filter the text boxes which are below the x-axis(, and to the right of y-axis).\n2. Run a sweeping line from x-axis (detected by axes detection algorithm) to the bottom of the image, and check when the sweeping line intersects with the maximum number of text boxes.\n3. This maximum intersection gives the bounding boxes for all of the x-labels.\n    \n![](images/LabelDetectionExample.gif)\n \n"
      },
      "source": "https://raw.githubusercontent.com/Cvrane/ChartReader/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8361226127859679,
      "result": {
        "original_header": "X-text",
        "type": "Text_excerpt",
        "value": "1. Filter the text boxes which are below the x-labels\n2. Run a sweeping line from x-labels to the bottom of the image, and check when the sweeping line intersects with the maximum number of text boxes.\n3. This maximum intersection gives all the bounding boxes for all the x-text.\n \n"
      },
      "source": "https://raw.githubusercontent.com/Cvrane/ChartReader/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9261845040706915,
      "result": {
        "original_header": "Y-labels:",
        "type": "Text_excerpt",
        "value": "1. Filter the text boxes which are to the left of y-axis.\n2. Run a sweeping line from y-axis and start moving towards the left, and check when the sweeping line intersects with the maximum number of text boxes.\n3. Pick these text boxes where there was maximum intersection, and filter them further using python regex to detect only numeric values.\n \n"
      },
      "source": "https://raw.githubusercontent.com/Cvrane/ChartReader/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8065590274160307,
      "result": {
        "original_header": "Y-text:",
        "type": "Text_excerpt",
        "value": "1. Filter the text boxes which are to the left of y-axis.\n2. The remaining text boxes that are not classified as y-labels will be considered as y-text.\n \n"
      },
      "source": "https://raw.githubusercontent.com/Cvrane/ChartReader/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9206504571039135,
      "result": {
        "original_header": "Legend detection",
        "type": "Text_excerpt",
        "value": "1. Filter the text boxes that are above the x-axis, and to the right of y-axis.\n2. Clean the text to remove 'I'. These are obtained since error bars in the charts are detected as 'I' by AWS Rekognition OCR API(s).\n3. Use an appropriate regex to disregard the numerical values. These are mostly the ones which are there on top of the bars to denote the bar value.\n4. Now merge the remaining text boxes (with x-value threshold of 10) to make sure all the multi-word legends are part of a single bounding box.\n5. Group bounding-boxes in such a way that each member in the group is either horizontally or vertically aligned to atleast one other member in the group.\n6. The maximum length group from all the groups obtained in Step 5 gives the bounding boxes for all the legends.\n7. Legend text can be parsed and obtained from these bounding boxes.\n \n"
      },
      "source": "https://raw.githubusercontent.com/Cvrane/ChartReader/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8514704352092777,
      "result": {
        "original_header": "Value-tick ratio calculation:",
        "type": "Text_excerpt",
        "value": "This ratio is used to calculate the y-values from each bar-plot using the pixel projection method. Y-axis ticks are detected by left-bounding boxes to the y-axis. \nSince the text detection (numeric values) isn't perfect, once the pixel values for the ticks and actual y-label texts are obtained, the outliers are removed by assuming a normal distribution and whether the values deviate very much. Then, the mean distance between the ticks is calculated. Further, the mean value of the actual y-label ticks is calculated. Finally, the value-tick ratio is calculated by: \n"
      },
      "source": "https://raw.githubusercontent.com/Cvrane/ChartReader/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.935468163041604,
      "result": {
        "original_header": "Pattern (or color) estimation",
        "type": "Text_excerpt",
        "value": "1. As an initial step, all the bounding boxes for the text in the image are whitened.\n2. Convert the resulting image into a binary image.\n3. Find contours (and bounding rectangles) in the resulting image.\n4. For each legend, find the nearest bounding box to the left and on the same height as the legend.\n5. Now in the original image, find the major color (or pattern) from the nearest bounding box obtained for each legend in Step 4.\n \n"
      },
      "source": "https://raw.githubusercontent.com/Cvrane/ChartReader/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8585994468314747,
      "result": {
        "original_header": "Reporting results",
        "type": "Text_excerpt",
        "value": "<table>\n  <tr>\n    <td>Parameter</td>\n    <td>Accuracy</td>\n    <td>True Positive Rate</td>\n  </tr>\n  <tr>\n    <td>Legends</td>\n    <td>0.8054</td>\n    <td>0.8054</td>\n  </tr>\n  <tr>\n    <td>X-axis ticks</td>\n    <td>0.9755</td>\n    <td>0.9755</td>\n  </tr>\n  <tr>\n    <td>Y-axis ticks</td>\n    <td>0.6815</td>\n    <td>0.6815</td>\n  </tr>\n  <tr>\n    <td>height/value ratio</td>\n    <td>0.8919</td>\n    <td>0.8919</td>\n  </tr>\n  <tr>\n    <td>Y-axis label</td>\n    <td>0.7758</td>\n    <td>0.7758</td>\n  </tr>\n  <tr>\n    <td>X-axis label</td>\n    <td>0.7129</td>\n    <td>0.7129</td>\n  </tr>\n  <tr>\n    <td>Data correlation</td>\n    <td>0.6470</td>\n    <td>0.7504</td>\n  </tr>\n  <tr>\n    <td>Data values</td>\n    <td>0.2158</td>\n    <td>0.4095</td>\n  </tr>\n</table>\n \n"
      },
      "source": "https://raw.githubusercontent.com/Cvrane/ChartReader/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/Cvrane/ChartReader/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "executable_example": [
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Cvrane/ChartReader/master/code/DataExtraction.ipynb"
      },
      "source": "https://raw.githubusercontent.com/Cvrane/ChartReader/master/code/DataExtraction.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Cvrane/ChartReader/master/code/AWS-Text-Rekognition.ipynb"
      },
      "source": "https://raw.githubusercontent.com/Cvrane/ChartReader/master/code/AWS-Text-Rekognition.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Cvrane/ChartReader/master/code/AxesDetection.ipynb"
      },
      "source": "https://raw.githubusercontent.com/Cvrane/ChartReader/master/code/AxesDetection.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Cvrane/ChartReader/master/code/JsonDataExtraction.ipynb"
      },
      "source": "https://raw.githubusercontent.com/Cvrane/ChartReader/master/code/JsonDataExtraction.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Cvrane/ChartReader/master/code/ChartClassification.ipynb"
      },
      "source": "https://raw.githubusercontent.com/Cvrane/ChartReader/master/code/ChartClassification.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Cvrane/ChartReader/master/code/ExtractPDFInfo.ipynb"
      },
      "source": "https://raw.githubusercontent.com/Cvrane/ChartReader/master/code/ExtractPDFInfo.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Cvrane/ChartReader/master/code/LabelDetection.ipynb"
      },
      "source": "https://raw.githubusercontent.com/Cvrane/ChartReader/master/code/LabelDetection.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Cvrane/ChartReader/master/code/ImageClassification.ipynb"
      },
      "source": "https://raw.githubusercontent.com/Cvrane/ChartReader/master/code/ImageClassification.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Cvrane/ChartReader/master/code/ChartClassification-Test.ipynb"
      },
      "source": "https://raw.githubusercontent.com/Cvrane/ChartReader/master/code/ChartClassification-Test.ipynb",
      "technique": "file_exploration"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 21
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/Cvrane/ChartReader/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "Cvrane/ChartReader"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "ChartReader"
      },
      "source": "https://raw.githubusercontent.com/Cvrane/ChartReader/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "images": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Cvrane/ChartReader/master/images/accuracy-curve1.png"
      },
      "source": "https://raw.githubusercontent.com/Cvrane/ChartReader/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Cvrane/ChartReader/master/images/accuracy-curve2.png"
      },
      "source": "https://raw.githubusercontent.com/Cvrane/ChartReader/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Cvrane/ChartReader/master/images/accuracy-curve3.png"
      },
      "source": "https://raw.githubusercontent.com/Cvrane/ChartReader/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Cvrane/ChartReader/master/images/accuracy-curve4.png"
      },
      "source": "https://raw.githubusercontent.com/Cvrane/ChartReader/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Cvrane/ChartReader/master/images/accuracy-curve5.png"
      },
      "source": "https://raw.githubusercontent.com/Cvrane/ChartReader/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Cvrane/ChartReader/master/images/BarplotPrediction.png"
      },
      "source": "https://raw.githubusercontent.com/Cvrane/ChartReader/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Cvrane/ChartReader/master/images/AxesDetectionExample1.png"
      },
      "source": "https://raw.githubusercontent.com/Cvrane/ChartReader/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Cvrane/ChartReader/master/images/AxesDetectionExample2.png"
      },
      "source": "https://raw.githubusercontent.com/Cvrane/ChartReader/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Cvrane/ChartReader/master/images/AxesDetectionResult.png"
      },
      "source": "https://raw.githubusercontent.com/Cvrane/ChartReader/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Cvrane/ChartReader/master/images/DoublePassAlgorithm.png"
      },
      "source": "https://raw.githubusercontent.com/Cvrane/ChartReader/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Cvrane/ChartReader/master/images/LabelDetectionExample.gif"
      },
      "source": "https://raw.githubusercontent.com/Cvrane/ChartReader/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Cvrane/ChartReader/master/images/equation2.gif"
      },
      "source": "https://raw.githubusercontent.com/Cvrane/ChartReader/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Cvrane/ChartReader/master/images/equation1.gif"
      },
      "source": "https://raw.githubusercontent.com/Cvrane/ChartReader/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Cvrane/ChartReader/master/images/DataExtractionExample.png"
      },
      "source": "https://raw.githubusercontent.com/Cvrane/ChartReader/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "installation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Image set",
        "parent_header": [
          "ChartReader"
        ],
        "type": "Text_excerpt",
        "value": "Bar plots used are here: https://drive.google.com/drive/u/1/folders/154sgx3M49NoKOoOjoppsSuvqd2WzqZqX\n"
      },
      "source": "https://raw.githubusercontent.com/Cvrane/ChartReader/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Data preparation",
        "parent_header": [
          "ChartReader",
          "Chart classification (Accuracy: 84.08%)"
        ],
        "type": "Text_excerpt",
        "value": "<b> Step 1: </b> ``google_images_download`` python module is used to download google images for each type of chart: Area chart, Line chart, bar plot, pie chart, venn diagram etc. based on their corresponding keywords.\n\n```\n$ git clone https://github.com/Joeclinton1/google-images-download.git\n$ cd google-images-download && python setup.py install\n```\n\n<b> Step 2: </b> The downloaded images are carefully reviewed and the incorrect images are removed.\n\nThe following are the training data used, and model files.\n<br>training corpus: https://drive.google.com/drive/u/1/folders/1M8kwdQE7bpjpdT08ldBURFdzLaQR9n5h\n<br>model: https://drive.google.com/drive/u/1/folders/1GVW_MtFFYT-Tj44p0_QLKM7hVnn_AcKI\n\nBelow is the count of images for each type:\n<table>\n<tr>\n<td>\n\n| Plot type     | Count         |\n| ------------- |:-------------:|\n| BarGraph      |   528         |\n| VennDiagram   |   364         |\n| PieChart      |   355         |\n| ScatterGraph  |   335         |\n\n</td>\n<td>\n\n| Plot type     | Count         |\n| ------------- |:-------------:|\n| TreeDiagram   |   297         |\n| FlowChart     |   293         |\n| Map           |   276         |\n| ParetoChart   |   329         |\n\n</td>\n<td>\n\n| Plot type     | Count         |\n| ------------- |:-------------:|\n| BubbleChart   |   311         |\n| LineGraph     |   300         |\n| AreaGraph     |   299         |\n| NetworkDiagram|   321         |\n| BoxPlot       |   312         |\n\n</td>\n</tr>\n</table>\n"
      },
      "source": "https://raw.githubusercontent.com/Cvrane/ChartReader/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "invocation": [
    {
      "confidence": 0.8358625235441725,
      "result": {
        "original_header": "Results (predictions on test data)",
        "type": "Text_excerpt",
        "value": "<h3 align=\"center\">\n  <img src=\"images/BarplotPrediction.png\" width=\"1000\">\n</h3>\n \n"
      },
      "source": "https://raw.githubusercontent.com/Cvrane/ChartReader/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8358625235441725,
      "result": {
        "original_header": "Axes Detection (Accuracy: 80.22%) [1006/1254 correct]",
        "type": "Text_excerpt",
        "value": "<h3 align=\"center\">\n  <img src=\"images/AxesDetectionExample1.png\" width=\"800\">\n</h3>\n<h3 align=\"center\">\n  <img src=\"images/AxesDetectionExample2.png\" width=\"800\">\n</h3>\n \n"
      },
      "source": "https://raw.githubusercontent.com/Cvrane/ChartReader/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8358625235441725,
      "result": {
        "original_header": "Results",
        "type": "Text_excerpt",
        "value": "<h3 align=\"center\">\n  <img src=\"images/AxesDetectionResult.png\" width=\"800\">\n</h3>\n \n"
      },
      "source": "https://raw.githubusercontent.com/Cvrane/ChartReader/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8358625235441725,
      "result": {
        "original_header": "Double-pass algorithm for text detection",
        "type": "Text_excerpt",
        "value": "<h3 align=\"center\">\n  <img src=\"images/DoublePassAlgorithm.png\" width=\"800\">\n</h3>\n \n"
      },
      "source": "https://raw.githubusercontent.com/Cvrane/ChartReader/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/Cvrane/ChartReader/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "aws-rekognition, axes-detection, deep-learning, figure-detection, opencv-python, tesseract-ocr, vgg-19"
      },
      "technique": "GitHub_API"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "ChartReader"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "User",
        "value": "Cvrane"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Jupyter Notebook",
        "size": 34343567,
        "type": "Programming_language",
        "value": "Jupyter Notebook"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 973,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Cvrane/ChartReader/master/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "somef_missing_categories": [
    "citation",
    "acknowledgement",
    "run",
    "download",
    "requirements",
    "contact",
    "contributors",
    "documentation",
    "license",
    "faq",
    "support",
    "identifier",
    "has_build_file"
  ],
  "somef_provenance": {
    "date": "2024-10-04 00:41:29",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 97
      },
      "technique": "GitHub_API"
    }
  ],
  "usage": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Getting bar plot for each legend",
        "parent_header": [
          "ChartReader",
          "Data extraction"
        ],
        "type": "Text_excerpt",
        "value": "1. All the pixel values of the image are divided into clusters. Prior to clustering, all the white pixels are removed, and the bounding boxes found by above procedure for each legend are whitened. \n2. The number of clusters are determined by the number of legends detected. The colors finalized in the above procedure form the initial clusters.\n3. We then simplify the given plot into multiple plots (one per each cluster). These plots would be a simple bar plot. i.e.., by clustering we convert a stacked bar chart into multiple simpler bar plots.\n4. We then get the contours for the plot, and subsequently bounding rectangles for the contours determined.\n5. For each label, the closest bounding rectangle is picked.\n6. The height of each bounding box is recorded by the help of the merging rectangles obtained by the above procedure. This ratio is used to further calculate the y-values :\n\n<h3 align=\"center\">\n  <img src=\"images/equation1.gif\">\n</h3>\n\nBelow shows data extraction results on an image.\n\n<h3 align=\"center\">\n  <img src=\"images/DataExtractionExample.png\">\n</h3>\n"
      },
      "source": "https://raw.githubusercontent.com/Cvrane/ChartReader/master/README.md",
      "technique": "header_analysis"
    }
  ]
}