{
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/brazil-data-cube/wlts-paper"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2021-09-30T14:40:09Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2024-03-04T22:13:32Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "Research compendium of the article: A plataform for land use and land cover data integration and trajectory analysis"
      },
      "technique": "GitHub_API"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/brazil-data-cube/wlts-paper/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "executable_example": [
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/analysis/scripts/wlts-operations/wlts-operations-python.ipynb"
      },
      "source": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/analysis/scripts/wlts-operations/wlts-operations-python.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/analysis/scripts/wlts-operations/wlts-operations-r.ipynb"
      },
      "source": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/analysis/scripts/wlts-operations/wlts-operations-r.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/analysis/scripts/alluvial-plot/1_wlts_alluvial-plot_data-extraction.ipynb"
      },
      "source": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/analysis/scripts/alluvial-plot/1_wlts_alluvial-plot_data-extraction.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/analysis/scripts/alluvial-plot/2_wlts-alluvial-plot_data-visualization.ipynb"
      },
      "source": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/analysis/scripts/alluvial-plot/2_wlts-alluvial-plot_data-visualization.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/analysis/scripts/lulc-trajectory-comparison/1_wlts-wlccs_lulc-trajectories-comparison_data-extraction.ipynb"
      },
      "source": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/analysis/scripts/lulc-trajectory-comparison/1_wlts-wlccs_lulc-trajectories-comparison_data-extraction.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/analysis/scripts/lulc-trajectory-comparison/2_wlts-wlccs_lulc-trajectories-comparison_analysis.ipynb"
      },
      "source": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/analysis/scripts/lulc-trajectory-comparison/2_wlts-wlccs_lulc-trajectories-comparison_analysis.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://mybinder.org/v2/gh/brazil-data-cube/wlts-paper/HEAD"
      },
      "source": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/README.Rmd",
      "technique": "regular_expression"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 0
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/brazil-data-cube/wlts-paper/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "brazil-data-cube/wlts-paper"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "A plataform for land use and land cover data integration and trajectory analysis"
      },
      "source": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/README.Rmd",
      "technique": "regular_expression"
    }
  ],
  "has_build_file": [
    {
      "confidence": 1,
      "result": {
        "format": "dockerfile",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/Dockerfile"
      },
      "source": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/Dockerfile",
      "technique": "file_exploration"
    }
  ],
  "images": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/./figures/running/environment/overview/png/environment-flow-overview.png"
      },
      "source": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/README.Rmd",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/./figures/running/environment/overview/png/environment-directories.png"
      },
      "source": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/README.Rmd",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/./figures/running/environment/binder/png/binder-home.png"
      },
      "source": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/README.Rmd",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/./figures/running/environment/binder/png/step1.png"
      },
      "source": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/README.Rmd",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/./figures/running/environment/binder/png/step2.png"
      },
      "source": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/README.Rmd",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/./figures/running/environment/binder/png/step3.png"
      },
      "source": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/README.Rmd",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/./figures/running/environment/binder/png/step4.png"
      },
      "source": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/README.Rmd",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/./figures/workflow/png/workflow-overview.png"
      },
      "source": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/README.Rmd",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/./figures/makegraph.png"
      },
      "source": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/README.Rmd",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/./figures/running/make/png/configure-token-1.png"
      },
      "source": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/README.Rmd",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/./figures/running/make/png/configure-token-2.png"
      },
      "source": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/README.Rmd",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/./figures/running/make/png/configure-token-3.png"
      },
      "source": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/README.Rmd",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/./figures/running/make/png/configure-token-4.png"
      },
      "source": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/README.Rmd",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/./figures/running/make/png/configure-token-5.png"
      },
      "source": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/README.Rmd",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/./figures/running/make/png/configure-token-6.png"
      },
      "source": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/README.Rmd",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/./figures/workflow/png/workflow_base-operations.png"
      },
      "source": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/README.Rmd",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/./figures/running/make/png/wlts-operations-1.png"
      },
      "source": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/README.Rmd",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/./figures/running/make/png/wlts-operations-2.png"
      },
      "source": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/README.Rmd",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/./figures/running/make/png/wlts-operations-3.png"
      },
      "source": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/README.Rmd",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/./figures/workflow/png/workflow_alluvial-plot.png"
      },
      "source": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/README.Rmd",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/./figures/running/make/png/alluvial-plot-1.png"
      },
      "source": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/README.Rmd",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/./figures/running/make/png/alluvial-plot-2.png"
      },
      "source": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/README.Rmd",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/./figures/running/make/png/alluvial-plot-3.png"
      },
      "source": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/README.Rmd",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/./figures/workflow/png/workflow_lulc-comparison.png"
      },
      "source": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/README.Rmd",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/./figures/running/make/png/lulc-trajectory-comparison-1.png"
      },
      "source": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/README.Rmd",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/./figures/running/make/png/lulc-trajectory-comparison-2.png"
      },
      "source": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/README.Rmd",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/./figures/running/make/png/lulc-trajectory-comparison-3.png"
      },
      "source": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/README.Rmd",
      "technique": "regular_expression"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/brazil-data-cube/wlts-paper/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "earth-observation, land-use-land-cover, reproducibility, research-compendium, web-service"
      },
      "technique": "GitHub_API"
    }
  ],
  "license": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Licenses",
        "parent_header": [
          "A plataform for land use and land cover data integration and trajectory analysis",
          "Running"
        ],
        "type": "Text_excerpt",
        "value": "**Code :** [MIT](LICENSE);\n\n**Data :** [CC-0](http://creativecommons.org/publicdomain/zero/1.0/);\n\n**Text and figures:**\n[CC-BY-4.0](http://creativecommons.org/licenses/by/4.0/);\n\n\n"
      },
      "source": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/README.Rmd",
      "technique": "header_analysis"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "wlts-paper"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "Organization",
        "value": "brazil-data-cube"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Jupyter Notebook",
        "size": 2201759,
        "type": "Programming_language",
        "value": "Jupyter Notebook"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Makefile",
        "size": 3821,
        "type": "Programming_language",
        "value": "Makefile"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Dockerfile",
        "size": 735,
        "type": "Programming_language",
        "value": "Dockerfile"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/README.Rmd"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "related_documentation": [
    {
      "confidence": 1,
      "result": {
        "format": "readthedocs",
        "type": "Url",
        "value": "https://jupyterlab.readthedocs.io/"
      },
      "source": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/README.Rmd",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "format": "readthedocs",
        "type": "Url",
        "value": "https://papermill.readthedocs.io/"
      },
      "source": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/README.Rmd",
      "technique": "regular_expression"
    }
  ],
  "run": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Running",
        "parent_header": [
          "A plataform for land use and land cover data integration and trajectory analysis"
        ],
        "type": "Text_excerpt",
        "value": "This section will present the steps required to use the code and data\nmaterials provided in this RC. First, the configuration of the\nenvironment needed to run the codes will be done. Next, we will present\nthe available ways to run the codes. The details of each of these steps\nare described in the sections below.\n"
      },
      "source": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/README.Rmd",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Environment",
        "parent_header": [
          "A plataform for land use and land cover data integration and trajectory analysis",
          "Running"
        ],
        "type": "Text_excerpt",
        "value": "During the production of this RC, the code execution to obtain the\nresults was done based on an environment with several software libraries\ninstalled. To make the codes execution and the results generated\nreproducible, we prepared a description of the environment used,\ndeclaring the software libraries used and their versions. With this\ndescription, others can run the codes in this RC from the same software\nlibraries, avoiding possible incompatibility.\n\nTo produce the environment description, we first organized and specified\nall the software and versions used to make the paper\u2019s results. We do\nthis with the [Conda](https://docs.conda.io/en/latest/) package manager\nbecause it allows the management of packages of both languages used in\nthe paper (R and Python). The result is the file\n[environment.yml](environment.yml), which describes all the versions and\npackages used. Next, we used this environment description to produce a\nDocker Image, in which all the packages described in the file\n[environment.yml](environment.yml) were installed. To enable the\ninteractive use of the generated environment, the Docker Image created\nwas based on the Docker Image\n[jupyter/base-notebook:lab-3.1.13](https://hub.docker.com/layers/jupyter/base-notebook/lab-3.1.13/images/sha256-9a388da87e9d2b8019df20439977953d0576f6168348f621498ac62b45e2f88f?context=explore),\nin which the installation of\n[JupyterLab](https://jupyterlab.readthedocs.io/en/stable/) was\navailable. With JupyterLab, users can interact with the environment\nthrough an interactive, high-level interface with features that\nfacilitate code and data analysis. The connection of each of these\nelements in the produced environment is depicted in Figure 1.\n\n<div align=\"center\">\n\n<img src=\"./figures/running/environment/overview/png/environment-flow-overview.png\" width=\"35%\" style=\"display: block; margin: auto;\" />\n\n<b>Figure 1.</b> Environment building flow.\n\n</div>\n\nAt the moment the Docker Image is being generated, all the RC components\nare copied into it. This way, when accessing the JupyterLab interface to\nuse the environment, the user already has available, in a directory\nnamed `wlts-paper`, the whole RC. Figure 2 shows the JupyterLab\ninterface, which is made available to the user, along with the RC\ncontents listed from the `wlts-paper` directory.\n\n<div align=\"center\">\n\n<img src=\"./figures/running/environment/overview/png/environment-directories.png\" width=\"80%\" style=\"display: block; margin: auto;\" />\n\n<b>Figure 2.</b> Environment `wlts-paper` directory.\n\n</div>\n\nThis way of specifying and making the environment available, based on\nDocker, allows the material in this RC, especially the codes, to be used\nin the same way as the authors did during the production of the results.\nThe configuration and use of this environment can be done in several\nways. In the topics below, we will present some of the ways to configure\nand use this environment.\n\n> The different approaches presented below, used for configuring and\n> running the environment, do not change its content. Thus, all the\n> properties defined above are valid for any of the ways of configuring\n> the environment.\n"
      },
      "source": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/README.Rmd",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Binder",
        "parent_header": [
          "A plataform for land use and land cover data integration and trajectory analysis",
          "Running",
          "Environment"
        ],
        "type": "Text_excerpt",
        "value": "The first available option for using the computational environment is\nwith [Binder](https://jupyter.org/binder), a tool that allows the\ncreation and sharing of executable environments from code repositories.\nWith Binder, all you need to do to access the executable environment of\nthis RC is click on the icon below:\n\n<div align=\"center\">\n\n[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/brazil-data-cube/wlts-paper/HEAD)\n\n</div>\n\nWhen you access the link, the Binder will create the executable\nenvironment with the same libraries and versions specified in the\n[environment.yml](environment.yml) file. When the environment is ready\nfor use, you will have to access it via a\n[JupyterLab](https://jupyterlab.readthedocs.io/en/stable/) interface.\nThe JupyterLab page that you will have access to is shown in Figure 3.\n\n<div align=\"center\">\n\n<img src=\"./figures/running/environment/binder/png/binder-home.png\" width=\"80%\" style=\"display: block; margin: auto;\" />\n\n<b>Figure 3.</b> JupyterLab on Binder.\n\n</div>\n\nAfter accessing the environment, you are ready to run these\nenvironments. To understand how the code is organized and how it can be\nexecuted, please go to Section [Workflow\nexecution](#workflow-execution).\n\n**Extra**: Using the link mentioned above summarizes the operations and\nmakes access to the environment direct. If the reader is interested, the\nstep-by-step instructions for using Binder are available below. We\nrecommend using this material as a reference to the behavior that Binder\nshould exhibit throughout the environment configuration steps.\n\n<details>\n<summary>\nStep-by-step environment setup in Binder\n</summary>\n\n<br/>\n\n> This step-by-step is an extended version of the tutorial presented\n> earlier on using the computing environment with Binder. If your\n> environment is already working, we recommend that you skip these steps\n\nTo get started, go to <https://mybinder.org/>:\n\n<div align=\"center\">\n\n<img src=\"./figures/running/environment/binder/png/step1.png\" width=\"75%\" style=\"display: block; margin: auto;\" />\n\n<b>Figure 4.</b> mybinder.org.\n\n</div>\n\n<br>\n\nOn the <https://mybinder.org/> page, enter in the *GitHub repository\nname or URL* field the repository address of this RC:\n\n    https://github.com/brazil-data-cube/wlts-paper\n\nNow, click on the **launch** button.\n\n<div align=\"center\">\n\n<img src=\"./figures/running/environment/binder/png/step2.png\" width=\"75%\" style=\"display: block; margin: auto;\" />\n\n<b>Figure 5.</b> RC repository configuration.\n\n</div>\n\n<br>\n\nWhen you click **launch**, Binder will start loading the repository and\nbuilding the environment you will work. The process may take a few\nminutes. At the end of the operation, the loading bar will reach the\nend, where the option (in green) **Launching** will be presented:\n\n<div align=\"center\">\n\n<img src=\"./figures/running/environment/binder/png/step3.png\" width=\"75%\" style=\"display: block; margin: auto;\" />\n\n<b>Figure 6.</b> RC repository launching.\n\n</div>\n\nAfter the building process, the environment is loaded, and you are\nredirected to the JupyterLab page:\n\n<div align=\"center\">\n\n<img src=\"./figures/running/environment/binder/png/step4.png\" width=\"75%\" style=\"display: block; margin: auto;\" />\n\n<b>Figure 7.</b> JupyterLab frontpage on Binder.\n\n</div>\n\n</details>\n\n<br>\n"
      },
      "source": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/README.Rmd",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Local machine (with DockerHub Image)",
        "parent_header": [
          "A plataform for land use and land cover data integration and trajectory analysis",
          "Running",
          "Environment"
        ],
        "type": "Text_excerpt",
        "value": "> During the production of this RC, all testing was performed using the\n> Linux environment. Therefore, the commands below may change slightly\n> on other operating systems.\n\nThe second option available is to use the RC environment directly on the\nuser\u2019s machine via\n[Docker](https://docs.docker.com/get-started/overview/). In this option,\nthe user runs the [Docker\nImage](https://docs.docker.com/get-started/overview/#docker-objects) of\nthis RC made available on DockerHub, which is ready to use, requiring no\nbuild steps. Below are the steps required to use this approach.\n\n> The steps presented below assume that the user has installed the\n> [Docker](https://www.docker.com/) and [Docker\n> Compose](https://docs.docker.com/compose/) tools. If you have not\n> installed them, please refer to the official documentation for each of\n> these tools:\n\n> 1.  [Install Docker Engine](https://docs.docker.com/engine/install/);\n> 2.  [Install Docker\n>     Compose](https://docs.docker.com/compose/install/).\n\n> Additionally, the user is expected to have [git](https://git-scm.com/)\n> installed on the machine. If you do not, please refer to the git\n> [official documentation](https://git-scm.com/download/linux) to do the\n> installation.\n\n> The versions of each of these tools used in the production of this\n> material are available below.\n\n<details>\n<summary>\nDocker, Docker Compose, and Git versions used for the production of this\nRC.\n</summary>\n\n**git**\n\n``` sh\ngit --version\n\n#> git version 2.27.0\n```\n\n**Docker**\n\n``` sh\ndocker version\n\n#> Client: Docker Engine - Community\n#>  Version:           20.10.8\n#>  API version:       1.41\n#>  Go version:        go1.16.6\n#>  Git commit:        3967b7d\n#>  Built:             Fri Jul 30 19:54:09 2021\n#>  OS/Arch:           linux/amd64\n#>  Context:           default\n#>  Experimental:      true\n\n#> Server: Docker Engine - Community\n#>  Engine:\n#>   Version:          20.10.8\n#>   API version:      1.41 (minimum version 1.12)\n#>   Go version:       go1.16.6\n#>   Git commit:       75249d8\n#>   Built:            Fri Jul 30 19:52:16 2021\n#>   OS/Arch:          linux/amd64\n#>   Experimental:     false\n#>  containerd:\n#>   Version:          1.4.9\n#>   GitCommit:        e25210fe30a0a703442421b0f60afac609f950a3\n#>  runc:\n#>   Version:          1.0.1\n#>   GitCommit:        v1.0.1-0-g4144b63\n#>  docker-init:\n#>   Version:          0.19.0\n#>   GitCommit:        de40ad0\n```\n\n**Docker Compose**\n\n``` sh\ndocker-compose --version\n\n#> docker-compose version 1.28.2, build 67630359\n```\n\n</details>\n\n<br/>\n\nTo use this local approach, the first step is to download the repository\nfor this RC. To do this, in a terminal on your machine, use `git` and\nclone the repository:\n\n``` sh\ngit clone https://github.com/brazil-data-cube/wlts-paper\n\n#> Cloning into 'wlts-paper'...\n#> remote: Enumerating objects: 263, done.\n#> remote: Counting objects: 100% (263/263), done.\n#> remote: Compressing objects: 100% (186/186), done.\n#> remote: Total 263 (delta 94), reused 235 (delta 68), pack-reused 0\n#> Receiving objects: 100% (263/263), 14.32 MiB | 14.56 MiB/s, done.\n#> Resolving deltas: 100% (94/94), done.\n```\n\nAfter the clone, in the directory you are in, there should be a\ndirectory named `wlts-paper`:\n\n``` sh\nls -l\n\n#> drwxrwxr-x 5 felipe felipe 4096 out  6 16:15 wlts-paper\n```\n\nAccess this directory and view its contents:\n\n``` sh\ncd wlts-paper\n\nls -l\n#> drwxrwxr-x 4 felipe felipe  4096 out  6 16:15 analysis\n#> -rw-rw-r-- 1 felipe felipe   261 out  6 16:15 docker-compose.dockerhub.yml\n#> -rw-rw-r-- 1 felipe felipe   324 out  6 16:15 docker-compose.local.yml\n#> -rw-rw-r-- 1 felipe felipe   735 out  6 16:15 Dockerfile\n#> -rw-rw-r-- 1 felipe felipe 10895 out  6 16:15 environment.yml\n#> drwxrwxr-x 4 felipe felipe  4096 out  6 16:15 figures\n#> -rw-rw-r-- 1 felipe felipe  3821 out  6 16:15 Makefile\n#> -rw-rw-r-- 1 felipe felipe 46436 out  6 16:15 README.md\n#> -rw-rw-r-- 1 felipe felipe 47304 out  6 16:15 README.Rmd\n#> -rw-rw-r-- 1 felipe felipe   226 out  6 16:15 wlts-paper.Rproj\n```\n\nIn the `wlts-paper` directory, notice the `docker-compose.dockerhub.yml`\nfile; this contains the instructions for running a [Docker\nContainer](https://docs.docker.com/get-started/overview/#docker-objects)\nfrom the image of this RC that is available on DockerHub. So, use this\nfile to run this RC environment:\n\n``` sh\ndocker-compose -f docker-compose.dockerhub.yml up\n```\n\nIf everything is correct so far, running the above command should\nproduce the output shown below:\n\n    (Omitted)\n\n    wlts-paper-environment-container |     \n    wlts-paper-environment-container |     To access the server, open this file in a browser:\n    wlts-paper-environment-container |         file:///home/jovyan/.local/share/jupyter/runtime/jpserver-8-open.html\n    wlts-paper-environment-container |     Or copy and paste one of these URLs:\n    wlts-paper-environment-container |         http://6fec052c07e8:8888/lab?token=b49897a7c22065285d3b9d942ffd86921eef44dbb64eeabc\n    wlts-paper-environment-container |      or http://127.0.0.1:8888/lab?token=b49897a7c22065285d3b9d942ffd86921eef44dbb64eeabc\n\nThis information allows access to the JupyterLab page. So, to access\nthis environment, copy the URL displayed in your terminal output that\nincludes the Jupyter access token. The copied address should look like\nthe one shown below:\n\n> Remember that this address and token vary with each run, so copy it\n> from your terminal. If you try to log in with the token shown below,\n> you will have problems using Jupyter.\n\n``` sh\nhttp://127.0.0.1:8888/lab?token=b49897a7c22065285d3b9d942ffd86921eef44dbb64eeabc\n```\n\nAfter copying the URL, access it using any browser of your choice. As an\nexample, to access this URL with firefox, you can use the command in the\nterminal:\n\n``` sh\nfirefox http://127.0.0.1:8888/lab?token=b49897a7c22065285d3b9d942ffd86921eef44dbb64eeabc\n```\n\nWhen you go there, you should see the JupyterLab page (Figure 3). Once\nyou have done this, you are ready to start executing the code in this\nRC. Go to the Section [Workflow execution](#workflow-execution).\n"
      },
      "source": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/README.Rmd",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Local machine (with Docker build)",
        "parent_header": [
          "A plataform for land use and land cover data integration and trajectory analysis",
          "Running",
          "Environment"
        ],
        "type": "Text_excerpt",
        "value": "> During the production of this RC, all testing was performed using the\n> Linux environment. Therefore, the commands below may change slightly\n> on other operating systems.\n\nAs an alternative version of the option presented in subsection [Local\nmachine (with DockerHub Image)](local-machine-with-dockerhub-image),\nthis third option is also available. In this option, analogous to the\nprevious subsection, the user downloads the RC content to his machine\nand runs it from a Docker Container with all the environment configured\nand ready to use. The difference in this third alternative is that the\n[Docker\nImage](https://docs.docker.com/get-started/overview/#docker-objects)\nversion is created on the user\u2019s machine, and no ready-to-use image is\nused.\n\nThe steps for using this approach are presented below.\n\n> This approach is recommended for users who already know Docker and\n> want to rebuild the environment from scratch.\n\nTo use this local approach with Docker Image build, the first step is to\ndownload the repository for this RC. To do this, in a terminal on your\nmachine, use `git` and clone the repository:\n\n``` sh\ngit clone https://github.com/brazil-data-cube/wlts-paper\n\n#> Cloning into 'wlts-paper'...\n#> remote: Enumerating objects: 263, done.\n#> remote: Counting objects: 100% (263/263), done.\n#> remote: Compressing objects: 100% (186/186), done.\n#> remote: Total 263 (delta 94), reused 235 (delta 68), pack-reused 0\n#> Receiving objects: 100% (263/263), 14.32 MiB | 14.56 MiB/s, done.\n#> Resolving deltas: 100% (94/94), done.\n```\n\nAfter the clone, in the directory you are in, there should be a\ndirectory named `wlts-paper`:\n\n``` sh\nls -l\n\n#> drwxrwxr-x 5 felipe felipe 4096 out  6 16:15 wlts-paper\n```\n\nAccess this directory and view its contents:\n\n``` sh\ncd wlts-paper\n\nls -l\n#> drwxrwxr-x 4 felipe felipe  4096 out  6 16:15 analysis\n#> -rw-rw-r-- 1 felipe felipe   261 out  6 16:15 docker-compose.dockerhub.yml\n#> -rw-rw-r-- 1 felipe felipe   324 out  6 16:15 docker-compose.local.yml\n#> -rw-rw-r-- 1 felipe felipe   735 out  6 16:15 Dockerfile\n#> -rw-rw-r-- 1 felipe felipe 10895 out  6 16:15 environment.yml\n#> drwxrwxr-x 4 felipe felipe  4096 out  6 16:15 figures\n#> -rw-rw-r-- 1 felipe felipe  3821 out  6 16:15 Makefile\n#> -rw-rw-r-- 1 felipe felipe 46436 out  6 16:15 README.md\n#> -rw-rw-r-- 1 felipe felipe 47304 out  6 16:15 README.Rmd\n#> -rw-rw-r-- 1 felipe felipe   226 out  6 16:15 wlts-paper.Rproj\n```\n\nIn the `wlts-paper` directory, notice the `docker-compose.local.yml`\nfile. This file contains the instructions for building and running this\nRC environment. So, with `Docker Compose`, use this file to build the\nDocker Image environment:\n\n``` sh\ndocker-compose -f docker-compose.local.yml build --no-cache\n```\n\nAfter the build, the Docker Image\n`brazildatacube/wlts-paper-environment:0.1-local` should be available in\nyour environment. So when you list the Docker Images on your machine,\nthis image should appear, as shown below:\n\n``` sh\ndocker image ls\n\n#> REPOSITORY                                TAG          IMAGE ID           CREATED         SIZE\n#> brazildatacube/wlts-paper-environment  0.1-local     ca5b517e098a   About a minute ago   5.09GB\n```\n\nYou can then start [Docker\nContainer](https://docs.docker.com/get-started/overview/#docker-objects)\nfrom the created Docker Image. To do this, use `Docker Compose` again:\n\n``` sh\ndocker-compose -f docker-compose.local.yml up\n```\n\nIf everything is correct so far, running the above command should\nproduce the output shown below:\n\n    (Omitted)\n\n    wlts-paper-environment-container | [C 2021-10-04 21:59:46.336 ServerApp] \n    wlts-paper-environment-container |     \n    wlts-paper-environment-container |     To access the server, open this file in a browser:\n    wlts-paper-environment-container |         file:///home/jovyan/.local/share/jupyter/runtime/jpserver-7-open.html\n    wlts-paper-environment-container |     Or copy and paste one of these URLs:\n    wlts-paper-environment-container |         http://bc26c6560801:8888/lab?token=8e487aba8f7b007a92ac3906b801f7e7fff299d0062c2cb1\n    wlts-paper-environment-container |      or http://127.0.0.1:8888/lab?token=8e487aba8f7b007a92ac3906b801f7e7fff299d0062c2cb1\n\nThis information allows access to the JupyterLab page. So, to access\nthis environment, copy the URL displayed in your terminal output that\nincludes the Jupyter access token. The copied address should look like\nthe one shown below:\n\n> Remember that this address and token vary with each run, so copy it\n> from your terminal. If you try to log in with the token shown below,\n> you will have problems using Jupyter.\n\n``` sh\nhttp://127.0.0.1:8888/lab?token=8e487aba8f7b007a92ac3906b801f7e7fff299d0062c2cb1\n```\n\nAfter copying the URL, access it using any browser of your choice. As an\nexample, to access this URL with firefox, you can use the command in the\nterminal:\n\n``` sh\nfirefox http://127.0.0.1:8888/lab?token=8e487aba8f7b007a92ac3906b801f7e7fff299d0062c2cb1\n```\n\nWhen you go there, you should see the JupyterLab page (Figure 3). Once\nyou have done this, you are ready to start executing the code in this\nRC. Go to the Section [Workflow execution](#workflow-execution).\n"
      },
      "source": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/README.Rmd",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Workflow execution",
        "parent_header": [
          "A plataform for land use and land cover data integration and trajectory analysis",
          "Running"
        ],
        "type": "Text_excerpt",
        "value": "> To follow the steps in this section, you must already have a\n> executable environment set up and ready to go. If not, please refer to\n> Section [Environment](#environment).\n\n> Note that for all the workflow execution code and configurations, it\n> will be assumed that the executions performed are **always** relative\n> to the directory `wlts-paper`. This directory contains all the\n> materials in this RC and is available in the environment configured\n> with the approaches presented in Section [Environment](#environment).\n\n> The **W**eb **L**and **T**rajectory **S**ervice (WLTS) and **W**eb\n> **L**and **C**over **C**lassification **S**ystem (WLCCS) services used\n> to run these notebooks are provided by the Brazil Data Cube (BDC)\n> project. However, to use these and other BDC services, creating a free\n> `access token` is necessary. If you do not have a BDC access token,\n> please refer to the BDC services [documentation](#) page for\n> information on creating one.\n\nThe materials provided in this RC complement the examples and explain\nhow we conducted the analyses in the paper. To consistently organize\nthese examples and analyses, we created a workflow consisting of three\nindependent parts in this RC. In all parts of the workflow, the codes\nwere organized into interactive Jupyter Notebooks, which explain the\noperations performed.\n\nFigure 8 illustrates the workflow parts and the Jupyter Notebooks that\ncompose them, along with their connections and orders. The execution of\neach of these parts does not depend on each other, making their\nexploration simpler. Below are the details of the elements that make up\nthe workflow presented. Afterward, we will describe the ways of using\nand executing this workflow.\n\n<div align=\"center\">\n\n<img src=\"./figures/workflow/png/workflow-overview.png\" width=\"100%\" style=\"display: block; margin: auto;\" />\n\n<b>Figure 8.</b> Workflow overview.\n\n</div>\n\n<br/>\n"
      },
      "source": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/README.Rmd",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Base operations",
        "parent_header": [
          "A plataform for land use and land cover data integration and trajectory analysis",
          "Running",
          "Parametrized batch using GNU Make"
        ],
        "type": "Text_excerpt",
        "value": "> The notebooks from this workflow step are available in the directory:\n> `analysis/scripts/wlts-operations`.\n\nThe `Base operations` is the part of the workflow that contains the\nexample code listings presented in the article. This workflow part has\ntwo Jupyter Notebooks:\n\n-   `wlts-operations-python.ipynb`: Jupyter Notebook with the example\n    code listings of Python client usage available for access to the\n    platform presented by Zioti *et al.* (2021);\n-   `wlts-operations-r.ipynb`: Jupyter Notebook with the R client\n    example code listings available for access to the platform presented\n    by Zioti *et al.* (2021).\n\nAs shown in Figure 8, both of these notebooks have no dependencies on\neach other, allowing them to be run in no particular order.\n"
      },
      "source": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/README.Rmd",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Alluvial Plot",
        "parent_header": [
          "A plataform for land use and land cover data integration and trajectory analysis",
          "Running",
          "Workflow execution"
        ],
        "type": "Text_excerpt",
        "value": "> The notebooks from this workflow step are available in the directory:\n> `analysis/scripts/alluvial-plot`.\n\nThe `Alluvial plot` is part of the workflow containing the codes used to\nproduce the alluvial plot presented by Zioti *et al.* (2021). This\nworkflow part has two Jupyter Notebooks:\n\n-   `1_wlts_alluvial-plot_data-extraction.ipynb`: Document with the\n    codes used for retrieving the LULC trajectories used as the basis\n    for producing the Alluvial plot;\n-   `2_wlts_alluvial-plot_data-visualization.ipynb`: Document with the\n    codes used to produce the Alluvial plot. Uses as a base the LULC\n    trajectories retrieved\u2019 in the notebook\n    `1_wlts_alluvial-plot_data-extraction.ipynb`.\n\nThus, as shown in Figure 8, the notebooks used for the generation of the\nalluvial plot have a dependency relationship, making the order of\nexecution relevant. When this relation is not preserved, there are\nproblems in the result production.\n"
      },
      "source": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/README.Rmd",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "LULC Trajectory comparison",
        "parent_header": [
          "A plataform for land use and land cover data integration and trajectory analysis",
          "Running",
          "Workflow execution"
        ],
        "type": "Text_excerpt",
        "value": "> The notebooks from this workflow step are available in the directory:\n> `analysis/scripts/lulc-trajectory-comparison`.\n\nThe `LULC Trajectory comparison` is the part of the workflow that\ncontains the codes used for producing the agreement analysis between\ntrajectories. For the production of this analysis. This workflow part\nhas two Jupyter Notebooks:\n\n-   `1_wlts-wlccs_lulc-trajectories-comparison_data-extraction.ipynb`:\n    Document with the codes for retrieving LULC trajectories;\n-   `2_wlts-wlccs_lulc-trajectories-comparison_analysis.ipynb`: Document\n    with the codes for producing the agreement analysis with the\n    trajectories retrieved in the notebook\n    `1_wlts-wlccs_lulc-trajectories-comparison_data-extraction.ipynb`.\n\nTherefore, as with the Alluvial plot, the execution of these notebooks\nhas an execution order, which is shown in Figure 8.\n"
      },
      "source": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/README.Rmd",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Parametrized batch using GNU Make",
        "parent_header": [
          "A plataform for land use and land cover data integration and trajectory analysis",
          "Running"
        ],
        "type": "Text_excerpt",
        "value": "> You must run the codes presented in this section in an environment\n> with the dependencies presented in the\n> [environment.yml](environment.yml). If necessary, please refer to\n> Section [Environment](#environment) to configure your environment.\n\nThe first workflow execution mode for this RC is the parameterized\nbatch. Here, each of the parts of the workflow is executed individually,\nfrom start to finish, without any user interaction. This execution mode\nis recommended for the users who wish to obtain the results without\nhaving to access and run the notebooks manually.\n\nTo implement this execution mode, the following tools were used:\n\n-   [GNU Make](https://www.gnu.org/software/make/): Para a modelagem e\n    execu\u00e7\u00e3o do workflow;\n-   [Papermill](https://papermill.readthedocs.io/en/latest/): Ferramenta\n    para a execu\u00e7\u00e3o parametrizada, via terminal, de Jupyter Notebooks.\n\nBy using these tools together, we model all the parts of the workflow\nand manage its execution without the need to modify the code or even\nchange the format (e.g., take the code out of Jupyter Notebooks and send\nit to conventional Python scripts).\n"
      },
      "source": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/README.Rmd",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Makefile",
        "parent_header": [
          "A plataform for land use and land cover data integration and trajectory analysis",
          "Running",
          "Parametrized batch using GNU Make"
        ],
        "type": "Text_excerpt",
        "value": "> If the reader is interested in learning `Make`, please see the page\n> [Reproducibility with\n> Make](https://the-turing-way.netlify.app/reproducible-research/make.html).\n\nTo use `GNU Make`, we have made a `Makefile` that materializes the whole\nworkflow through [make\nrules](https://www.gnu.org/software/make/manual/html_node/Rules.html).\nThe following rules are available:\n\n> **Tip**: To view these rules directly from the Makefile, you can run\n> the command in the root directory of this RC: `make help`.\n\n    alluvial-plot                  (Workflow) Execute the notebooks to generate the Alluvial Plot presented in the paper.\n    all                            (Workflow) Execute all workflow steps.\n    clean                          (Workflow) Remove all workflow results.\n    generate-make-graph            (Miscellaneous) Generate a graph from the Makefile rules\n    lulc-trajectory-comparison     (Workflow) Execute the notebooks to generate the Agreement analysis presented in the paper.\n    wlts-operations                (Workflow) Execute the notebooks with the WLTS and WLCCS base operations presented in the paper.\n\nEach of the `wlts-operations`, `alluvial-plot`, and\n`lulc-trajectory-comparison` rules represent the parts of the workflow\npresented above. Additionally, the rules `all` and `clean` are used\nrespectively for performing all the workflow steps and cleaning up all\nthe results generated by the notebooks.\n\nThe connection of all these rules can be seen as a dependency graph,\nwhich is generated with the\n[makefile2graph](https://github.com/lindenb/makefile2graph) tool .\n\n<details>\n<summary>\nClick here to visualize the Makefile dependencies graph\n</summary>\n\n<div align=\"center\">\n\n<img src=\"./figures/makegraph.png\" width=\"100%\" style=\"display: block; margin: auto;\" />\n\n<b>Figure 9.</b> Makefile dependency graph.\n\n</div>\n\n</details>\n\n<br>\n\nIn the following sections, how each of these rules is used to execute\nthis RC workflow will be presented.\n"
      },
      "source": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/README.Rmd",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Parameterization",
        "parent_header": [
          "A plataform for land use and land cover data integration and trajectory analysis",
          "Running",
          "Parametrized batch using GNU Make"
        ],
        "type": "Text_excerpt",
        "value": "Batch mode execution, once started, does not allow user interaction\nuntil its completion. However, in this RC, an `access token` is required\nto retrieve the trajectories from the WLTS and WLCCS services provided\nby the BDC project.\n\nTo avoid having to specify this `access token` to each Jupyter Notebook\nbefore execution in batch mode, we use the notebook execution\nparameterization capabilities provided by the `papermill`. This\n`papermill` functionality allows all notebooks that require this\ninformation to receive it from a single definition of the\n`access token`, made in a configuration file.\n\nThus, before starting executions of the parts of the workflow, it is\nnecessary to create this configuration file. In this RC, this\nconfiguration file is in the path\n`analysis/data/raw_data/workflow_parameters.yml`. When you access it,\nyou will see a file with the following format:\n\n> Remember that the path `analysis/data/raw_data/` is relative to the RC\n> root directory. So, for example, if you use the environment set up\n> with some of the approaches presented in Section\n> [Environment](#environment), this path will be relative to the\n> `wlts-paper` directory.\n\n    bdc_access_token: \"YOUR-BDC-SERVICES-TOKEN-HERE\"\n\nChange the file\u2019s contents, replacing the text\n`YOUR-BDC-SERVICES-TOKEN-HERE` with your BDC `access token`. By doing\nthis, you are now ready to run the workflow in batch mode.\n\n<details>\n<summary>\nClick here for the step-by-step configuration of the access token\nparameter (Optional)\n</summary>\n\n<br/>\n\n> If you are having trouble setting up the `workflow_parameters.yml`\n> file, use the steps below. If you have already done the setup, it is\n> not necessary to follow these steps.\n\n> This step-by-step assumes that you are using the environment\n> configured with one of the approaches presented in Section\n> [Environment](#environment).\n\nFrom the JupyterLab initial page, go to the `wlts-paper` directory:\n\n<div align=\"center\">\n\n<img src=\"./figures/running/make/png/configure-token-1.png\" width=\"80%\" style=\"display: block; margin: auto;\" />\n\n<b>Figure 10.</b> Selection of `wlts-paper` directory on JupyterLab.\n\n</div>\n\n<br/>\n\nThen go to the `analysis` directory:\n\n<div align=\"center\">\n\n<img src=\"./figures/running/make/png/configure-token-2.png\" width=\"80%\" style=\"display: block; margin: auto;\" />\n\n<b>Figure 11.</b> Selection of `analysis` directory on JupyterLab.\n\n</div>\n\n<br/>\n\nInside the `analysis` directory, go to the `data` directory:\n\n<div align=\"center\">\n\n<img src=\"./figures/running/make/png/configure-token-3.png\" width=\"80%\" style=\"display: block; margin: auto;\" />\n\n<b>Figure 12.</b> Selection of `data` directory on JupyterLab.\n\n</div>\n\n<br/>\n\nNow go to the `raw_data` directory, where the files and data used as\ninput in the workflow are:\n\n<div align=\"center\">\n\n<img src=\"./figures/running/make/png/configure-token-4.png\" width=\"80%\" style=\"display: block; margin: auto;\" />\n\n<b>Figure 13.</b> Selection of `raw_data` directory on JupyterLab.\n\n</div>\n\n<br/>\n\nIn the `raw_data` directory, you will see the `workflow_parameters.yml`\nfile. Open this file:\n\n<div align=\"center\">\n\n<img src=\"./figures/running/make/png/configure-token-5.png\" width=\"80%\" style=\"display: block; margin: auto;\" />\n\n<b>Figure 14.</b> Selection of `workflow_parameters.yml` file on\nJupyterLab.\n\n</div>\n\n<br/>\n\nWith the `workflow_parameters.yml` file open, change the\n`bdc_access_token` key, replacing the text\n`YOUR-BDC-SERVICES-TOKEN-HERE` with your `access token` from BDC.\n\n<div align=\"center\">\n\n<img src=\"./figures/running/make/png/configure-token-6.png\" width=\"80%\" style=\"display: block; margin: auto;\" />\n\n<b>Figure 15.</b> Configuration of `bdc_access_token` in\n`workflow_parameters.yml` file on JupyterLab.\n\n</div>\n\n<br/>\n\nNow you have the `access token` parameter set and ready to be used in\nthe batch run of this RC workflow.\n\n</details>\n\n<br/>\n\n#### Base operations\n\nThe first part of the workflow to be presented is `Base operations`. As\nmentioned earlier, this part has the code listings presented by Zioti\n*et al.* (2021). To run this part, you need to be in the RC root\ndirectory. Once you are in the root directory, run the command:\n\n``` sh\nmake wlts-operations\n```\n\nIn general, when this execution is performed, you have the execution\nflow shown in Figure 13. Based on the `wlts-operations` rule, the\n`GNU Make` uses the `papermill` and does the parameterized execution of\nboth notebooks in this step.\n\n<div align=\"center\">\n\n<img src=\"./figures/workflow/png/workflow_base-operations.png\" width=\"80%\" style=\"display: block; margin: auto;\" />\n\n<b>Figure 16.</b> `Base operations` execution flow.\n\n</div>\n\nThe results are available in the directory\n`analysis/data/derived_data/base-operations` at the end of the run. When\nlisting this directory, the following content should be presented:\n\n> Remember that the path `analysis/data/derived_data/base-operations` is\n> relative to the RC root directory. So, for example, if you are using\n> the environment set up with some of the approaches presented in\n> Section [Environment](#environment), this path will be relative to the\n> `wlts-paper` directory.\n\n``` sh\nls -l analysis/data/derived_data/base-operations\n\n#> total 12\n#> -rw-r--r-- 1 root root 1536 Oct  6 15:28 listing1_python.csv\n#> -rw-r--r-- 1 root root 1866 Oct  6 15:28 listing1_r.csv\n#> -rw-r--r-- 1 root root  639 Oct  6 15:28 listing3_python.csv\n```\n\nNote also that the outputs from each cell in the notebooks are persisted\nin the documents themselves. See the notebooks run in the\n`analysis/scripts/wlts-operations/` directory to view these details.\n\n<details>\n<summary>\nClick here for the step-by-step execution (Optional)\n</summary>\n\n<br/>\n\n> If you have trouble executing the `wlts-operations` rule from `make`,\n> follow the steps below.\n\n> This step-by-step assumes that you are using the environment\n> configured with one of the approaches presented in Section\n> [Environment](#environment).\n\nFirst, go to `Terminal` in the JupyterLab interface:\n\n<div align=\"center\">\n\n<img src=\"./figures/running/make/png/wlts-operations-1.png\" width=\"80%\" style=\"display: block; margin: auto;\" />\n\n<b>Figure 17.</b> Terminal selection on JupyterLab menu.\n\n</div>\n\n<br/>\n\nIn the terminal, go to `wlts-paper`, the directory where this RC is\nstored in the environment. Then run the `make wlts-operations` command:\n\n<div align=\"center\">\n\n<img src=\"./figures/running/make/png/wlts-operations-2.png\" width=\"80%\" style=\"display: block; margin: auto;\" />\n\n<b>Figure 18.</b> `make wlts-operations` on JupyterLab terminal.\n\n</div>\n\n<br/>\n\nWhen the execution starts, the terminal will display bars with the\nprogress of the operation:\n\n<div align=\"center\">\n\n<img src=\"./figures/running/make/png/wlts-operations-3.png\" width=\"80%\" style=\"display: block; margin: auto;\" />\n\n<b>Figure 19.</b> `make wlts-operations` progress bar.\n\n</div>\n\n<br/>\n\nThe generated results will be saved in the directory\n`analysis/data/derived_data/base-operations`.\n\n</details>\n\n<br/>\n"
      },
      "source": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/README.Rmd",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Alluvial plot",
        "parent_header": [
          "A plataform for land use and land cover data integration and trajectory analysis",
          "Running",
          "Parametrized batch using GNU Make"
        ],
        "type": "Text_excerpt",
        "value": "In `Alluvial plot`, as mentioned, the Jupyter Notebooks are executed to\ngenerate the alluvial plot. The execution of this part of the workflow\nis analogous to that presented in `Base operations`. First, go to the\nroot directory where the RC is stored. Then run the `alluvial-plot`\nrule:\n\n``` sh\nmake alluvial-plot\n```\n\nIn the execution, first, the\n`1_wlts_alluvial-plot_data-extraction.ipynb` notebook is run, which will\nretrieve the LULC trajectories. After completing the first notebook, the\n`2_wlts_alluvial-plot_data-visualization.ipynb` notebook is executed,\ngenerating the alluvial plot. This flow is summarized in Figure 20.\n\n<div align=\"center\">\n\n<img src=\"./figures/workflow/png/workflow_alluvial-plot.png\" width=\"80%\" style=\"display: block; margin: auto;\" />\n\n<b>Figure 20.</b> `Alluvial plot` execution flow.\n\n</div>\n\n<br/>\n\nThe results are available in the directory\n`analysis/data/derived_data/alluvial-plot` at the end of the run. When\nlisting this directory, the following content should be presented:\n\n> Remember that the path `analysis/data/derived_data/alluvial-plot` is\n> relative to the RC root directory. So, for example, if you are using\n> the environment set up with some of the approaches presented in\n> Section [Environment](#environment), this path will be relative to the\n> `wlts-paper` directory.\n\n``` sh\nls -l analysis/data/derived_data/alluvial-plot\n\n#> total 1432\n#> -rw-r--r-- 1 root root 1384790 Oct  6 17:32 plot_alluvial_terraclass_amz.png\n#> -rw-r--r-- 1 root root   74375 Oct  6 17:30 sao-felix-do-xingu_trajectories.rds\n```\n\nNote also that the outputs from each cell in the notebooks are persisted\nin the documents themselves. See the notebooks run in the\n`analysis/scripts/alluvial-plot/` directory to view these details.\n\n<details>\n<summary>\nClick here for the step-by-step execution (Optional)\n</summary>\n\n<br/>\n\n> If you have trouble executing the `alluvial-plot` rule from `make`,\n> follow the steps below.\n\n> This step-by-step assumes that you are using the environment\n> configured with one of the approaches presented in Section\n> [Environment](#environment).\n\nFirst, go to `Terminal` in the JupyterLab interface:\n\n<div align=\"center\">\n\n<img src=\"./figures/running/make/png/alluvial-plot-1.png\" width=\"80%\" style=\"display: block; margin: auto;\" />\n\n<b>Figure 21.</b> Terminal selection on JupyterLab menu.\n\n</div>\n\n<br/>\n\nIn the terminal, go to `wlts-paper`, the directory where this RC is\nstored in the environment. Then run the `make alluvial-plot` command:\n\n<div align=\"center\">\n\n<img src=\"./figures/running/make/png/alluvial-plot-2.png\" width=\"80%\" style=\"display: block; margin: auto;\" />\n\n<b>Figure 22.</b> `make alluvial-plot` on JupyterLab terminal.\n\n</div>\n\n<br/>\n\nWhen the execution starts, the terminal will display bars with the\nprogress of the operation:\n\n<div align=\"center\">\n\n<img src=\"./figures/running/make/png/alluvial-plot-3.png\" width=\"80%\" style=\"display: block; margin: auto;\" />\n\n<b>Figure 23.</b> `make alluvial-plot` progress bar.\n\n</div>\n\n<br/>\n\nThe generated results will be saved in the directory\n`analysis/data/derived_data/alluvial-plot/`.\n\n</details>\n\n<br/>\n"
      },
      "source": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/README.Rmd",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "LULC Trajectory Comparison",
        "parent_header": [
          "A plataform for land use and land cover data integration and trajectory analysis",
          "Running",
          "Parametrized batch using GNU Make"
        ],
        "type": "Text_excerpt",
        "value": "In the last of the operations, `LULC Trajectory Comparison`, as seen\nearlier, one produces an agreement analysis between trajectories from\ntwo distinct data collections. The execution of this operation can be\ndone at the root of this RC using the `lulc-trajectory-comparison` rule:\n\n``` sh\nmake lulc-trajectory-comparison\n```\n\nFigure 24 shows the general execution flow of this rule. First, the\n`1_wlts-wlccs_lulc-trajectories-comparison_data-extraction.ipynb`\nnotebook is executed. This notebook retrieves the trajectories from two\ndata collections. This data is then used as input to run the notebook\n`2_wlts-wlccs_lulc-trajectories-comparison_analysis.ipynb`.\n\n<div align=\"center\">\n\n<img src=\"./figures/workflow/png/workflow_lulc-comparison.png\" width=\"80%\" style=\"display: block; margin: auto;\" />\n\n<b>Figure 24.</b> `LULC Trajectory Comparison` execution flow.\n\n</div>\n\n<br/>\n\nThe results are available in the directory\n`analysis/data/derived_data/lulc-trajectory-comparison` at the end of\nthe run. When listing this directory, the following content should be\npresented:\n\n> Remember that the path\n> `analysis/data/derived_data/lulc-trajectory-comparison` is relative to\n> the RC root directory. So, for example, if you are using the\n> environment set up with some of the approaches presented in Section\n> [Environment](#environment), this path will be relative to the\n> `wlts-paper` directory.\n\n``` sh\nls -l analysis/data/derived_data/lulc-trajectory-comparison\n\n#> total 2100\n#> -rw-r--r-- 1 root root  311930 Oct  6 19:29 harmonized-trajectories_download_2021-10-06_15-28-17_825991.log\n#> -rw-r--r-- 1 root root 1818889 Oct  6 19:29 harmonized-trajectories_mapbiomas-terraclass_2014.json\n#> -rw-r--r-- 1 root root    3502 Oct  6 19:29 trajectory-concordance_tc-mb-2014.csv\n#> -rw-r--r-- 1 root root     176 Oct  6 19:29 trajectory-concordance_tc-mb-2014_matrix.csv\n```\n\nNote also that the outputs from each cell in the notebooks are persisted\nin the documents themselves. See the notebooks run in the\n`analysis/scripts/lulc-trajectory-comparison/` directory to view these\ndetails.\n\n<details>\n<summary>\nClick here for the step-by-step execution (Optional)\n</summary>\n\n<br/>\n\n> If you have trouble executing the `lulc-trajectory-comparison` rule\n> from `make`, follow the steps below.\n\n> This step-by-step assumes that you are using the environment\n> configured with one of the approaches presented in Section\n> [Environment](#environment).\n\nFirst, go to `Terminal` in the JupyterLab interface:\n\n<div align=\"center\">\n\n<img src=\"./figures/running/make/png/lulc-trajectory-comparison-1.png\" width=\"80%\" style=\"display: block; margin: auto;\" />\n\n<b>Figure 25.</b> Terminal selection on JupyterLab menu.\n\n</div>\n\n<br/>\n\nIn the terminal, go to `wlts-paper`, the directory where this RC is\nstored in the environment. Then run the\n`make lulc-trajectory-comparison` command:\n\n<div align=\"center\">\n\n<img src=\"./figures/running/make/png/lulc-trajectory-comparison-2.png\" width=\"80%\" style=\"display: block; margin: auto;\" />\n\n<b>Figure 26.</b> `make lulc-trajectory-comparison` on JupyterLab\nterminal.\n\n</div>\n\n<br/>\n\nWhen the execution starts, the terminal will display bars with the\nprogress of the operation:\n\n<div align=\"center\">\n\n<img src=\"./figures/running/make/png/lulc-trajectory-comparison-3.png\" width=\"80%\" style=\"display: block; margin: auto;\" />\n\n<b>Figure 27.</b> `make lulc-trajectory-comparison` progress bar.\n\n</div>\n\n<br/>\n\nThe generated results will be saved in the directory\n`analysis/data/derived_data/lulc-trajectory-comparison/`.\n\n</details>\n\n<br/>\n"
      },
      "source": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/README.Rmd",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Interactive execution",
        "parent_header": [
          "A plataform for land use and land cover data integration and trajectory analysis",
          "Running"
        ],
        "type": "Text_excerpt",
        "value": "In addition to the parameterized batch execution of Jupyter Notebooks,\nit is also possible to make interactive and individual execution of each\ndocument. This approach is recommended for those interested in\nunderstanding the steps performed in the code to produce the results.\n\nIn the interactive approach, for the executions, unlike the batch\noperations, there is no previous configuration to be done; everything is\nconfigured directly on each of the notebooks. Thus, for interactive\nexecution, you must consider two points:\n\n-   `Access token definition`: The definition of the `access token` must\n    be made on each of the notebooks individually. Instructions on where\n    to insert this `token` are available in the documents themselves;\n-   `Specifying the input/output directories`: By default, the notebooks\n    are configured to run, considering the RC root as the working\n    directory. However, this premise does not hold when changing the\n    directory in the JupyterLab interface to access the notebooks and\n    then make their interactive execution. Thus, it is necessary to\n    change the reference of the input and output directories considering\n    the directory where the notebook is stored. To exemplify the\n    necessary change, consider the organizational structure of this RC\n    in the environment configured in Section\n    [Environment](#environment):\n\n> As mentioned, in the environment configured with the steps presented\n> in Section [Environment](#environment), the RC root is represented by\n> the `wlts-paper` directory.\n\n    \u2514\u2500\u2500 wlts-paper\n        \u251c\u2500\u2500 data\n        \u2502    \u251c\u2500\u2500 raw_data\n        \u2502    \u2514\u2500\u2500 derived_data\n        \u2514\u2500\u2500 scripts \n            \u251c\u2500\u2500 alluvial-plot\n            \u251c\u2500\u2500 wlts-operations\n            \u2514\u2500\u2500 lulc-trajectory-comparison\n\nIn the default configuration, notebooks execute considering paths\nrelative to `wlts-paper`. So, for example, the output directory of the\n`alluvial plot`, in the source code is:\n\n    output_directory <- \"analysis/data/derived_data/alluvial-plot\"\n\nHowever, if you are in the `wlts-paper/scripts/alluvial-plot` directory,\nrunning the notebook, the path\n`analysis/data/derived_data/alluvial-plot` may fail. Therefore, a change\nis needed that allows the notebook code to use the same directories. In\nthis case, the necessary change transforms the output path definition to\nthe following variable:\n\n    output_directory <- \"../../data/derived_data/alluvial-plot\"\n\nThis change will make the code look for two directory levels above the\ncurrent one for the `data` directory, when is considered that the\nrunning is done directly from the `wlts-paper/scripts/alluvial-plot`\ndirectory.\n\nThis change should be considered on all notebooks when interactive\nexecution is being performed.\n"
      },
      "source": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/README.Rmd",
      "technique": "header_analysis"
    }
  ],
  "somef_missing_categories": [
    "installation",
    "citation",
    "acknowledgement",
    "download",
    "requirements",
    "contact",
    "contributors",
    "documentation",
    "faq",
    "support",
    "identifier"
  ],
  "somef_provenance": {
    "date": "2024-10-04 00:31:58",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 9
      },
      "technique": "GitHub_API"
    }
  ],
  "type": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "notebook-application"
      },
      "technique": "software_type_heuristics"
    }
  ],
  "usage": [
    {
      "confidence": 1,
      "result": {
        "original_header": "A plataform for land use and land cover data integration and trajectory analysis",
        "type": "Text_excerpt",
        "value": "[![rc](https://img.shields.io/badge/research%20compendium-ready-brightgreen)](#)\n[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/brazil-data-cube/wlts-paper/HEAD)\n[![Docker\nPulls](https://img.shields.io/docker/pulls/brazildatacube/wlts-paper-environment)](https://hub.docker.com/r/brazildatacube/wlts-paper-environment)\n\nThis repository is a `Research Compendium` (RC), with all the materials\n(codes, data, and computational environment) required for the\nreproduction and evaluation of the results presented in the article:\n\n> Zioti *et al.* (2021).\n> `A plataform for land use and land cover data integration and trajectory analysis`.\n> Paper submitted for International Journal of Applied Earth Observation\n> and Geoinformation (2021).\n"
      },
      "source": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/README.Rmd",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Compendium content",
        "parent_header": [
          "A plataform for land use and land cover data integration and trajectory analysis"
        ],
        "type": "Text_excerpt",
        "value": "The directory **analysis**, centralizes the codes and data used in the\nRC. It has two subdirectories, the first of which, **analysis/data**,\nstores the input and output data in the following structure:\n\n-   [:file\\_folder: analysis/data/raw\\_data/](analysis/data/raw_data/):\n    Directory with the input data. It has the following elements:\n\n    -   [workflow\\_parameters.yml](analysis/data/raw_data/workflow_parameters.yml):\n        Workflow configuration file. This file should be used when the\n        full run is done with the `Makefile`;\n\n    -   [study-area\\_sao-felix-do-xingu](analysis/data/raw_data/study-area_sao-felix-do-xingu/):\n        Directory with the shapefile from the regularly spaced grid of\n        1x1 km used in the workflow analysis;\n\n    -   [terraclass\\_amazonia\\_v2\\_color-palette.yml](analysis/data/raw_data/terraclass_amazonia_v2_color-palette.yml):\n        File with the definition of the color palette used in the\n        alluvial plot.\n\n-   [:file\\_folder:\n    analysis/data/derived\\_data/](analysis/data/derived_data/):\n    Directory with the output data. By default, these directories are\n    kept empty in the repository, requiring code execution to generate\n    results. This directory has the following elements:\n\n    -   [alluvial-plot](analysis/data/derived_data/alluvial-plot/):\n        Directory to save the alluvial plot figure;\n\n    -   [base-operations](analysis/data/derived_data/base-operations/):\n        Directory to save the code listings (article examples) outputs;\n\n    -   [lulc-trajectory-comparison](analysis/data/derived_data/lulc-trajectory-comparison/):\n        Directory to save the agreement analysis results.\n\nThe second **analysis** subdirectory is the **analysis/scripts**\ndirectory, which stores the codes for this RC. It has the following\nelements:\n\n-   [:file\\_folder: alluvial-plot](analysis/scripts/alluvial-plot/):\n    Jupyter Notebooks to generate the alluvial plot;\n\n-   [:file\\_folder: wlts-operations](analysis/scripts/wlts-operations/):\n    Jupyter Notebooks with the code listings presented in the paper;\n\n-   [:file\\_folder:\n    lulc-trajectory-comparison](analysis/scripts/lulc-trajectory-comparison/):\n    Jupyter Notebooks for agreement analysis.\n\nBesides these directories, there are also files used for the\nspecification of the computing environment needed to run the Jupyter\nNotebooks:\n\n-   `docker-compose.local.yml`: File with instructions for building and\n    running the Docker environment provided in this RC;\n\n-   `docker-compose.dockerhub.yml` (No local build required): File with\n    instructions for running the Docker environment provided in this RC.\n    Uses the Docker Image provided on DockerHub;\n\n-   `environment.yml`: Conda environment description file, with the\n    dependencies and their versions, used in the production of the\n    results of the article and necessary for the reproduction of the\n    results of the article;\n\n-   `Dockerfile`: Docker Image specification file. It is based on the\n    packages and versions specified in the `environment.yml` file.\n\nIn addition to these, there is also the `Makefile` where the workflow of\nthis RC is modeled.\n"
      },
      "source": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/README.Rmd",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Environment",
        "parent_header": [
          "A plataform for land use and land cover data integration and trajectory analysis",
          "Running"
        ],
        "type": "Text_excerpt",
        "value": "During the production of this RC, the code execution to obtain the\nresults was done based on an environment with several software libraries\ninstalled. To make the codes execution and the results generated\nreproducible, we prepared a description of the environment used,\ndeclaring the software libraries used and their versions. With this\ndescription, others can run the codes in this RC from the same software\nlibraries, avoiding possible incompatibility.\n\nTo produce the environment description, we first organized and specified\nall the software and versions used to make the paper\u2019s results. We do\nthis with the [Conda](https://docs.conda.io/en/latest/) package manager\nbecause it allows the management of packages of both languages used in\nthe paper (R and Python). The result is the file\n[environment.yml](environment.yml), which describes all the versions and\npackages used. Next, we used this environment description to produce a\nDocker Image, in which all the packages described in the file\n[environment.yml](environment.yml) were installed. To enable the\ninteractive use of the generated environment, the Docker Image created\nwas based on the Docker Image\n[jupyter/base-notebook:lab-3.1.13](https://hub.docker.com/layers/jupyter/base-notebook/lab-3.1.13/images/sha256-9a388da87e9d2b8019df20439977953d0576f6168348f621498ac62b45e2f88f?context=explore),\nin which the installation of\n[JupyterLab](https://jupyterlab.readthedocs.io/en/stable/) was\navailable. With JupyterLab, users can interact with the environment\nthrough an interactive, high-level interface with features that\nfacilitate code and data analysis. The connection of each of these\nelements in the produced environment is depicted in Figure 1.\n\n<div align=\"center\">\n\n<img src=\"./figures/running/environment/overview/png/environment-flow-overview.png\" width=\"35%\" style=\"display: block; margin: auto;\" />\n\n<b>Figure 1.</b> Environment building flow.\n\n</div>\n\nAt the moment the Docker Image is being generated, all the RC components\nare copied into it. This way, when accessing the JupyterLab interface to\nuse the environment, the user already has available, in a directory\nnamed `wlts-paper`, the whole RC. Figure 2 shows the JupyterLab\ninterface, which is made available to the user, along with the RC\ncontents listed from the `wlts-paper` directory.\n\n<div align=\"center\">\n\n<img src=\"./figures/running/environment/overview/png/environment-directories.png\" width=\"80%\" style=\"display: block; margin: auto;\" />\n\n<b>Figure 2.</b> Environment `wlts-paper` directory.\n\n</div>\n\nThis way of specifying and making the environment available, based on\nDocker, allows the material in this RC, especially the codes, to be used\nin the same way as the authors did during the production of the results.\nThe configuration and use of this environment can be done in several\nways. In the topics below, we will present some of the ways to configure\nand use this environment.\n\n> The different approaches presented below, used for configuring and\n> running the environment, do not change its content. Thus, all the\n> properties defined above are valid for any of the ways of configuring\n> the environment.\n"
      },
      "source": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/README.Rmd",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Binder",
        "parent_header": [
          "A plataform for land use and land cover data integration and trajectory analysis",
          "Running",
          "Environment"
        ],
        "type": "Text_excerpt",
        "value": "The first available option for using the computational environment is\nwith [Binder](https://jupyter.org/binder), a tool that allows the\ncreation and sharing of executable environments from code repositories.\nWith Binder, all you need to do to access the executable environment of\nthis RC is click on the icon below:\n\n<div align=\"center\">\n\n[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/brazil-data-cube/wlts-paper/HEAD)\n\n</div>\n\nWhen you access the link, the Binder will create the executable\nenvironment with the same libraries and versions specified in the\n[environment.yml](environment.yml) file. When the environment is ready\nfor use, you will have to access it via a\n[JupyterLab](https://jupyterlab.readthedocs.io/en/stable/) interface.\nThe JupyterLab page that you will have access to is shown in Figure 3.\n\n<div align=\"center\">\n\n<img src=\"./figures/running/environment/binder/png/binder-home.png\" width=\"80%\" style=\"display: block; margin: auto;\" />\n\n<b>Figure 3.</b> JupyterLab on Binder.\n\n</div>\n\nAfter accessing the environment, you are ready to run these\nenvironments. To understand how the code is organized and how it can be\nexecuted, please go to Section [Workflow\nexecution](#workflow-execution).\n\n**Extra**: Using the link mentioned above summarizes the operations and\nmakes access to the environment direct. If the reader is interested, the\nstep-by-step instructions for using Binder are available below. We\nrecommend using this material as a reference to the behavior that Binder\nshould exhibit throughout the environment configuration steps.\n\n<details>\n<summary>\nStep-by-step environment setup in Binder\n</summary>\n\n<br/>\n\n> This step-by-step is an extended version of the tutorial presented\n> earlier on using the computing environment with Binder. If your\n> environment is already working, we recommend that you skip these steps\n\nTo get started, go to <https://mybinder.org/>:\n\n<div align=\"center\">\n\n<img src=\"./figures/running/environment/binder/png/step1.png\" width=\"75%\" style=\"display: block; margin: auto;\" />\n\n<b>Figure 4.</b> mybinder.org.\n\n</div>\n\n<br>\n\nOn the <https://mybinder.org/> page, enter in the *GitHub repository\nname or URL* field the repository address of this RC:\n\n    https://github.com/brazil-data-cube/wlts-paper\n\nNow, click on the **launch** button.\n\n<div align=\"center\">\n\n<img src=\"./figures/running/environment/binder/png/step2.png\" width=\"75%\" style=\"display: block; margin: auto;\" />\n\n<b>Figure 5.</b> RC repository configuration.\n\n</div>\n\n<br>\n\nWhen you click **launch**, Binder will start loading the repository and\nbuilding the environment you will work. The process may take a few\nminutes. At the end of the operation, the loading bar will reach the\nend, where the option (in green) **Launching** will be presented:\n\n<div align=\"center\">\n\n<img src=\"./figures/running/environment/binder/png/step3.png\" width=\"75%\" style=\"display: block; margin: auto;\" />\n\n<b>Figure 6.</b> RC repository launching.\n\n</div>\n\nAfter the building process, the environment is loaded, and you are\nredirected to the JupyterLab page:\n\n<div align=\"center\">\n\n<img src=\"./figures/running/environment/binder/png/step4.png\" width=\"75%\" style=\"display: block; margin: auto;\" />\n\n<b>Figure 7.</b> JupyterLab frontpage on Binder.\n\n</div>\n\n</details>\n\n<br>\n"
      },
      "source": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/README.Rmd",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Local machine (with DockerHub Image)",
        "parent_header": [
          "A plataform for land use and land cover data integration and trajectory analysis",
          "Running",
          "Environment"
        ],
        "type": "Text_excerpt",
        "value": "> During the production of this RC, all testing was performed using the\n> Linux environment. Therefore, the commands below may change slightly\n> on other operating systems.\n\nThe second option available is to use the RC environment directly on the\nuser\u2019s machine via\n[Docker](https://docs.docker.com/get-started/overview/). In this option,\nthe user runs the [Docker\nImage](https://docs.docker.com/get-started/overview/#docker-objects) of\nthis RC made available on DockerHub, which is ready to use, requiring no\nbuild steps. Below are the steps required to use this approach.\n\n> The steps presented below assume that the user has installed the\n> [Docker](https://www.docker.com/) and [Docker\n> Compose](https://docs.docker.com/compose/) tools. If you have not\n> installed them, please refer to the official documentation for each of\n> these tools:\n\n> 1.  [Install Docker Engine](https://docs.docker.com/engine/install/);\n> 2.  [Install Docker\n>     Compose](https://docs.docker.com/compose/install/).\n\n> Additionally, the user is expected to have [git](https://git-scm.com/)\n> installed on the machine. If you do not, please refer to the git\n> [official documentation](https://git-scm.com/download/linux) to do the\n> installation.\n\n> The versions of each of these tools used in the production of this\n> material are available below.\n\n<details>\n<summary>\nDocker, Docker Compose, and Git versions used for the production of this\nRC.\n</summary>\n\n**git**\n\n``` sh\ngit --version\n\n#> git version 2.27.0\n```\n\n**Docker**\n\n``` sh\ndocker version\n\n#> Client: Docker Engine - Community\n#>  Version:           20.10.8\n#>  API version:       1.41\n#>  Go version:        go1.16.6\n#>  Git commit:        3967b7d\n#>  Built:             Fri Jul 30 19:54:09 2021\n#>  OS/Arch:           linux/amd64\n#>  Context:           default\n#>  Experimental:      true\n\n#> Server: Docker Engine - Community\n#>  Engine:\n#>   Version:          20.10.8\n#>   API version:      1.41 (minimum version 1.12)\n#>   Go version:       go1.16.6\n#>   Git commit:       75249d8\n#>   Built:            Fri Jul 30 19:52:16 2021\n#>   OS/Arch:          linux/amd64\n#>   Experimental:     false\n#>  containerd:\n#>   Version:          1.4.9\n#>   GitCommit:        e25210fe30a0a703442421b0f60afac609f950a3\n#>  runc:\n#>   Version:          1.0.1\n#>   GitCommit:        v1.0.1-0-g4144b63\n#>  docker-init:\n#>   Version:          0.19.0\n#>   GitCommit:        de40ad0\n```\n\n**Docker Compose**\n\n``` sh\ndocker-compose --version\n\n#> docker-compose version 1.28.2, build 67630359\n```\n\n</details>\n\n<br/>\n\nTo use this local approach, the first step is to download the repository\nfor this RC. To do this, in a terminal on your machine, use `git` and\nclone the repository:\n\n``` sh\ngit clone https://github.com/brazil-data-cube/wlts-paper\n\n#> Cloning into 'wlts-paper'...\n#> remote: Enumerating objects: 263, done.\n#> remote: Counting objects: 100% (263/263), done.\n#> remote: Compressing objects: 100% (186/186), done.\n#> remote: Total 263 (delta 94), reused 235 (delta 68), pack-reused 0\n#> Receiving objects: 100% (263/263), 14.32 MiB | 14.56 MiB/s, done.\n#> Resolving deltas: 100% (94/94), done.\n```\n\nAfter the clone, in the directory you are in, there should be a\ndirectory named `wlts-paper`:\n\n``` sh\nls -l\n\n#> drwxrwxr-x 5 felipe felipe 4096 out  6 16:15 wlts-paper\n```\n\nAccess this directory and view its contents:\n\n``` sh\ncd wlts-paper\n\nls -l\n#> drwxrwxr-x 4 felipe felipe  4096 out  6 16:15 analysis\n#> -rw-rw-r-- 1 felipe felipe   261 out  6 16:15 docker-compose.dockerhub.yml\n#> -rw-rw-r-- 1 felipe felipe   324 out  6 16:15 docker-compose.local.yml\n#> -rw-rw-r-- 1 felipe felipe   735 out  6 16:15 Dockerfile\n#> -rw-rw-r-- 1 felipe felipe 10895 out  6 16:15 environment.yml\n#> drwxrwxr-x 4 felipe felipe  4096 out  6 16:15 figures\n#> -rw-rw-r-- 1 felipe felipe  3821 out  6 16:15 Makefile\n#> -rw-rw-r-- 1 felipe felipe 46436 out  6 16:15 README.md\n#> -rw-rw-r-- 1 felipe felipe 47304 out  6 16:15 README.Rmd\n#> -rw-rw-r-- 1 felipe felipe   226 out  6 16:15 wlts-paper.Rproj\n```\n\nIn the `wlts-paper` directory, notice the `docker-compose.dockerhub.yml`\nfile; this contains the instructions for running a [Docker\nContainer](https://docs.docker.com/get-started/overview/#docker-objects)\nfrom the image of this RC that is available on DockerHub. So, use this\nfile to run this RC environment:\n\n``` sh\ndocker-compose -f docker-compose.dockerhub.yml up\n```\n\nIf everything is correct so far, running the above command should\nproduce the output shown below:\n\n    (Omitted)\n\n    wlts-paper-environment-container |     \n    wlts-paper-environment-container |     To access the server, open this file in a browser:\n    wlts-paper-environment-container |         file:///home/jovyan/.local/share/jupyter/runtime/jpserver-8-open.html\n    wlts-paper-environment-container |     Or copy and paste one of these URLs:\n    wlts-paper-environment-container |         http://6fec052c07e8:8888/lab?token=b49897a7c22065285d3b9d942ffd86921eef44dbb64eeabc\n    wlts-paper-environment-container |      or http://127.0.0.1:8888/lab?token=b49897a7c22065285d3b9d942ffd86921eef44dbb64eeabc\n\nThis information allows access to the JupyterLab page. So, to access\nthis environment, copy the URL displayed in your terminal output that\nincludes the Jupyter access token. The copied address should look like\nthe one shown below:\n\n> Remember that this address and token vary with each run, so copy it\n> from your terminal. If you try to log in with the token shown below,\n> you will have problems using Jupyter.\n\n``` sh\nhttp://127.0.0.1:8888/lab?token=b49897a7c22065285d3b9d942ffd86921eef44dbb64eeabc\n```\n\nAfter copying the URL, access it using any browser of your choice. As an\nexample, to access this URL with firefox, you can use the command in the\nterminal:\n\n``` sh\nfirefox http://127.0.0.1:8888/lab?token=b49897a7c22065285d3b9d942ffd86921eef44dbb64eeabc\n```\n\nWhen you go there, you should see the JupyterLab page (Figure 3). Once\nyou have done this, you are ready to start executing the code in this\nRC. Go to the Section [Workflow execution](#workflow-execution).\n"
      },
      "source": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/README.Rmd",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Local machine (with Docker build)",
        "parent_header": [
          "A plataform for land use and land cover data integration and trajectory analysis",
          "Running",
          "Environment"
        ],
        "type": "Text_excerpt",
        "value": "> During the production of this RC, all testing was performed using the\n> Linux environment. Therefore, the commands below may change slightly\n> on other operating systems.\n\nAs an alternative version of the option presented in subsection [Local\nmachine (with DockerHub Image)](local-machine-with-dockerhub-image),\nthis third option is also available. In this option, analogous to the\nprevious subsection, the user downloads the RC content to his machine\nand runs it from a Docker Container with all the environment configured\nand ready to use. The difference in this third alternative is that the\n[Docker\nImage](https://docs.docker.com/get-started/overview/#docker-objects)\nversion is created on the user\u2019s machine, and no ready-to-use image is\nused.\n\nThe steps for using this approach are presented below.\n\n> This approach is recommended for users who already know Docker and\n> want to rebuild the environment from scratch.\n\nTo use this local approach with Docker Image build, the first step is to\ndownload the repository for this RC. To do this, in a terminal on your\nmachine, use `git` and clone the repository:\n\n``` sh\ngit clone https://github.com/brazil-data-cube/wlts-paper\n\n#> Cloning into 'wlts-paper'...\n#> remote: Enumerating objects: 263, done.\n#> remote: Counting objects: 100% (263/263), done.\n#> remote: Compressing objects: 100% (186/186), done.\n#> remote: Total 263 (delta 94), reused 235 (delta 68), pack-reused 0\n#> Receiving objects: 100% (263/263), 14.32 MiB | 14.56 MiB/s, done.\n#> Resolving deltas: 100% (94/94), done.\n```\n\nAfter the clone, in the directory you are in, there should be a\ndirectory named `wlts-paper`:\n\n``` sh\nls -l\n\n#> drwxrwxr-x 5 felipe felipe 4096 out  6 16:15 wlts-paper\n```\n\nAccess this directory and view its contents:\n\n``` sh\ncd wlts-paper\n\nls -l\n#> drwxrwxr-x 4 felipe felipe  4096 out  6 16:15 analysis\n#> -rw-rw-r-- 1 felipe felipe   261 out  6 16:15 docker-compose.dockerhub.yml\n#> -rw-rw-r-- 1 felipe felipe   324 out  6 16:15 docker-compose.local.yml\n#> -rw-rw-r-- 1 felipe felipe   735 out  6 16:15 Dockerfile\n#> -rw-rw-r-- 1 felipe felipe 10895 out  6 16:15 environment.yml\n#> drwxrwxr-x 4 felipe felipe  4096 out  6 16:15 figures\n#> -rw-rw-r-- 1 felipe felipe  3821 out  6 16:15 Makefile\n#> -rw-rw-r-- 1 felipe felipe 46436 out  6 16:15 README.md\n#> -rw-rw-r-- 1 felipe felipe 47304 out  6 16:15 README.Rmd\n#> -rw-rw-r-- 1 felipe felipe   226 out  6 16:15 wlts-paper.Rproj\n```\n\nIn the `wlts-paper` directory, notice the `docker-compose.local.yml`\nfile. This file contains the instructions for building and running this\nRC environment. So, with `Docker Compose`, use this file to build the\nDocker Image environment:\n\n``` sh\ndocker-compose -f docker-compose.local.yml build --no-cache\n```\n\nAfter the build, the Docker Image\n`brazildatacube/wlts-paper-environment:0.1-local` should be available in\nyour environment. So when you list the Docker Images on your machine,\nthis image should appear, as shown below:\n\n``` sh\ndocker image ls\n\n#> REPOSITORY                                TAG          IMAGE ID           CREATED         SIZE\n#> brazildatacube/wlts-paper-environment  0.1-local     ca5b517e098a   About a minute ago   5.09GB\n```\n\nYou can then start [Docker\nContainer](https://docs.docker.com/get-started/overview/#docker-objects)\nfrom the created Docker Image. To do this, use `Docker Compose` again:\n\n``` sh\ndocker-compose -f docker-compose.local.yml up\n```\n\nIf everything is correct so far, running the above command should\nproduce the output shown below:\n\n    (Omitted)\n\n    wlts-paper-environment-container | [C 2021-10-04 21:59:46.336 ServerApp] \n    wlts-paper-environment-container |     \n    wlts-paper-environment-container |     To access the server, open this file in a browser:\n    wlts-paper-environment-container |         file:///home/jovyan/.local/share/jupyter/runtime/jpserver-7-open.html\n    wlts-paper-environment-container |     Or copy and paste one of these URLs:\n    wlts-paper-environment-container |         http://bc26c6560801:8888/lab?token=8e487aba8f7b007a92ac3906b801f7e7fff299d0062c2cb1\n    wlts-paper-environment-container |      or http://127.0.0.1:8888/lab?token=8e487aba8f7b007a92ac3906b801f7e7fff299d0062c2cb1\n\nThis information allows access to the JupyterLab page. So, to access\nthis environment, copy the URL displayed in your terminal output that\nincludes the Jupyter access token. The copied address should look like\nthe one shown below:\n\n> Remember that this address and token vary with each run, so copy it\n> from your terminal. If you try to log in with the token shown below,\n> you will have problems using Jupyter.\n\n``` sh\nhttp://127.0.0.1:8888/lab?token=8e487aba8f7b007a92ac3906b801f7e7fff299d0062c2cb1\n```\n\nAfter copying the URL, access it using any browser of your choice. As an\nexample, to access this URL with firefox, you can use the command in the\nterminal:\n\n``` sh\nfirefox http://127.0.0.1:8888/lab?token=8e487aba8f7b007a92ac3906b801f7e7fff299d0062c2cb1\n```\n\nWhen you go there, you should see the JupyterLab page (Figure 3). Once\nyou have done this, you are ready to start executing the code in this\nRC. Go to the Section [Workflow execution](#workflow-execution).\n"
      },
      "source": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/README.Rmd",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Workflow execution",
        "parent_header": [
          "A plataform for land use and land cover data integration and trajectory analysis",
          "Running"
        ],
        "type": "Text_excerpt",
        "value": "> To follow the steps in this section, you must already have a\n> executable environment set up and ready to go. If not, please refer to\n> Section [Environment](#environment).\n\n> Note that for all the workflow execution code and configurations, it\n> will be assumed that the executions performed are **always** relative\n> to the directory `wlts-paper`. This directory contains all the\n> materials in this RC and is available in the environment configured\n> with the approaches presented in Section [Environment](#environment).\n\n> The **W**eb **L**and **T**rajectory **S**ervice (WLTS) and **W**eb\n> **L**and **C**over **C**lassification **S**ystem (WLCCS) services used\n> to run these notebooks are provided by the Brazil Data Cube (BDC)\n> project. However, to use these and other BDC services, creating a free\n> `access token` is necessary. If you do not have a BDC access token,\n> please refer to the BDC services [documentation](#) page for\n> information on creating one.\n\nThe materials provided in this RC complement the examples and explain\nhow we conducted the analyses in the paper. To consistently organize\nthese examples and analyses, we created a workflow consisting of three\nindependent parts in this RC. In all parts of the workflow, the codes\nwere organized into interactive Jupyter Notebooks, which explain the\noperations performed.\n\nFigure 8 illustrates the workflow parts and the Jupyter Notebooks that\ncompose them, along with their connections and orders. The execution of\neach of these parts does not depend on each other, making their\nexploration simpler. Below are the details of the elements that make up\nthe workflow presented. Afterward, we will describe the ways of using\nand executing this workflow.\n\n<div align=\"center\">\n\n<img src=\"./figures/workflow/png/workflow-overview.png\" width=\"100%\" style=\"display: block; margin: auto;\" />\n\n<b>Figure 8.</b> Workflow overview.\n\n</div>\n\n<br/>\n"
      },
      "source": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/README.Rmd",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Base operations",
        "parent_header": [
          "A plataform for land use and land cover data integration and trajectory analysis",
          "Running",
          "Parametrized batch using GNU Make"
        ],
        "type": "Text_excerpt",
        "value": "> The notebooks from this workflow step are available in the directory:\n> `analysis/scripts/wlts-operations`.\n\nThe `Base operations` is the part of the workflow that contains the\nexample code listings presented in the article. This workflow part has\ntwo Jupyter Notebooks:\n\n-   `wlts-operations-python.ipynb`: Jupyter Notebook with the example\n    code listings of Python client usage available for access to the\n    platform presented by Zioti *et al.* (2021);\n-   `wlts-operations-r.ipynb`: Jupyter Notebook with the R client\n    example code listings available for access to the platform presented\n    by Zioti *et al.* (2021).\n\nAs shown in Figure 8, both of these notebooks have no dependencies on\neach other, allowing them to be run in no particular order.\n"
      },
      "source": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/README.Rmd",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Alluvial Plot",
        "parent_header": [
          "A plataform for land use and land cover data integration and trajectory analysis",
          "Running",
          "Workflow execution"
        ],
        "type": "Text_excerpt",
        "value": "> The notebooks from this workflow step are available in the directory:\n> `analysis/scripts/alluvial-plot`.\n\nThe `Alluvial plot` is part of the workflow containing the codes used to\nproduce the alluvial plot presented by Zioti *et al.* (2021). This\nworkflow part has two Jupyter Notebooks:\n\n-   `1_wlts_alluvial-plot_data-extraction.ipynb`: Document with the\n    codes used for retrieving the LULC trajectories used as the basis\n    for producing the Alluvial plot;\n-   `2_wlts_alluvial-plot_data-visualization.ipynb`: Document with the\n    codes used to produce the Alluvial plot. Uses as a base the LULC\n    trajectories retrieved\u2019 in the notebook\n    `1_wlts_alluvial-plot_data-extraction.ipynb`.\n\nThus, as shown in Figure 8, the notebooks used for the generation of the\nalluvial plot have a dependency relationship, making the order of\nexecution relevant. When this relation is not preserved, there are\nproblems in the result production.\n"
      },
      "source": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/README.Rmd",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "LULC Trajectory comparison",
        "parent_header": [
          "A plataform for land use and land cover data integration and trajectory analysis",
          "Running",
          "Workflow execution"
        ],
        "type": "Text_excerpt",
        "value": "> The notebooks from this workflow step are available in the directory:\n> `analysis/scripts/lulc-trajectory-comparison`.\n\nThe `LULC Trajectory comparison` is the part of the workflow that\ncontains the codes used for producing the agreement analysis between\ntrajectories. For the production of this analysis. This workflow part\nhas two Jupyter Notebooks:\n\n-   `1_wlts-wlccs_lulc-trajectories-comparison_data-extraction.ipynb`:\n    Document with the codes for retrieving LULC trajectories;\n-   `2_wlts-wlccs_lulc-trajectories-comparison_analysis.ipynb`: Document\n    with the codes for producing the agreement analysis with the\n    trajectories retrieved in the notebook\n    `1_wlts-wlccs_lulc-trajectories-comparison_data-extraction.ipynb`.\n\nTherefore, as with the Alluvial plot, the execution of these notebooks\nhas an execution order, which is shown in Figure 8.\n"
      },
      "source": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/README.Rmd",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Parametrized batch using GNU Make",
        "parent_header": [
          "A plataform for land use and land cover data integration and trajectory analysis",
          "Running"
        ],
        "type": "Text_excerpt",
        "value": "> You must run the codes presented in this section in an environment\n> with the dependencies presented in the\n> [environment.yml](environment.yml). If necessary, please refer to\n> Section [Environment](#environment) to configure your environment.\n\nThe first workflow execution mode for this RC is the parameterized\nbatch. Here, each of the parts of the workflow is executed individually,\nfrom start to finish, without any user interaction. This execution mode\nis recommended for the users who wish to obtain the results without\nhaving to access and run the notebooks manually.\n\nTo implement this execution mode, the following tools were used:\n\n-   [GNU Make](https://www.gnu.org/software/make/): Para a modelagem e\n    execu\u00e7\u00e3o do workflow;\n-   [Papermill](https://papermill.readthedocs.io/en/latest/): Ferramenta\n    para a execu\u00e7\u00e3o parametrizada, via terminal, de Jupyter Notebooks.\n\nBy using these tools together, we model all the parts of the workflow\nand manage its execution without the need to modify the code or even\nchange the format (e.g., take the code out of Jupyter Notebooks and send\nit to conventional Python scripts).\n"
      },
      "source": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/README.Rmd",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Makefile",
        "parent_header": [
          "A plataform for land use and land cover data integration and trajectory analysis",
          "Running",
          "Parametrized batch using GNU Make"
        ],
        "type": "Text_excerpt",
        "value": "> If the reader is interested in learning `Make`, please see the page\n> [Reproducibility with\n> Make](https://the-turing-way.netlify.app/reproducible-research/make.html).\n\nTo use `GNU Make`, we have made a `Makefile` that materializes the whole\nworkflow through [make\nrules](https://www.gnu.org/software/make/manual/html_node/Rules.html).\nThe following rules are available:\n\n> **Tip**: To view these rules directly from the Makefile, you can run\n> the command in the root directory of this RC: `make help`.\n\n    alluvial-plot                  (Workflow) Execute the notebooks to generate the Alluvial Plot presented in the paper.\n    all                            (Workflow) Execute all workflow steps.\n    clean                          (Workflow) Remove all workflow results.\n    generate-make-graph            (Miscellaneous) Generate a graph from the Makefile rules\n    lulc-trajectory-comparison     (Workflow) Execute the notebooks to generate the Agreement analysis presented in the paper.\n    wlts-operations                (Workflow) Execute the notebooks with the WLTS and WLCCS base operations presented in the paper.\n\nEach of the `wlts-operations`, `alluvial-plot`, and\n`lulc-trajectory-comparison` rules represent the parts of the workflow\npresented above. Additionally, the rules `all` and `clean` are used\nrespectively for performing all the workflow steps and cleaning up all\nthe results generated by the notebooks.\n\nThe connection of all these rules can be seen as a dependency graph,\nwhich is generated with the\n[makefile2graph](https://github.com/lindenb/makefile2graph) tool .\n\n<details>\n<summary>\nClick here to visualize the Makefile dependencies graph\n</summary>\n\n<div align=\"center\">\n\n<img src=\"./figures/makegraph.png\" width=\"100%\" style=\"display: block; margin: auto;\" />\n\n<b>Figure 9.</b> Makefile dependency graph.\n\n</div>\n\n</details>\n\n<br>\n\nIn the following sections, how each of these rules is used to execute\nthis RC workflow will be presented.\n"
      },
      "source": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/README.Rmd",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Parameterization",
        "parent_header": [
          "A plataform for land use and land cover data integration and trajectory analysis",
          "Running",
          "Parametrized batch using GNU Make"
        ],
        "type": "Text_excerpt",
        "value": "Batch mode execution, once started, does not allow user interaction\nuntil its completion. However, in this RC, an `access token` is required\nto retrieve the trajectories from the WLTS and WLCCS services provided\nby the BDC project.\n\nTo avoid having to specify this `access token` to each Jupyter Notebook\nbefore execution in batch mode, we use the notebook execution\nparameterization capabilities provided by the `papermill`. This\n`papermill` functionality allows all notebooks that require this\ninformation to receive it from a single definition of the\n`access token`, made in a configuration file.\n\nThus, before starting executions of the parts of the workflow, it is\nnecessary to create this configuration file. In this RC, this\nconfiguration file is in the path\n`analysis/data/raw_data/workflow_parameters.yml`. When you access it,\nyou will see a file with the following format:\n\n> Remember that the path `analysis/data/raw_data/` is relative to the RC\n> root directory. So, for example, if you use the environment set up\n> with some of the approaches presented in Section\n> [Environment](#environment), this path will be relative to the\n> `wlts-paper` directory.\n\n    bdc_access_token: \"YOUR-BDC-SERVICES-TOKEN-HERE\"\n\nChange the file\u2019s contents, replacing the text\n`YOUR-BDC-SERVICES-TOKEN-HERE` with your BDC `access token`. By doing\nthis, you are now ready to run the workflow in batch mode.\n\n<details>\n<summary>\nClick here for the step-by-step configuration of the access token\nparameter (Optional)\n</summary>\n\n<br/>\n\n> If you are having trouble setting up the `workflow_parameters.yml`\n> file, use the steps below. If you have already done the setup, it is\n> not necessary to follow these steps.\n\n> This step-by-step assumes that you are using the environment\n> configured with one of the approaches presented in Section\n> [Environment](#environment).\n\nFrom the JupyterLab initial page, go to the `wlts-paper` directory:\n\n<div align=\"center\">\n\n<img src=\"./figures/running/make/png/configure-token-1.png\" width=\"80%\" style=\"display: block; margin: auto;\" />\n\n<b>Figure 10.</b> Selection of `wlts-paper` directory on JupyterLab.\n\n</div>\n\n<br/>\n\nThen go to the `analysis` directory:\n\n<div align=\"center\">\n\n<img src=\"./figures/running/make/png/configure-token-2.png\" width=\"80%\" style=\"display: block; margin: auto;\" />\n\n<b>Figure 11.</b> Selection of `analysis` directory on JupyterLab.\n\n</div>\n\n<br/>\n\nInside the `analysis` directory, go to the `data` directory:\n\n<div align=\"center\">\n\n<img src=\"./figures/running/make/png/configure-token-3.png\" width=\"80%\" style=\"display: block; margin: auto;\" />\n\n<b>Figure 12.</b> Selection of `data` directory on JupyterLab.\n\n</div>\n\n<br/>\n\nNow go to the `raw_data` directory, where the files and data used as\ninput in the workflow are:\n\n<div align=\"center\">\n\n<img src=\"./figures/running/make/png/configure-token-4.png\" width=\"80%\" style=\"display: block; margin: auto;\" />\n\n<b>Figure 13.</b> Selection of `raw_data` directory on JupyterLab.\n\n</div>\n\n<br/>\n\nIn the `raw_data` directory, you will see the `workflow_parameters.yml`\nfile. Open this file:\n\n<div align=\"center\">\n\n<img src=\"./figures/running/make/png/configure-token-5.png\" width=\"80%\" style=\"display: block; margin: auto;\" />\n\n<b>Figure 14.</b> Selection of `workflow_parameters.yml` file on\nJupyterLab.\n\n</div>\n\n<br/>\n\nWith the `workflow_parameters.yml` file open, change the\n`bdc_access_token` key, replacing the text\n`YOUR-BDC-SERVICES-TOKEN-HERE` with your `access token` from BDC.\n\n<div align=\"center\">\n\n<img src=\"./figures/running/make/png/configure-token-6.png\" width=\"80%\" style=\"display: block; margin: auto;\" />\n\n<b>Figure 15.</b> Configuration of `bdc_access_token` in\n`workflow_parameters.yml` file on JupyterLab.\n\n</div>\n\n<br/>\n\nNow you have the `access token` parameter set and ready to be used in\nthe batch run of this RC workflow.\n\n</details>\n\n<br/>\n\n#### Base operations\n\nThe first part of the workflow to be presented is `Base operations`. As\nmentioned earlier, this part has the code listings presented by Zioti\n*et al.* (2021). To run this part, you need to be in the RC root\ndirectory. Once you are in the root directory, run the command:\n\n``` sh\nmake wlts-operations\n```\n\nIn general, when this execution is performed, you have the execution\nflow shown in Figure 13. Based on the `wlts-operations` rule, the\n`GNU Make` uses the `papermill` and does the parameterized execution of\nboth notebooks in this step.\n\n<div align=\"center\">\n\n<img src=\"./figures/workflow/png/workflow_base-operations.png\" width=\"80%\" style=\"display: block; margin: auto;\" />\n\n<b>Figure 16.</b> `Base operations` execution flow.\n\n</div>\n\nThe results are available in the directory\n`analysis/data/derived_data/base-operations` at the end of the run. When\nlisting this directory, the following content should be presented:\n\n> Remember that the path `analysis/data/derived_data/base-operations` is\n> relative to the RC root directory. So, for example, if you are using\n> the environment set up with some of the approaches presented in\n> Section [Environment](#environment), this path will be relative to the\n> `wlts-paper` directory.\n\n``` sh\nls -l analysis/data/derived_data/base-operations\n\n#> total 12\n#> -rw-r--r-- 1 root root 1536 Oct  6 15:28 listing1_python.csv\n#> -rw-r--r-- 1 root root 1866 Oct  6 15:28 listing1_r.csv\n#> -rw-r--r-- 1 root root  639 Oct  6 15:28 listing3_python.csv\n```\n\nNote also that the outputs from each cell in the notebooks are persisted\nin the documents themselves. See the notebooks run in the\n`analysis/scripts/wlts-operations/` directory to view these details.\n\n<details>\n<summary>\nClick here for the step-by-step execution (Optional)\n</summary>\n\n<br/>\n\n> If you have trouble executing the `wlts-operations` rule from `make`,\n> follow the steps below.\n\n> This step-by-step assumes that you are using the environment\n> configured with one of the approaches presented in Section\n> [Environment](#environment).\n\nFirst, go to `Terminal` in the JupyterLab interface:\n\n<div align=\"center\">\n\n<img src=\"./figures/running/make/png/wlts-operations-1.png\" width=\"80%\" style=\"display: block; margin: auto;\" />\n\n<b>Figure 17.</b> Terminal selection on JupyterLab menu.\n\n</div>\n\n<br/>\n\nIn the terminal, go to `wlts-paper`, the directory where this RC is\nstored in the environment. Then run the `make wlts-operations` command:\n\n<div align=\"center\">\n\n<img src=\"./figures/running/make/png/wlts-operations-2.png\" width=\"80%\" style=\"display: block; margin: auto;\" />\n\n<b>Figure 18.</b> `make wlts-operations` on JupyterLab terminal.\n\n</div>\n\n<br/>\n\nWhen the execution starts, the terminal will display bars with the\nprogress of the operation:\n\n<div align=\"center\">\n\n<img src=\"./figures/running/make/png/wlts-operations-3.png\" width=\"80%\" style=\"display: block; margin: auto;\" />\n\n<b>Figure 19.</b> `make wlts-operations` progress bar.\n\n</div>\n\n<br/>\n\nThe generated results will be saved in the directory\n`analysis/data/derived_data/base-operations`.\n\n</details>\n\n<br/>\n"
      },
      "source": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/README.Rmd",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Alluvial plot",
        "parent_header": [
          "A plataform for land use and land cover data integration and trajectory analysis",
          "Running",
          "Parametrized batch using GNU Make"
        ],
        "type": "Text_excerpt",
        "value": "In `Alluvial plot`, as mentioned, the Jupyter Notebooks are executed to\ngenerate the alluvial plot. The execution of this part of the workflow\nis analogous to that presented in `Base operations`. First, go to the\nroot directory where the RC is stored. Then run the `alluvial-plot`\nrule:\n\n``` sh\nmake alluvial-plot\n```\n\nIn the execution, first, the\n`1_wlts_alluvial-plot_data-extraction.ipynb` notebook is run, which will\nretrieve the LULC trajectories. After completing the first notebook, the\n`2_wlts_alluvial-plot_data-visualization.ipynb` notebook is executed,\ngenerating the alluvial plot. This flow is summarized in Figure 20.\n\n<div align=\"center\">\n\n<img src=\"./figures/workflow/png/workflow_alluvial-plot.png\" width=\"80%\" style=\"display: block; margin: auto;\" />\n\n<b>Figure 20.</b> `Alluvial plot` execution flow.\n\n</div>\n\n<br/>\n\nThe results are available in the directory\n`analysis/data/derived_data/alluvial-plot` at the end of the run. When\nlisting this directory, the following content should be presented:\n\n> Remember that the path `analysis/data/derived_data/alluvial-plot` is\n> relative to the RC root directory. So, for example, if you are using\n> the environment set up with some of the approaches presented in\n> Section [Environment](#environment), this path will be relative to the\n> `wlts-paper` directory.\n\n``` sh\nls -l analysis/data/derived_data/alluvial-plot\n\n#> total 1432\n#> -rw-r--r-- 1 root root 1384790 Oct  6 17:32 plot_alluvial_terraclass_amz.png\n#> -rw-r--r-- 1 root root   74375 Oct  6 17:30 sao-felix-do-xingu_trajectories.rds\n```\n\nNote also that the outputs from each cell in the notebooks are persisted\nin the documents themselves. See the notebooks run in the\n`analysis/scripts/alluvial-plot/` directory to view these details.\n\n<details>\n<summary>\nClick here for the step-by-step execution (Optional)\n</summary>\n\n<br/>\n\n> If you have trouble executing the `alluvial-plot` rule from `make`,\n> follow the steps below.\n\n> This step-by-step assumes that you are using the environment\n> configured with one of the approaches presented in Section\n> [Environment](#environment).\n\nFirst, go to `Terminal` in the JupyterLab interface:\n\n<div align=\"center\">\n\n<img src=\"./figures/running/make/png/alluvial-plot-1.png\" width=\"80%\" style=\"display: block; margin: auto;\" />\n\n<b>Figure 21.</b> Terminal selection on JupyterLab menu.\n\n</div>\n\n<br/>\n\nIn the terminal, go to `wlts-paper`, the directory where this RC is\nstored in the environment. Then run the `make alluvial-plot` command:\n\n<div align=\"center\">\n\n<img src=\"./figures/running/make/png/alluvial-plot-2.png\" width=\"80%\" style=\"display: block; margin: auto;\" />\n\n<b>Figure 22.</b> `make alluvial-plot` on JupyterLab terminal.\n\n</div>\n\n<br/>\n\nWhen the execution starts, the terminal will display bars with the\nprogress of the operation:\n\n<div align=\"center\">\n\n<img src=\"./figures/running/make/png/alluvial-plot-3.png\" width=\"80%\" style=\"display: block; margin: auto;\" />\n\n<b>Figure 23.</b> `make alluvial-plot` progress bar.\n\n</div>\n\n<br/>\n\nThe generated results will be saved in the directory\n`analysis/data/derived_data/alluvial-plot/`.\n\n</details>\n\n<br/>\n"
      },
      "source": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/README.Rmd",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "LULC Trajectory Comparison",
        "parent_header": [
          "A plataform for land use and land cover data integration and trajectory analysis",
          "Running",
          "Parametrized batch using GNU Make"
        ],
        "type": "Text_excerpt",
        "value": "In the last of the operations, `LULC Trajectory Comparison`, as seen\nearlier, one produces an agreement analysis between trajectories from\ntwo distinct data collections. The execution of this operation can be\ndone at the root of this RC using the `lulc-trajectory-comparison` rule:\n\n``` sh\nmake lulc-trajectory-comparison\n```\n\nFigure 24 shows the general execution flow of this rule. First, the\n`1_wlts-wlccs_lulc-trajectories-comparison_data-extraction.ipynb`\nnotebook is executed. This notebook retrieves the trajectories from two\ndata collections. This data is then used as input to run the notebook\n`2_wlts-wlccs_lulc-trajectories-comparison_analysis.ipynb`.\n\n<div align=\"center\">\n\n<img src=\"./figures/workflow/png/workflow_lulc-comparison.png\" width=\"80%\" style=\"display: block; margin: auto;\" />\n\n<b>Figure 24.</b> `LULC Trajectory Comparison` execution flow.\n\n</div>\n\n<br/>\n\nThe results are available in the directory\n`analysis/data/derived_data/lulc-trajectory-comparison` at the end of\nthe run. When listing this directory, the following content should be\npresented:\n\n> Remember that the path\n> `analysis/data/derived_data/lulc-trajectory-comparison` is relative to\n> the RC root directory. So, for example, if you are using the\n> environment set up with some of the approaches presented in Section\n> [Environment](#environment), this path will be relative to the\n> `wlts-paper` directory.\n\n``` sh\nls -l analysis/data/derived_data/lulc-trajectory-comparison\n\n#> total 2100\n#> -rw-r--r-- 1 root root  311930 Oct  6 19:29 harmonized-trajectories_download_2021-10-06_15-28-17_825991.log\n#> -rw-r--r-- 1 root root 1818889 Oct  6 19:29 harmonized-trajectories_mapbiomas-terraclass_2014.json\n#> -rw-r--r-- 1 root root    3502 Oct  6 19:29 trajectory-concordance_tc-mb-2014.csv\n#> -rw-r--r-- 1 root root     176 Oct  6 19:29 trajectory-concordance_tc-mb-2014_matrix.csv\n```\n\nNote also that the outputs from each cell in the notebooks are persisted\nin the documents themselves. See the notebooks run in the\n`analysis/scripts/lulc-trajectory-comparison/` directory to view these\ndetails.\n\n<details>\n<summary>\nClick here for the step-by-step execution (Optional)\n</summary>\n\n<br/>\n\n> If you have trouble executing the `lulc-trajectory-comparison` rule\n> from `make`, follow the steps below.\n\n> This step-by-step assumes that you are using the environment\n> configured with one of the approaches presented in Section\n> [Environment](#environment).\n\nFirst, go to `Terminal` in the JupyterLab interface:\n\n<div align=\"center\">\n\n<img src=\"./figures/running/make/png/lulc-trajectory-comparison-1.png\" width=\"80%\" style=\"display: block; margin: auto;\" />\n\n<b>Figure 25.</b> Terminal selection on JupyterLab menu.\n\n</div>\n\n<br/>\n\nIn the terminal, go to `wlts-paper`, the directory where this RC is\nstored in the environment. Then run the\n`make lulc-trajectory-comparison` command:\n\n<div align=\"center\">\n\n<img src=\"./figures/running/make/png/lulc-trajectory-comparison-2.png\" width=\"80%\" style=\"display: block; margin: auto;\" />\n\n<b>Figure 26.</b> `make lulc-trajectory-comparison` on JupyterLab\nterminal.\n\n</div>\n\n<br/>\n\nWhen the execution starts, the terminal will display bars with the\nprogress of the operation:\n\n<div align=\"center\">\n\n<img src=\"./figures/running/make/png/lulc-trajectory-comparison-3.png\" width=\"80%\" style=\"display: block; margin: auto;\" />\n\n<b>Figure 27.</b> `make lulc-trajectory-comparison` progress bar.\n\n</div>\n\n<br/>\n\nThe generated results will be saved in the directory\n`analysis/data/derived_data/lulc-trajectory-comparison/`.\n\n</details>\n\n<br/>\n"
      },
      "source": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/README.Rmd",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Interactive execution",
        "parent_header": [
          "A plataform for land use and land cover data integration and trajectory analysis",
          "Running"
        ],
        "type": "Text_excerpt",
        "value": "In addition to the parameterized batch execution of Jupyter Notebooks,\nit is also possible to make interactive and individual execution of each\ndocument. This approach is recommended for those interested in\nunderstanding the steps performed in the code to produce the results.\n\nIn the interactive approach, for the executions, unlike the batch\noperations, there is no previous configuration to be done; everything is\nconfigured directly on each of the notebooks. Thus, for interactive\nexecution, you must consider two points:\n\n-   `Access token definition`: The definition of the `access token` must\n    be made on each of the notebooks individually. Instructions on where\n    to insert this `token` are available in the documents themselves;\n-   `Specifying the input/output directories`: By default, the notebooks\n    are configured to run, considering the RC root as the working\n    directory. However, this premise does not hold when changing the\n    directory in the JupyterLab interface to access the notebooks and\n    then make their interactive execution. Thus, it is necessary to\n    change the reference of the input and output directories considering\n    the directory where the notebook is stored. To exemplify the\n    necessary change, consider the organizational structure of this RC\n    in the environment configured in Section\n    [Environment](#environment):\n\n> As mentioned, in the environment configured with the steps presented\n> in Section [Environment](#environment), the RC root is represented by\n> the `wlts-paper` directory.\n\n    \u2514\u2500\u2500 wlts-paper\n        \u251c\u2500\u2500 data\n        \u2502    \u251c\u2500\u2500 raw_data\n        \u2502    \u2514\u2500\u2500 derived_data\n        \u2514\u2500\u2500 scripts \n            \u251c\u2500\u2500 alluvial-plot\n            \u251c\u2500\u2500 wlts-operations\n            \u2514\u2500\u2500 lulc-trajectory-comparison\n\nIn the default configuration, notebooks execute considering paths\nrelative to `wlts-paper`. So, for example, the output directory of the\n`alluvial plot`, in the source code is:\n\n    output_directory <- \"analysis/data/derived_data/alluvial-plot\"\n\nHowever, if you are in the `wlts-paper/scripts/alluvial-plot` directory,\nrunning the notebook, the path\n`analysis/data/derived_data/alluvial-plot` may fail. Therefore, a change\nis needed that allows the notebook code to use the same directories. In\nthis case, the necessary change transforms the output path definition to\nthe following variable:\n\n    output_directory <- \"../../data/derived_data/alluvial-plot\"\n\nThis change will make the code look for two directory levels above the\ncurrent one for the `data` directory, when is considered that the\nrunning is done directly from the `wlts-paper/scripts/alluvial-plot`\ndirectory.\n\nThis change should be considered on all notebooks when interactive\nexecution is being performed.\n"
      },
      "source": "https://raw.githubusercontent.com/brazil-data-cube/wlts-paper/master/README.Rmd",
      "technique": "header_analysis"
    }
  ]
}