{
  "application_domain": [
    {
      "confidence": 30.21,
      "result": {
        "type": "String",
        "value": "Reinforcement Learning"
      },
      "technique": "supervised_classification"
    }
  ],
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/Pulkit-Khandelwal/Reinforcement-Learning-Notebooks"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2018-06-02T23:37:52Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2024-09-26T18:25:57Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "A collection of Reinforcement Learning algorithms from Sutton and Barto's book and other research papers implemented in Python."
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 0.9683021552278375,
      "result": {
        "original_header": "A collection of Reinforcement Learning algorithms from Sutton and Barto's book and other research papers implemented in Python.",
        "type": "Text_excerpt",
        "value": "These notebooks should be used while you read the book and go beyond the same with the referenced papers. I would suggest watching David Silver's videos and reading the book simultaneously. And when you are done with a few chapters, start implementing them. The algorithms follow a pattern and mostly are variants of each other. I have tried my best to explain each notebook's results and possible future directions. \n\nDisclaimer: The code is a little messy. I'd written this when I was not a Pythonista. If you would like to clean them up and want to make it into a nice interface, feel free to contact me. I will be very pleased to collaborate. If you use them then please cite the source and also mention the credits as listed below. Also, email me with ways to improve, let me know if you find any bugs. \n"
      },
      "source": "https://raw.githubusercontent.com/Pulkit-Khandelwal/Reinforcement-Learning-Notebooks/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/Pulkit-Khandelwal/Reinforcement-Learning-Notebooks/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "executable_example": [
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Pulkit-Khandelwal/Reinforcement-Learning-Notebooks/master/Real%20Time%20Dynamic%20Programming/gauss_seidel_VI.ipynb"
      },
      "source": "https://raw.githubusercontent.com/Pulkit-Khandelwal/Reinforcement-Learning-Notebooks/master/Real%20Time%20Dynamic%20Programming/gauss_seidel_VI.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Pulkit-Khandelwal/Reinforcement-Learning-Notebooks/master/Real%20Time%20Dynamic%20Programming/Policy_Evaluation.ipynb"
      },
      "source": "https://raw.githubusercontent.com/Pulkit-Khandelwal/Reinforcement-Learning-Notebooks/master/Real%20Time%20Dynamic%20Programming/Policy_Evaluation.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Pulkit-Khandelwal/Reinforcement-Learning-Notebooks/master/Emphatic%20Temporal-Difference%20Learning/Emphatic_TD.ipynb"
      },
      "source": "https://raw.githubusercontent.com/Pulkit-Khandelwal/Reinforcement-Learning-Notebooks/master/Emphatic%20Temporal-Difference%20Learning/Emphatic_TD.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Pulkit-Khandelwal/Reinforcement-Learning-Notebooks/master/Temporal-Difference%20Learning%20by%20Harm%20van%20Seijen/TD_FA_True_Online_lambda.ipynb"
      },
      "source": "https://raw.githubusercontent.com/Pulkit-Khandelwal/Reinforcement-Learning-Notebooks/master/Temporal-Difference%20Learning%20by%20Harm%20van%20Seijen/TD_FA_True_Online_lambda.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Pulkit-Khandelwal/Reinforcement-Learning-Notebooks/master/TD%20Control%20methods%20-%20Expected%20SARSA/td_learning_3_cliff_walking.ipynb"
      },
      "source": "https://raw.githubusercontent.com/Pulkit-Khandelwal/Reinforcement-Learning-Notebooks/master/TD%20Control%20methods%20-%20Expected%20SARSA/td_learning_3_cliff_walking.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Pulkit-Khandelwal/Reinforcement-Learning-Notebooks/master/TD%20Control%20methods%20-%20Expected%20SARSA/td_learning_3_windy_grid.ipynb"
      },
      "source": "https://raw.githubusercontent.com/Pulkit-Khandelwal/Reinforcement-Learning-Notebooks/master/TD%20Control%20methods%20-%20Expected%20SARSA/td_learning_3_windy_grid.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Pulkit-Khandelwal/Reinforcement-Learning-Notebooks/master/TD%20Control%20methods%20-%20Expected%20SARSA/td_learning_3_grid_world.ipynb"
      },
      "source": "https://raw.githubusercontent.com/Pulkit-Khandelwal/Reinforcement-Learning-Notebooks/master/TD%20Control%20methods%20-%20Expected%20SARSA/td_learning_3_grid_world.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Pulkit-Khandelwal/Reinforcement-Learning-Notebooks/master/Q%28sigma%29%20and%20multi-step%20bootstrapping%20methods/n_step_importance_sampling_cliff.ipynb"
      },
      "source": "https://raw.githubusercontent.com/Pulkit-Khandelwal/Reinforcement-Learning-Notebooks/master/Q%28sigma%29%20and%20multi-step%20bootstrapping%20methods/n_step_importance_sampling_cliff.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Pulkit-Khandelwal/Reinforcement-Learning-Notebooks/master/Q%28sigma%29%20and%20multi-step%20bootstrapping%20methods/n_step_windy_grid.ipynb"
      },
      "source": "https://raw.githubusercontent.com/Pulkit-Khandelwal/Reinforcement-Learning-Notebooks/master/Q%28sigma%29%20and%20multi-step%20bootstrapping%20methods/n_step_windy_grid.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Pulkit-Khandelwal/Reinforcement-Learning-Notebooks/master/Q%28sigma%29%20and%20multi-step%20bootstrapping%20methods/n_step_cliff.ipynb"
      },
      "source": "https://raw.githubusercontent.com/Pulkit-Khandelwal/Reinforcement-Learning-Notebooks/master/Q%28sigma%29%20and%20multi-step%20bootstrapping%20methods/n_step_cliff.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Pulkit-Khandelwal/Reinforcement-Learning-Notebooks/master/Q%28sigma%29%20and%20multi-step%20bootstrapping%20methods/n_step_importance_sampling_ratio_windy_grid.ipynb"
      },
      "source": "https://raw.githubusercontent.com/Pulkit-Khandelwal/Reinforcement-Learning-Notebooks/master/Q%28sigma%29%20and%20multi-step%20bootstrapping%20methods/n_step_importance_sampling_ratio_windy_grid.ipynb",
      "technique": "file_exploration"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 200
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/Pulkit-Khandelwal/Reinforcement-Learning-Notebooks/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "Pulkit-Khandelwal/Reinforcement-Learning-Notebooks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "Reinforcement-Learning-Notebooks"
      },
      "source": "https://raw.githubusercontent.com/Pulkit-Khandelwal/Reinforcement-Learning-Notebooks/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "installation": [
    {
      "confidence": 0.9748745873119394,
      "result": {
        "original_header": "A collection of Reinforcement Learning algorithms from Sutton and Barto's book and other research papers implemented in Python.",
        "type": "Text_excerpt",
        "value": "\nDisclaimer: The code is a little messy. I'd written this when I was not a Pythonista. If you would like to clean them up and want to make it into a nice interface, feel free to contact me. I will be very pleased to collaborate. If you use them then please cite the source and also mention the credits as listed below. Also, email me with ways to improve, let me know if you find any bugs. \n"
      },
      "source": "https://raw.githubusercontent.com/Pulkit-Khandelwal/Reinforcement-Learning-Notebooks/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/Pulkit-Khandelwal/Reinforcement-Learning-Notebooks/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ""
      },
      "technique": "GitHub_API"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "Reinforcement-Learning-Notebooks"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "User",
        "value": "Pulkit-Khandelwal"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Jupyter Notebook",
        "size": 3728987,
        "type": "Programming_language",
        "value": "Jupyter Notebook"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 13729,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Pulkit-Khandelwal/Reinforcement-Learning-Notebooks/master/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "somef_missing_categories": [
    "citation",
    "acknowledgement",
    "run",
    "download",
    "requirements",
    "contact",
    "contributors",
    "documentation",
    "license",
    "usage",
    "faq",
    "support",
    "identifier",
    "has_build_file"
  ],
  "somef_provenance": {
    "date": "2024-10-04 00:30:58",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 1047
      },
      "technique": "GitHub_API"
    }
  ]
}