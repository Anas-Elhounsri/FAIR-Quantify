{
  "application_domain": [
    {
      "confidence": 91.65,
      "result": {
        "type": "String",
        "value": "Natural Language Processing"
      },
      "technique": "supervised_classification"
    }
  ],
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/elangovana/PPI-typed-relation-extractor"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2018-05-13T10:05:22Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2023-10-27T18:30:46Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "Relation extraction for protein to protein interactions to extraction strongly typed PPI relations.. My research topic.. So work in progress"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 0.9964824873058366,
      "result": {
        "original_header": "PPI typed relation extraction",
        "type": "Text_excerpt",
        "value": "Protein - protein interactions (PPI) play a very important role in various aspects of cell biology (Zhou & He, 2008). The PPI interactions form complex networks and can be represented as a graph, where each node represents a protein and an edge represents a type of relationship between the 2 proteins.\nManually curating these networks by reading journals and regularly maintaining them with the latest information is beyond human lifespan (Baumgartner, Cohen, Fox, Acquaah-Mensah, & Hunter, 2007). \n \n"
      },
      "source": "https://raw.githubusercontent.com/elangovana/PPI-typed-relation-extractor/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8413919639345909,
      "result": {
        "original_header": "Task definition",
        "type": "Text_excerpt",
        "value": "For instance, in the sentence \u201cFull-length cPLA2 was phosphorylated stoichiometrically by p42 mitogen-activated protein (MAP) kinase  in vitro\u201d , \n-\tThe protein name recognition phase recognizes \u201ccPLA2\u201d & \u201cp42 mitogen-activated protein (MAP) kinase\u201d as protein names. Some entity recognition tasks also involve recognizing the entity roles, such as \u201ccPLA2\u201d as the theme or the target protein, and \u201cp42 mitogen-activated protein (MAP) kinase\u201d as the agent protein or the source of the interaction.\n-\tThe protein-protein interaction extraction task recognizes \u201cphosphorylate\u201d as the relationship between \u201ccPLA2\u201d & \u201cp42 mitogen-activated protein (MAP) kinase\u201d. \n"
      },
      "source": "https://raw.githubusercontent.com/elangovana/PPI-typed-relation-extractor/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "documentation": [
    {
      "confidence": 1,
      "result": {
        "format": "wiki",
        "type": "Url",
        "value": "https://github.com/elangovana/PPI-typed-relation-extractor/wiki"
      },
      "source": "https://raw.githubusercontent.com/elangovana/PPI-typed-relation-extractor/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "download": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Download IMEX raw xml files from intact",
        "parent_header": [
          "PPI typed relation extraction",
          "Run via Docker",
          "Download and analyse the dataset with elastic search"
        ],
        "type": "Text_excerpt",
        "value": "\n1. Download dataset from Imex ftp site ftp.ebi.ac.uk\n    ```bash\n    basedata=/home/ubuntu/data\n \n    sudo docker run -v ${basedata}:/data  lanax/kegg-pathway-extractor:latest scripts/dowloadintactinteractions.sh /data  \"<filepattern e.g. human*.xml>\" \"<optional s3 destination>\"\n    ```\n"
      },
      "source": "https://raw.githubusercontent.com/elangovana/PPI-typed-relation-extractor/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Optional: Visualise through elastic search on AWS",
        "parent_header": [
          "PPI typed relation extraction",
          "Run via Docker",
          "Download and analyse the dataset with elastic search"
        ],
        "type": "Text_excerpt",
        "value": "1. Sample download intact files with pattern human0* and elastic search index\n    ```bash\n    region=$1\n    esdomain=$2\n    accesskey=$3\n    accesssecret=$4\n    s3path=$5\n \n    basedata=/home/ubuntu/data\n    file_pattern=human0*\n \n    script=scripts/run_pipeline_download_esindex.sh\n    sudo docker run -v ${basedata}:/data --env elasticsearch_domain_name=$esdomain --env AWS_ACCESS_KEY_ID=$accesskey   --env AWS_REGION=$region --env AWS_SECRET_ACCESS_KEY=$accesssecret lanax/kegg-pathway-extractor:latest $script /data $file_pattern $s3path \n    ```\n\n"
      },
      "source": "https://raw.githubusercontent.com/elangovana/PPI-typed-relation-extractor/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/elangovana/PPI-typed-relation-extractor/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "executable_example": [
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/elangovana/PPI-typed-relation-extractor/master/Sagemaker%20-%20AIMED%20all%20experiments.ipynb"
      },
      "source": "https://raw.githubusercontent.com/elangovana/PPI-typed-relation-extractor/master/Sagemaker%20-%20AIMED%20all%20experiments.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/elangovana/PPI-typed-relation-extractor/master/AIMedDataExploration-Ylhsieh.ipynb"
      },
      "source": "https://raw.githubusercontent.com/elangovana/PPI-typed-relation-extractor/master/AIMedDataExploration-Ylhsieh.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/elangovana/PPI-typed-relation-extractor/master/Sagemaker-Bert.ipynb"
      },
      "source": "https://raw.githubusercontent.com/elangovana/PPI-typed-relation-extractor/master/Sagemaker-Bert.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/elangovana/PPI-typed-relation-extractor/master/TokeniserAnalysis.ipynb"
      },
      "source": "https://raw.githubusercontent.com/elangovana/PPI-typed-relation-extractor/master/TokeniserAnalysis.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/elangovana/PPI-typed-relation-extractor/master/Sagemaker-AIMed.ipynb"
      },
      "source": "https://raw.githubusercontent.com/elangovana/PPI-typed-relation-extractor/master/Sagemaker-AIMed.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/elangovana/PPI-typed-relation-extractor/master/Training%20verifcation.ipynb"
      },
      "source": "https://raw.githubusercontent.com/elangovana/PPI-typed-relation-extractor/master/Training%20verifcation.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/elangovana/PPI-typed-relation-extractor/master/training_groundtruth.ipynb"
      },
      "source": "https://raw.githubusercontent.com/elangovana/PPI-typed-relation-extractor/master/training_groundtruth.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/elangovana/PPI-typed-relation-extractor/master/ResultsExplorer.ipynb"
      },
      "source": "https://raw.githubusercontent.com/elangovana/PPI-typed-relation-extractor/master/ResultsExplorer.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/elangovana/PPI-typed-relation-extractor/master/DataAnalysisBioCreativeMutation.ipynb"
      },
      "source": "https://raw.githubusercontent.com/elangovana/PPI-typed-relation-extractor/master/DataAnalysisBioCreativeMutation.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/elangovana/PPI-typed-relation-extractor/master/Sagemaker.ipynb"
      },
      "source": "https://raw.githubusercontent.com/elangovana/PPI-typed-relation-extractor/master/Sagemaker.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/elangovana/PPI-typed-relation-extractor/master/LargeScalePredictionAnalysis.ipynb"
      },
      "source": "https://raw.githubusercontent.com/elangovana/PPI-typed-relation-extractor/master/LargeScalePredictionAnalysis.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/elangovana/PPI-typed-relation-extractor/master/ResultsExplorer-Untyped.ipynb"
      },
      "source": "https://raw.githubusercontent.com/elangovana/PPI-typed-relation-extractor/master/ResultsExplorer-Untyped.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/elangovana/PPI-typed-relation-extractor/master/AIMedDataExploration.ipynb"
      },
      "source": "https://raw.githubusercontent.com/elangovana/PPI-typed-relation-extractor/master/AIMedDataExploration.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/elangovana/PPI-typed-relation-extractor/master/ClassificationDataExploration.ipynb"
      },
      "source": "https://raw.githubusercontent.com/elangovana/PPI-typed-relation-extractor/master/ClassificationDataExploration.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/elangovana/PPI-typed-relation-extractor/master/DataExploration.ipynb"
      },
      "source": "https://raw.githubusercontent.com/elangovana/PPI-typed-relation-extractor/master/DataExploration.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/elangovana/PPI-typed-relation-extractor/master/Sagemaker-AIMed-Bert.ipynb"
      },
      "source": "https://raw.githubusercontent.com/elangovana/PPI-typed-relation-extractor/master/Sagemaker-AIMed-Bert.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/elangovana/PPI-typed-relation-extractor/master/Sagemaker-Bert-Classification.ipynb"
      },
      "source": "https://raw.githubusercontent.com/elangovana/PPI-typed-relation-extractor/master/Sagemaker-Bert-Classification.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/elangovana/PPI-typed-relation-extractor/master/Spark-pubmed-abstracts-analysis.ipynb"
      },
      "source": "https://raw.githubusercontent.com/elangovana/PPI-typed-relation-extractor/master/Spark-pubmed-abstracts-analysis.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/elangovana/PPI-typed-relation-extractor/master/ResultsExplorer-AImed.ipynb"
      },
      "source": "https://raw.githubusercontent.com/elangovana/PPI-typed-relation-extractor/master/ResultsExplorer-AImed.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/elangovana/PPI-typed-relation-extractor/master/DataAnalysisBioCreativeMutationResults.ipynb"
      },
      "source": "https://raw.githubusercontent.com/elangovana/PPI-typed-relation-extractor/master/DataAnalysisBioCreativeMutationResults.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/elangovana/PPI-typed-relation-extractor/master/SageMakerLargeScalePrediction.ipynb"
      },
      "source": "https://raw.githubusercontent.com/elangovana/PPI-typed-relation-extractor/master/SageMakerLargeScalePrediction.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/elangovana/PPI-typed-relation-extractor/master/RecallPrecisionPlot.ipynb"
      },
      "source": "https://raw.githubusercontent.com/elangovana/PPI-typed-relation-extractor/master/RecallPrecisionPlot.ipynb",
      "technique": "file_exploration"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 6
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/elangovana/PPI-typed-relation-extractor/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "elangovana/PPI-typed-relation-extractor"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "PPI typed relation extraction"
      },
      "source": "https://raw.githubusercontent.com/elangovana/PPI-typed-relation-extractor/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "has_build_file": [
    {
      "confidence": 1,
      "result": {
        "format": "dockerfile",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/elangovana/PPI-typed-relation-extractor/master/source/Dockerfile"
      },
      "source": "https://raw.githubusercontent.com/elangovana/PPI-typed-relation-extractor/master/source/Dockerfile",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "dockerfile",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/elangovana/PPI-typed-relation-extractor/master/sm_container/Dockerfile"
      },
      "source": "https://raw.githubusercontent.com/elangovana/PPI-typed-relation-extractor/master/sm_container/Dockerfile",
      "technique": "file_exploration"
    }
  ],
  "has_script_file": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/elangovana/PPI-typed-relation-extractor/master/source/scripts/ensemble_inference.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/elangovana/PPI-typed-relation-extractor/master/source/scripts/pubtator_annotations_inference_transformer_s3.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/elangovana/PPI-typed-relation-extractor/master/source/scripts/run_pipelinee_parallel.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/elangovana/PPI-typed-relation-extractor/master/source/scripts/inference.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/elangovana/PPI-typed-relation-extractor/master/source/scripts/run_pipeline_download_esindex.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/elangovana/PPI-typed-relation-extractor/master/source/scripts/dowloadintactinteractions.sh"
      },
      "technique": "file_exploration"
    }
  ],
  "installation": [
    {
      "confidence": 0.9962121270310861,
      "result": {
        "original_header": "AImed",
        "type": "Text_excerpt",
        "value": "1. Download from ftp://ftp.cs.utexas.edu/pub/mooney/bio-data/interactions.tar.gz\" \n2. Convert the raw dataset into XML for using instructions in http://mars.cs.utu.fi/PPICorpora/\n      ```bash\n      convert_aimed.py -i  aimed_interactions_input_dir -o aimed.xml\n\n      ``` \n1. Next convert the xml to dataframe json\n    \n    - Option A: This convert xml to dataframe json,  and pre-processes so that protien names that are not relevant are masked as \"PROTEIN\"\n       \n       ```bash\n        export PYTHONPATH=./source\n        python source/datatransformer/AimedXmlToDataFramePreprocessed.py tests/test_datatransformer/data/sample_aimed_pyyasaol_converted.xml /tmp/df.json\n        ```\n    \n    - Option B : If you want to just convert the AIMedXML to json without replacing non-participating protein names to \"PROTEIN\", then use this script instead\n    \n        BASH3*\n    \n1. Run 10 fold training with unique docid\n    \n    BASH4*\n    \n1. Run 10 fold training ignore unique doc id\n    \n    BASH5*\n \n1. To use use the pretrained embeddings by _Chiu et al. How to Train good Word Embeddings for Biomedical NLP_  download the embeddings from https://github.com/cambridgeltl/BioNLP-2016  \n"
      },
      "source": "https://raw.githubusercontent.com/elangovana/PPI-typed-relation-extractor/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9999269387639255,
      "result": {
        "original_header": "Other embeddings",
        "type": "Text_excerpt",
        "value": "1. To use the embedding from Collobert https://ronan.collobert.com/pub/matos/2014_hellinger_eacl.pdf . They can be downloaded from http://www.lebret.ch/words/embeddings/. First convert the vocab / words format into a single file as shown here. \n   The resulting file can then be used as the normal embedding file.\n   \n    ```bash\n    python ./source/algorithms/collobert_embedding_formatter.py  --vocabfile vocab.txt --embedfile words.txt --outputfile words_vocab_collabert.txt\n    ```\n  \n"
      },
      "source": "https://raw.githubusercontent.com/elangovana/PPI-typed-relation-extractor/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9836870750163222,
      "result": {
        "original_header": "Pretrained biobert",
        "type": "Text_excerpt",
        "value": "1. Download pretrained biobert from https://github.com/naver/biobert-pretrained/releases, specifically https://github.com/naver/biobert-pretrained/releases/download/v1.1-pubmed/biobert_v1.1_pubmed.tar.gz \n   \n2. Convert the tf model to a pytorch model\n   \n    ```bash\n    PYTHONPATH=./source\n    python ./source/algorithms/BiobertTfConverter.py  --modeldir \"<modeldir>\" --outputdir \"<outputdir>\"\n    ```\n    \n3. Train \n    ```bash\n    export PYTHONPATH=./source\n    python ./source/algorithms/main_train_bert.py --dataset PpiAimedDatasetFactory --trainfile Aimedsample.json --traindir tests/data/ --valfile Aimedsample.json --valdir tests/data --pretrained_biobert_dir \"<biobertdir>\"\n\n    ```\n    \n     \n"
      },
      "source": "https://raw.githubusercontent.com/elangovana/PPI-typed-relation-extractor/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "invocation": [
    {
      "confidence": 0.8797084663749177,
      "result": {
        "original_header": "AImed",
        "type": "Text_excerpt",
        "value": "2. Convert the raw dataset into XML for using instructions in http://mars.cs.utu.fi/PPICorpora/\n      ```bash\n      convert_aimed.py -i  aimed_interactions_input_dir -o aimed.xml\n\n      ``` \n"
      },
      "source": "https://raw.githubusercontent.com/elangovana/PPI-typed-relation-extractor/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8261440513339446,
      "result": {
        "original_header": "Other embeddings",
        "type": "Text_excerpt",
        "value": "1. To use the embedding from Collobert https://ronan.collobert.com/pub/matos/2014_hellinger_eacl.pdf . They can be downloaded from http://www.lebret.ch/words/embeddings/. First convert the vocab / words format into a single file as shown here. \n   The resulting file can then be used as the normal embedding file.\n   \n    ```bash\n    python ./source/algorithms/collobert_embedding_formatter.py  --vocabfile vocab.txt --embedfile words.txt --outputfile words_vocab_collabert.txt\n    ```\n  \n"
      },
      "source": "https://raw.githubusercontent.com/elangovana/PPI-typed-relation-extractor/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8828874735698315,
      "result": {
        "original_header": "Pretrained biobert",
        "type": "Text_excerpt",
        "value": "   \n2. Convert the tf model to a pytorch model\n   \n    ```bash\n    PYTHONPATH=./source\n    python ./source/algorithms/BiobertTfConverter.py  --modeldir \"<modeldir>\" --outputdir \"<outputdir>\"\n    ```\n    \n3. Train \n    ```bash\n    export PYTHONPATH=./source\n    python ./source/algorithms/main_train_bert.py --dataset PpiAimedDatasetFactory --trainfile Aimedsample.json --traindir tests/data/ --valfile Aimedsample.json --valdir tests/data --pretrained_biobert_dir \"<biobertdir>\"\n\n    ```\n    \n     \n"
      },
      "source": "https://raw.githubusercontent.com/elangovana/PPI-typed-relation-extractor/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/elangovana/PPI-typed-relation-extractor/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ""
      },
      "technique": "GitHub_API"
    }
  ],
  "license": [
    {
      "confidence": 1,
      "result": {
        "name": "MIT License",
        "spdx_id": "MIT",
        "type": "License",
        "url": "https://api.github.com/licenses/mit",
        "value": "https://api.github.com/licenses/mit"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "type": "File_dump",
        "value": "MIT License\n\nCopyright (c) 2018 elangovana\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
      },
      "source": "https://raw.githubusercontent.com/elangovana/PPI-typed-relation-extractor/master/LICENSE",
      "technique": "file_exploration"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "PPI-typed-relation-extractor"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "User",
        "value": "elangovana"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Jupyter Notebook",
        "size": 4270980,
        "type": "Programming_language",
        "value": "Jupyter Notebook"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 652158,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Shell",
        "size": 6182,
        "type": "Programming_language",
        "value": "Shell"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Dockerfile",
        "size": 1393,
        "type": "Programming_language",
        "value": "Dockerfile"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "XSLT",
        "size": 1383,
        "type": "Programming_language",
        "value": "XSLT"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/elangovana/PPI-typed-relation-extractor/master/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "releases": [
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "elangovana",
          "type": "User"
        },
        "date_created": "2020-04-14T10:59:54Z",
        "date_published": "2020-06-13T02:23:30Z",
        "description": "## Assigning function to protein-protein interactions: a weakly supervised BioBERT-based approach using PubMed abstracts \r\n\r\nThis is the source code and data as is at the time when the paper is submitted\r\n\r\n1. The typed PPI dataset created by processing Intact\r\n2. Untyped version of PPI \r\n3. AIMED - Part rep processed dataset\r\n4. AIMED - All rep processed dataset",
        "html_url": "https://github.com/elangovana/PPI-typed-relation-extractor/releases/tag/3.0",
        "name": "Assigning function to protein-protein interactions: a weakly supervised BioBERT-based approach using PubMed abstracts ",
        "release_id": 27514822,
        "tag": "3.0",
        "tarball_url": "https://api.github.com/repos/elangovana/PPI-typed-relation-extractor/tarball/3.0",
        "type": "Release",
        "url": "https://api.github.com/repos/elangovana/PPI-typed-relation-extractor/releases/27514822",
        "value": "https://api.github.com/repos/elangovana/PPI-typed-relation-extractor/releases/27514822",
        "zipball_url": "https://api.github.com/repos/elangovana/PPI-typed-relation-extractor/zipball/3.0"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "elangovana",
          "type": "User"
        },
        "date_created": "2019-10-17T01:24:44Z",
        "date_published": "2019-10-17T01:30:46Z",
        "description": "### 10 Fold F1-score on AIMed dataset is 60.46 \r\nThis experiment used the following parameters . The dataset is attached \r\n```bash\r\nexport PYTHONPATH=./src\r\n/usr/bin/python -m main_train_k_fold --batchsize 32 --cnn_kernel_size 3 --cnn_num_layers 2 --cnn_output 64 --dataset PpiAimedDatasetFactory --dropout_rate_cnn 0.5 --earlystoppingpatience 50 --embeddim 200 --embeddingfile PubMed-shuffle-win-2.bin.txt --epochs 1000 --fc_drop_out_rate 0.5 --fc_layer_size 256 --input_drop_out_rate 0.2 --learningrate 0.001 --log-level INFO --network RelationExtractorSimpleResnetCnnPosNetworkFactory --pool_stride 2 --pooling_kernel_size 3 --train_val_vocab_merge 1 --trainfile AIMedFull.json --weight_decay 1e-05\r\n```",
        "html_url": "https://github.com/elangovana/PPI-typed-relation-extractor/releases/tag/1.0",
        "name": "Aimed dataset 10 Fold F1-score: 60.46",
        "release_id": 20760555,
        "tag": "1.0",
        "tarball_url": "https://api.github.com/repos/elangovana/PPI-typed-relation-extractor/tarball/1.0",
        "type": "Release",
        "url": "https://api.github.com/repos/elangovana/PPI-typed-relation-extractor/releases/20760555",
        "value": "https://api.github.com/repos/elangovana/PPI-typed-relation-extractor/releases/20760555",
        "zipball_url": "https://api.github.com/repos/elangovana/PPI-typed-relation-extractor/zipball/1.0"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "elangovana",
          "type": "User"
        },
        "date_created": "2018-09-27T11:40:25Z",
        "date_published": "2018-09-28T09:27:26Z",
        "description": "Extracts imex dataset and converts them into data frame",
        "html_url": "https://github.com/elangovana/PPI-typed-relation-extractor/releases/tag/0.6.0",
        "name": "Data Extraction",
        "release_id": 13145973,
        "tag": "0.6.0",
        "tarball_url": "https://api.github.com/repos/elangovana/PPI-typed-relation-extractor/tarball/0.6.0",
        "type": "Release",
        "url": "https://api.github.com/repos/elangovana/PPI-typed-relation-extractor/releases/13145973",
        "value": "https://api.github.com/repos/elangovana/PPI-typed-relation-extractor/releases/13145973",
        "zipball_url": "https://api.github.com/repos/elangovana/PPI-typed-relation-extractor/zipball/0.6.0"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "elangovana",
          "type": "User"
        },
        "date_created": "2018-09-20T10:48:26Z",
        "date_published": "2018-09-21T06:32:27Z",
        "html_url": "https://github.com/elangovana/PPI-typed-relation-extractor/releases/tag/0.5.0",
        "name": "Basic working version",
        "release_id": 13018368,
        "tag": "0.5.0",
        "tarball_url": "https://api.github.com/repos/elangovana/PPI-typed-relation-extractor/tarball/0.5.0",
        "type": "Release",
        "url": "https://api.github.com/repos/elangovana/PPI-typed-relation-extractor/releases/13018368",
        "value": "https://api.github.com/repos/elangovana/PPI-typed-relation-extractor/releases/13018368",
        "zipball_url": "https://api.github.com/repos/elangovana/PPI-typed-relation-extractor/zipball/0.5.0"
      },
      "technique": "GitHub_API"
    }
  ],
  "run": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Optional: Visualise through elastic search on AWS",
        "parent_header": [
          "PPI typed relation extraction",
          "Run via Docker",
          "Download and analyse the dataset with elastic search"
        ],
        "type": "Text_excerpt",
        "value": "1. Sample download intact files with pattern human0* and elastic search index\n    ```bash\n    region=$1\n    esdomain=$2\n    accesskey=$3\n    accesssecret=$4\n    s3path=$5\n \n    basedata=/home/ubuntu/data\n    file_pattern=human0*\n \n    script=scripts/run_pipeline_download_esindex.sh\n    sudo docker run -v ${basedata}:/data --env elasticsearch_domain_name=$esdomain --env AWS_ACCESS_KEY_ID=$accesskey   --env AWS_REGION=$region --env AWS_SECRET_ACCESS_KEY=$accesssecret lanax/kegg-pathway-extractor:latest $script /data $file_pattern $s3path \n    ```\n\n"
      },
      "source": "https://raw.githubusercontent.com/elangovana/PPI-typed-relation-extractor/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Training and Validation",
        "parent_header": [
          "PPI typed relation extraction",
          "Run locally from source"
        ],
        "type": "Text_excerpt",
        "value": "1. Download dataset from Imex ftp site ftp.ebi.ac.uk\n    ```bash\n    cd ./source\n    bash scripts/dowloadintactinteractions.sh \"<localdir>\" \"<filepattern e.g. human*.xml>\" \"<optional s3 destination>\"\n    ```\n\n2. Create raw but json formatted dataset locally from source\n    \n    ```bash\n    export PYTHONPATH=./source\n    python source/pipeline/main_pipeline_dataprep.py \"<inputdir containing imex xml files>\" \"outputdir\"\n    ```\n\n3. Create pubtator formatted abstracts so that GnormPlus can recognises entities\n\n    ```bash\n    export PYTHONPATH=./source\n    python source/dataformatters/main_formatter.py \"<datafilecreatedfrompreviousstep>\" \"<outputfile>\"\n    ```\n4.  Extract entities using GNormPlus\n    \n    ```bash\n    docker pull lanax/gnormplus\n    cp \n    docker run -it -v /data/:/gnormdata lanax/gnormplus\n\n    # within docker\n    # Step1  edit the setup.txt to human specifies only..\n    # Step 2 run process\n    java -Xmx10G -Xms10G -jar /GNormPlusJava/GNormPlus.jar /gnormdata/input /gnormdata/output setup.txt > /gnormdata/gnormplus.log 2>&1 &\n\n    ```\n    \n    Sample setup.txt\n    \n    ```text\n    \n    #===Annotation\n    #Attribution setting:\n    #FocusSpecies = Taxonomy ID\n    #\tAll: All species\n    #\t9606: Human\n    #\t4932: yeast\n    #\t7227: Fly\n    #\t10090: Mouse\n    #\t10116: Rat\n    #\t7955: Zebrafish\n    #\t3702: Arabidopsis thaliana\n    #open: True\n    #close: False\n    \n    [Focus Species]\n        FocusSpecies = 9606\n    [Dictionary & Model]\n        DictionaryFolder = Dictionary\n        GNRModel = Dictionary/GNR.Model\n        SCModel = Dictionary/SimConcept.Model\n        GeneIDMatch = True\n        Normalization2Protein = False\n        DeleteTmp = True\n\n\n    ```\n    \n    \n4. Download NCBI to Uniprot Id mapping file\n   \n   From https://www.uniprot.org/downloads , download the ID mapping file ftp://ftp.uniprot.org/pub/databases/uniprot/current_release/knowledgebase/idmapping/. This contains the ID mapping between UNIPROT and NCBI. We need this as GNormplus use NCBI gene id and we need the protein names.\n   The dat file contains three columns, delimited by tab:\n   \n    - UniProtKB-AC \n    - ID_type \n    - ID\n    \n    e.g \n    ```text\n    P43405\tDNASU\t6850\n    P43405\tGeneID\t6850\n    P43405\tGenomeRNAi\t6850\n    A0A024R244\tGeneID\t6850\n    A0A024R244\tGenomeRNAi\t6850\n    A0A024R273\tGeneID\t6850\n    A0A024R273\tGenomeRNAi\t6850\n    A8K4G2\tDNASU\t6850\n    ```\n \n4. Download wordtovec pretrained models (either pubmed+pmc trained or  pubmed+pmc+wikipedia)and convert to text format \n\n    ```bash\n    # Download word to vec trained only on pubmed and pmc\n    wget -O /data/PubMed-and-PMC-w2v.bin http://evexdb.org/pmresources/vec-space-models/PubMed-and-PMC-w2v.bin\n \n    python ./source/dataformatters/main_wordToVecBinToText.py /data/PubMed-and-PMC-w2v.bin /data/PubMed-and-PMC-w2v.bin.txt\n    ```\n    \n    ```bash\n    # Download word to vec trained only on pubmed and pmc and wikipedia\n    wget  -O /data/wikipedia-pubmed-and-PMC-w2v.bin http://evexdb.org/pmresources/vec-space-models/wikipedia-pubmed-and-PMC-w2v.bin\n \n    python ./source/dataformatters/main_wordToVecBinToText.py /data/wikipedia-pubmed-and-PMC-w2v.bin /data/wikipedia-pubmed-and-PMC-w2v.bin.txt\n    ```\n\n4. Run the data exploration notebook [DataExploration.ipynb](DataExploration.ipynb) to clean data, generate negative samples and  normalise abstract \n\n4. Run train job\n    ```bash\n    export PYTHONPATH=./source\n    python source/algorithms/main_train.py  --dataset PpiDatasetFactory --trainfile sample_train.json --traindir tests/data/ --valfile sample_train.json  --valdir tests/data --embeddingfile sample_PubMed-and-PMC-w2v.bin.txt --embeddingdir ./tests/test_algorithms --embeddim 200 --outdir outdir --modeldir outdir\n    ```\n\n5. Consolidated train + predict\n    ```bash\n     #!/usr/bin/env bash\n    \n        \n     set -e\n     set -x\n  \n     # Init\n     base_dir=/data\n     s3_dest=s3://yourbucket/results\n    \n    \n     fmtdt=`date +\"%y%m%d_%H%M\"`\n     base_name=model_${fmtdt}\n     outdir=${base_dir}/${base_name}\n     echo ${outdir}\n     mkdir ${outdir}\n      \n     export PYTHONPATH=\"./source\"\n     \n     mkdir ${outdir}\n     \n     # Git head to trace to source to reproduce run\n     git log -1 > ${outdir}/run.log\n     \n     # Train\n     python ./source/algorithms/main_train.py --dataset PpiDatasetFactory --trainfile train_unique_pub_v3_lessnegatve.json --traindir /data  --valfile val_unique_pub_v3_lessnegatve.json --valfile /data --embeddingfile wikipedia-pubmed-and-PMC-w2v.bin.txt  --embeddingdir /data --embeddim 200 --outdir ${outdir}  --epochs 50  --log-level INFO >> ${outdir}/run.log 2>&1\n     \n     # Predict on validation set\n     python ./source/algorithms/main_predict.py PpiDatasetFactory /data/test_unique_pub_v3_lessnegatve.json ${outdir}  ${outdir} >> ${outdir}/run.log 2>&1\n     mv ${outdir}/predicted.json ${outdir}/predicted_test_unique_pub_v3_lessnegatve.json\n     \n     # Predict on test set\n     python ./source/algorithms/main_predict.py PpiDatasetFactory  /data/val_unique_pub_v3_lessnegatve.json ${outdir}  ${outdir} >> ${outdir}/run.log 2>&1\n     mv ${outdir}/predicted.json ${outdir}/predicted_val_unique_pub_v3_lessnegatve.json\n    \n     #Copy results to s3\n     aws s3 sync ${outdir} ${s3_dest}/${base_name} >> ${outdir}/synclog 2>&1\n    \n    ```\n    "
      },
      "source": "https://raw.githubusercontent.com/elangovana/PPI-typed-relation-extractor/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Large scale inference on pubmed abstracts",
        "parent_header": [
          "PPI typed relation extraction",
          "Run locally from source"
        ],
        "type": "Text_excerpt",
        "value": "1. Download pubmed FTP and convert to json. For more details see https://github.com/elangovana/pubmed-downloader/tree/master \n\n1. Convert json to pubtator format to prepare the dataset for GNormPlus\n\n    ```bash\n    export PYTHONPATH=./source\n    python source/dataformatters/pubmed_abstracts_to_pubtator_format.py \"<inputdir_jsonfiles_result_of_step_1>\" \"<destination_dir_pubtator_format>\"\n    ```\n1. Run GNormPlus to recognise entities using the pubtator formatted files from the previous step, without protein names  normalisation. See https://github.com/elangovana/docker-gnormplus \n\n1. Generate json using the results of GNormplus annotations in pubtator format.\n    ```bash\n    export PYTHONPATH=./source\n    python ./source/datatransformer/pubtator_annotations_inference_transformer.py tests/test_datatransformer/data_sample_annotation /tmp tmpmap.dat\n    ```\n\n1. Run inference\n    ```bash\n     python ./algorithms/main_predict.py PPIDataset /data/val_unique_pub_v6_less_negative.json /tmp/model_artefacts /tmp --positives-filter-threshold .95\n\n    ```\n\n\n"
      },
      "source": "https://raw.githubusercontent.com/elangovana/PPI-typed-relation-extractor/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "somef_missing_categories": [
    "citation",
    "acknowledgement",
    "requirements",
    "contact",
    "contributors",
    "usage",
    "faq",
    "support",
    "identifier"
  ],
  "somef_provenance": {
    "date": "2024-10-04 00:37:26",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 16
      },
      "technique": "GitHub_API"
    }
  ]
}