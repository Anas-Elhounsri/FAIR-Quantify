{
  "application_domain": [
    {
      "confidence": 15.9,
      "result": {
        "type": "String",
        "value": "Computer Vision"
      },
      "technique": "supervised_classification"
    },
    {
      "confidence": 10.58,
      "result": {
        "type": "String",
        "value": "Audio"
      },
      "technique": "supervised_classification"
    }
  ],
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/orcasound/orcaal-research"
      },
      "technique": "GitHub_API"
    }
  ],
  "contributing_guidelines": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Contributing to AL-MLresearch",
        "parent_header": [
          "AL-MLresearch"
        ],
        "type": "Text_excerpt",
        "value": "To contribute to AL-MLresearch, follow these steps:\n\n1. Fork this repository.\n2. Create a branch: `git checkout -b <branch_name>`.\n3. Make your changes and commit them: `git commit -m '<commit_message>'`\n4. Push to the original branch: `git push origin <AL-MLresearch>/<location>`\n5. Create the pull request.\n\nAlternatively see the GitHub documentation on [creating a pull request](https://help.github.com/en/github/collaborating-with-issues-and-pull-requests/creating-a-pull-request).\n"
      },
      "source": "https://raw.githubusercontent.com/orcasound/orcaal-research/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "contributors": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Contributors",
        "parent_header": [
          "AL-MLresearch"
        ],
        "type": "Text_excerpt",
        "value": "Thanks to the following people who have contributed to this project without whom the project would never have been completed.\n\nMy Mentors:\n * [@jesselopez](https://github.com/yosoyjay)\n * [@valentina-s](https://github.com/valentina-s) \n * [@scottveirs](https://github.com/scottveirs) \n * [@abhisheksingh](https://github.com/ZER-0-NE)\n * [@valveirs](https://github.com/veirs)\n\nMy partner who is working on the front-end part\n * [@jorgediego](https://github.com/jd-rs)\n\nThanks to [OrcaCNN](https://github.com/axiom-data-science/OrcaCNN) and [Ketos](https://gitlab.meridian.cs.dal.ca/public_projects/ketos) for their thorough documentation and code which helped not only me develop preprocessing and training stage but also helped me develop scripts.\n"
      },
      "source": "https://raw.githubusercontent.com/orcasound/orcaal-research/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2020-08-27T06:32:23Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2023-06-12T10:33:13Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "Code, research, and pre-processing steps involved in the OrcaAL tool (Kunal's GSoC 2020 project)"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 0.9867219681521245,
      "result": {
        "original_header": "AL-MLresearch",
        "type": "Text_excerpt",
        "value": "This repository contains code, research work, and pre-processing steps involved in developing the Orcacall detection model for the \"OrcaAL\" Active learning tool during the 2020 Google Summer of Code. The deployment of the model within the tool is described in [the OrcaAL repo](https://orcasound.github.io/orcaal/). \nMost of the orca audio data present in the world are unlabeled. Even though labeling data is an expensive, difficult, and slow process, it is an essential part of the advancing machine learning (ML) systems. What if a model could achieve accuracy by annotating a small portion of a large dataset? One way of doing this is [Active Learning](https://en.wikipedia.org/wiki/Active_learning_(machine_learning)) which can allow a human to spend 10-20% of the time annotating data and still get the good model performance. \nTherefore, we going to build an active learning tool that would label the vast amount of unlabeled data coming in real-time streams from ocean observing systems.\nFor more extensive research, jump to the [notebooks directory](https://github.com/orcasound/orcaal-research/tree/master/notebooks).\n \n"
      },
      "source": "https://raw.githubusercontent.com/orcasound/orcaal-research/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9774025363540653,
      "result": {
        "original_header": "Dataset",
        "type": "Text_excerpt",
        "value": "This github repository consists of the necessary steps taken for the backend of OrcaAL, i.e. preprocessing, building CNN models, and active learning. Along with this, this repository also quantifies the different accuracies achieved by each model experiment along with the steps necessary steps taken to achieve that accuracy. \n"
      },
      "source": "https://raw.githubusercontent.com/orcasound/orcaal-research/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.975306886795357,
      "result": {
        "original_header": "Implementation",
        "type": "Text_excerpt",
        "value": "The implementation part consists of the stages:\n- Data extraction and preprocessing \n- Model building and training\n- Active learning\n \n"
      },
      "source": "https://raw.githubusercontent.com/orcasound/orcaal-research/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/orcasound/orcaal-research/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "executable_example": [
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/orcasound/orcaal-research/master/notebooks/case_three/preprocess/preprocessing_PCEN_and_Wavlet_denoising.ipynb"
      },
      "source": "https://raw.githubusercontent.com/orcasound/orcaal-research/master/notebooks/case_three/preprocess/preprocessing_PCEN_and_Wavlet_denoising.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/orcasound/orcaal-research/master/notebooks/case_three/training/Resnet152_pre_pcen_wd_train.ipynb"
      },
      "source": "https://raw.githubusercontent.com/orcasound/orcaal-research/master/notebooks/case_three/training/Resnet152_pre_pcen_wd_train.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/orcasound/orcaal-research/master/notebooks/case_three/training/CNN_for_SRKW.ipynb"
      },
      "source": "https://raw.githubusercontent.com/orcasound/orcaal-research/master/notebooks/case_three/training/CNN_for_SRKW.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/orcasound/orcaal-research/master/notebooks/case_three/training/Training.ipynb"
      },
      "source": "https://raw.githubusercontent.com/orcasound/orcaal-research/master/notebooks/case_three/training/Training.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/orcasound/orcaal-research/master/notebooks/active_learning/more_uncertain_active_learning_pipeline.ipynb"
      },
      "source": "https://raw.githubusercontent.com/orcasound/orcaal-research/master/notebooks/active_learning/more_uncertain_active_learning_pipeline.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/orcasound/orcaal-research/master/notebooks/active_learning/active_learning_pipeline.ipynb"
      },
      "source": "https://raw.githubusercontent.com/orcasound/orcaal-research/master/notebooks/active_learning/active_learning_pipeline.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/orcasound/orcaal-research/master/notebooks/case_two/preprocess/preprocessing_using_PCEN.ipynb"
      },
      "source": "https://raw.githubusercontent.com/orcasound/orcaal-research/master/notebooks/case_two/preprocess/preprocessing_using_PCEN.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/orcasound/orcaal-research/master/notebooks/case_two/training/training_on_PCEN_spectrograms.ipynb"
      },
      "source": "https://raw.githubusercontent.com/orcasound/orcaal-research/master/notebooks/case_two/training/training_on_PCEN_spectrograms.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/orcasound/orcaal-research/master/notebooks/preprocessing_and_training_using_Ketos/training/training_on_RNN_using_Ketos.ipynb"
      },
      "source": "https://raw.githubusercontent.com/orcasound/orcaal-research/master/notebooks/preprocessing_and_training_using_Ketos/training/training_on_RNN_using_Ketos.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/orcasound/orcaal-research/master/notebooks/preprocessing_and_training_using_Ketos/training/Training_SRKWs_Ketos.ipynb"
      },
      "source": "https://raw.githubusercontent.com/orcasound/orcaal-research/master/notebooks/preprocessing_and_training_using_Ketos/training/Training_SRKWs_Ketos.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/orcasound/orcaal-research/master/notebooks/preprocessing_and_training_using_Ketos/preprocessing/preprocessing_using_Ketos.ipynb"
      },
      "source": "https://raw.githubusercontent.com/orcasound/orcaal-research/master/notebooks/preprocessing_and_training_using_Ketos/preprocessing/preprocessing_using_Ketos.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/orcasound/orcaal-research/master/notebooks/case_one/training/training_on_case_one_on_model_VGG_and_CNN.ipynb"
      },
      "source": "https://raw.githubusercontent.com/orcasound/orcaal-research/master/notebooks/case_one/training/training_on_case_one_on_model_VGG_and_CNN.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/orcasound/orcaal-research/master/notebooks/case_one/preprocessing/preprocess_case_one.ipynb"
      },
      "source": "https://raw.githubusercontent.com/orcasound/orcaal-research/master/notebooks/case_one/preprocessing/preprocess_case_one.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/orcasound/orcaal-research/master/experiments/Grayscale_magspectrogram_scipy.ipynb"
      },
      "source": "https://raw.githubusercontent.com/orcasound/orcaal-research/master/experiments/Grayscale_magspectrogram_scipy.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/orcasound/orcaal-research/master/experiments/Sir_Val%27s_method_color.ipynb"
      },
      "source": "https://raw.githubusercontent.com/orcasound/orcaal-research/master/experiments/Sir_Val%27s_method_color.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/orcasound/orcaal-research/master/experiments/Grayscale_specs_mag.ipynb"
      },
      "source": "https://raw.githubusercontent.com/orcasound/orcaal-research/master/experiments/Grayscale_specs_mag.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/orcasound/orcaal-research/master/experiments/Spectrograms.ipynb"
      },
      "source": "https://raw.githubusercontent.com/orcasound/orcaal-research/master/experiments/Spectrograms.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/orcasound/orcaal-research/master/experiments/Preprocess_grayscale.ipynb"
      },
      "source": "https://raw.githubusercontent.com/orcasound/orcaal-research/master/experiments/Preprocess_grayscale.ipynb",
      "technique": "file_exploration"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 4
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/orcasound/orcaal-research/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "orcasound/orcaal-research"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "AL-MLresearch"
      },
      "source": "https://raw.githubusercontent.com/orcasound/orcaal-research/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "has_build_file": [
    {
      "confidence": 1,
      "result": {
        "format": "dockerfile",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/orcasound/orcaal-research/master/src/preprocessing_script/Dockerfile"
      },
      "source": "https://raw.githubusercontent.com/orcasound/orcaal-research/master/src/preprocessing_script/Dockerfile",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "dockerfile",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/orcasound/orcaal-research/master/src/training_script/Dockerfile"
      },
      "source": "https://raw.githubusercontent.com/orcasound/orcaal-research/master/src/training_script/Dockerfile",
      "technique": "file_exploration"
    }
  ],
  "images": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/orcasound/orcaal-research/master/AL-MLresearch</h1>\n<p>This repository contains code, research work, and pre-processing steps involved in developing the Orcacall detection model for the "
      },
      "source": "https://raw.githubusercontent.com/orcasound/orcaal-research/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "installation": [
    {
      "confidence": 1.0,
      "result": {
        "original_header": "General project flow",
        "type": "Text_excerpt",
        "value": "The directory structure of our project looks like this: \n```\n\u251c\u2500\u2500 experiments\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 experiments/Grayscale_magspectrogram_scipy.ipynb <- CNN model trained on grayscale power_spectral_density spectrograms\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 experiments/Grayscale_specs_mag.ipynb  <- Differenet CNN model trained on grayscale power_spectral_density spectrograms\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 experiments/Preprocess_grayscale.ipynb <- Preprocessing of the grayscale spectrograms\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 experiments/README.md\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 experiments/Sir_Val's_method_color.ipynb <- Preprocessing of the power_spectral_density spectrograms as suggested by Val\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 experiments/Spectrograms.ipynb <- Different spectrograms that are generated and their code\n\u251c\u2500\u2500 notebooks\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 notebooks/active_learning\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 notebooks/active_learning/active_learning_pipeline.ipynb <- Active learning pipelne notebook\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 notebooks/case_one\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 notebooks/case_one/Preprocessing \n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 notebooks/case_one/Preprocessing/preprocess_case_one.ipynb <- Jupyter notebook in colab performing preprocessing\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 notebooks/case_one/README.md\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 notebooks/case_one/Training\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u251c\u2500\u2500 notebooks/case_one/Training/README.md\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u2514\u2500\u2500 notebooks/case_one/Training/training_on_case_one_on_model_VGG_and_CNN.ipynb <- Jupyter notebook in colab performing training.\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 notebooks/case_three\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 notebooks/case_three/Preprocess\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 notebooks/case_three/Preprocess/preprocessing_PCEN_and_Wavlet_denoising.ipynb <- Jupyter notebook in colab performing preprocessing process.\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 notebooks/case_three/Preprocess/README.md\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 notebooks/case_three/README.md\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 notebooks/case_three/Training\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u251c\u2500\u2500 notebooks/case_three/Training/CNN_for_SRKW.ipynb <- Jupyter notebook in colab performing training stage on case three preprocessed spectrograms.\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u251c\u2500\u2500 notebooks/case_three/Training/README.md\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u251c\u2500\u2500 notebooks/case_three/Training/Resnet152_pre_pcen_wd_train.ipynb <- Jupyter notebook in colab performing training stage using Resnet152\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u2514\u2500\u2500 notebooks/case_three/Training/Training.ipynb <- Jupyter notebook in colab performing training stage using VGGG-16\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 notebooks/case_two\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 notebooks/case_two/Preprocess\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 notebooks/case_two/Preprocess/preprocessing_using_PCEN.ipynb <- Jupyter notebook in colab performing preprocessing process using case two\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 notebooks/case_two/Training\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u2514\u2500\u2500 notebooks/case_two/Training/training_on_PCEN_spectrograms.ipynb <- Jupyter notebook in colab performing training on stage two spectrograms.\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 notebooks/preprocessing_and_training_using_Ketos\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 notebooks/preprocessing_and_training_using_Ketos/Preprocessing\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 notebooks/preprocessing_and_training_using_Ketos/Preprocessing/preprocessing_using_Ketos.ipynb \n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 notebooks/preprocessing_and_training_using_Ketos/Preprocessing/README.md\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 notebooks/preprocessing_and_training_using_Ketos/Training\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u251c\u2500\u2500 notebooks/preprocessing_and_training_using_Ketos/Training/training_on_RNN_using_Ketos.ipynb\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u2514\u2500\u2500 notebooks/preprocessing_and_training_using_Ketos/Training/Training_SRKWs_Ketos.ipynb\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0  \n\u2502\u00a0\u00a0 \u2514\u2500\u2500 notebooks/README.md\n\u251c\u2500\u2500 requirements.txt\n\u251c\u2500\u2500 src\n\u00a0\u00a0  \u251c\u2500\u2500 active_learning_script\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 active_learning.py\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 README.md\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 datasets\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 1562337136_0004.wav\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 extracted_calls1.wav\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 test_extract_audio.tsv\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 test_srkw\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 calls\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 extracted_calls4.png\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 extracted_calls5.png\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 extracted_calls6.png\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 no_calls\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u251c\u2500\u2500 extracted_calls1.png\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u251c\u2500\u2500 extracted_calls2.png\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u251c\u2500\u2500 extracted_calls3.png\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u251c\u2500\u2500 extracted_calls4.png\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u251c\u2500\u2500 extracted_calls5.png\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u2514\u2500\u2500 extracted_calls6.png\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 test_wav.wav\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 src/preprocessing_script\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 src/preprocessing_script/Dockerfile   <- The Dockerfile of the preprocessing script. \n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 src/preprocessing_script/preprocess.py <- The preprocessing script. \n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 src/preprocessing_script/README.md  \n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 src/preprocessing_script/requirements.txt <- Requirement file\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 src/preprocessing_script/selection_table.py <- Selection table for generating background noise\n|   \u251c\u2500\u2500 tests\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 README.md\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 test_active_learning.py\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 test_model_build_and_training.py\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 test_model_predict.py\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 test_preprocess.py\n\u2502\u00a0\u00a0 |\u00a0\u00a0 \u2514\u2500\u2500 test_report.py\n|   \u2514\u2500\u2500 src/training_script\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 src/training_script/Dockerfile <- The Dockerfile of the training script. \n\u2502\u00a0\u00a0     \u251c\u2500\u2500 src/training_script/model_build_and_training.py <- The model building and training script.\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 src/training_script/README.md\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 src/training_script/requirements.txt <- Requirement file\n\u2502   \n\u2502   \n|\n\u2502\n\u2502   \n\u2502\n\u2514\u2500\u2500 trained_models\n\u00a0\u00a0 \u2514\u2500\u2500 trained_models/README.md <- Links to the different models that could be used\n\n\n```\n \n"
      },
      "source": "https://raw.githubusercontent.com/orcasound/orcaal-research/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "invocation": [
    {
      "confidence": 0.8939842738478163,
      "result": {
        "original_header": "General project flow",
        "type": "Text_excerpt",
        "value": "The directory structure of our project looks like this: \n```\n\u251c\u2500\u2500 experiments\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 experiments/Grayscale_magspectrogram_scipy.ipynb <- CNN model trained on grayscale power_spectral_density spectrograms\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 experiments/Grayscale_specs_mag.ipynb  <- Differenet CNN model trained on grayscale power_spectral_density spectrograms\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 experiments/Preprocess_grayscale.ipynb <- Preprocessing of the grayscale spectrograms\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 experiments/README.md\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 experiments/Sir_Val's_method_color.ipynb <- Preprocessing of the power_spectral_density spectrograms as suggested by Val\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 experiments/Spectrograms.ipynb <- Different spectrograms that are generated and their code\n\u251c\u2500\u2500 notebooks\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 notebooks/active_learning\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 notebooks/active_learning/active_learning_pipeline.ipynb <- Active learning pipelne notebook\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 notebooks/case_one\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 notebooks/case_one/Preprocessing \n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 notebooks/case_one/Preprocessing/preprocess_case_one.ipynb <- Jupyter notebook in colab performing preprocessing\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 notebooks/case_one/README.md\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 notebooks/case_one/Training\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u251c\u2500\u2500 notebooks/case_one/Training/README.md\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u2514\u2500\u2500 notebooks/case_one/Training/training_on_case_one_on_model_VGG_and_CNN.ipynb <- Jupyter notebook in colab performing training.\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 notebooks/case_three\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 notebooks/case_three/Preprocess\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 notebooks/case_three/Preprocess/preprocessing_PCEN_and_Wavlet_denoising.ipynb <- Jupyter notebook in colab performing preprocessing process.\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 notebooks/case_three/Preprocess/README.md\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 notebooks/case_three/README.md\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 notebooks/case_three/Training\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u251c\u2500\u2500 notebooks/case_three/Training/CNN_for_SRKW.ipynb <- Jupyter notebook in colab performing training stage on case three preprocessed spectrograms.\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u251c\u2500\u2500 notebooks/case_three/Training/README.md\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u251c\u2500\u2500 notebooks/case_three/Training/Resnet152_pre_pcen_wd_train.ipynb <- Jupyter notebook in colab performing training stage using Resnet152\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u2514\u2500\u2500 notebooks/case_three/Training/Training.ipynb <- Jupyter notebook in colab performing training stage using VGGG-16\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 notebooks/case_two\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 notebooks/case_two/Preprocess\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 notebooks/case_two/Preprocess/preprocessing_using_PCEN.ipynb <- Jupyter notebook in colab performing preprocessing process using case two\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 notebooks/case_two/Training\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u2514\u2500\u2500 notebooks/case_two/Training/training_on_PCEN_spectrograms.ipynb <- Jupyter notebook in colab performing training on stage two spectrograms.\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 notebooks/preprocessing_and_training_using_Ketos\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 notebooks/preprocessing_and_training_using_Ketos/Preprocessing\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 notebooks/preprocessing_and_training_using_Ketos/Preprocessing/preprocessing_using_Ketos.ipynb \n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 notebooks/preprocessing_and_training_using_Ketos/Preprocessing/README.md\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 notebooks/preprocessing_and_training_using_Ketos/Training\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u251c\u2500\u2500 notebooks/preprocessing_and_training_using_Ketos/Training/training_on_RNN_using_Ketos.ipynb\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u2514\u2500\u2500 notebooks/preprocessing_and_training_using_Ketos/Training/Training_SRKWs_Ketos.ipynb\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0  \n\u2502\u00a0\u00a0 \u2514\u2500\u2500 notebooks/README.md\n\u251c\u2500\u2500 requirements.txt\n\u251c\u2500\u2500 src\n\u00a0\u00a0  \u251c\u2500\u2500 active_learning_script\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 active_learning.py\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 README.md\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 datasets\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 1562337136_0004.wav\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 extracted_calls1.wav\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 test_extract_audio.tsv\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 test_srkw\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 calls\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 extracted_calls4.png\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 extracted_calls5.png\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 extracted_calls6.png\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 no_calls\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u251c\u2500\u2500 extracted_calls1.png\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u251c\u2500\u2500 extracted_calls2.png\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u251c\u2500\u2500 extracted_calls3.png\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u251c\u2500\u2500 extracted_calls4.png\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u251c\u2500\u2500 extracted_calls5.png\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u2514\u2500\u2500 extracted_calls6.png\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 test_wav.wav\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 src/preprocessing_script\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 src/preprocessing_script/Dockerfile   <- The Dockerfile of the preprocessing script. \n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 src/preprocessing_script/preprocess.py <- The preprocessing script. \n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 src/preprocessing_script/README.md  \n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 src/preprocessing_script/requirements.txt <- Requirement file\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 src/preprocessing_script/selection_table.py <- Selection table for generating background noise\n|   \u251c\u2500\u2500 tests\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 README.md\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 test_active_learning.py\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 test_model_build_and_training.py\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 test_model_predict.py\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 test_preprocess.py\n\u2502\u00a0\u00a0 |\u00a0\u00a0 \u2514\u2500\u2500 test_report.py\n|   \u2514\u2500\u2500 src/training_script\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 src/training_script/Dockerfile <- The Dockerfile of the training script. \n\u2502\u00a0\u00a0     \u251c\u2500\u2500 src/training_script/model_build_and_training.py <- The model building and training script.\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 src/training_script/README.md\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 src/training_script/requirements.txt <- Requirement file\n\u2502   \n\u2502   \n|\n\u2502\n\u2502   \n\u2502\n\u2514\u2500\u2500 trained_models\n\u00a0\u00a0 \u2514\u2500\u2500 trained_models/README.md <- Links to the different models that could be used\n\n\n```\n \n"
      },
      "source": "https://raw.githubusercontent.com/orcasound/orcaal-research/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/orcasound/orcaal-research/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ""
      },
      "technique": "GitHub_API"
    }
  ],
  "license": [
    {
      "confidence": 1,
      "result": {
        "name": "MIT License",
        "spdx_id": "MIT",
        "type": "License",
        "url": "https://api.github.com/licenses/mit",
        "value": "https://api.github.com/licenses/mit"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "type": "File_dump",
        "value": "MIT License\n\nCopyright (c) 2020 Orcasound\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
      },
      "source": "https://raw.githubusercontent.com/orcasound/orcaal-research/master/LICENSE",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "License",
        "parent_header": [
          "AL-MLresearch"
        ],
        "type": "Text_excerpt",
        "value": "\nThis project uses the following license: [MIT](https://choosealicense.com/licenses/mit/#).\n"
      },
      "source": "https://raw.githubusercontent.com/orcasound/orcaal-research/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "orcaal-research"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "Organization",
        "value": "orcasound"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Jupyter Notebook",
        "size": 11522958,
        "type": "Programming_language",
        "value": "Jupyter Notebook"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 83914,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Dockerfile",
        "size": 1331,
        "type": "Programming_language",
        "value": "Dockerfile"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/orcasound/orcaal-research/master/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "somef_missing_categories": [
    "citation",
    "acknowledgement",
    "run",
    "download",
    "requirements",
    "contact",
    "documentation",
    "usage",
    "faq",
    "support",
    "identifier"
  ],
  "somef_provenance": {
    "date": "2024-10-03 22:54:08",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 7
      },
      "technique": "GitHub_API"
    }
  ]
}