{
  "application_domain": [
    {
      "confidence": 18.58,
      "result": {
        "type": "String",
        "value": "Computer Vision"
      },
      "technique": "supervised_classification"
    }
  ],
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/aaditya-pdgupta/neural_network_in_biology"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2022-08-20T10:16:44Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2022-08-26T11:05:03Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "Neural network has been applied widely in biology since the 1980s, and has advanced tremendously in the field of research, and others lately.  Here, we use artificial neural networks  to classify that the Mushroom is poisonous or edible to eat. The identification of edible and poisonous mushrooms among its existing species is a must due to its high demand for people's everyday meal and major advantage on medical science."
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Introduction",
        "parent_header": [
          "Classification of Mushrooms"
        ],
        "type": "Text_excerpt",
        "value": "Neural networks, also known as artificial neural networks (ANNs) or simulated network (SNNs) are sub-set of machine learning and are heart of deep learning algorithms. A standard neural network (NN) consists of many simple, connected processors called neuron , each producing a sequence of real valued activations. An artificial neuron recieves a signals and then processes them and can signal neurons connected to it.\n\nANNs are comprised of a node layers, containing an input layer, one or more hidden layers and an output layer. Each node or artificial neuron, connects to another has an associated weight and threshold. If the output of any individual node is above the specified threshold value, that node is activated, sending data to the next layer of the next layer of the network.\n\n<p align=\"center\">\n  <img src=\"../main/Pictures/artificial_neural_network.jpg\" width=\"250\" height=\"250\"/>\n</p>\n\nThe aim of constructing ANNs is to create artificial intelligence inspired by the working of human brain, even though the latter is not yet fully understood. They are based on the computers and man's brain abilities. In a similar way, the main asset of neural network is the ability of their neurons to take part in an analysis while working simultaneously but independently from each other.Artificial neural networks are also good at analysing large sets of unlabeled, often high-dimensional data-where it may be difficult to determine a prior which questions are most relevant and rewarding to ask\n\nThe tools for machine learning with neural networks were developed long ago, most of them during the second half of the last century. In 1943, McCulloch and Pitts analysed how networks of neurons can process information.\n\n"
      },
      "source": "https://raw.githubusercontent.com/aaditya-pdgupta/neural_network_in_biology/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 0.9614259984806564,
      "result": {
        "original_header": "Multi-layer Neural Network",
        "type": "Text_excerpt",
        "value": "A multi-layer neural network contains more than one layer of artificial neurons or nodes. They differ widely in design. It is important to note that while single-layer neural networks were useful early in the evolution of AI, the vast majority of networks used today have a multi-layer model. \nMulti-layer neural networks can be set up in numerous ways. Typically, they have at least one iput layer, which send weighted inputs series of hidden layers, and an output layer at the end. These more sophisticated setups are also assosicated with nonlinear builds using sidmoids and other function to direct the firing or activation of artificial neurons. A fully connected multi-layer neural network is called as  Multilayer Perceptron(MLP). In above figure we have one hidden layer including one input layer and one output layer.  An MLP is a typical example of feedforward artificial neural network. \nThe number of layers and the number of neurons are reffered to as hyperparameters of a neural network and these need tuning. Cross validation techniques must be used to find ideal values. An example of a multi-layer is shown in figure. It contains a layer of n input neuron $I_{i}$ (i = 1,...,n), a hidden layer( $H_{m}$ ) of m neuron on $H_{j}$ with the activation function $f_{Hj}$ (j = 1,...,m) and output layer of n neuron $O_{k}$ with the activation function $f_{Ok}$ (k = 1,....,n). The activation functions can be different for different layers. The connection between the neurons are weighed with different values, $v_{ij}$ are the weights between the hidden layer and the output layer. Using these weights, the networks propagates the external signal through the layers prodeucing the output signal which is of the form $I_{i}$.  \nThis type of ANN, which simply propagates the input through all the layers, is called a feed-forward multi-layer ANN. The example discussed here contains only oner hideen layer. The network architecture can be extended to contain as many hidden layer as necessary.\n \n"
      },
      "source": "https://raw.githubusercontent.com/aaditya-pdgupta/neural_network_in_biology/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9073214577694818,
      "result": {
        "original_header": "ANN learning",
        "type": "Text_excerpt",
        "value": "The learning process for an ANN is the process through which the weights of the network are determined. This is achieved by adjusting the weights until the certain criteria are satisfied. The ANN is presented with a training dataset which contains the input vector and a target associated with each input vector. The target is the desired output. The weights of the ANN are adjusted iteratively such that the difference between the actual output of the ANN and the target is minimized. The most common supervised learning method is based on the gradient descent learning rule. The method optimises the network weights such that a certain objective function E is minimized by calculating the gradient of E in the weight space and moving the weight vector along the negative gradient. The binary crossentropy (BCE) is used for training. The BCE calculates the loss by computing the following average: \nwhere, $\\hat{O_{i}}$ is the i-th scalar value in the output, $O_{i}$ is the corresponding target value, and N is the number of scalar values in the model output. For each iteration (usually called epoch), the gradient descent weight optimisation contains two phases:\n* feed-forward pass in which the output of the network is calculated with the current value of the weights, activation function and bias\n* backward propagation in which the errors of the output signal are propagated back from the output layer towards the input layer and the weights are adjusted as a function of the back-propagated errors. \n(i) initialisation of the weights  \n(ii) initialisation of the loss functions \n      (a) calculate $H_{jp}$ and $O_{kp}$ (feed-forward phase)\n      \n      (b) calculate the output error and the hidden layer error\n      \n      (c) adjust the weights $w_{kj}$ and $v_{kj} (black-propagation phase)\n      \n(iv) test the stopping criteria; if this is not met then the process continues from the step(ii) \nAs stopping criteria, common choices are a maximum number of epochs, a minimum value of the error function evaluated for the training data set, and the over-fitting point. The initialisation of the weights, the learning rate and the momentum are very important for the convergence and the efficiency of the learning process.  \n"
      },
      "source": "https://raw.githubusercontent.com/aaditya-pdgupta/neural_network_in_biology/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9978721227418099,
      "result": {
        "original_header": "Application in biology",
        "type": "Text_excerpt",
        "value": "Neural network has been applied widely in biology since the 1980s, and has advanced tremendously in the field of reasearch, and others lately. Baldi and Brunak used application in biology to explain the theory of neural network.The spectrum of apllications of artificial neural network is very wide. ANNs is used for the diagonis of different diseases in both palnt and animal caused due to different factors. The capacity of ANNs to analyze large amounts of data and detect patterns warrants application in analysis of medical images, calssification of tumors and prediction of survival have some how made easy resarch in medical biology. \nNeural networks have also been actively used in many bioinformatics applications such as DNA sequence, prediction, protein secondary structure prediction, gene expresssion profiles classification and analysis of gene expression patterns. The concepts of neural network used in pattern classification and signal processing gene procesing have been sucessfully applied in bioinformatics. Neural Likewise, in medical science ANNs have been extensively applied in diagosis, electronic signal analysis, radiology etc. ANNs have been used by many authors for clinical reserach. Application of ANNs are increasing in medical data mining. In agriculture Artififcial neural networks are one of the most popular tools for high production efficiency combined with a high quality products. ANNs can replace the classical methods of modelling many issuses, and are one of the main alternatives to classical mathematical models.networks have also been applied to the analysis of gene expression patterns as an alternative to hierarchial cluster methods. Neural networks have been used in agriculture for selection of appropriate net of plant during sudden and quick changes of environmental condition and predict the result of it. Here, we use ANN to classify that the Yeast is poisonous or edible to eat based on its properties.\n \n"
      },
      "source": "https://raw.githubusercontent.com/aaditya-pdgupta/neural_network_in_biology/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9984045473459581,
      "result": {
        "original_header": "Motivation",
        "type": "Text_excerpt",
        "value": "Mushroom specis can be both edible and non-edible. The non-edible are toxic and poisonous. The identification of edible and poisonous mushrooms among its existing species is a must due to its high demand for people's everyday meal and major advantage on medical science. It is very difficult to distinguish between edible and poisonous mushrooms due to their similar apperance. Distinguishing edible from poisonous mushroom species needs meticulous care to detail; there is no single trait by which poisonous mushrooms can be recognized, nor one by which all edible mushrooms can be recognized. So, ANNs will be able to classify if a mushroom is poisonous or not using data mining as one of the approaches for obtaining computer assisted knowledge. In this, we use the training dataset that contain the mushroom images that classify it into edible and poisonous. Here our approach aim is to classifies and predict for the class (groups) of mushrooms when submit the features of the mushrooms to different techniques of machine learning. \n"
      },
      "source": "https://raw.githubusercontent.com/aaditya-pdgupta/neural_network_in_biology/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9990592879077833,
      "result": {
        "original_header": "Data",
        "type": "Text_excerpt",
        "value": "A dataset that was originally contributed to the UCI Machine Learning repository nearly 30 years ago, mushroom hunting (otherwise known as \"shrooming\") is used to for the ANN purpose. It helps to learn which features (inputs) spell certain death and which are most palatable in this dataset of mushroom characteristics.This dataset includes descriptions of hypothetical samples corresponding to 23 species of gilled mushrooms in the Agaricus and Lepiota Family Mushroom drawn from The Audubon Society Field Guide to North American Mushrooms (1981). Each species is identified as definitely edible, definitely poisonous, or of unknown edibility and not recommended. This latter class was combined with the poisonous one. The Guide clearly states that there is no simple rule for determining the edibility of a mushroom; no rule like \"leaflets three, let it be'' for Poisonous Oak and Ivy.  \n* In this dataset, we consider the cap-shape in different letter notation such as bell-b, conical-c, convex-x, flat-f, knobbed-k and sunnksen as s. We also differntiate the different features of cap surface as fibrous-f, grooves-g, scaly-y, smooth-k. \n* Likewise, we also adrressed the different feautures of cap colaor as brown-n, buff-b, cinnamon-c, gray-g, green-r, pink-p, purple-u, red-e, white-w and yellow-y. \n* For odor, we have almond-a, anise-I, creosote-c, fishy-y, foul-f, musty-m, none-n, pungent-p and spicy-s. On the basis of gill-attachement we have denoted attached-a, descending-d, free-f and notched-n. Gill-spacing is denoted as close-c, crowded-w and distant-d. \n* In same way, gill-size features are denoted as broad-b and narrow-n. Gill color for black-k, brown-n, buff-b,, chocolate-h, gary-g, green-r, orange-o, pink-p, purple-u, red-e, white-w and yellow-y. \n* Similarly, for stalk shape feature different noatation is used such as enlarging-e and tapering-t. For different features of stalk-root we denoted bulbos-b, club-c, cup-u, equal-e, rhizomorphs-z, rooted-r and missing-?.\n*  We also have a different features under stalk-surface-below-ring which is denoted as fibrous-f, scale-y, silky-k and smooth-s. Continously for stalk-color-above-ring features we denote brown-n, buff-b, cinnamon-c, gray-g, orange-o, pink-p, red-e, white-w and yellow-y. \n*  For veil-type, we denote partial-p a-and universal-u. Similarly for veil-color we denote brown-n, orange-o, white-w and yellow-y. At last for ring-number none-n, one-o and two-t. \n  \n"
      },
      "source": "https://raw.githubusercontent.com/aaditya-pdgupta/neural_network_in_biology/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9904411679614817,
      "result": {
        "original_header": "Separation Using Machine Learning",
        "type": "Text_excerpt",
        "value": "A Multi-layer Neural Network act as a classifier to distinguish signal from background for classification of mushroom is constructed in python using tensorflow. The weights of input are also generated using random number generator in python. A Neural Network model with 16 node, 1 discriminator layers with adam optimizer and binary corresntropy used for optimization and loss calculation. The small learning avoids the overshooting. Here, fig titled Network response shows the neural network output for the signal and distribution for the training and testing sample of mushrooms. Here separation is very good which shows the accuracy is very high. Fig titled with Reciever Opertaing Curve shows the ROC curve of the neural network output. From the area under the ROC curve, it is clear that the efficiency of our neural network training is 1 which is perfect and there is no over fitting of data. Fig titled with Discriminator losses shows the loss of the neural network setup with varying the number of the epoches. Here, both training and testing sample decreases at once with the increase in the number of epochs which shows that there is no loss. Again if we have glance at fig titled Model accuracy shows the accuracy of the neural network setup with varying the number of the epoches. Both training and testing sample increases at same path with increase in the number of epohs which shows that the accuracy of the model is 100% .      \n"
      },
      "source": "https://raw.githubusercontent.com/aaditya-pdgupta/neural_network_in_biology/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9750178714653158,
      "result": {
        "original_header": "Discussion",
        "type": "Text_excerpt",
        "value": "A Multi-layer Neural Network as a classifier to distinguish signal from bakground was constructed. We used the prediction power of neural network to classify whether a mushroom is edible or poisonous. Our network achieved an accuracy of over 99%. We used the just NN environment for building the network that was a feed forward  Multi-Layer Perceptron with one input layer, one hidden layer and one output layer. The average predicatibility rate was above 99% for prediction of whether the mushroom is edible or poisonous.\n \n"
      },
      "source": "https://raw.githubusercontent.com/aaditya-pdgupta/neural_network_in_biology/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9789341767805433,
      "result": {
        "type": "Text_excerpt",
        "value": "The preprint version of this article is published on biorxiv. \n"
      },
      "source": "https://raw.githubusercontent.com/aaditya-pdgupta/neural_network_in_biology/main/README.md",
      "technique": "supervised_classification"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/aaditya-pdgupta/neural_network_in_biology/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "executable_example": [
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/aaditya-pdgupta/neural_network_in_biology/main/practice/machine_learning_test_2.ipynb"
      },
      "source": "https://raw.githubusercontent.com/aaditya-pdgupta/neural_network_in_biology/main/practice/machine_learning_test_2.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/aaditya-pdgupta/neural_network_in_biology/main/practice/machine_learning_test_3.ipynb"
      },
      "source": "https://raw.githubusercontent.com/aaditya-pdgupta/neural_network_in_biology/main/practice/machine_learning_test_3.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/aaditya-pdgupta/neural_network_in_biology/main/practice/machine_learning_test_1.ipynb"
      },
      "source": "https://raw.githubusercontent.com/aaditya-pdgupta/neural_network_in_biology/main/practice/machine_learning_test_1.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/aaditya-pdgupta/neural_network_in_biology/main/practice/.ipynb_checkpoints/machine_learning_test_3-checkpoint.ipynb"
      },
      "source": "https://raw.githubusercontent.com/aaditya-pdgupta/neural_network_in_biology/main/practice/.ipynb_checkpoints/machine_learning_test_3-checkpoint.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/aaditya-pdgupta/neural_network_in_biology/main/practice/.ipynb_checkpoints/machine_learning_test_2-checkpoint.ipynb"
      },
      "source": "https://raw.githubusercontent.com/aaditya-pdgupta/neural_network_in_biology/main/practice/.ipynb_checkpoints/machine_learning_test_2-checkpoint.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/aaditya-pdgupta/neural_network_in_biology/main/practice/.ipynb_checkpoints/machine_learning_test_1-checkpoint.ipynb"
      },
      "source": "https://raw.githubusercontent.com/aaditya-pdgupta/neural_network_in_biology/main/practice/.ipynb_checkpoints/machine_learning_test_1-checkpoint.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/aaditya-pdgupta/neural_network_in_biology/main/classify_yeast/Classification_of_mushroom.ipynb"
      },
      "source": "https://raw.githubusercontent.com/aaditya-pdgupta/neural_network_in_biology/main/classify_yeast/Classification_of_mushroom.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/aaditya-pdgupta/neural_network_in_biology/main/classify_yeast/.ipynb_checkpoints/Classification_of_mushroom-checkpoint.ipynb"
      },
      "source": "https://raw.githubusercontent.com/aaditya-pdgupta/neural_network_in_biology/main/classify_yeast/.ipynb_checkpoints/Classification_of_mushroom-checkpoint.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/aaditya-pdgupta/neural_network_in_biology/main/fig_of_inputs/Untitled.ipynb"
      },
      "source": "https://raw.githubusercontent.com/aaditya-pdgupta/neural_network_in_biology/main/fig_of_inputs/Untitled.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/aaditya-pdgupta/neural_network_in_biology/main/fig_of_inputs/Input_fig.ipynb"
      },
      "source": "https://raw.githubusercontent.com/aaditya-pdgupta/neural_network_in_biology/main/fig_of_inputs/Input_fig.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/aaditya-pdgupta/neural_network_in_biology/main/fig_of_inputs/test.ipynb"
      },
      "source": "https://raw.githubusercontent.com/aaditya-pdgupta/neural_network_in_biology/main/fig_of_inputs/test.ipynb",
      "technique": "file_exploration"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 0
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/aaditya-pdgupta/neural_network_in_biology/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "aaditya-pdgupta/neural_network_in_biology"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "Introduction"
      },
      "source": "https://raw.githubusercontent.com/aaditya-pdgupta/neural_network_in_biology/main/README.md",
      "technique": "regular_expression"
    }
  ],
  "images": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/aaditya-pdgupta/neural_network_in_biology/main/../main/Pictures/artificial_neural_network.jpg"
      },
      "source": "https://raw.githubusercontent.com/aaditya-pdgupta/neural_network_in_biology/main/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/aaditya-pdgupta/neural_network_in_biology/main/../main/Pictures/multi.jpg"
      },
      "source": "https://raw.githubusercontent.com/aaditya-pdgupta/neural_network_in_biology/main/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/aaditya-pdgupta/neural_network_in_biology/main/../main/Pictures/bioinformatics.jpg"
      },
      "source": "https://raw.githubusercontent.com/aaditya-pdgupta/neural_network_in_biology/main/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/aaditya-pdgupta/neural_network_in_biology/main/../main/Pictures/mushroom_pic.jpg"
      },
      "source": "https://raw.githubusercontent.com/aaditya-pdgupta/neural_network_in_biology/main/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/aaditya-pdgupta/neural_network_in_biology/main/../main/Pictures/different_types_of_mushroom.jpg"
      },
      "source": "https://raw.githubusercontent.com/aaditya-pdgupta/neural_network_in_biology/main/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/aaditya-pdgupta/neural_network_in_biology/main/../main/classify_yeast/separation_discriminator.jpg"
      },
      "source": "https://raw.githubusercontent.com/aaditya-pdgupta/neural_network_in_biology/main/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/aaditya-pdgupta/neural_network_in_biology/main/../main/classify_yeast/roc.jpg"
      },
      "source": "https://raw.githubusercontent.com/aaditya-pdgupta/neural_network_in_biology/main/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/aaditya-pdgupta/neural_network_in_biology/main/../main/classify_yeast/losses.jpg"
      },
      "source": "https://raw.githubusercontent.com/aaditya-pdgupta/neural_network_in_biology/main/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/aaditya-pdgupta/neural_network_in_biology/main/../main/classify_yeast/acc.jpg"
      },
      "source": "https://raw.githubusercontent.com/aaditya-pdgupta/neural_network_in_biology/main/README.md",
      "technique": "regular_expression"
    }
  ],
  "installation": [
    {
      "confidence": 0.8315970085126835,
      "result": {
        "original_header": "ANN learning",
        "type": "Text_excerpt",
        "value": "to summarise, the supervised learning process implies the following steps: \n"
      },
      "source": "https://raw.githubusercontent.com/aaditya-pdgupta/neural_network_in_biology/main/README.md",
      "technique": "supervised_classification"
    }
  ],
  "invocation": [
    {
      "confidence": 0.8258241121387184,
      "result": {
        "original_header": "Application in biology",
        "type": "Text_excerpt",
        "value": "<p align=\"center\">\n  <img src=\"../main/Pictures/bioinformatics.jpg\" width=\"300\" height=\"300\"/>\n</p> \n"
      },
      "source": "https://raw.githubusercontent.com/aaditya-pdgupta/neural_network_in_biology/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.843518041574009,
      "result": {
        "original_header": "Motivation",
        "type": "Text_excerpt",
        "value": "<p align=\"center\">\n  <img src=\"../main/Pictures/different_types_of_mushroom.jpg\" width=\"300\" height=\"300\"/>\n</p>\n \n"
      },
      "source": "https://raw.githubusercontent.com/aaditya-pdgupta/neural_network_in_biology/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8727715584421669,
      "result": {
        "original_header": "Separation Using Machine Learning",
        "type": "Text_excerpt",
        "value": "<p align=\"center\">\n  <img src=\"../main/classify_yeast/separation_discriminator.jpg\"  width=\"48%\" />\n  <img src=\"../main/classify_yeast/roc.jpg\"  width=\"48%\" /> \n</p> \n\n<p align=\"center\">\n  <img src=\"../main/classify_yeast/losses.jpg\"  width=\"48%\" />\n  <img src=\"../main/classify_yeast/acc.jpg\"  width=\"48%\" /> \n</p>\n \n"
      },
      "source": "https://raw.githubusercontent.com/aaditya-pdgupta/neural_network_in_biology/main/README.md",
      "technique": "supervised_classification"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/aaditya-pdgupta/neural_network_in_biology/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ""
      },
      "technique": "GitHub_API"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "neural_network_in_biology"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "User",
        "value": "aaditya-pdgupta"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Jupyter Notebook",
        "size": 640689,
        "type": "Programming_language",
        "value": "Jupyter Notebook"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 6734,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/aaditya-pdgupta/neural_network_in_biology/main/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "somef_missing_categories": [
    "citation",
    "acknowledgement",
    "run",
    "download",
    "requirements",
    "contact",
    "contributors",
    "documentation",
    "license",
    "usage",
    "faq",
    "support",
    "identifier",
    "has_build_file"
  ],
  "somef_provenance": {
    "date": "2024-10-04 01:01:37",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 0
      },
      "technique": "GitHub_API"
    }
  ]
}