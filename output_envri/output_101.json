{
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/marketneutral/alphatools"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2018-08-28T14:45:00Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2024-10-03T01:59:35Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "Quantitative finance research tools in Python"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 0.9669162183943463,
      "result": {
        "original_header": "Bring Your Own Data",
        "type": "Text_excerpt",
        "value": "To \"Bring Your Own Data\", you simply point the Factory object to an endpoint and specify the schema. This is done by adding to the `json` file `data_sources.json`. For example, if you have a `csv` file on disk, `data.csv`, and a PostgreSQL table somewhere else, you would create `data_sources.json` as\n```json\n{\n\t\"my_special_data\": {\n\t\t\"url\": \"/full/path/to/data/data.csv\",\n\t\t\"schema\": \"var * {asof_date: datetime, sid: int64, value: float64}\"\n\t},\n\t\n\t\"my_database_data\": {\n\t\t\"url\": \"postgresql://$USER:$PASS@hostname::my-table-name\",\n\t\t\"schema\": \"var * {asof_date: datetime, sid: int64, price_to_book: float64}\"\n}\n```\n \nIn the case of the example PostgreSQL `url`, note that the text `$USER` will be substituted with the text in the environment variable `USER` and the text `$PASS` will be substituted with the text in the environment variable `PASS`. Basically, any text token in the `url` which is preceeded by `$` will be substituted by the text in the environment variable of that name. Hence, you do not need to expose actual credentials in this file. \nThe `schema` is specified as a `dshape` from the package `datashape` (docs [here]()). The magic happens via the `blaze/datashape/odo` stack. You can specify the `url` to a huge variety of source formats including `json`, `csv`, PostgreSQL tables, MongoDB collections, `bcolz`, Microsoft Excel(!?), `.gz` compressed files, collections of files (e.g., `myfiles_*.csv`), and remote locations like Amazon S3 and a Hadoop Distributed File System. To me, the [`odo`](https://en.wikipedia.org/wiki/Odo_(Star_Trek)) [documentation on URI strings](http://odo.pydata.org/en/latest/uri.html) is the clearest explanation on this. \nNote that this data must be mapped to the `sid` as mapped by `zipline ingest`. Also, the data rowwise dates must be in a column titled `asof_date`. You can then access this data like\n```python\nfrom alphatools.data import Factory\n\t:\n\t:\n\t:\n\t\nmy_factor = Factory['my_database_data'].price_to_book.latest.rank()\np.add(my_factor)\n```\n \nThis functionality should allow you to use new data in research very quickly with the absolute minimal amount of data engineering and/or munging. For example, commercial risk model providers often provide a single file per day for factor loadings (e.g., `data_yyyymmdd_fac.csv`). After `sid` mapping and converting the date column name to `asof_date`,  this data can be immediately available in `Pipeline` by putting a `url` in `data_sources.json` like `\"url\": \"/path/to/dir/data_*_fac.csv\"`, and `schema` like `\"var * {asof_date: datetime, sid: int64, MKT_BETA: float64, VALUE: float64, MOMENTUM: float64, ST_REVERSAL: float64 ...\"`.\n \n"
      },
      "source": "https://raw.githubusercontent.com/marketneutral/alphatools/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9769520943788219,
      "result": {
        "original_header": "Expression Alphas",
        "type": "Text_excerpt",
        "value": "The ability to parse \"expression\" alphas is meant to help speed the research process and/or allow financial professionals with minimal Python experience to test alpha ideas. See [\"101 Formulaic Alphas\"](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2701346) for details on this DSL. The (EBNF) grammar is fully specified [\"here\"](https://github.com/marketneutral/alphatools/blob/master/alphatools/expression/expression.lark). We use the `Lark` Python [parsing library](https://github.com/lark-parser/lark) (great name, no relation). Currently, the data for `open`, `high`, `low`, `close`, `volume` are accessible; the following calculations and operators are implemented \n* `vwap`: the daily vwap (as a default, this is approximated with `(close + (opens + high + low)/3)/2`).\n* `returns`: daily close-to-close returns.\n* `+`,`-`, `*`, `/`, `^`: as expected, though only for two terms (i.e., only \\<expr\\> \\<op\\> \\<expr\\>); `^` is exponentiation, not bitwise or.\n* `-x`: unary minus on x (i.e., negation).\n* `abs(x)`, `log(x)`, `sign(x)`: elementwise standard math operations.\n* `>`, `<`, `==`, `||`: elementwise comparator operations returning 1 or 0.\n* `x ? y : z`: C-style ternary operator; `if x: y; else z`.\n* `rank(x)`: scaled ranks, per day, across all assets (i.e., the cross-sectional rank); ranks are descending such that the rank of the maximum raw value in the vector is 1.0; the smallest rank is 1/N. The re-scale of the ranks to the interval [1/N,1] is implied by Alpha 1: 0.50 is subtracted from the final ranked value. The ordinal method is used to match `Pipeline` method `.rank()`.\n* `delay(x, days)`: *x* lagged by *days*. Note that the *days* parameter in `delay` and `delta` differs from the `window_length` parameter you may be familiar with in `Pipeline`. The `window_length` refers to a the number of data points in the (row axis of the) data matrix, *not* the number of days lag. For example, in `Pipeline` if you want daily returns, you specify a `window_length` of `2` since you need 2 data points--today and the day prior--to get a daily return. In an expression alpha, the *days* is the lag *from today*. Concretely, a simple example to show is: the `Pipeline` factor `Returns(window_length=2)` is precisely equal to the expression alpha `delta(close,1)/delay(close,1)`.\n* `correlation(x, y, days)`: the Pearson correlation of the values for assets in *x* to the corresponding values for the same assets in *y* over *days*; note this is very slow in the current implementation.\n* `covariance(x, y, days)`: the covariance of the values for assets in *x* to the corresponding values for the same assets in *y* over *days*; note this is very slow as well currently.\n* `delta(x, days)`: diff on *x* per *days* timestep.\n* `signedpower(x, a)`: elementwise `sign(x)*(abs(x)^a)`.\n* `decay_linear(x, days)`: weighted sum of *x* over the past *days* with linearly decaying weights (weights sum to 1; max of the weights is on the most recent day).\n* `indneutralize(x, g)`: `x`, cross-sectionally \"neutralized\" (i.e., demeaned) against the group membership classifier `g`. `g` must be in the set {`IndClass.sector`, `IndClass.industry`, `IndClass.subindustry`}. The set `g` maps to the `Pipeline` classifiers `Sector()` and `SubIndustry()` in `alphatools.ics`. Concretely, the `Pipeline` factor `Returns().demean(groupby=Sector())` is equivalent (save a corner case on NaN treatment) to the expression `indneutralize(returns, IndClass.sector)`. If you do not specifically pass a token for `g`, the default of `IndClass.industry` is applied.\n* `ts_max(x, days)`: the per asset time series max on *x* over the trailing *days* (also `ts_min(...)`).\n* `max(a, b)`: The paper says that `max` is an alias for `ts_max(a, b)`; I think this is an error. Alphas 71, 73, 76, 87, and 96 do not parse with `max` as alias for `ts_max`. Rather I believe that `max` means elementwise maximum of two arrays (i.e., like `pmax(...)` in R and `np.maximum(...)` in Numpy) and have implemented it as such; same for `min(a, b)`. \n* `ts_argmax(x, days)`: on which day `ts_max(x, days)` occurred (also `ts_argmin(...)`) scaled to the interval [1/days,1]. For example, if window (*days*) is 10 days, and the max is in the most recent day, it will return 1.0; if the max is in the earliest day it will return 0.10.\n* `ts_rank(x, days)`: the time series rank per asset on *x* over the the trailing *days*. Currently this is in the range [0,1], but should be [1/days,1].\n* `sum(x, days)`: the sum per asset on *x* over the trailing *days*.\n* `product(x, days)`: the product per asset on *x* over the trailing *days*.\n* `stddev(x, days)`: the standard deviation per asset on *x* over the trailing *days*.\n* `adv{days}`: the average daily **dollar** volume per asset over the trailing *days* (e.g., `adv20` gives the 20-day trailing average daily dollar volume). \nThe expression alpha parser produces `zipline` compatible `Pipeline` factor code. This implementation makes use of the `bottleneck` package which provides many `numpy`-style rolling aggregations, implemented in highly optimized compiled C code. The `bottleneck` package is distributed in binary form in the Anaconda Python distribution (see Installation below). \nThis is quite helpful, in my opinion, to understand a third-party alpha like this. So what's happening? Looking top to bottom at each level, left to right: if zero is less than the minimum of the daily price change over the trailing five days (i.e., if the stock has gone **up** *every day* for the last five days), then the factor value is simpy the price change over the *most recent* day, which is a positive number by definition, and thus bets that positive momentum will continue. That branch should be pretty rare (meaning it would be rare for a stock to go up every day for five days in a row). Otherwise, we check if the max price change in the last 5 days is less than zero (i.e., the stock has gone **down** *every day* for the last 5 days), then the factor value again is just the price change over the *most recent day*, which is a negative number by definition. Thus if the stock has gone straight down for 5 days, the factor bets that it will continue. This should also be rare. Lastly, if neither of these two states exist, the factor value is just -1 times the last day's price change; i.e., a bet on mean reversion. Hence, by inspecting the parse tree like this, we can understand that this alpha is a momentum/mean-reversion switching factor; it assumes momentum will persist if the prior five days have moved in the same direction, otherwise it assumes mean-reversion will occur. \nThere is no compile-time optimization of the AST at all! What is happening is that the compiler walks down the AST and converts each node into a Python equivalent (`numpy`, `bottleneck`, and/or `pandas`) expression, keeping track of the call stack so that future references to prior calculations are correct. The resulting Python code is in the style of \"three-address code\". There is of course plenty of optimization which can be done. \nNote that there is no reference implementation of the expression-style alpha syntax to test against and that there are many specific details lacking the paper. As such, this implementation makes some assumptions where necessary (as a simple example, the paper does not specify if `rank` is ascending or descending, however, it obviously should be ascending as a larger raw value should produce a larger numberical rank to keep the alpha vector *directly* proportional). This is experimental and I have created only a handful of tests.\n \n"
      },
      "source": "https://raw.githubusercontent.com/marketneutral/alphatools/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9708078336211354,
      "result": {
        "original_header": "Using Your Own Data in Expression Alphas",
        "type": "Text_excerpt",
        "value": "It is also possible to use the \"bring your own data\" functionality provided by the `Factory` object in an expression alpha. This is done with one or more `factory` expressions. The syntax is \n* `factory(\"<dataset>\")`: where `\"<dataset>\"` is the name you would pass into the `Factory` object (for now assuming the data is in a column called \"value\"). Concretely, if you have a dataset, \"sample\", defined in the `data_sources.json` file, you can access it in an expression as:\n```\n(returns > 0) ? factory(\"sample\") : -sum(returns, 5)\n```\nThis compiles to the `Pipeline` factor as:\n```python\nclass ExprAlpha_1(CustomFactor):\n    inputs = [Returns(window_length=2), Factory[\"sample\"].value]\n    window_length = 7\n\n    def compute(self, today, assets, out, returns, factory0):\n        v0 = np.greater(returns, 0)\n        v1 = pd.DataFrame(data=returns).rolling(\n            window=5, center=False, min_periods=1).sum().values\n        v2 = -v1\n        v3 = np.where(v0, factory0, v2)\n        out[:] = v3[-1]\n```\n \n"
      },
      "source": "https://raw.githubusercontent.com/marketneutral/alphatools/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9873859436184812,
      "result": {
        "original_header": "A Word on Sector and Industry Classfiers Included",
        "type": "Text_excerpt",
        "value": "Sector and Industry data were scraped from Yahoo Finance on September 18, 2017 for the full Quandl WIKI universe at that time. The SIC and CIK codes were scraped from [Rank and Filed](http://rankandfiled.com/) on September 15, 2017. The classifiers built from this data assume that the codes have never and do never change (i.e., there is no concept of an asset being reclassified over time). **Be aware that there is lookahead bias in this** (e.g., a good example of why there is lookahead bias is with Corning, Inc. which is classified as a Technology/Electronic Components company in this dataset, but from 1851 to the 2000s(?) was actually classified as a boring Industrial glass company; the economic make up the company changed sometime in the early 1990s when optic fiber production became an important revenue driver and later with iPhone glass. At some point, the ICS providers changed the classification from \"boring\" to \"high tech\", but this was surely lagging the actual transformation of the company; hence...lookahead bias).\n \n"
      },
      "source": "https://raw.githubusercontent.com/marketneutral/alphatools/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9923480342231641,
      "result": {
        "original_header": "A Word on Fundamental Data",
        "type": "Text_excerpt",
        "value": "Although there is a `Fundamentals` factor included, there is no Fundamental data included in the package. This factor was built on top of the `DataFrameLoader` to get a `pandas.DataFrame` into a factor. I think I will deprecate this in favor of using the `Factory` object as described above. In the meantime, the `Fundamentals` pipeline factors can be built from `make_fundamentals.py` with your own data. Note that these factors use the `DataFrameLoader` which means the data must fit in memory. \n \n"
      },
      "source": "https://raw.githubusercontent.com/marketneutral/alphatools/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9841314386125685,
      "result": {
        "original_header": "Disclaimer",
        "type": "Text_excerpt",
        "value": "Though this is in the `LICENSE` file, it bears noting that this software is provided on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied, including, without limitation, any warranties or conditions of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A PARTICULAR PURPOSE \nAdditionally, nothing in this package constitutes investment advice. This package is a personal project and nothing in its functionality or examples is reflective of any past or current employer. \nI hope you enjoy this package. Please leave feedback.\n \n"
      },
      "source": "https://raw.githubusercontent.com/marketneutral/alphatools/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9958862982174744,
      "result": {
        "type": "Text_excerpt",
        "value": "This package aims to provide environments within which best-in-class open source tools across **both** financial research (e.g., `zipline`, `alphelens`, and `pyfolio`) and machine learning (e.g., `scikit-learn`, `LightGBM`, `PyMC3`, `pytorch`, and `fastai`) operate together. The \"stable\" enviroment is on Python 3.5 and does not include `fastai`. The \"latest\" environment is on Python 3.6 and relies on the backwards compatibility PEP for packages which state only 3.5 support (e.g., `zipline`). The latest environment includes the pre-release of PyTorch 1.0 and fastai 1.0.x. The PyTorch version in both environments is currently \"CPU\" only (i.e., no GPU/CUDA for now). The \"tests\" are only testing that the environments are built without conflict for now. \nAdditionally, this package provides functions to make the equity alpha factor research process more accessible and productive. Convenience functions sit on top of  and, specifically, the  cross-sectional classes and functions in that package. `alphatools` allows you to  \n- `run_pipeline` in a Jupyter notebook (or from any arbitrary Python code) **in your local environment**,\n- create `Pipeline` factors **at runtime** on **arbitrary data sources** (just expose the endpoint for data sitting somewhere, specify the schema, and...it's available for use in `Pipeline`!),\n- parse and compile **\"expression\" style alphas** as described the paper  into `Pipeline` factors, and\n- work with and plot ingested **pricing data from an arbitrary bundle** with a `get_pricing(...)` function call. \n"
      },
      "source": "https://raw.githubusercontent.com/marketneutral/alphatools/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/marketneutral/alphatools/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "executable_example": [
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/marketneutral/alphatools/master/notebooks/pyfolio-minimal.ipynb"
      },
      "source": "https://raw.githubusercontent.com/marketneutral/alphatools/master/notebooks/pyfolio-minimal.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/marketneutral/alphatools/master/notebooks/research-set-bundle.ipynb"
      },
      "source": "https://raw.githubusercontent.com/marketneutral/alphatools/master/notebooks/research-set-bundle.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/marketneutral/alphatools/master/notebooks/pipeline-blaze-minimal.ipynb"
      },
      "source": "https://raw.githubusercontent.com/marketneutral/alphatools/master/notebooks/pipeline-blaze-minimal.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/marketneutral/alphatools/master/notebooks/BayesSearchCV-minimal.ipynb"
      },
      "source": "https://raw.githubusercontent.com/marketneutral/alphatools/master/notebooks/BayesSearchCV-minimal.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/marketneutral/alphatools/master/notebooks/pymc3-minimal.ipynb"
      },
      "source": "https://raw.githubusercontent.com/marketneutral/alphatools/master/notebooks/pymc3-minimal.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/marketneutral/alphatools/master/notebooks/pipeline-minimal.ipynb"
      },
      "source": "https://raw.githubusercontent.com/marketneutral/alphatools/master/notebooks/pipeline-minimal.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/marketneutral/alphatools/master/notebooks/research-minimal-scratch.ipynb"
      },
      "source": "https://raw.githubusercontent.com/marketneutral/alphatools/master/notebooks/research-minimal-scratch.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/marketneutral/alphatools/master/notebooks/lightgbm-minimal.ipynb"
      },
      "source": "https://raw.githubusercontent.com/marketneutral/alphatools/master/notebooks/lightgbm-minimal.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/marketneutral/alphatools/master/notebooks/research-minimal.ipynb"
      },
      "source": "https://raw.githubusercontent.com/marketneutral/alphatools/master/notebooks/research-minimal.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/marketneutral/alphatools/master/notebooks/expression-alphas.ipynb"
      },
      "source": "https://raw.githubusercontent.com/marketneutral/alphatools/master/notebooks/expression-alphas.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/marketneutral/alphatools/master/notebooks/pipeline-blaze-factory.ipynb"
      },
      "source": "https://raw.githubusercontent.com/marketneutral/alphatools/master/notebooks/pipeline-blaze-factory.ipynb",
      "technique": "file_exploration"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 83
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/marketneutral/alphatools/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "marketneutral/alphatools"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ""
      },
      "source": "https://raw.githubusercontent.com/marketneutral/alphatools/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "has_script_file": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/marketneutral/alphatools/master/install_latest.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/marketneutral/alphatools/master/install_stable.sh"
      },
      "technique": "file_exploration"
    }
  ],
  "images": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://user-images.githubusercontent.com/16124573/45173356-f3b9f180-b1d5-11e8-97ba-5e92154c630a.png"
      },
      "source": "https://raw.githubusercontent.com/marketneutral/alphatools/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://user-images.githubusercontent.com/16124573/45169838-6e7e0f00-b1cc-11e8-9967-0c9d8bf70172.png"
      },
      "source": "https://raw.githubusercontent.com/marketneutral/alphatools/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "installation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Installation",
        "type": "Text_excerpt",
        "value": "Run the following in order:\n\n```\ngit clone https://github.com/marketneutral/alphatools\ncd alphatools\n./install_stable.sh\nzipline ingest\n```\n\nNote that when you run `zipline ingest` the security master is built from scratch and each `sid` is assigned at that time. You must map the `Sector`, `Industry` classifiers in this package **and all your own data** after every `zipline ingest`. You can map the `Sector` and `Industry` classifiers with\n\n```\nalphatools ingest\n```\n\n"
      },
      "source": "https://raw.githubusercontent.com/marketneutral/alphatools/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 0.9913528903795453,
      "result": {
        "original_header": "Bring Your Own Data",
        "type": "Text_excerpt",
        "value": "In the case of the example PostgreSQL `url`, note that the text `$USER` will be substituted with the text in the environment variable `USER` and the text `$PASS` will be substituted with the text in the environment variable `PASS`. Basically, any text token in the `url` which is preceeded by `$` will be substituted by the text in the environment variable of that name. Hence, you do not need to expose actual credentials in this file. \n"
      },
      "source": "https://raw.githubusercontent.com/marketneutral/alphatools/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.986991580972627,
      "result": {
        "original_header": "Expression Alphas",
        "type": "Text_excerpt",
        "value": "The expression alpha parser produces `zipline` compatible `Pipeline` factor code. This implementation makes use of the `bottleneck` package which provides many `numpy`-style rolling aggregations, implemented in highly optimized compiled C code. The `bottleneck` package is distributed in binary form in the Anaconda Python distribution (see Installation below). \n<img src=\"https://user-images.githubusercontent.com/16124573/45169838-6e7e0f00-b1cc-11e8-9967-0c9d8bf70172.png\" width=\"750\"> \nYou can see the resuling `Pipeline` code (though this is not necessary to use the alpha in `run_pipeline`) with `print(e.pipeline_code)`:\n```python\nclass ExprAlpha_1(CustomFactor):\n    inputs = [USEP.close]\n    window_length = 17\n\n    def compute(self, today, assets, out, close):\n        v0 = close - np.roll(close, 1, axis=0)\n        v1 = bn.move_min(v0, window=5, min_count=1,  axis=0)\n        v2 = np.less(0, v1)\n        v3 = close - np.roll(close, 1, axis=0)\n        v4 = close - np.roll(close, 1, axis=0)\n        v5 = bn.move_max(v4, window=5, min_count=1,  axis=0)\n        v6 = np.less(v5, 0)\n        v7 = close - np.roll(close, 1, axis=0)\n        v8 = close - np.roll(close, 1, axis=0)\n        v9 = 1*v8\n        v10 = -v9\n        v11 = np.where(v6, v7, v10)\n        v12 = np.where(v2, v3, v11)\n        out[:] = v12[-1]\n```\n \n"
      },
      "source": "https://raw.githubusercontent.com/marketneutral/alphatools/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8691855461434965,
      "result": {
        "original_header": "Disclaimer",
        "type": "Text_excerpt",
        "value": "Lastly, there are no automated tests (or any significnat tests for that matter), no automated nightly build, no docstrings, or any other features associated with what you might consider a well supported open source package.  \nI hope you enjoy this package. Please leave feedback.\n \n"
      },
      "source": "https://raw.githubusercontent.com/marketneutral/alphatools/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9999996837275875,
      "result": {
        "type": "Text_excerpt",
        "value": "This package aims to provide environments within which best-in-class open source tools across **both** financial research (e.g., `zipline`, `alphelens`, and `pyfolio`) and machine learning (e.g., `scikit-learn`, `LightGBM`, `PyMC3`, `pytorch`, and `fastai`) operate together. The \"stable\" enviroment is on Python 3.5 and does not include `fastai`. The \"latest\" environment is on Python 3.6 and relies on the backwards compatibility PEP for packages which state only 3.5 support (e.g., `zipline`). The latest environment includes the pre-release of PyTorch 1.0 and fastai 1.0.x. The PyTorch version in both environments is currently \"CPU\" only (i.e., no GPU/CUDA for now). The \"tests\" are only testing that the environments are built without conflict for now. \n"
      },
      "source": "https://raw.githubusercontent.com/marketneutral/alphatools/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "invocation": [
    {
      "confidence": 0.8655228051308941,
      "result": {
        "original_header": "Bring Your Own Data",
        "type": "Text_excerpt",
        "value": "To \"Bring Your Own Data\", you simply point the Factory object to an endpoint and specify the schema. This is done by adding to the `json` file `data_sources.json`. For example, if you have a `csv` file on disk, `data.csv`, and a PostgreSQL table somewhere else, you would create `data_sources.json` as\n```json\n{\n\t\"my_special_data\": {\n\t\t\"url\": \"/full/path/to/data/data.csv\",\n\t\t\"schema\": \"var * {asof_date: datetime, sid: int64, value: float64}\"\n\t},\n\t\n\t\"my_database_data\": {\n\t\t\"url\": \"postgresql://$USER:$PASS@hostname::my-table-name\",\n\t\t\"schema\": \"var * {asof_date: datetime, sid: int64, price_to_book: float64}\"\n}\n```\n \n"
      },
      "source": "https://raw.githubusercontent.com/marketneutral/alphatools/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8248878278288548,
      "result": {
        "original_header": "Expression Alphas",
        "type": "Text_excerpt",
        "value": "\nThe abstract snytax tree (\"AST\") can be visualized with `from lark.tree import pydot__tree_to_png; pydot__tree_to_png(e.tree, \"alpha9.png\")`: \n"
      },
      "source": "https://raw.githubusercontent.com/marketneutral/alphatools/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8255504711278145,
      "result": {
        "type": "Text_excerpt",
        "value": "For example, with `alphatools`, you can, say, within a Jupyter notebook,\n```python\nfrom alphatools.research import run_pipeline\nfrom alphatools.ics import Sector\nfrom alphatools.data import Factory\nfrom alphatools.expression import ExpressionAlpha\nfrom zipline.pipeline.data import USEquityPricing as USEP\nfrom zipline.pipeline.factors import Returns, AverageDollarVolume\nfrom zipline.pipeline import Pipeline\n\nn_assets = 500\nuniverse = AverageDollarVolume(window_length=120).top(n_assets)\n\nmy_factor = (\n    (-Returns(mask=universe, window_length=5)\n      .demean(groupby=Sector()))\n    .rank()/n_assets\n)\n\nexpr_factor = (\n    ExpressionAlpha(\n        'rank(indneutralize(-log(close/delay(close, 4)), IndClass.sector))'\n    ).make_pipeline_factor().pipeline_factor(mask=universe)\n)\n\np = Pipeline(screen=universe)\n\np.add(my_factor, '5d_MR_Sector_Neutral_Rank')\np.add(expr_factor, '5d_MR_Expression_Alpha')\n\np.add(Factory['my_special_data'].value.latest.zscore(), 'Special_Factor')\n\nstart_date = '2017-01-04'\nend_date = '2017-12-28'\n\ndf = run_pipeline(p, start_date, end_date)\n```\n \n"
      },
      "source": "https://raw.githubusercontent.com/marketneutral/alphatools/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/marketneutral/alphatools/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "data-science, machine-learning, python, quant, quantitative-finance"
      },
      "technique": "GitHub_API"
    }
  ],
  "license": [
    {
      "confidence": 1,
      "result": {
        "name": "Apache License 2.0",
        "spdx_id": "Apache-2.0",
        "type": "License",
        "url": "https://api.github.com/licenses/apache-2.0",
        "value": "https://api.github.com/licenses/apache-2.0"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "type": "File_dump",
        "value": "                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright 2018 Jonathan Larkin\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n"
      },
      "source": "https://raw.githubusercontent.com/marketneutral/alphatools/master/LICENSE",
      "technique": "file_exploration"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "alphatools"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "User",
        "value": "marketneutral"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Jupyter Notebook",
        "size": 3046462,
        "type": "Programming_language",
        "value": "Jupyter Notebook"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 50530,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Shell",
        "size": 2949,
        "type": "Programming_language",
        "value": "Shell"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/marketneutral/alphatools/master/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "releases": [
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "marketneutral",
          "type": "User"
        },
        "date_created": "2018-08-28T15:07:34Z",
        "date_published": "2018-08-28T16:29:40Z",
        "description": "This is the first release of `alphatools`. ",
        "html_url": "https://github.com/marketneutral/alphatools/releases/tag/0.10",
        "name": "First Release",
        "release_id": 12615441,
        "tag": "0.10",
        "tarball_url": "https://api.github.com/repos/marketneutral/alphatools/tarball/0.10",
        "type": "Release",
        "url": "https://api.github.com/repos/marketneutral/alphatools/releases/12615441",
        "value": "https://api.github.com/repos/marketneutral/alphatools/releases/12615441",
        "zipball_url": "https://api.github.com/repos/marketneutral/alphatools/zipball/0.10"
      },
      "technique": "GitHub_API"
    }
  ],
  "somef_missing_categories": [
    "citation",
    "acknowledgement",
    "run",
    "download",
    "requirements",
    "contact",
    "contributors",
    "documentation",
    "usage",
    "faq",
    "support",
    "identifier",
    "has_build_file"
  ],
  "somef_provenance": {
    "date": "2024-10-03 23:14:53",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 405
      },
      "technique": "GitHub_API"
    }
  ]
}