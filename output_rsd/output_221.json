{
  "citation": [
    {
      "confidence": 1,
      "result": {
        "format": "cff",
        "type": "File_dump",
        "value": "# This CITATION.cff file was generated with cffinit.\n# Visit https://bit.ly/cffinit to generate yours today!\n\ncff-version: 1.2.0\ntitle: 'BIOMERO: BioImage analysis in OMERO'\nmessage: >-\n  If you use this software, please cite it using the\n  metadata from this file.\ntype: software\nauthors:\n  - given-names: Torec Tom\n    family-names: Luik\n    email: t.t.luik@amsterdamumc.nl\n    affiliation: Amsterdam UMC\n    orcid: 'https://orcid.org/0009-0007-9361-0586'\n  - given-names: Rodrigo\n    family-names: Rosas-Bertolini\n    affiliation: Amsterdam UMC\n  - given-names: Eric A.J.\n    family-names: Reits\n    affiliation: Amsterdam UMC\n  - given-names: Ron A.\n    family-names: Hoebe\n    affiliation: Amsterdam UMC\n  - given-names: Przemek M.\n    family-names: Krawczyk\n    affiliation: Amsterdam UMC\nidentifiers:\n  - type: url\n    value: 'https://arxiv.org/abs/2402.00734'\n    description: Preprint on arxiv\n  - type: doi\n    value: 10.5281/zenodo.8108214\n    description: ZENODO DOI for all versions\nrepository-code: 'https://github.com/NL-BioImaging/biomero'\nurl: 'https://nl-bioimaging.github.io/biomero/'\nrepository: 'https://github.com/NL-BioImaging/biomero-scripts'\nrepository-artifact: 'https://pypi.org/project/biomero/'\nabstract: >-\n  In the rapidly evolving field of bioimaging, the\n  integration and orchestration of Findable, Accessible,\n  Interoperable, and Reusable (FAIR) image analysis\n  workflows remains a challenge. We introduce BIOMERO, a\n  bridge connecting OMERO, a renowned bioimaging data\n  management platform, FAIR workflows and high-performance\n  computing (HPC) environments. BIOMERO, featuring our\n  opensource Python library \"OMERO Slurm Client\",\n  facilitates seamless execution of FAIR workflows,\n  particularly for large datasets from High Content or High\n  Throughput Screening. BIOMERO empowers researchers by\n  eliminating the need for specialized knowledge, enabling\n  scalable image processing directly from OMERO. BIOMERO\n  notably supports the sharing and utilization of FAIR\n  workflows between OMERO, Cytomine/BIAFLOWS, and other\n  bioimaging communities. BIOMERO will promote the\n  widespread adoption of FAIR workflows, emphasizing\n  reusability, across the realm of bioimaging research. Its\n  user-friendly interface will empower users, including\n  those without technical expertise, to seamlessly apply\n  these workflows to their datasets, democratizing the\n  utilization of AI by the broader research community.\nkeywords:\n  - python\n  - omero\n  - slurm\n  - high-performance-computing\n  - fair\n  - image-analysis\n  - bioimaging\n  - cytomine\n  - biomero\n  - biaflows\n  - high-throughput-screening\n  - high-content-screening\nlicense: Apache-2.0\n"
      },
      "source": "https://raw.githubusercontent.com/NL-BioImaging/biomero/main/CITATION.cff",
      "technique": "file_exploration"
    }
  ],
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/NL-BioImaging/biomero"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2023-05-10T13:04:43Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2024-07-25T04:52:49Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "BIOMERO - A python library for easy connecting between OMERO (jobs) and a Slurm cluster"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 0.9331704136052,
      "result": {
        "original_header": "BIOMERO - BioImage analysis in OMERO",
        "type": "Text_excerpt",
        "value": "The **BIOMERO** framework, for **B**io**I**mage analysis in **OMERO**, allows you to run (FAIR) bioimage analysis workflows directly from OMERO on a high-performance compute (HPC) cluster, remotely through SSH. \nThe BIOMERO framework consists of this Python library `biomero`, together with the [BIOMERO scripts](https://github.com/NL-BioImaging/biomero-scripts) that can be run directly from the OMERO web interface. \nThe package includes the `SlurmClient` class, which provides **SSH-based connectivity** and interaction with a [Slurm](https://slurm.schedmd.com/quickstart.html) (high-performance compute) cluster. The package enables users to submit jobs, monitor job status, retrieve job output, and perform other Slurm-related tasks. Additionally, the package offers functionality for configuring and managing paths to Slurm data and Singularity images (think Docker containers...), as well as specific FAIR image analysis workflows and their associated repositories.  \nOverall, the `biomero` package simplifies the integration of HPC functionality within the OMERO platform for admins and provides an efficient and end-user-friendly interface towards both the HPC and FAIR workflows. \n"
      },
      "source": "https://raw.githubusercontent.com/NL-BioImaging/biomero/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9767190798543488,
      "result": {
        "original_header": "Overview",
        "type": "Text_excerpt",
        "value": "In the figure below we show our **BIOMERO** framework, for **B**io**I**mage analysis in **OMERO**.  \nBIOMERO consists of this Python library (`biomero`) and the integrations within OMERO, currently through our [BIOMERO scripts](https://github.com/NL-BioImaging/biomero-scripts). \n"
      },
      "source": "https://raw.githubusercontent.com/NL-BioImaging/biomero/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9614247581172455,
      "result": {
        "original_header": "Quickstart",
        "type": "Text_excerpt",
        "value": "For a quick overview of what this library can do for you, we can install an example setup locally with Docker: \n1. Setup a local OMERO w/ this library: \n    - Follow Quickstart of https://github.com/Cellular-Imaging-Amsterdam-UMC/NL-BIOMERO\n2. Setup a local Slurm w/ SSH access: \n    - Follow Quickstart of https://github.com/TorecLuik/slurm-docker-cluster\n3. Upload some data with OMERO.insight to `localhost` server (... we are working on a web importer ... TBC)\n4. Try out some scripts from https://github.com/NL-BioImaging/biomero-scripts (already installed in step 1!):\n    1. Run script `slurm/init/SLURM Init environment...`\n    2. Get a coffee or something. This will take at least 10 min to download all the workflow images. Maybe write a nice review on `image.sc` of this software, or here on the `Discussions` tab of Github.\n    3. Select your image / dataset and run script `slurm/workflows/SLURM Run Workflow...`\n        - Select at least one of the `Select how to import your results`, e.g. change `Import into NEW Dataset` text to `hello world`\n        - Select a fun workflow, e.g. `cellpose`.\n            - Change the `nuc channel` to the channel to segment (note that 0 is for grey, so 1,2,3 for RGB)\n            - Uncheck the `use gpu` (step 2, our HPC cluster, doesn't come with GPU support built into the containers)\n        - Refresh your OMERO `Explore` tab to see your `hello world` dataset with a mask image when the workflow is done! \n"
      },
      "source": "https://raw.githubusercontent.com/NL-BioImaging/biomero/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9491397658341494,
      "result": {
        "original_header": "BIOMERO scripts",
        "type": "Text_excerpt",
        "value": "The easiest interaction from OMERO with this library currently is through our BIOMERO scripts, which are just a set of OMERO scripts using this library for all the steps one needs to run a image analysis workflow from OMERO on Slurm and retrieve the results back into OMERO. \nFor example, [workflows/Slurm Run Workflow](https://github.com/NL-BioImaging/biomero-scripts/blob/master/workflows/SLURM_Run_Workflow.py) should provide an easy way to send data to Slurm, run the configured and chosen workflow, poll Slurm until jobs are done (or errors) and retrieve the results when the job is done. This workflow script uses some of the other scripts, like \n- [`workflows/Slurm Run Workflow Batched`](https://github.com/NL-BioImaging/biomero-scripts/blob/master/workflows/SLURM_Run_Workflow_Batched.py): This will allow you to run several `workflows/Slurm Run Workflow` in parallel, by batching your input images into smaller chunks (e.g. turn 64 images into 2 batches of 32 images each). It will then poll all these jobs. \n- [`workflows/Slurm CellPose Segmentation`](https://github.com/NL-BioImaging/biomero-scripts/blob/master/workflows/SLURM_CellPose_Segmentation.py): This is a more primitive script that only runs the actual workflow `CellPose` (if correctly configured). You will need to manually transfer data first (with `Slurm Image Transfer`) and manually retrieve data afterward (with `Slurm Get Results`). \n"
      },
      "source": "https://raw.githubusercontent.com/NL-BioImaging/biomero/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9381801766799094,
      "result": {
        "original_header": "(Docker) containers",
        "type": "Text_excerpt",
        "value": "We host BIOMERO container dockerfiles at [NL-BIOMERO](https://github.com/Cellular-Imaging-Amsterdam-UMC/NL-BIOMERO), which publishes container images to our public dockerhub [cellularimagingcf](https://hub.docker.com/repositories/cellularimagingcf). Specifically the [cellularimagingcf/biomero](https://hub.docker.com/repository/docker/cellularimagingcf/biomero/general) image is an OMERO processor container with BIOMERO library installed. When we release a new version of BIOMERO, we will also release a new version of these containers (because we deploy these locally at our Core Facility - Cellular Imaging). \nNote2: We will also update these containers with our own desired changes, so they will likely not be 1:1 copy with basic omero containers. Especially when we start making a nicer UI for BIOMERO. We will keep up-to-date with the OMERO releases when possible.\n \n"
      },
      "source": "https://raw.githubusercontent.com/NL-BioImaging/biomero/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9461820049657556,
      "result": {
        "original_header": "SSH",
        "type": "Text_excerpt",
        "value": "Note: this library is built for **SSH-based connections**. If you could, it would be a lot easier to just have the OMERO `processor` server and the `slurm` client server be (on) the same machine: then you can just directly call `sbatch` and other `slurm` commands from OMERO scripts and Slurm would have better access to your data.  \nThis is mainly for those cases where you already have an external HPC cluster and want to connect your OMERO instance. \nTheoretically, you could extend the `SlurmClient` class and change the `run` commands to not use SSH, but just a `subprocess`. We might implement this if we need it in the future.\nBut then you could also look at other Python libraries like [submitit](https://github.com/facebookincubator/submitit).\n \n"
      },
      "source": "https://raw.githubusercontent.com/NL-BioImaging/biomero/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9682390548132721,
      "result": {
        "original_header": "SlurmClient class",
        "type": "Text_excerpt",
        "value": "The SlurmClient class is the main entrypoint in using this library.\nIt is a Python class that extends the Connection class from the Fabric library. It allows connecting to and interacting with a Slurm cluster over SSH.  \nIt includes attributes for specifying paths to directories for Slurm data and Singularity images, as well as specific paths, repositories, and Dockerhub information for different Singularity image models.  \nIt also offers a `from_config` class method to create a `SlurmClient` object by reading configuration parameters from a file. Overall, the class provides a convenient way to work with Slurm clusters and manage job execution and monitoring. \n"
      },
      "source": "https://raw.githubusercontent.com/NL-BioImaging/biomero/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9449551049617402,
      "result": {
        "original_header": "slurm-config.ini",
        "type": "Text_excerpt",
        "value": "The `slurm-config.ini` file is a configuration file used by the `biomero` Python package to specify various settings related to SSH and Slurm. Here is a brief description of its contents: \n[**SLURM**]: This section includes settings specific to Slurm. It defines the paths on the SLURM entrypoint for storing data files (slurm_data_path), container image files (slurm_images_path), and Slurm job scripts (slurm_script_path). It also specifies the repository (slurm_script_repo) from which to pull the Slurm scripts. \n[**MODELS**]: This section is used to define different model settings. Each model has a unique key and requires corresponding values for `<key>_repo` (repository containing the descriptor.json file, which will describe parameters and where to find the image), and `<key>_job` (jobscript name and location in the `slurm_script_repo`). The example shows settings for several segmentation models, including Cellpose, Stardist, CellProfiler, DeepCell, and ImageJ. \nThe `slurm-config.ini` file allows users to configure paths, repositories, and other settings specific to their Slurm cluster and the `biomero` package, providing flexibility and customization options.\n \n"
      },
      "source": "https://raw.githubusercontent.com/NL-BioImaging/biomero/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9240639049815538,
      "result": {
        "original_header": "Time Limit on Slurm",
        "type": "Text_excerpt",
        "value": "An important Slurm job config is the time limit: `SBATCH --time=00:45:00` is the default in BIOMERO (max 45 minutes per job).\nThe format is `d-hh:mm:ss` \nWARNING: After this time, the job will timeout and this scenario is not handled by BIOMERO (yet)! You will lose your processing progress. \nYou can change this timeout value: \n- For ALL workflows, in the [job_template.sh](./resources/job_template.sh) (e.g. `#SBATCH --time=08:00:00` for 8 hours)\n- For ONE workflow, in the [slurm-config.ini](./resources/slurm-config.ini) (e.g. `cellpose_job_time=08:00:00` for 8 hours)\n- Per specific run, provide it in the OMERO script UI like [SLURM_CellPose_Segmentation.py](https://github.com/NL-BioImaging/biomero-scripts/blob/master/workflows/SLURM_CellPose_Segmentation.py)  \nNote that it might take longer for Slurm to schedule your job if you put the time very high, or possibly even make it wait indefinitely (see --time explanation in https://slurm.schedmd.com/sbatch.html). We will work on smart timing, but for now it is hardcoded and configurable. \n"
      },
      "source": "https://raw.githubusercontent.com/NL-BioImaging/biomero/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9572569404492015,
      "result": {
        "original_header": "Workflow metadata via descriptor.json",
        "type": "Text_excerpt",
        "value": "A lot of the automation in this library is based on metadata of the workflow, provided in the source code of the workflow, specifically the [descriptor.json](https://github.com/TorecLuik/W_NucleiSegmentation-Cellpose/blob/v1.2.7/descriptor.json). \nFor example, the OMERO script UI can be generated automatically, based on this descriptor. And also, the Slurm job script can be generated automatically, based on this descriptor. \nThis metadata scheme is (based on) Cytomine / BIAFLOWS, and you can find details of it and how to create one yourself on their website, e.g. this [Cytomine dev-guide](https://doc.uliege.cytomine.org/dev-guide/algorithms/write-app#create-the-json-descriptor) or this [BIAFLOWS dev-guide](https://neubias-wg5.github.io/developer_guide_add_new_workflow_to_biaflows_instance.html). \n**NOTE!** We do not require the `cytomine_<...>` authentication parameters. They are not mandatory. In fact, we ignore them. But it might be beneficial to make your workflow compatible with Cytomine as well.\n \n"
      },
      "source": "https://raw.githubusercontent.com/NL-BioImaging/biomero/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8833861729695031,
      "result": {
        "original_header": "Schema",
        "type": "Text_excerpt",
        "value": "At this point, we are using the `cytomine-0.1` [schema](https://doc.uliege.cytomine.org/dev-guide/algorithms/descriptor-reference), in the future we will also want to support other schemas, like [Boutiques](https://boutiques.github.io/), [commonwl](https://www.commonwl.org/) or [MLFlow](https://www.mlflow.org/docs/latest/projects.html).  \nWe will try to stay compatible with all such schemas (perhaps with less functionality because of missing metadata). \nAt this point, we do not strictly validate the schema, we just read expected fields from the `descriptor.json`.\n \n"
      },
      "source": "https://raw.githubusercontent.com/NL-BioImaging/biomero/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9913174683895277,
      "result": {
        "original_header": "Multiple versions",
        "type": "Text_excerpt",
        "value": "Note that while it is possible to have multiple versions of the same workflow on Slurm (and select the desired one in OMERO), it is not possible to configure this yet. We assume for now you only want one version to start with. You can always update this config to download a new version to Slurm.\n \n"
      },
      "source": "https://raw.githubusercontent.com/NL-BioImaging/biomero/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9778705685291937,
      "result": {
        "original_header": "I/O",
        "type": "Text_excerpt",
        "value": "Unless you change the `Slurm` job, the input is expected to be:\n- The `infolder` parameter\n    - pointing to a folder with multiple input files/images\n- The `gtfolder` parameter (Optional)\n    - pointing to a `ground-truth` input files, generally not needed for prediction / processing purposes.\n- The `outfolder` parameter\n    - where you write all your output files (to get copied back to OMERO)\n \n"
      },
      "source": "https://raw.githubusercontent.com/NL-BioImaging/biomero/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9124654610478586,
      "result": {
        "original_header": "Wrapper.py",
        "type": "Text_excerpt",
        "value": "Note that you can also use the [wrapper.py](https://github.com/Neubias-WG5/W_Template/blob/master/wrapper.py) setup from BIAFLOWS to handle the I/O for you: \n```python\nwith BiaflowsJob.from_cli(argv) as bj:\n        # Change following to the actual problem class of the workflow\n        ...\n        \n        # 1. Prepare data for workflow\n        in_imgs, gt_imgs, in_path, gt_path, out_path, tmp_path = prepare_data(problem_cls, bj, is_2d=True, **bj.flags)\n\n        # 2. Run image analysis workflow\n        bj.job.update(progress=25, statusComment=\"Launching workflow...\")\n\n        # Add here the code for running the analysis script\n\n        # 3. Upload data to BIAFLOWS\n        ...\n        \n        # 4. Compute and upload metrics\n        ...\n\n        # 5. Pipeline finished\n        ...\n```\n \nThis wrapper handles the input parameters for you, providing the input images as `in_imgs`, et cetera. Then you add your commandline call between point 2 and 3, and possibly some preprocessing between point 1 and 2:\n```python\n#add here the code for running the analysis script\n``` \nWe use a `tmp_path` to store both input and output, then move the output to the `out_path` after the processing is done. \nAlso note that some preprocessing is done in step 1: \n```python\n# Make sure all images have at least 224x224 dimensions\n# and that minshape / maxshape * minshape >= 224\n# 0 = Grayscale (if input RGB, convert to grayscale)\n# 1,2,3 = rgb channel\nnuc_channel = bj.parameters.nuc_channel\nresized = {}\nfor bfimg in in_imgs:\n    ...\n    imageio.imwrite(os.path.join(tmp_path, bfimg.filename), img)\n``` \n"
      },
      "source": "https://raw.githubusercontent.com/NL-BioImaging/biomero/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9654519000360372,
      "result": {
        "original_header": "How to add your new custom workflow",
        "type": "Text_excerpt",
        "value": "Building workflows like this will make them more [FAIR](https://www.go-fair.org/fair-principles/) (also for [software](https://fair-software.eu/about)) and uses best practices like code versioning and containerization! \nHere is a shorter version:\nSay you have a script in Python and you want to make it available on OMERO and Slurm. \n1. Rewrite your script to be headless / to be executable on the commandline. This requires handling of commandline parameters as input.\n    - Make sure the I/O matches the Slurm job, see [previous chapter](#io).\n2. Describe these commandline parameters in a `descriptor.json` (see previous [chapter](#workflow-metadata-via-descriptorjson)). E.g. [like this](https://doc.uliege.cytomine.org/dev-guide/algorithms/write-app#create-the-json-descriptor).\n3. Describe the requirements / environment of your script in a `requirements.txt`, [like this](https://learnpython.com/blog/python-requirements-file/). Make sure to pin your versions for future reproducability!\n2. Package your script in a Docker container. E.g. [like this](https://www.docker.com/blog/how-to-dockerize-your-python-applications/).\n    - Note: Please watch out for the pitfalls of reproducability with Dockerfiles: [Always version your packages!](https://pythonspeed.com/articles/dockerizing-python-is-hard/).\n3. Publish your source code, Dockerfile and descriptor.json to a new Github repository (free for public repositories). You can generate a new repository [from template](https://docs.github.com/en/repositories/creating-and-managing-repositories/creating-a-repository-from-a-template), using [this template](https://github.com/Neubias-WG5/W_Template) provided by Neubias (BIAFLOWS). Then replace the input of the files with yours.\n4. (Recommended) Publish a new version of your code (e.g. v1.0.0). E.g. [like this](https://docs.github.com/en/repositories/releasing-projects-on-github/managing-releases-in-a-repository).\n5. Publish your container on Dockerhub (free for public repositories), using the same versioning as your source code. [Like this](https://docs.docker.com/get-started/publish-your-own-image/) from Windows Docker or [like this](https://www.geeksforgeeks.org/docker-publishing-images-to-docker-hub/) from a commandline.\n    - (Recommended) Please use a tag that equals your repository version, instead of `latest`. This improves reproducability!\n    - (Optional) this library grabs `latest` if the code repository is given no version, but the `master` branch.\n6. Follow the steps from the previous [chapter](#how-to-add-an-existing-workflow):\n    - Add details to `slurm-config.ini`\n    - Run `SlurmClient.from_config(init_slurm=True)` (e.g. the init environment script.)\n \n"
      },
      "source": "https://raw.githubusercontent.com/NL-BioImaging/biomero/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9756546857451133,
      "result": {
        "original_header": "Batching",
        "type": "Text_excerpt",
        "value": "We can simply use `Slurm` for running your workflow 1:1, so 1 job to 1 workflow. This could speed up your workflow already, as `Slurm` servers are likely equipped with strong CPU and GPU. \nHowever, `Slurm` is also built for parallel processing on multiple (or the same) servers. We can accomplish this by running multiple jobs for 1 workflow. This is simple for [embarrassingly parallel](https://en.wikipedia.org/wiki/Embarrassingly_parallel#:~:text=In%20parallel%20computing%2C%20an%20embarrassingly,a%20number%20of%20parallel%20tasks.) tasks, like segmenting multiple images: just provide each job with a different set of input images. If you have 100 images, you could run 10 jobs on 10 images and (given enough resources available for you on Slurm) that could be 10x faster. In theory, you could run 1 job per image, but at some point you run into the overhead cost of Slurm (and OMERO) and it might actually slow down again (as you incur this cost a 100 times instead of 10 times).\n \n"
      },
      "source": "https://raw.githubusercontent.com/NL-BioImaging/biomero/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.931744535086764,
      "result": {
        "original_header": "Using the GPU on Slurm",
        "type": "Text_excerpt",
        "value": "This is because GPU resources are expensive and some programs do not work with GPU. \n"
      },
      "source": "https://raw.githubusercontent.com/NL-BioImaging/biomero/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9054488253748745,
      "result": {
        "original_header": "Transfering data",
        "type": "Text_excerpt",
        "value": "We have added methods to this library to help with transferring data to the `Slurm` cluster, using the same SSH connection (via SCP or SFTP). \nAnd more; see the docstring of `SlurmClient` and example OMERO scripts.\n \n"
      },
      "source": "https://raw.githubusercontent.com/NL-BioImaging/biomero/main/README.md",
      "technique": "supervised_classification"
    }
  ],
  "documentation": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/NL-BioImaging/biomero/tree/main/docs"
      },
      "technique": "file_exploration"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/NL-BioImaging/biomero/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "faq": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Generating jobs",
        "parent_header": [
          "Slurm jobs"
        ],
        "type": "Text_excerpt",
        "value": "By default, `biomero` will generate basic slurm jobs for each workflow, based on the metadata provided in `descriptor.json` and a [job template](./resources/job_template.sh).\nIt will replace `$PARAMS` with the (non-`cytomine_`) parameters given in `descriptor.json`. See also the [Parameters](#parameters) section below.\n"
      },
      "source": "https://raw.githubusercontent.com/NL-BioImaging/biomero/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "How to add your own Slurm job",
        "parent_header": [
          "Slurm jobs"
        ],
        "type": "Text_excerpt",
        "value": "You could change the [job template](./resources/job_template.sh) and generate new jobs, by running `SlurmClient.from_config(init_slurm=True)` (or `slurmClient.update_slurm_scripts(generate_jobs=True)`) \n\nOr you could add your jobs to a [Github repository](https://github.com/TorecLuik/slurm-scripts) and reference this in `slurm-config.ini`, both in the field `slurm_script_repo` and every `<workflow>_job`:\n\n```ini\n# -------------------------------------\n# REPOSITORIES\n# -------------------------------------\n# A (github) repository to pull the slurm scripts from.\n#\n# Note: \n# If you provide no repository, we will generate scripts instead!\n# Based on the job_template and the descriptor.json\n#\nslurm_script_repo=https://github.com/TorecLuik/slurm-scripts\n\n[MODELS]\n# -------------------------------------\n# Model settings\n# -------------------------------------\n# ...\n# -------------------------------------\n# CELLPOSE SEGMENTATION\n# -------------------------------------\n# The path to store the container on the slurm_images_path\ncellpose=cellpose\n# The (e.g. github) repository with the descriptor.json file\ncellpose_repo=https://github.com/TorecLuik/W_NucleiSegmentation-Cellpose/tree/v1.2.7\n# The jobscript in the 'slurm_script_repo'\ncellpose_job=jobs/cellpose.sh\n```\n\nYou can update the jobs by calling `slurmClient.update_slurm_scripts()`, which will pull the repository('s default branch).\n\nThis might be useful, for example if you have other hardware requirements for your workflow(s) than the default job asks for, or if you want to run more than just 1 singularity container.\n"
      },
      "source": "https://raw.githubusercontent.com/NL-BioImaging/biomero/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Parameters",
        "parent_header": [
          "Slurm jobs",
          "How to add your own Slurm job"
        ],
        "type": "Text_excerpt",
        "value": "The library will provide the parameters from your `descriptor.json` as environment variables to the call. E.g. `set DIAMETER=0; sbatch ...`.\n\nOther environment variables provided are:\n- `DATA_PATH` \n    - Made of `<slurm_data_path>/<input_folder>`. The base dir for data folders for this execution. We expect it to contain `/data/in`, `/data/in` and `/data/in` folders in our template and data transfer setup.\n- `IMAGE_PATH`\n    - Made of `<slurm_images_path>/<model_path>`, as described in `slurm-config.ini`\n- `IMAGE_VERSION`\n- `SINGULARITY_IMAGE`\n    - Already uses the `IMAGE_VERSION` above, as `<container_name>_<IMAGE_VERSION>.sif`\n\nWe (potentially) override the following Slurm job settings programmatically:\n- `--mail-user={email}` (optional)\n- `--time={time}` (optional)\n- `--output=omero-%4j.log` (mandatory)\n\nWe could add more overrides in the future, and perhaps make them available as global configuration variables in `slurm-config.ini`."
      },
      "source": "https://raw.githubusercontent.com/NL-BioImaging/biomero/main/README.md",
      "technique": "header_analysis"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 2
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/NL-BioImaging/biomero/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "NL-BioImaging/biomero"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "BIOMERO - BioImage analysis in OMERO"
      },
      "source": "https://raw.githubusercontent.com/NL-BioImaging/biomero/main/README.md",
      "technique": "regular_expression"
    }
  ],
  "has_script_file": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/NL-BioImaging/biomero/main/resources/pull_images.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/NL-BioImaging/biomero/main/resources/job_template.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/NL-BioImaging/biomero/main/resources/convert_job_array.sh"
      },
      "technique": "file_exploration"
    }
  ],
  "identifier": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://zenodo.org/badge/latestdoi/638954891"
      },
      "source": "https://raw.githubusercontent.com/NL-BioImaging/biomero/main/README.md",
      "technique": "regular_expression"
    }
  ],
  "images": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/NL-BioImaging/biomero/assets/68958516/ff437ed2-d4b7-48b4-a7e3-12f1dbf00981"
      },
      "source": "https://raw.githubusercontent.com/NL-BioImaging/biomero/main/README.md",
      "technique": "regular_expression"
    }
  ],
  "installation": [
    {
      "confidence": 0.9972269073961073,
      "result": {
        "original_header": "BIOMERO - BioImage analysis in OMERO",
        "type": "Text_excerpt",
        "value": "_WARNING_: Please note that default settings are for short/medium jobs. If you run long workflows (>45min), you will run into 2 lethal issues:\n- Your Slurm job will timeout after **45 minutes**! See [Time Limit on Slurm](#time-limit-on-slurm) on what configs to change.\n- Your OMERO script (incl [biomero-scripts](https://github.com/NL-BioImaging/biomero-scripts)) will timeout after **60 minutes**! Change [omero script timeout](https://omero.readthedocs.io/en/stable/sysadmins/config.html#omero.scripts.timeout) settings if you expect longer workflows.\n \n"
      },
      "source": "https://raw.githubusercontent.com/NL-BioImaging/biomero/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9870639735417166,
      "result": {
        "original_header": "Quickstart",
        "type": "Text_excerpt",
        "value": "For a quick overview of what this library can do for you, we can install an example setup locally with Docker: \n1. Setup a local OMERO w/ this library: \n    - Follow Quickstart of https://github.com/Cellular-Imaging-Amsterdam-UMC/NL-BIOMERO\n2. Setup a local Slurm w/ SSH access: \n    - Follow Quickstart of https://github.com/TorecLuik/slurm-docker-cluster\n3. Upload some data with OMERO.insight to `localhost` server (... we are working on a web importer ... TBC)\n4. Try out some scripts from https://github.com/NL-BioImaging/biomero-scripts (already installed in step 1!):\n    1. Run script `slurm/init/SLURM Init environment...`\n    2. Get a coffee or something. This will take at least 10 min to download all the workflow images. Maybe write a nice review on `image.sc` of this software, or here on the `Discussions` tab of Github.\n    3. Select your image / dataset and run script `slurm/workflows/SLURM Run Workflow...`\n        - Select at least one of the `Select how to import your results`, e.g. change `Import into NEW Dataset` text to `hello world`\n        - Select a fun workflow, e.g. `cellpose`.\n            - Change the `nuc channel` to the channel to segment (note that 0 is for grey, so 1,2,3 for RGB)\n            - Uncheck the `use gpu` (step 2, our HPC cluster, doesn't come with GPU support built into the containers)\n        - Refresh your OMERO `Explore` tab to see your `hello world` dataset with a mask image when the workflow is done! \n"
      },
      "source": "https://raw.githubusercontent.com/NL-BioImaging/biomero/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.999966881119394,
      "result": {
        "original_header": "OMERO Requirements",
        "type": "Text_excerpt",
        "value": "!!*NOTE*: Do not install [Example Minimal Slurm Script](https://github.com/NL-BioImaging/biomero-scripts/blob/master/Example_Minimal_Slurm_Script.py) if you do not trust your users with your Slurm cluster. It has literal Command Injection for the SSH user as a **FEATURE**.  \n"
      },
      "source": "https://raw.githubusercontent.com/NL-BioImaging/biomero/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9693293597799172,
      "result": {
        "original_header": "BIOMERO scripts",
        "type": "Text_excerpt",
        "value": "We have provided the BIOMERO scripts at https://github.com/NL-BioImaging/biomero-scripts (hopefully installed in a previous step).  \nOther example OMERO scripts are:\n- [`data/Slurm Get Update`](https://github.com/NL-BioImaging/biomero-scripts/blob/master/data/SLURM_Get_Update.py): to run while you are waiting on a job to finish on Slurm; it will try to get a `%` progress from your job's logfile. Depends on your job/workflow logging a `%` of course. \n- [`workflows/Slurm CellPose Segmentation`](https://github.com/NL-BioImaging/biomero-scripts/blob/master/workflows/SLURM_CellPose_Segmentation.py): This is a more primitive script that only runs the actual workflow `CellPose` (if correctly configured). You will need to manually transfer data first (with `Slurm Image Transfer`) and manually retrieve data afterward (with `Slurm Get Results`). \nYou are encouraged to create your own custom scripts. Do note the copy-left license enforced by OME.\n \n"
      },
      "source": "https://raw.githubusercontent.com/NL-BioImaging/biomero/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9715318892706111,
      "result": {
        "original_header": "(Docker) containers",
        "type": "Text_excerpt",
        "value": "You can mount your specific configurations over those in the container, for example:\n```\n# Run the biomero container\necho \"Starting BIOMERO...\"\npodman run -d --rm --name biomero \\\n  -e CONFIG_omero_master_host=omeroserver \\\n  -e OMERO_WORKER_NAME=biomero \\\n  -e CONFIG_omero_logging_level=10 \\\n  --network omero \\\n  --volume /mnt/datadisk/omero:/OMERO \\\n  --volume /mnt/data:/data \\\n  --volume /my/slurm-config.ini:/etc/slurm-config.ini \\\n  --secret ssh-config,target=/tmp/.ssh/config --secret ssh-key,target=/tmp/.ssh/id_rsa --secret ssh-pubkey,target=/tmp/.ssh/id_rsa.pub  --secret ssh-known_hosts,target=/tmp/.ssh/known_hosts \\\n  --userns=keep-id:uid=1000,gid=997 \\\n  cellularimagingcf/biomero:0.2.3\n```\n \nThis will spin up the docker container (in Podman) with omero config (`-e CONFIG_omero_..`), mounting the required data drives (`--volume /mnt/...`) and adding a new slurm config (`--volume /my/slurm-config.ini:/etc/slurm-config.ini`) and the required SSH settings (`--secret ...,target=/tmp/.ssh/...`) to access the remote HPC. \nNote: the [BIOMERO scripts](https://github.com/NL-BioImaging/biomero-scripts) are installed on the [main server](https://hub.docker.com/repository/docker/cellularimagingcf/omeroserver/general), not on the BIOMERO processor.  \n"
      },
      "source": "https://raw.githubusercontent.com/NL-BioImaging/biomero/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.985507795108577,
      "result": {
        "original_header": "slurm-config.ini",
        "type": "Text_excerpt",
        "value": "Note also that you can override the default Slurm job values using this model configuration, like memory, GPU, time limit, etc.\nAll values for sbatch can be applied (see e.g. [here](https://slurm.schedmd.com/sbatch.html)) and will be forwarded to the job command. \nFor example\n```\n# Run CellPose Slurm with 10 GB GPU\ncellpose_job_gres=gpu:1g.10gb:1\n# Run CellPose Slurm with 15 GB CPU memory\ncellpose_job_mem=15GB\n``` \nThe `slurm-config.ini` file allows users to configure paths, repositories, and other settings specific to their Slurm cluster and the `biomero` package, providing flexibility and customization options.\n \n"
      },
      "source": "https://raw.githubusercontent.com/NL-BioImaging/biomero/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9999999999996589,
      "result": {
        "original_header": "How to add an existing workflow",
        "type": "Text_excerpt",
        "value": "To add an existing (containerized) workflow, add it to the `slurm-config.ini` file like in our example:\n```ini\n# -------------------------------------\n# CELLPOSE SEGMENTATION\n# -------------------------------------\n# The path to store the container on the slurm_images_path\ncellpose=cellpose\n# The (e.g. github) repository with the descriptor.json file\ncellpose_repo=https://github.com/TorecLuik/W_NucleiSegmentation-Cellpose/tree/v1.2.7\n# The jobscript in the 'slurm_script_repo'\ncellpose_job=jobs/cellpose.sh\n```\nHere, \n1. the name referenced for this workflow is `cellpose`\n2. the location of the container on slurm will be `<slurm_images_path>/cellpose`\n3. the code repository is `https://github.com/TorecLuik/W_NucleiSegmentation-Cellpose` \n4. the specific version we want is `v1.2.7`\n5. the container can be found on bitbucket\n    - under the path given in the metadata file: [descriptor.json](https://github.com/TorecLuik/W_NucleiSegmentation-Cellpose/blob/v1.2.7/descriptor.json)\n5. the location of the jobscript on slurm will be `<slurm_script_repo>/jobs/cellpose.sh`. \n    - This either references a git repo, where it matches this path, \n    - or it will be the location where the library will generate a jobscript (if no repo is given)\n \n"
      },
      "source": "https://raw.githubusercontent.com/NL-BioImaging/biomero/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9999955379612475,
      "result": {
        "original_header": "Multiple versions",
        "type": "Text_excerpt",
        "value": "Note that while it is possible to have multiple versions of the same workflow on Slurm (and select the desired one in OMERO), it is not possible to configure this yet. We assume for now you only want one version to start with. You can always update this config to download a new version to Slurm.\n \n"
      },
      "source": "https://raw.githubusercontent.com/NL-BioImaging/biomero/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9400071426294866,
      "result": {
        "original_header": "Wrapper.py",
        "type": "Text_excerpt",
        "value": "Note that you can also use the [wrapper.py](https://github.com/Neubias-WG5/W_Template/blob/master/wrapper.py) setup from BIAFLOWS to handle the I/O for you: \n```python\nwith BiaflowsJob.from_cli(argv) as bj:\n        # Change following to the actual problem class of the workflow\n        ...\n        \n        # 1. Prepare data for workflow\n        in_imgs, gt_imgs, in_path, gt_path, out_path, tmp_path = prepare_data(problem_cls, bj, is_2d=True, **bj.flags)\n\n        # 2. Run image analysis workflow\n        bj.job.update(progress=25, statusComment=\"Launching workflow...\")\n\n        # Add here the code for running the analysis script\n\n        # 3. Upload data to BIAFLOWS\n        ...\n        \n        # 4. Compute and upload metrics\n        ...\n\n        # 5. Pipeline finished\n        ...\n```\n \nFor example, from [Cellpose](https://github.com/TorecLuik/W_NucleiSegmentation-Cellpose/blob/master/wrapper.py) container workflow:\n```python\n...\n\n# 2. Run image analysis workflow\nbj.job.update(progress=25, statusComment=\"Launching workflow...\")\n\n# Add here the code for running the analysis script\nprob_thresh = bj.parameters.prob_threshold\ndiameter = bj.parameters.diameter\ncp_model = bj.parameters.cp_model\nuse_gpu = bj.parameters.use_gpu\nprint(f\"Chosen model: {cp_model} | Channel {nuc_channel} | Diameter {diameter} | Cell prob threshold {prob_thresh} | GPU {use_gpu}\")\ncmd = [\"python\", \"-m\", \"cellpose\", \"--dir\", tmp_path, \"--pretrained_model\", f\"{cp_model}\", \"--save_tif\", \"--no_npy\", \"--chan\", \"{:d}\".format(nuc_channel), \"--diameter\", \"{:f}\".format(diameter), \"--cellprob_threshold\", \"{:f}\".format(prob_thresh)]\nif use_gpu:\n    print(\"Using GPU!\")\n    cmd.append(\"--use_gpu\")\nstatus = subprocess.run(cmd)\n\nif status.returncode != 0:\n    print(\"Running Cellpose failed, terminate\")\n    sys.exit(1)\n\n# Crop to original shape\nfor bimg in in_imgs:\n    shape = resized.get(bimg.filename, None)\n    if shape:\n        img = imageio.imread(os.path.join(tmp_path,bimg.filename_no_extension+\"_cp_masks.tif\"))\n        img = img[0:shape[0], 0:shape[1]]\n        imageio.imwrite(os.path.join(out_path,bimg.filename), img)\n    else:\n        shutil.copy(os.path.join(tmp_path,bimg.filename_no_extension+\"_cp_masks.tif\"), os.path.join(out_path,bimg.filename))\n\n# 3. Upload data to BIAFLOWS\n```\nWe get the commandline parameters from `bj.parameters` (biaflows job) and provide that the `cmd` commandline string. Then we run it with `subprocess.run(cmd)` and check the `status`.  \nAlso note that some preprocessing is done in step 1: \n```python\n# Make sure all images have at least 224x224 dimensions\n# and that minshape / maxshape * minshape >= 224\n# 0 = Grayscale (if input RGB, convert to grayscale)\n# 1,2,3 = rgb channel\nnuc_channel = bj.parameters.nuc_channel\nresized = {}\nfor bfimg in in_imgs:\n    ...\n    imageio.imwrite(os.path.join(tmp_path, bfimg.filename), img)\n``` \nAnother example is this `imageJ` [wrapper](https://github.com/Neubias-WG5/W_NucleiSegmentation3D-ImageJ/blob/master/wrapper.py):\n```python\n...\n\n# 3. Call the image analysis workflow using the run script\nnj.job.update(progress=25, statusComment=\"Launching workflow...\")\n\ncommand = \"/usr/bin/xvfb-run java -Xmx6000m -cp /fiji/jars/ij.jar ij.ImageJ --headless --console \" \\\n            \"-macro macro.ijm \\\"input={}, output={}, radius={}, min_threshold={}\\\"\".format(in_path, out_path, nj.parameters.ij_radius, nj.parameters.ij_min_threshold)\nreturn_code = call(command, shell=True, cwd=\"/fiji\")  # waits for the subprocess to return\n\nif return_code != 0:\n    err_desc = \"Failed to execute the ImageJ macro (return code: {})\".format(return_code)\n    nj.job.update(progress=50, statusComment=err_desc)\n    raise ValueError(err_desc)\n    \n```\nOnce again, just a commandline `--headless` call to `ImageJ`, wrapped in this Python script and this container. \n"
      },
      "source": "https://raw.githubusercontent.com/NL-BioImaging/biomero/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9935732151870907,
      "result": {
        "original_header": "How to add your new custom workflow",
        "type": "Text_excerpt",
        "value": "Here is a shorter version:\nSay you have a script in Python and you want to make it available on OMERO and Slurm. \nThese are the steps required: \n1. Rewrite your script to be headless / to be executable on the commandline. This requires handling of commandline parameters as input.\n    - Make sure the I/O matches the Slurm job, see [previous chapter](#io).\n2. Describe these commandline parameters in a `descriptor.json` (see previous [chapter](#workflow-metadata-via-descriptorjson)). E.g. [like this](https://doc.uliege.cytomine.org/dev-guide/algorithms/write-app#create-the-json-descriptor).\n3. Describe the requirements / environment of your script in a `requirements.txt`, [like this](https://learnpython.com/blog/python-requirements-file/). Make sure to pin your versions for future reproducability!\n2. Package your script in a Docker container. E.g. [like this](https://www.docker.com/blog/how-to-dockerize-your-python-applications/).\n    - Note: Please watch out for the pitfalls of reproducability with Dockerfiles: [Always version your packages!](https://pythonspeed.com/articles/dockerizing-python-is-hard/).\n3. Publish your source code, Dockerfile and descriptor.json to a new Github repository (free for public repositories). You can generate a new repository [from template](https://docs.github.com/en/repositories/creating-and-managing-repositories/creating-a-repository-from-a-template), using [this template](https://github.com/Neubias-WG5/W_Template) provided by Neubias (BIAFLOWS). Then replace the input of the files with yours.\n4. (Recommended) Publish a new version of your code (e.g. v1.0.0). E.g. [like this](https://docs.github.com/en/repositories/releasing-projects-on-github/managing-releases-in-a-repository).\n5. Publish your container on Dockerhub (free for public repositories), using the same versioning as your source code. [Like this](https://docs.docker.com/get-started/publish-your-own-image/) from Windows Docker or [like this](https://www.geeksforgeeks.org/docker-publishing-images-to-docker-hub/) from a commandline.\n    - (Recommended) Please use a tag that equals your repository version, instead of `latest`. This improves reproducability!\n    - (Optional) this library grabs `latest` if the code repository is given no version, but the `master` branch.\n6. Follow the steps from the previous [chapter](#how-to-add-an-existing-workflow):\n    - Add details to `slurm-config.ini`\n    - Run `SlurmClient.from_config(init_slurm=True)` (e.g. the init environment script.)\n \n"
      },
      "source": "https://raw.githubusercontent.com/NL-BioImaging/biomero/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9413923399659387,
      "result": {
        "original_header": "Using the GPU on Slurm",
        "type": "Text_excerpt",
        "value": "Note, the [default](./resources/job_template.sh) Slurm job script will not request any GPU resources. \nWe can instead _enable_ the use of GPU by either providing our own Slurm job scripts, or setting an override value in `slurm-config.ini`:\n```ini\n# -------------------------------------\n# CELLPOSE SEGMENTATION\n# -------------------------------------\n# The path to store the container on the slurm_images_path\ncellpose=cellpose\n# The (e.g. github) repository with the descriptor.json file\ncellpose_repo=https://github.com/TorecLuik/W_NucleiSegmentation-Cellpose/tree/v1.2.7\n# The jobscript in the 'slurm_script_repo'\ncellpose_job=jobs/cellpose.sh\n# Override the default job values for this workflow\n# Or add a job value to this workflow\n# If you don't want to override, comment out / delete the line.\n# Run CellPose Slurm with 10 GB GPU\ncellpose_job_gres=gpu:1g.10gb:1\n```\n \nIn fact, any `..._job_...=...` configuration value will be forwarded to the Slurm commandline. \nSlurm commandline parameters override those in the script, so the above one requests 1 10GB gpu for Cellpose. \nE.g. you could also set the time limit higher:\n```ini\n# -------------------------------------\n# CELLPOSE SEGMENTATION\n# -------------------------------------\n# The path to store the container on the slurm_images_path\ncellpose=cellpose\n# The (e.g. github) repository with the descriptor.json file\ncellpose_repo=https://github.com/TorecLuik/W_NucleiSegmentation-Cellpose/tree/v1.2.7\n# The jobscript in the 'slurm_script_repo'\ncellpose_job=jobs/cellpose.sh\n# Override the default job values for this workflow\n# Or add a job value to this workflow\n# If you don't want to override, comment out / delete the line.\n# Run with longer time limit\ncellpose_job_time=00:30:00\n```\n \n"
      },
      "source": "https://raw.githubusercontent.com/NL-BioImaging/biomero/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9722729253333335,
      "result": {
        "original_header": "Testing the Python code",
        "type": "Text_excerpt",
        "value": "You can test the library by installing the extra test dependencies: \n1. Create a venv to isolate the python install:\n`python -m venv venvTest` \n2. Install OSC with test dependencies:\n`venvTest/Scripts/python -m pip install .[test]` \n3. Run pytest from this venv:\n`venvTest/Scripts/pytest`\n \n"
      },
      "source": "https://raw.githubusercontent.com/NL-BioImaging/biomero/main/README.md",
      "technique": "supervised_classification"
    }
  ],
  "invocation": [
    {
      "confidence": 0.8368700280208605,
      "result": {
        "original_header": "BIOMERO scripts",
        "type": "Text_excerpt",
        "value": "-  [`data/Slurm Image Transfer`](https://github.com/NL-BioImaging/biomero-scripts/blob/master/data/_SLURM_Image_Transfer.py): to export your selected images / dataset / screen as TIFF files to a Slurm dir.\n- [`data/Slurm Get Results`](https://github.com/NL-BioImaging/biomero-scripts/blob/master/data/SLURM_Get_Results.py): to import your Slurm job results back into OMERO as a zip, dataset or attachment. \n"
      },
      "source": "https://raw.githubusercontent.com/NL-BioImaging/biomero/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8032778650619142,
      "result": {
        "original_header": "(Docker) containers",
        "type": "Text_excerpt",
        "value": "You can mount your specific configurations over those in the container, for example:\n```\n# Run the biomero container\necho \"Starting BIOMERO...\"\npodman run -d --rm --name biomero \\\n  -e CONFIG_omero_master_host=omeroserver \\\n  -e OMERO_WORKER_NAME=biomero \\\n  -e CONFIG_omero_logging_level=10 \\\n  --network omero \\\n  --volume /mnt/datadisk/omero:/OMERO \\\n  --volume /mnt/data:/data \\\n  --volume /my/slurm-config.ini:/etc/slurm-config.ini \\\n  --secret ssh-config,target=/tmp/.ssh/config --secret ssh-key,target=/tmp/.ssh/id_rsa --secret ssh-pubkey,target=/tmp/.ssh/id_rsa.pub  --secret ssh-known_hosts,target=/tmp/.ssh/known_hosts \\\n  --userns=keep-id:uid=1000,gid=997 \\\n  cellularimagingcf/biomero:0.2.3\n```\n \n"
      },
      "source": "https://raw.githubusercontent.com/NL-BioImaging/biomero/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8892214566987199,
      "result": {
        "original_header": "Wrapper.py",
        "type": "Text_excerpt",
        "value": "For example, from [Cellpose](https://github.com/TorecLuik/W_NucleiSegmentation-Cellpose/blob/master/wrapper.py) container workflow:\n```python\n...\n\n# 2. Run image analysis workflow\nbj.job.update(progress=25, statusComment=\"Launching workflow...\")\n\n# Add here the code for running the analysis script\nprob_thresh = bj.parameters.prob_threshold\ndiameter = bj.parameters.diameter\ncp_model = bj.parameters.cp_model\nuse_gpu = bj.parameters.use_gpu\nprint(f\"Chosen model: {cp_model} | Channel {nuc_channel} | Diameter {diameter} | Cell prob threshold {prob_thresh} | GPU {use_gpu}\")\ncmd = [\"python\", \"-m\", \"cellpose\", \"--dir\", tmp_path, \"--pretrained_model\", f\"{cp_model}\", \"--save_tif\", \"--no_npy\", \"--chan\", \"{:d}\".format(nuc_channel), \"--diameter\", \"{:f}\".format(diameter), \"--cellprob_threshold\", \"{:f}\".format(prob_thresh)]\nif use_gpu:\n    print(\"Using GPU!\")\n    cmd.append(\"--use_gpu\")\nstatus = subprocess.run(cmd)\n\nif status.returncode != 0:\n    print(\"Running Cellpose failed, terminate\")\n    sys.exit(1)\n\n# Crop to original shape\nfor bimg in in_imgs:\n    shape = resized.get(bimg.filename, None)\n    if shape:\n        img = imageio.imread(os.path.join(tmp_path,bimg.filename_no_extension+\"_cp_masks.tif\"))\n        img = img[0:shape[0], 0:shape[1]]\n        imageio.imwrite(os.path.join(out_path,bimg.filename), img)\n    else:\n        shutil.copy(os.path.join(tmp_path,bimg.filename_no_extension+\"_cp_masks.tif\"), os.path.join(out_path,bimg.filename))\n\n# 3. Upload data to BIAFLOWS\n```\nWe get the commandline parameters from `bj.parameters` (biaflows job) and provide that the `cmd` commandline string. Then we run it with `subprocess.run(cmd)` and check the `status`.  \nAnother example is this `imageJ` [wrapper](https://github.com/Neubias-WG5/W_NucleiSegmentation3D-ImageJ/blob/master/wrapper.py):\n```python\n...\n\n# 3. Call the image analysis workflow using the run script\nnj.job.update(progress=25, statusComment=\"Launching workflow...\")\n\ncommand = \"/usr/bin/xvfb-run java -Xmx6000m -cp /fiji/jars/ij.jar ij.ImageJ --headless --console \" \\\n            \"-macro macro.ijm \\\"input={}, output={}, radius={}, min_threshold={}\\\"\".format(in_path, out_path, nj.parameters.ij_radius, nj.parameters.ij_min_threshold)\nreturn_code = call(command, shell=True, cwd=\"/fiji\")  # waits for the subprocess to return\n\nif return_code != 0:\n    err_desc = \"Failed to execute the ImageJ macro (return code: {})\".format(return_code)\n    nj.job.update(progress=50, statusComment=err_desc)\n    raise ValueError(err_desc)\n    \n```\nOnce again, just a commandline `--headless` call to `ImageJ`, wrapped in this Python script and this container. \n"
      },
      "source": "https://raw.githubusercontent.com/NL-BioImaging/biomero/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8074180322753476,
      "result": {
        "original_header": "Testing the Python code",
        "type": "Text_excerpt",
        "value": "3. Run pytest from this venv:\n`venvTest/Scripts/pytest`\n \n"
      },
      "source": "https://raw.githubusercontent.com/NL-BioImaging/biomero/main/README.md",
      "technique": "supervised_classification"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/NL-BioImaging/biomero/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "biaflows, bioimaging, biomero, cytomine, fair, high-content-screening, high-performance-computing, high-throughput-screening, image-analysis, omero, python, slurm"
      },
      "technique": "GitHub_API"
    }
  ],
  "license": [
    {
      "confidence": 1,
      "result": {
        "name": "Apache License 2.0",
        "spdx_id": "Apache-2.0",
        "type": "License",
        "url": "https://api.github.com/licenses/apache-2.0",
        "value": "https://api.github.com/licenses/apache-2.0"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "type": "File_dump",
        "value": "                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright [yyyy] [name of copyright owner]\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n"
      },
      "source": "https://raw.githubusercontent.com/NL-BioImaging/biomero/main/LICENSE",
      "technique": "file_exploration"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "biomero"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "Organization",
        "value": "NL-BioImaging"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 146470,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Shell",
        "size": 4691,
        "type": "Programming_language",
        "value": "Shell"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Dockerfile",
        "size": 432,
        "type": "Programming_language",
        "value": "Dockerfile"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/NL-BioImaging/biomero/main/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "related_documentation": [
    {
      "confidence": 1,
      "result": {
        "format": "readthedocs",
        "type": "Url",
        "value": "https://omero.readthedocs.io/"
      },
      "source": "https://raw.githubusercontent.com/NL-BioImaging/biomero/main/README.md",
      "technique": "regular_expression"
    }
  ],
  "releases": [
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "TorecLuik",
          "type": "User"
        },
        "date_created": "2024-07-24T08:44:59Z",
        "date_published": "2024-07-24T08:49:34Z",
        "description": "- Bump to 1.14.0 for BIOMERO scripts update for duplicate parameter names\r\n- Setup for multiple measurements workflows\r\n\r\n**Full Changelog**: https://github.com/NL-BioImaging/biomero/compare/v1.13.0...v1.14.0",
        "html_url": "https://github.com/NL-BioImaging/biomero/releases/tag/v1.14.0",
        "name": "v1.14.0",
        "release_id": 166857794,
        "tag": "v1.14.0",
        "tarball_url": "https://api.github.com/repos/NL-BioImaging/biomero/tarball/v1.14.0",
        "type": "Release",
        "url": "https://api.github.com/repos/NL-BioImaging/biomero/releases/166857794",
        "value": "https://api.github.com/repos/NL-BioImaging/biomero/releases/166857794",
        "zipball_url": "https://api.github.com/repos/NL-BioImaging/biomero/zipball/v1.14.0"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "TorecLuik",
          "type": "User"
        },
        "date_created": "2024-07-17T12:42:52Z",
        "date_published": "2024-07-17T14:36:44Z",
        "description": "- Allow pulling a conversion container instead of building it on Slurm. This reduces the rights required on Slurm for BIOMERO. \r\n  - We build and release our default converter with every BIOMERO version @ `cellularimagingcf/convert_zarr_to_tiff`, even if there are no changes. Just to be sure there is always a 'compatible' version to go with your BIOMERO version, which is true for the old way of doing it.\r\n  - This image can be added in the `slurm-config.ini` under a new `[CONVERTERS]` subsection.\r\n    - When you init the Slurm environment, it will check for this config and download this converter image. If there is no such config, it will default to previous behavior (which is building a Singularity image on the Slurm server itself).\r\n    - Example setting:\r\n ```\r\n[CONVERTERS]\r\n# -------------------------------------\r\n# Converters settings\r\n# -------------------------------------\r\n# Settings for linking to external converters.\r\n# \r\n# By default, BIOMERO exports images as ZARR to the HPC.\r\n# But, the workflow you want to execute might require \r\n# a different filetype. E.g. most of our example workflows\r\n# require TIFF input files. \r\n#\r\n# By default we will build a converter on Slurm for you.\r\n# Theoretically you can add other converters here to pull\r\n# those instead. These should be available on dockerhub.\r\n# \r\n# -------------------------------------\r\n# ZARR TO TIFF\r\n# -------------------------------------\r\n# Uncomment this if you want to pull the image instead of \r\n# build it. E.g. if you don't have singularity build rights\r\n# on your Slurm.\r\n#\r\n# Please pin it to a specific version to reduce unforeseen errors.\r\n#\r\n# Key should be the types \"X_to_Y\" and value should be the docker image\r\nzarr_to_tiff=cellularimagingcf/convert_zarr_to_tiff:1.13.0\r\n```\r\n\r\n\r\n**Full Changelog**: https://github.com/NL-BioImaging/biomero/compare/v1.12.0...v1.13.0",
        "html_url": "https://github.com/NL-BioImaging/biomero/releases/tag/v1.13.0",
        "name": "v1.13.0",
        "release_id": 165866626,
        "tag": "v1.13.0",
        "tarball_url": "https://api.github.com/repos/NL-BioImaging/biomero/tarball/v1.13.0",
        "type": "Release",
        "url": "https://api.github.com/repos/NL-BioImaging/biomero/releases/165866626",
        "value": "https://api.github.com/repos/NL-BioImaging/biomero/releases/165866626",
        "zipball_url": "https://api.github.com/repos/NL-BioImaging/biomero/zipball/v1.13.0"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "TorecLuik",
          "type": "User"
        },
        "date_created": "2024-07-15T15:34:19Z",
        "date_published": "2024-07-15T15:40:28Z",
        "description": "**Full Changelog**: https://github.com/NL-BioImaging/biomero/compare/v1.13.0-alpha.5...v1.13.0-alpha.6",
        "html_url": "https://github.com/NL-BioImaging/biomero/releases/tag/v1.13.0-alpha.6",
        "name": "v1.13.0-alpha.6",
        "release_id": 165482137,
        "tag": "v1.13.0-alpha.6",
        "tarball_url": "https://api.github.com/repos/NL-BioImaging/biomero/tarball/v1.13.0-alpha.6",
        "type": "Release",
        "url": "https://api.github.com/repos/NL-BioImaging/biomero/releases/165482137",
        "value": "https://api.github.com/repos/NL-BioImaging/biomero/releases/165482137",
        "zipball_url": "https://api.github.com/repos/NL-BioImaging/biomero/zipball/v1.13.0-alpha.6"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "TorecLuik",
          "type": "User"
        },
        "date_created": "2024-06-20T16:42:30Z",
        "date_published": "2024-06-20T16:47:28Z",
        "description": "**Full Changelog**: https://github.com/NL-BioImaging/biomero/compare/v1.13.0-alpha.4...v1.13.0-alpha.5",
        "html_url": "https://github.com/NL-BioImaging/biomero/releases/tag/v1.13.0-alpha.5",
        "name": "v1.13.0-alpha.5",
        "release_id": 161522479,
        "tag": "v1.13.0-alpha.5",
        "tarball_url": "https://api.github.com/repos/NL-BioImaging/biomero/tarball/v1.13.0-alpha.5",
        "type": "Release",
        "url": "https://api.github.com/repos/NL-BioImaging/biomero/releases/161522479",
        "value": "https://api.github.com/repos/NL-BioImaging/biomero/releases/161522479",
        "zipball_url": "https://api.github.com/repos/NL-BioImaging/biomero/zipball/v1.13.0-alpha.5"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "TorecLuik",
          "type": "User"
        },
        "date_created": "2024-06-20T16:23:02Z",
        "date_published": "2024-06-20T16:24:29Z",
        "description": "**Full Changelog**: https://github.com/NL-BioImaging/biomero/compare/v1.13.0-alpha.3...v1.13.0-alpha.4",
        "html_url": "https://github.com/NL-BioImaging/biomero/releases/tag/v1.13.0-alpha.4",
        "name": "v1.13.0-alpha.4",
        "release_id": 161519119,
        "tag": "v1.13.0-alpha.4",
        "tarball_url": "https://api.github.com/repos/NL-BioImaging/biomero/tarball/v1.13.0-alpha.4",
        "type": "Release",
        "url": "https://api.github.com/repos/NL-BioImaging/biomero/releases/161519119",
        "value": "https://api.github.com/repos/NL-BioImaging/biomero/releases/161519119",
        "zipball_url": "https://api.github.com/repos/NL-BioImaging/biomero/zipball/v1.13.0-alpha.4"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "TorecLuik",
          "type": "User"
        },
        "date_created": "2024-06-20T14:43:50Z",
        "date_published": "2024-06-20T14:45:03Z",
        "description": "**Full Changelog**: https://github.com/NL-BioImaging/biomero/compare/v1.13.0-alpha.2...v1.13.0-alpha.3",
        "html_url": "https://github.com/NL-BioImaging/biomero/releases/tag/v1.13.0-alpha.3",
        "name": "v1.13.0-alpha.3",
        "release_id": 161500239,
        "tag": "v1.13.0-alpha.3",
        "tarball_url": "https://api.github.com/repos/NL-BioImaging/biomero/tarball/v1.13.0-alpha.3",
        "type": "Release",
        "url": "https://api.github.com/repos/NL-BioImaging/biomero/releases/161500239",
        "value": "https://api.github.com/repos/NL-BioImaging/biomero/releases/161500239",
        "zipball_url": "https://api.github.com/repos/NL-BioImaging/biomero/zipball/v1.13.0-alpha.3"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "TorecLuik",
          "type": "User"
        },
        "date_created": "2024-06-20T12:21:36Z",
        "date_published": "2024-06-20T12:22:39Z",
        "description": "**Full Changelog**: https://github.com/NL-BioImaging/biomero/compare/v1.13.0-alpha.1...v1.13.0-alpha.2",
        "html_url": "https://github.com/NL-BioImaging/biomero/releases/tag/v1.13.0-alpha.2",
        "name": "v1.13.0-alpha.2",
        "release_id": 161467354,
        "tag": "v1.13.0-alpha.2",
        "tarball_url": "https://api.github.com/repos/NL-BioImaging/biomero/tarball/v1.13.0-alpha.2",
        "type": "Release",
        "url": "https://api.github.com/repos/NL-BioImaging/biomero/releases/161467354",
        "value": "https://api.github.com/repos/NL-BioImaging/biomero/releases/161467354",
        "zipball_url": "https://api.github.com/repos/NL-BioImaging/biomero/zipball/v1.13.0-alpha.2"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "TorecLuik",
          "type": "User"
        },
        "date_created": "2024-06-20T11:34:42Z",
        "date_published": "2024-06-20T11:36:09Z",
        "description": "\r\n**Full Changelog**: https://github.com/NL-BioImaging/biomero/compare/v1.13.0-alpha...v1.13.0-alpha.1",
        "html_url": "https://github.com/NL-BioImaging/biomero/releases/tag/v1.13.0-alpha.1",
        "name": "v1.13.0-alpha.1",
        "release_id": 161458531,
        "tag": "v1.13.0-alpha.1",
        "tarball_url": "https://api.github.com/repos/NL-BioImaging/biomero/tarball/v1.13.0-alpha.1",
        "type": "Release",
        "url": "https://api.github.com/repos/NL-BioImaging/biomero/releases/161458531",
        "value": "https://api.github.com/repos/NL-BioImaging/biomero/releases/161458531",
        "zipball_url": "https://api.github.com/repos/NL-BioImaging/biomero/zipball/v1.13.0-alpha.1"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "TorecLuik",
          "type": "User"
        },
        "date_created": "2024-06-13T16:41:28Z",
        "date_published": "2024-06-13T16:54:26Z",
        "description": "* Builds the converter image so that we can pull it instead of build it\r\n\r\n**Full Changelog**: https://github.com/NL-BioImaging/biomero/compare/v1.12.0...v1.13.0-alpha",
        "html_url": "https://github.com/NL-BioImaging/biomero/releases/tag/v1.13.0-alpha",
        "name": "v1.13.0-alpha",
        "release_id": 160340873,
        "tag": "v1.13.0-alpha",
        "tarball_url": "https://api.github.com/repos/NL-BioImaging/biomero/tarball/v1.13.0-alpha",
        "type": "Release",
        "url": "https://api.github.com/repos/NL-BioImaging/biomero/releases/160340873",
        "value": "https://api.github.com/repos/NL-BioImaging/biomero/releases/160340873",
        "zipball_url": "https://api.github.com/repos/NL-BioImaging/biomero/zipball/v1.13.0-alpha"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "TorecLuik",
          "type": "User"
        },
        "date_created": "2024-05-29T12:42:03Z",
        "date_published": "2024-05-29T13:37:57Z",
        "description": "* Conversion ZARR to TIFF: write TIFF with extra metadata for (handling of > 3 channels in) cellprofiler/imagej\r\n\r\n**Full Changelog**: https://github.com/NL-BioImaging/biomero/compare/v1.11.0...v1.12.0",
        "html_url": "https://github.com/NL-BioImaging/biomero/releases/tag/v1.12.0",
        "name": "v1.12.0",
        "release_id": 157994837,
        "tag": "v1.12.0",
        "tarball_url": "https://api.github.com/repos/NL-BioImaging/biomero/tarball/v1.12.0",
        "type": "Release",
        "url": "https://api.github.com/repos/NL-BioImaging/biomero/releases/157994837",
        "value": "https://api.github.com/repos/NL-BioImaging/biomero/releases/157994837",
        "zipball_url": "https://api.github.com/repos/NL-BioImaging/biomero/zipball/v1.12.0"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "TorecLuik",
          "type": "User"
        },
        "date_created": "2024-05-23T16:29:27Z",
        "date_published": "2024-05-23T16:35:40Z",
        "description": "* Bump for updated scripts v1.11.0\r\n   * Improved CSV handling and description tooltips for all workflows.\r\n\r\n**Full Changelog**: https://github.com/NL-BioImaging/biomero/compare/v1.10.0...v1.11.0",
        "html_url": "https://github.com/NL-BioImaging/biomero/releases/tag/v1.11.0",
        "name": "v1.11.0",
        "release_id": 157169555,
        "tag": "v1.11.0",
        "tarball_url": "https://api.github.com/repos/NL-BioImaging/biomero/tarball/v1.11.0",
        "type": "Release",
        "url": "https://api.github.com/repos/NL-BioImaging/biomero/releases/157169555",
        "value": "https://api.github.com/repos/NL-BioImaging/biomero/releases/157169555",
        "zipball_url": "https://api.github.com/repos/NL-BioImaging/biomero/zipball/v1.11.0"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "TorecLuik",
          "type": "User"
        },
        "date_created": "2024-05-22T14:38:30Z",
        "date_published": "2024-05-22T14:43:58Z",
        "description": "* Bump for updated scripts v1.10.0\r\n\r\n**Full Changelog**: https://github.com/NL-BioImaging/biomero/compare/v1.9.1...v1.10.0",
        "html_url": "https://github.com/NL-BioImaging/biomero/releases/tag/v1.10.0",
        "name": "v1.10.0",
        "release_id": 156902143,
        "tag": "v1.10.0",
        "tarball_url": "https://api.github.com/repos/NL-BioImaging/biomero/tarball/v1.10.0",
        "type": "Release",
        "url": "https://api.github.com/repos/NL-BioImaging/biomero/releases/156902143",
        "value": "https://api.github.com/repos/NL-BioImaging/biomero/releases/156902143",
        "zipball_url": "https://api.github.com/repos/NL-BioImaging/biomero/zipball/v1.10.0"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "TorecLuik",
          "type": "User"
        },
        "date_created": "2024-05-22T14:15:53Z",
        "date_published": "2024-05-22T14:24:18Z",
        "description": "* Fix a breaking bug in the init method, introduced with escaping folder names. Should be able to setup new workflows again w/ v1.9.1.\r\n\r\n**Full Changelog**: https://github.com/NL-BioImaging/biomero/compare/v1.9.0...v1.9.1",
        "html_url": "https://github.com/NL-BioImaging/biomero/releases/tag/v1.9.1",
        "name": "v1.9.1",
        "release_id": 156897206,
        "tag": "v1.9.1",
        "tarball_url": "https://api.github.com/repos/NL-BioImaging/biomero/tarball/v1.9.1",
        "type": "Release",
        "url": "https://api.github.com/repos/NL-BioImaging/biomero/releases/156897206",
        "value": "https://api.github.com/repos/NL-BioImaging/biomero/releases/156897206",
        "zipball_url": "https://api.github.com/repos/NL-BioImaging/biomero/zipball/v1.9.1"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "TorecLuik",
          "type": "User"
        },
        "date_created": "2024-05-13T13:11:23Z",
        "date_published": "2024-05-13T13:19:37Z",
        "description": "## What's Changed\r\n* Fixed handling of OMERO datasets/folders with spaces in the name: #12 \r\n* Fixed handling of a GIT repo for (job) scripts #11 \r\n* changed target folder for slurm-config.ini in description by @jo-mueller in https://github.com/NL-BioImaging/biomero/pull/10\r\n\r\n## New Contributors\r\n* @jo-mueller made their first contribution in https://github.com/NL-BioImaging/biomero/pull/10\r\n\r\n**Full Changelog**: https://github.com/NL-BioImaging/biomero/compare/v1.8.0...v1.9.0",
        "html_url": "https://github.com/NL-BioImaging/biomero/releases/tag/v1.9.0",
        "name": "v1.9.0",
        "release_id": 155507781,
        "tag": "v1.9.0",
        "tarball_url": "https://api.github.com/repos/NL-BioImaging/biomero/tarball/v1.9.0",
        "type": "Release",
        "url": "https://api.github.com/repos/NL-BioImaging/biomero/releases/155507781",
        "value": "https://api.github.com/repos/NL-BioImaging/biomero/releases/155507781",
        "zipball_url": "https://api.github.com/repos/NL-BioImaging/biomero/zipball/v1.9.0"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "TorecLuik",
          "type": "User"
        },
        "date_created": "2024-04-04T15:27:32Z",
        "date_published": "2024-04-04T16:17:07Z",
        "description": "- Cleanup after conversion too\r\n- Don't copy metadata from original images anymore (it copied datatype too)\r\n\r\n**Full Changelog**: https://github.com/NL-BioImaging/biomero/compare/v1.7.1...v1.8.0",
        "html_url": "https://github.com/NL-BioImaging/biomero/releases/tag/v1.8.0",
        "name": "v1.8.0",
        "release_id": 149807004,
        "tag": "v1.8.0",
        "tarball_url": "https://api.github.com/repos/NL-BioImaging/biomero/tarball/v1.8.0",
        "type": "Release",
        "url": "https://api.github.com/repos/NL-BioImaging/biomero/releases/149807004",
        "value": "https://api.github.com/repos/NL-BioImaging/biomero/releases/149807004",
        "zipball_url": "https://api.github.com/repos/NL-BioImaging/biomero/zipball/v1.8.0"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "TorecLuik",
          "type": "User"
        },
        "date_created": "2024-04-03T15:00:00Z",
        "date_published": "2024-04-04T13:16:16Z",
        "description": "Fix bugs:\r\n- Slurm job now stops complaining about missing Singularity\r\n- CANCELLED+ state of job array is now handled properly (if you cancel a job array...)\r\n- Cleanup now also removes the large amount of converter logs made by the job array\r\n- Reduced DEBUG logging of imported modules from OMERO and Paramiko\r\n- Fixed a printing bug in the minimal slurm script \r\n- Turned more BIOMERO-scripts print statements into logger statements\r\n\r\n**Full Changelog**: https://github.com/NL-BioImaging/biomero/compare/v1.7.0...v1.7.1",
        "html_url": "https://github.com/NL-BioImaging/biomero/releases/tag/v1.7.1",
        "name": "v1.7.1",
        "release_id": 149770797,
        "tag": "v1.7.1",
        "tarball_url": "https://api.github.com/repos/NL-BioImaging/biomero/tarball/v1.7.1",
        "type": "Release",
        "url": "https://api.github.com/repos/NL-BioImaging/biomero/releases/149770797",
        "value": "https://api.github.com/repos/NL-BioImaging/biomero/releases/149770797",
        "zipball_url": "https://api.github.com/repos/NL-BioImaging/biomero/zipball/v1.7.1"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "TorecLuik",
          "type": "User"
        },
        "date_created": "2024-04-02T12:16:18Z",
        "date_published": "2024-04-02T12:55:06Z",
        "description": "Finetuning!\r\n\r\n- Added an Azure deployment for both BIOMERO and SLURM, go see the new tutorial!\r\n- Made the init script async, because we cannot wait in OMERO for all the container images to download on SLURM. That does not scale.\r\n  - Split up a few of the init methods into their own methods so you could run them seperately \r\n  - Added a new script to check the 'progress' of available workflows on SLURM, called 'SLURM_check_setup'. \r\n  - Will probably rename the 'init' category to 'admin' if we keep adding more scripts that are not for end-users but for OMERO admins.\r\n\r\n**Full Changelog**: https://github.com/NL-BioImaging/biomero/compare/v1.6.0...v1.7.0",
        "html_url": "https://github.com/NL-BioImaging/biomero/releases/tag/v1.7.0",
        "name": "v1.7.0",
        "release_id": 149388373,
        "tag": "v1.7.0",
        "tarball_url": "https://api.github.com/repos/NL-BioImaging/biomero/tarball/v1.7.0",
        "type": "Release",
        "url": "https://api.github.com/repos/NL-BioImaging/biomero/releases/149388373",
        "value": "https://api.github.com/repos/NL-BioImaging/biomero/releases/149388373",
        "zipball_url": "https://api.github.com/repos/NL-BioImaging/biomero/zipball/v1.7.0"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "TorecLuik",
          "type": "User"
        },
        "date_created": "2024-02-29T11:00:43Z",
        "date_published": "2024-02-29T12:16:55Z",
        "description": "- Separated file conversion and slurm workflow into 2 jobs to avoid a deadlock\r\n- Added a method to specifically run file conversion to biomero\r\n- Added a slim / simple result class SlurmJob, to allow easier waiting on job completion on slurm. Note it is not asynchronous / concurrent. You just wait the current thread at this moment (which works fine with 1 workflow per omero job).\r\n- Fixed the job status methods to handle job arrays too\r\n\r\n**Full Changelog**: https://github.com/NL-BioImaging/biomero/compare/v1.5.1...v1.6.0",
        "html_url": "https://github.com/NL-BioImaging/biomero/releases/tag/v1.6.0",
        "name": "v1.6.0",
        "release_id": 144180583,
        "tag": "v1.6.0",
        "tarball_url": "https://api.github.com/repos/NL-BioImaging/biomero/tarball/v1.6.0",
        "type": "Release",
        "url": "https://api.github.com/repos/NL-BioImaging/biomero/releases/144180583",
        "value": "https://api.github.com/repos/NL-BioImaging/biomero/releases/144180583",
        "zipball_url": "https://api.github.com/repos/NL-BioImaging/biomero/zipball/v1.6.0"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "TorecLuik",
          "type": "User"
        },
        "date_created": "2024-02-24T12:26:45Z",
        "date_published": "2024-02-24T15:13:41Z",
        "description": "- [BUG] Fix bug where conversion script cannot handle filenames with spaces in them. Now it lists them properly.\r\n\r\n**Full Changelog**: https://github.com/NL-BioImaging/biomero/compare/v1.5.0...v1.5.1",
        "html_url": "https://github.com/NL-BioImaging/biomero/releases/tag/v1.5.1",
        "name": "v1.5.1",
        "release_id": 143484203,
        "tag": "v1.5.1",
        "tarball_url": "https://api.github.com/repos/NL-BioImaging/biomero/tarball/v1.5.1",
        "type": "Release",
        "url": "https://api.github.com/repos/NL-BioImaging/biomero/releases/143484203",
        "value": "https://api.github.com/repos/NL-BioImaging/biomero/releases/143484203",
        "zipball_url": "https://api.github.com/repos/NL-BioImaging/biomero/zipball/v1.5.1"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "TorecLuik",
          "type": "User"
        },
        "date_created": "2024-02-21T16:22:44Z",
        "date_published": "2024-02-21T16:29:49Z",
        "description": "- Match versions with updated (batch) biomero-scripts (v1.5.0)\r\n- Small updates to README/comments\r\n\r\n**Full Changelog**: https://github.com/NL-BioImaging/biomero/compare/v1.4.0...v1.5.0",
        "html_url": "https://github.com/NL-BioImaging/biomero/releases/tag/v1.5.0",
        "name": "v1.5.0",
        "release_id": 143018203,
        "tag": "v1.5.0",
        "tarball_url": "https://api.github.com/repos/NL-BioImaging/biomero/tarball/v1.5.0",
        "type": "Release",
        "url": "https://api.github.com/repos/NL-BioImaging/biomero/releases/143018203",
        "value": "https://api.github.com/repos/NL-BioImaging/biomero/releases/143018203",
        "zipball_url": "https://api.github.com/repos/NL-BioImaging/biomero/zipball/v1.5.0"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "TorecLuik",
          "type": "User"
        },
        "date_created": "2024-02-05T12:32:17Z",
        "date_published": "2024-02-19T16:40:18Z",
        "description": "Match version with new biomero-scripts release\r\n\r\n**Full Changelog**: https://github.com/NL-BioImaging/biomero/compare/v1.3.0...v1.4.0",
        "html_url": "https://github.com/NL-BioImaging/biomero/releases/tag/v1.4.0",
        "name": "v1.4.0",
        "release_id": 142627051,
        "tag": "v1.4.0",
        "tarball_url": "https://api.github.com/repos/NL-BioImaging/biomero/tarball/v1.4.0",
        "type": "Release",
        "url": "https://api.github.com/repos/NL-BioImaging/biomero/releases/142627051",
        "value": "https://api.github.com/repos/NL-BioImaging/biomero/releases/142627051",
        "zipball_url": "https://api.github.com/repos/NL-BioImaging/biomero/zipball/v1.4.0"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "CellularImagingCF",
          "type": "User"
        },
        "date_created": "2024-02-01T14:17:40Z",
        "date_published": "2024-02-01T15:16:13Z",
        "description": "- Changes required for enabling [BIOMERO scripts](https://github.com/NL-BioImaging/biomero-scripts) v1.3.0\r\n  - BIOMERO scripts v1.3.0 added support for uploading CSV output files (from workflows) back into OMERO as OMERO.tables\r\n\r\n**Full Changelog**: https://github.com/NL-BioImaging/biomero/compare/v1.2.0...v1.3.0",
        "html_url": "https://github.com/NL-BioImaging/biomero/releases/tag/v1.3.0",
        "name": "v1.3.0",
        "release_id": 139526348,
        "tag": "v1.3.0",
        "tarball_url": "https://api.github.com/repos/NL-BioImaging/biomero/tarball/v1.3.0",
        "type": "Release",
        "url": "https://api.github.com/repos/NL-BioImaging/biomero/releases/139526348",
        "value": "https://api.github.com/repos/NL-BioImaging/biomero/releases/139526348",
        "zipball_url": "https://api.github.com/repos/NL-BioImaging/biomero/zipball/v1.3.0"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "CellularImagingCF",
          "type": "User"
        },
        "date_created": "2024-01-30T13:31:58Z",
        "date_published": "2024-01-30T13:35:39Z",
        "description": "Renamed the whole package from omero_slurm_client / omero-slurm-client to biomero.\r\n\r\nInstall the new biomero package via GitHub or PyPI.\r\n\r\n`from biomero import SlurmClient`\r\n\r\n## What's Changed\r\n* Bump paramiko from 3.2.0 to 3.4.0 by @dependabot in https://github.com/NL-BioImaging/biomero/pull/7\r\n\r\n\r\n**Full Changelog**: https://github.com/NL-BioImaging/biomero/compare/v1.1.1...v1.2.0",
        "html_url": "https://github.com/NL-BioImaging/biomero/releases/tag/v1.2.0",
        "name": "v1.2.0",
        "release_id": 139127635,
        "tag": "v1.2.0",
        "tarball_url": "https://api.github.com/repos/NL-BioImaging/biomero/tarball/v1.2.0",
        "type": "Release",
        "url": "https://api.github.com/repos/NL-BioImaging/biomero/releases/139127635",
        "value": "https://api.github.com/repos/NL-BioImaging/biomero/releases/139127635",
        "zipball_url": "https://api.github.com/repos/NL-BioImaging/biomero/zipball/v1.2.0"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "TorecLuik",
          "type": "User"
        },
        "date_created": "2024-01-25T16:17:04Z",
        "date_published": "2024-01-25T16:22:14Z",
        "description": "- Drop support for Python 3.6\r\n- Use request cache 1.1.1 which supports conditional requests to GitHub, circumventing a lot of the rate limit.\r\n\r\n**Full Changelog**: https://github.com/NL-BioImaging/omero-slurm-client/compare/v1.0.0...v1.1.1",
        "html_url": "https://github.com/NL-BioImaging/biomero/releases/tag/v1.1.1",
        "name": "v1.1.1",
        "release_id": 138546380,
        "tag": "v1.1.1",
        "tarball_url": "https://api.github.com/repos/NL-BioImaging/biomero/tarball/v1.1.1",
        "type": "Release",
        "url": "https://api.github.com/repos/NL-BioImaging/biomero/releases/138546380",
        "value": "https://api.github.com/repos/NL-BioImaging/biomero/releases/138546380",
        "zipball_url": "https://api.github.com/repos/NL-BioImaging/biomero/zipball/v1.1.1"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "TorecLuik",
          "type": "User"
        },
        "date_created": "2023-12-20T13:46:20Z",
        "date_published": "2023-12-20T13:56:25Z",
        "description": "Publish the first version of the OMERO Slurm Client to accompany the upcoming paper: BIOMERO.\r\n\r\nFeatures:\r\n- Connect OMERO with generic remote HPC (over SSH).\r\n- Run generic containerized (FAIR) image analysis workflows from OMERO web on remote HPC.\r\n- Manage export and import of data to / from OMERO.\r\n- Publish all source code, scripts, tutorials, and a few containers for OMERO, Slurm and workflows.\r\n\r\nMerry Christmas and a happy new year!\r\n\r\n**Full Changelog**: https://github.com/NL-BioImaging/omero-slurm-client/compare/v0.2.0-alpha...v1.0.0",
        "html_url": "https://github.com/NL-BioImaging/biomero/releases/tag/v1.0.0",
        "name": "Version 1",
        "release_id": 134629876,
        "tag": "v1.0.0",
        "tarball_url": "https://api.github.com/repos/NL-BioImaging/biomero/tarball/v1.0.0",
        "type": "Release",
        "url": "https://api.github.com/repos/NL-BioImaging/biomero/releases/134629876",
        "value": "https://api.github.com/repos/NL-BioImaging/biomero/releases/134629876",
        "zipball_url": "https://api.github.com/repos/NL-BioImaging/biomero/zipball/v1.0.0"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "TorecLuik",
          "type": "User"
        },
        "date_created": "2023-10-05T09:42:02Z",
        "date_published": "2023-10-05T09:44:38Z",
        "description": "Let's release and publish a version.\r\n\r\nLibrary should work for 2D image-to-image workflows, like CellPose.\r\n\r\nRecent upgrades:\r\n- Add support for ZARR export (to bypass the 'rendering engine' interpreting the image)\r\n- Add support for (an array of) conversion containers; add a ZARR to TIFF converter by default\r\n- Finalize some tutorials\r\n\r\n**Full Changelog**: https://github.com/NL-BioImaging/omero-slurm-client/compare/v0.1.0-alpha...v0.2.0-alpha",
        "html_url": "https://github.com/NL-BioImaging/biomero/releases/tag/v0.2.0-alpha",
        "name": "v0.2.0-alpha",
        "release_id": 123827856,
        "tag": "v0.2.0-alpha",
        "tarball_url": "https://api.github.com/repos/NL-BioImaging/biomero/tarball/v0.2.0-alpha",
        "type": "Release",
        "url": "https://api.github.com/repos/NL-BioImaging/biomero/releases/123827856",
        "value": "https://api.github.com/repos/NL-BioImaging/biomero/releases/123827856",
        "zipball_url": "https://api.github.com/repos/NL-BioImaging/biomero/zipball/v0.2.0-alpha"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "TorecLuik",
          "type": "User"
        },
        "date_created": "2023-07-03T08:39:01Z",
        "date_published": "2023-07-03T09:27:18Z",
        "description": "A release for Zenodo DOI",
        "html_url": "https://github.com/NL-BioImaging/biomero/releases/tag/v0.1.1-alpha",
        "name": "Version 0.1.1 (pre-release)",
        "release_id": 110836590,
        "tag": "v0.1.1-alpha",
        "tarball_url": "https://api.github.com/repos/NL-BioImaging/biomero/tarball/v0.1.1-alpha",
        "type": "Release",
        "url": "https://api.github.com/repos/NL-BioImaging/biomero/releases/110836590",
        "value": "https://api.github.com/repos/NL-BioImaging/biomero/releases/110836590",
        "zipball_url": "https://api.github.com/repos/NL-BioImaging/biomero/zipball/v0.1.1-alpha"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "TorecLuik",
          "type": "User"
        },
        "date_created": "2023-07-03T08:39:01Z",
        "date_published": "2023-07-03T08:48:32Z",
        "description": "Initial pre-release version.\r\n\r\n**Full Changelog**: https://github.com/NL-BioImaging/omero-slurm-client/commits/v0.1.0-alpha",
        "html_url": "https://github.com/NL-BioImaging/biomero/releases/tag/v0.1.0-alpha",
        "name": "Version 0.1.0 (alpha)",
        "release_id": 110831776,
        "tag": "v0.1.0-alpha",
        "tarball_url": "https://api.github.com/repos/NL-BioImaging/biomero/tarball/v0.1.0-alpha",
        "type": "Release",
        "url": "https://api.github.com/repos/NL-BioImaging/biomero/releases/110831776",
        "value": "https://api.github.com/repos/NL-BioImaging/biomero/releases/110831776",
        "zipball_url": "https://api.github.com/repos/NL-BioImaging/biomero/zipball/v0.1.0-alpha"
      },
      "technique": "GitHub_API"
    }
  ],
  "requirements": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Slurm Requirements",
        "parent_header": [
          "Prerequisites &amp; Getting Started with BIOMERO"
        ],
        "type": "Text_excerpt",
        "value": "Note: This library has only been tested on Slurm versions 21.08.6 and 22.05.09 !\n\nYour Slurm cluster/login node needs to have:\n1. SSH access w/ public key (headless)\n2. SCP access (generally comes with SSH)\n3. 7zip installed\n4. Singularity/Apptainer installed\n5. (Optional) Git installed, if you want your own job scripts\n6. Slurm accounting enabled\n"
      },
      "source": "https://raw.githubusercontent.com/NL-BioImaging/biomero/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "OMERO Requirements",
        "parent_header": [
          "Prerequisites &amp; Getting Started with BIOMERO"
        ],
        "type": "Text_excerpt",
        "value": "Your OMERO _processing_ node needs to have:\n1. SSH client and access to the Slurm cluster (w/ private key / headless)\n2. SCP access to the Slurm cluster\n3. Python3.7+\n4. This library installed \n    - Latest release on PyPI `python3 -m pip install biomero`\n    - or latest Github version `python3 -m pip install 'git+https://github.com/NL-BioImaging/biomero'`\n5. Configuration setup at `/etc/slurm-.ini`\n6. Requirements for some scripts: `python3 -m pip install ezomero==1.1.1 tifffile==2020.9.3` and the [OMERO CLI Zarr plugin](https://github.com/ome/omero-cli-zarr).\n\nYour OMERO _server_ node needs to have:\n1. Some OMERO example scripts installed to interact with this library:\n    - My examples on github: `https://github.com/NL-BioImaging/biomero-scripts`\n    - Install those at `/opt/omero/server/OMERO.server/lib/scripts/slurm/`, e.g. `git clone https://github.com/NL-BioImaging/biomero-scripts.git <path>/slurm`\n\n!!*NOTE*: Do not install [Example Minimal Slurm Script](https://github.com/NL-BioImaging/biomero-scripts/blob/master/Example_Minimal_Slurm_Script.py) if you do not trust your users with your Slurm cluster. It has literal Command Injection for the SSH user as a **FEATURE**. \n\n\n\n"
      },
      "source": "https://raw.githubusercontent.com/NL-BioImaging/biomero/main/README.md",
      "technique": "header_analysis"
    }
  ],
  "somef_missing_categories": [
    "acknowledgement",
    "run",
    "download",
    "contact",
    "contributors",
    "support",
    "has_build_file",
    "executable_example"
  ],
  "somef_provenance": {
    "date": "2024-10-03 23:37:09",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 12
      },
      "technique": "GitHub_API"
    }
  ],
  "type": [
    {
      "confidence": 0.82,
      "result": {
        "type": "String",
        "value": "commandline-application"
      },
      "technique": "software_type_heuristics"
    }
  ],
  "usage": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Getting Started",
        "parent_header": [
          "Prerequisites &amp; Getting Started with BIOMERO"
        ],
        "type": "Text_excerpt",
        "value": "To connect an OMERO processor to a Slurm cluster using the `biomero` library, users can follow these steps:\n\n1. Setup passwordless public key authentication between your OMERO `processor` server and your HPC server. E.g. follow  a [SSH tutorial](https://www.ssh.com/academy/ssh/public-key-authentication) or [this one](https://linuxize.com/post/how-to-setup-passwordless-ssh-login/).\n    - You could use 1 Slurm account for all `processor` servers, and share the same private key to all of them.\n    - Or you could use unique accounts, but give them all the same alias in step 2.\n\n2. Create a SSH config file named `config` in the `.ssh` directory of (all) the OMERO `processor` servers, within the `omero` user's home directory (`~/.ssh/config`). This file should specify the hostname, username, port, and private key path for the Slurm cluster, under some alias. This alias we will provide to the library. We provide an example in the [resources](./resources/config) directory.\n\n    - This will allow a uniform SSH naming, and makes the connection headless; making it easy for the library.\n\n    - Test the SSH connection manually! `ssh slurm` (as the omero user) should connect you to the Slurm server (given that you named it `slurm` in the `config`).\n\n    - Congratulations! Now the servers are connected. Next, we make sure to setup the connection between OMERO and Slurm.\n\n3. At this point, ensure that the `slurm-config.ini` file is correctly configured with the necessary SSH and Slurm settings, including the host, data path, images path, and model details. Customize the configuration according to the specific Slurm cluster setup. We provide an example in the [resources](./resources/slurm-config.ini) section. To read it automatically, place this `ini` file in one of the following locations (on the OMERO `processor` server):\n    - `/etc/slurm-config.ini`\n    - `~/slurm-config.ini`\n\n    *Note*: Make sure to place the `slurm-config.ini` in the target folder at build time of your docker container instead of mounting it at runtime. This is because the library reads the config file at import time, and if it is not found, it will not work.\n\n4. Install OMERO scripts from [OMERO Slurm Scripts](https://github.com/NL-BioImaging/biomero-scripts), e.g. \n    - `cd /opt/omero/server/OMERO.server/lib/scripts`\n    - `git clone https://github.com/NL-BioImaging/biomero-scripts.git slurm`\n\n!!*NOTE*: Do not install [Example Minimal Slurm Script](https://github.com/NL-BioImaging/biomero-scripts/blob/master/Example_Minimal_Slurm_Script.py) if you do not trust your users with your Slurm cluster. It has literal Command Injection for the SSH user as a **FEATURE**. \n\n5. Install [BIOMERO Scripts](https://github.com/NL-BioImaging/biomero-scripts/) requirements, e.g.\n    - `python3 -m pip install ezomero==1.1.1 tifffile==2020.9.3` \n    - the [OMERO CLI Zarr plugin](https://github.com/ome/omero-cli-zarr), e.g. \n    `python3 -m pip install omero-cli-zarr==0.5.3` && `yum install -y blosc-devel`\n    - the [bioformats2raw-0.7.0](https://github.com/glencoesoftware/bioformats2raw/releases/download/v0.7.0/bioformats2raw-0.7.0.zip), e.g. `unzip -d /opt bioformats2raw-0.7.0.zip && export PATH=\"$PATH:/opt/bioformats2raw-0.7.0/bin\"`\n\n6. To finish setting up your `SlurmClient` and Slurm server, run it once with `init_slurm=True`. This is provided in a OMERO script form at [init/Slurm Init environment](https://github.com/NL-BioImaging/biomero-scripts/blob/master/init/SLURM_Init_environment.py) , which you just installed in previous step.\n    - Provide the configfile location explicitly if it is not a default one defined earlier, otherwise you can omit that field. \n    - Please note the requirements for your Slurm cluster. We do not install Singularity / 7zip on your cluster for you (at the time of writing).\n    - This operation will make it create the directories you provided in the `slurm-config.ini`, pull any described Singularity images to the server (note: might take a while), and generate (or clone from Git) any job scripts for these workflows:\n\n```python\nwith SlurmClient.from_config(configfile=configfile,\n                            init_slurm=True) as slurmClient:\n    slurmClient.validate(validate_slurm_setup=True)\n```\n\nWith the configuration files in place, you can utilize the `SlurmClient` class from the `biomero` library to connect to the Slurm cluster over SSH, enabling the submission and management of Slurm jobs from an OMERO processor. \n"
      },
      "source": "https://raw.githubusercontent.com/NL-BioImaging/biomero/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "See the tutorials",
        "type": "Text_excerpt",
        "value": "I have also provided tutorials on connecting to a Local or Cloud Slurm, and tutorials on how to add your FAIR workflows to this setup. Those can give some more insights as well.\n"
      },
      "source": "https://raw.githubusercontent.com/NL-BioImaging/biomero/main/README.md",
      "technique": "header_analysis"
    }
  ]
}