{
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/zpf0117b/CLMB"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2021-11-03T22:19:05Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2024-04-16T13:49:26Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "Contrastive Learning for Metagenomic Binning"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 0.9295365928959953,
      "result": {
        "original_header": "CLMB",
        "type": "Text_excerpt",
        "value": "A simple framework for CLMB - a novel deep Contrastive Learningfor Metagenomic Binning \nCreated by Pengfei Zhang, senior of Department of Computer Science, University of Science and Technology of China. \nWe develop it under the framework of [VAMB](https://github.com/RasmussenLab/vamb/blob/master/doc/tutorial.ipynb), which is published on Nature Biotechnology (https://doi.org/10.1038/s41587-020-00777-4). All the commands are the same. We added files simclr_module.py augmentation.py and modified files \\_\\_main\\_\\_.py encode.py to implement our algorithm. \nThis is a simple implement of CLMB and the codes are not pretty. We will polish the code, add interfaces, and write documentations later. \nThe basic idea of the CLMB module is that, since the noise of real dataset is hard to calculate, we add simulated noise to the data and force the training to be robustto them.  By effectively tacking the noise in the metagenomics data using the contrastive deep learningframework (https://arxiv.org/pdf/2002.05709.pdf), we can group pairs of contigs that originate from the same type of bacterial together while dividing contigs from different species to different bins. \n"
      },
      "source": "https://raw.githubusercontent.com/zpf0117b/CLMB/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9527591577090883,
      "result": {
        "original_header": "Vamb",
        "type": "Text_excerpt",
        "value": "Created by Jakob Nybo Nissen and Simon Rasmussen, Technical University of Denmark and Novo Nordisk Foundation Center for Protein Research, University of Copenhagen. \nVamb is a metagenomic binner which feeds sequence composition information from a contig catalogue and co-abundance information from BAM files into a variational autoencoder and clusters the latent representation. It performs excellently with multiple samples, and pretty good on single-sample data. Vamb is implemented purely in Python (with a little bit of Cython) and can be used both from command line and from within a Python interpreter. \nFor more information about the implementation, methodological considerations, and advanced usage of Vamb, see the tutorial file (`doc/tutorial.html`) \n"
      },
      "source": "https://raw.githubusercontent.com/zpf0117b/CLMB/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9254212620549994,
      "result": {
        "original_header": "Inputs",
        "type": "Text_excerpt",
        "value": "Vamb relies on two properties of the DNA sequences to be binned: \n* The kmer-composition of the sequence (here tetranucleotide frequency, *TNF*) and\n* The abundance of the contigs in each sample (the *depth* or the *RPKM*). \n* TNF is calculated from a regular FASTA file of DNA sequences.\n* Depth is calculated from BAM-files of a set of reads from each sample mapped to that same FASTA file. \n:warning: *Important:* Vamb can use information from multi-mapping reads, but all alignments of a single read __must__ be consecutive in the BAM files. See section 4 of *Recommended workflow*. \nRemember that the quality of Vamb's bins are no better than the quality of the input files. If your BAM files are constructed carelessly, for example by allowing reads from distinct species to crossmap indiscriminately, your BAM files will not contain information with which Vamb can separate those species. In general, you want reads to map only to contigs within the same phylogenetic distance that you want Vamb to bin together. \nEstimation of TNF and RPKM is subject to statistical uncertainty. Therefore, Vamb works less well on short sequences and on data with low depth. Vamb *can* work on shorter sequences such as genes, which are more easily homology reduced. However, we recommend *not* using homology reduction on the input sequences, and instead prevent duplicated strains by using binsplitting (see section: _recommended workflow_.)\n \n"
      },
      "source": "https://raw.githubusercontent.com/zpf0117b/CLMB/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9078742082189151,
      "result": {
        "original_header": "Outputs",
        "type": "Text_excerpt",
        "value": "- `log.txt` - a text file with information about the Vamb run. Look here (and at stderr) if you experience errors.\n- `tnf.npz`, `lengths.npz` `rpkm.npz`, `mask.npz` and `latent.npz` - [Numpy .npz](https://numpy.org/devdocs/reference/generated/numpy.lib.format.html) files with TNFs, contig lengths. RPKM, which sequences were successfully encoded, and the latent encoding of the sequences.\n- `model.pt` - containing a PyTorch model object of the trained VAE. You can load the VAE from this file using `vamb.encode.VAE.load` from Python.\n- `clusters.tsv` - a two-column text file with one row per sequence: Left column for the cluster (i.e bin) name, right column for the sequence name. You can create the FASTA-file bins themselves using `vamb.vambtools.write_bins`, or using the function `vamb.vambtools.write_bins` (see `doc/tutorial.html` for more details).\n \n"
      },
      "source": "https://raw.githubusercontent.com/zpf0117b/CLMB/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9403860950550404,
      "result": {
        "original_header": "Recommended workflow",
        "type": "Text_excerpt",
        "value": "We use AdapterRemoval combined with FastQC for this - but you can use whichever tool you think gives the best results. \n__2) Assemble each sample individually and get the contigs out__ \nWe recommend using metaSPAdes on each sample individually. You can also use scaffolds or other nucleotide sequences instead of contigs as input sequences to Vamb. Assemble each sample individually, as single-sample assembly followed by samplewise binsplitting gives the best results. \nYou should not try to bin very short sequences. When deciding the length cutoff for your input sequences, there's a tradeoff here between choosing a too low cutoff, retaining hard-to-bin contigs which adversely affects the binning of *all* contigs, and choosing a too high one, throwing out good data. We use a length cutoff of 2000 bp as default but haven't actually run tests for the optimal value. \nYour contig headers must be unique. Furthermore, if you want to use binsplitting (and you should!), your contig headers must be of the format {Samplename}{Separator}{X}, such that the part of the string before the *first* occurrence of {Separator} gives a name of the sample it originated from. For example, you could call contig number 115 from sample number 9 \"S9C115\", where \"S9\" would be {Samplename}, \"C\" is {Separator} and \"115\" is {X}. \nVamb is faily memory efficient, and we have run Vamb with 1000 samples and 5.9 million contigs using <30 GB of RAM. If you have a dataset too large to fit in RAM and feel the temptation to bin each sample individually, you can instead use a tool like MASH to group similar samples together in smaller batches, bin these batches individually. This way, you can still leverage co-abundance. **NB:** We have a version using memory-mapping that is much more RAM-efficient but 10-20% slower. Here we have processed a dataset of 942 samples with 30M contigs (total of 117Gbp contig sequence) in 40Gb RAM - see branch `mmap`. \n:warning: *Important:* If you allow reads to map to multiple contigs, the abundance estimation will be more accurate. However, all BAM records for a single read *must* be consecutive in the BAM file, or else Vamb will miscount these alignments. This is the default order in the output of almost all aligners, but if you use BAM files sorted by alignment position and have multi-mapping reads, you must sort them by read name first. \nBe careful to choose proper parameters for your aligner - in general, if reads from contig A align to contig B, then Vamb will bin A and B together. So your aligner should map reads with the same level of discrimination that you want Vamb to use. Although you can use any aligner that produces a specification-compliant BAM file, we prefer using `minimap2`:\n```minimap2 -T almeida.fna -t 28 -N 5 -ax sr almeida.mmi sample1.forward.fastq.gz sample1.reverse.fastq.gz | samtools view -F 3584 -b --threads 8 > sample1.bam```\n \n:warning: *Important:* Do *not* filter the aligments for mapping quality as specified by the MAPQ field of the BAM file. This field gives the probability that the mapping position is correct, which is influenced by the number of alternative mapping locations. Filtering low MAPQ alignments away removes alignments to homologous sequences which biases the depth estimation. \nIf you are using BAM files where you do not trust the validity of every alignment in the file, you can filter the alignments for minimum nucleotide identity using the `-z` flag (uses the `NM` optional field of the alignment, we recommend setting it to `0.95`), and/or filter for minimum alignments score using the `-s` flag (uses the `AS` optional field of the alignment.) \nWe have found that MetaBAT2's `jgi_summarize_bam_contig_depths` program estimates BAM depths more accurate than Vamb's `parsebam` module. For the best results, we recommend [downloading MetaBAT2](https://bitbucket.org/berkeleylab/metabat/src/master/), using `jgi_summarize_bam_contig_depths` to estimate depths, and then running Vamb with `--jgi` instead of `--bamfiles`. Also consider using the `snakemake` workflow which will do this for you.  \nBy default, Vamb does not output any FASTA files of the bins. In the examples below, the option `--minfasta 200000` is set, meaning that all bins with a size of 200 kbp or more will be output as FASTA files.\nIf you trust the alignments in your BAM files, use: \nwhere `SEP` in the {Separator} chosen in step 3, e.g. `C` in that example, `OUT` is the name of the output directory to create, `FASTA` the path to the FASTA file and `BAM1` the path to the first BAM file. You can also use shell globbing to input multiple BAM files: `my_bamdir/*bam`. \nIf you don't trust your alignments, set the `-z` and `-s` flag as appropriate, depending on the properties of your aligner. For example, if I used the aligner BWA MEM, I would use: \n"
      },
      "source": "https://raw.githubusercontent.com/zpf0117b/CLMB/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9685612111608684,
      "result": {
        "original_header": "Parameter optimisation (optional)",
        "type": "Text_excerpt",
        "value": "The default hyperparameters of Vamb will provide good performance on any dataset. However, since running Vamb is fast (especially using GPUs) it is possible to try to run Vamb with different hyperparameters to see if better performance can be achieved (note that here we measure performance as the number of near-complete bins assessed by CheckM). We recommend to try to increase and decrease the size of the neural network and have used Vamb on datasets where increasing the network resulted in more near-complete bins and other datasets where decreasing the network resulted in more near-complete bins. To do this you can run Vamb as (default for multiple samples is `-l 32 -n 512 512`)`:\n```\nvamb -l 24 -n 384 384 --outdir path/to/outdir --fasta /path/to/catalogue.fna.gz --bamfiles /path/to/bam/*.bam -o C --minfasta 200000\nvamb -l 40 -n 768 768 --outdir path/to/outdir --fasta /path/to/catalogue.fna.gz --bamfiles /path/to/bam/*.bam -o C --minfasta 200000\n```\n \nIt is possible to try any combination of latent and hidden neurons as well as other sizes of the layers. Number of near-complete bins can be assessed using CheckM and compared between the methods. Potentially see the snakemake folder `workflow` for an automated way to run Vamb with multiple parameters. \n"
      },
      "source": "https://raw.githubusercontent.com/zpf0117b/CLMB/main/README.md",
      "technique": "supervised_classification"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/zpf0117b/CLMB/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "executable_example": [
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/zpf0117b/CLMB/main/doc/tutorial.ipynb"
      },
      "source": "https://raw.githubusercontent.com/zpf0117b/CLMB/main/doc/tutorial.ipynb",
      "technique": "file_exploration"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 2
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/zpf0117b/CLMB/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "zpf0117b/CLMB"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "CLMB"
      },
      "source": "https://raw.githubusercontent.com/zpf0117b/CLMB/main/README.md",
      "technique": "regular_expression"
    }
  ],
  "installation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Installation:",
        "parent_header": [
          "CLMB"
        ],
        "type": "Text_excerpt",
        "value": "Install the latest version from GitHub you can clone and install it using:\n\n```\ngit clone https://github.com/RasmussenLab/vamb -b master\ncd vamb\npip install -e .\n```\n\n"
      },
      "source": "https://raw.githubusercontent.com/zpf0117b/CLMB/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 0.9956082687464554,
      "result": {
        "original_header": "Inputs",
        "type": "Text_excerpt",
        "value": "So before you can run Vamb, you need to have files from which Vamb can calculate these values: \n"
      },
      "source": "https://raw.githubusercontent.com/zpf0117b/CLMB/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.940312140385322,
      "result": {
        "original_header": "Outputs",
        "type": "Text_excerpt",
        "value": "Vamb produces the following output files: \n"
      },
      "source": "https://raw.githubusercontent.com/zpf0117b/CLMB/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9302239523224103,
      "result": {
        "original_header": "Recommended workflow",
        "type": "Text_excerpt",
        "value": "You can use the function `vamb.vambtools.concatenate_fasta` for this or the script `src/concatenate.py`.  \nBe careful to choose proper parameters for your aligner - in general, if reads from contig A align to contig B, then Vamb will bin A and B together. So your aligner should map reads with the same level of discrimination that you want Vamb to use. Although you can use any aligner that produces a specification-compliant BAM file, we prefer using `minimap2`:\n```minimap2 -T almeida.fna -t 28 -N 5 -ax sr almeida.mmi sample1.forward.fastq.gz sample1.reverse.fastq.gz | samtools view -F 3584 -b --threads 8 > sample1.bam```\n \nIf you are using BAM files where you do not trust the validity of every alignment in the file, you can filter the alignments for minimum nucleotide identity using the `-z` flag (uses the `NM` optional field of the alignment, we recommend setting it to `0.95`), and/or filter for minimum alignments score using the `-s` flag (uses the `AS` optional field of the alignment.) \nBy default, Vamb does not output any FASTA files of the bins. In the examples below, the option `--minfasta 200000` is set, meaning that all bins with a size of 200 kbp or more will be output as FASTA files.\nIf you trust the alignments in your BAM files, use: \nIf you don't trust your alignments, set the `-z` and `-s` flag as appropriate, depending on the properties of your aligner. For example, if I used the aligner BWA MEM, I would use: \n"
      },
      "source": "https://raw.githubusercontent.com/zpf0117b/CLMB/main/README.md",
      "technique": "supervised_classification"
    }
  ],
  "invocation": [
    {
      "confidence": 0.8129696555032755,
      "result": {
        "original_header": "Recommended workflow",
        "type": "Text_excerpt",
        "value": "__5) Run Vamb__ \n"
      },
      "source": "https://raw.githubusercontent.com/zpf0117b/CLMB/main/README.md",
      "technique": "supervised_classification"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/zpf0117b/CLMB/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ""
      },
      "technique": "GitHub_API"
    }
  ],
  "license": [
    {
      "confidence": 1,
      "result": {
        "name": "MIT License",
        "spdx_id": "MIT",
        "type": "License",
        "url": "https://api.github.com/licenses/mit",
        "value": "https://api.github.com/licenses/mit"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "type": "File_dump",
        "value": "MIT License\n\nCopyright (c) 2018 Technical University of Denmark\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
      },
      "source": "https://raw.githubusercontent.com/zpf0117b/CLMB/main/LICENSE",
      "technique": "file_exploration"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "CLMB"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "User",
        "value": "zpf0117b"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 234873,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Cython",
        "size": 3210,
        "type": "Programming_language",
        "value": "Cython"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Shell",
        "size": 2303,
        "type": "Programming_language",
        "value": "Shell"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/zpf0117b/CLMB/main/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "related_documentation": [
    {
      "confidence": 1,
      "result": {
        "format": "readthedocs",
        "type": "Url",
        "value": "https://snakemake.readthedocs.io/"
      },
      "source": "https://raw.githubusercontent.com/zpf0117b/CLMB/main/README.md",
      "technique": "regular_expression"
    }
  ],
  "related_papers": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://arxiv.org/pdf/2002.05709.pdf"
      },
      "source": "https://raw.githubusercontent.com/zpf0117b/CLMB/main/README.md",
      "technique": "regular_expression"
    }
  ],
  "run": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Running",
        "type": "Text_excerpt",
        "value": "For a detailed explanation of the parameters of Vamb, or different inputs, see the tutorial in the `doc` directory. \n\n**Updated in 3.0.2: for a snakemake pipeline see `workflow` directory.**\n\nFor more command-line options, see the command-line help menu:\n```\nvamb -h\n```\n"
      },
      "source": "https://raw.githubusercontent.com/zpf0117b/CLMB/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Here's how to run Vamb",
        "parent_header": [
          "Running"
        ],
        "type": "Text_excerpt",
        "value": "For this example, let us suppose you have a directory of short (e.g. Illumina) reads in a\ndirectory `/path/to/reads`, and that _you have already quality controlled them_.\n\n1. Run your favorite metagenomic assembler on each sample individually:\n\n```\nspades.py --meta /path/to/reads/sample1.fw.fq.gz /path/to/reads/sample1.rv.fq.gz\n-k 21,29,39,59,79,99 -t 24 -m 100gb -o /path/to/assemblies/sample1\n```\n\n2. Use Vamb's `concatenate.py` to make the FASTA catalogue of all your assemblies:\n\n```\nconcatenate.py /path/to/catalogue.fna.gz /path/to/assemblies/sample1/contigs.fasta\n/path/to/assemblies/sample2/contigs.fasta  [ ... ]\n```\n\n3. Use your favorite short-read aligner to map each your read files back to the resulting FASTA file:\n\n```\nminimap2 -d catalogue.mmi /path/to/catalogue.fna.gz; # make index\nminimap2 -t 8 -N 50 -ax sr catalogue.mmi /path/to/reads/sample1.fw.fq.gz /path/to/reads/sample1.rv.fq.gz | samtools view -F 3584 -b --threads 8 > /path/to/bam/sample1.bam\n```\n\n4. Run Vamb:\n\n```\nvamb --outdir path/to/outdir --fasta /path/to/catalogue.fna.gz --bamfiles /path/to/bam/*.bam -o C --minfasta 200000\n```\n\nNote that we have found that MetaBAT2's `jgi_summarize_bam_contig_depths` program estimates BAM depths more accurate than Vamb's `parsebam` module (see below). If you want to use this approach instead we provide an easy to use `snakemake` workflow which will do this for you. \n"
      },
      "source": "https://raw.githubusercontent.com/zpf0117b/CLMB/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Snakemake workflow",
        "parent_header": [
          "Running"
        ],
        "type": "Text_excerpt",
        "value": "To make it even easier to run Vamb in the best possible way, we have created a [Snakemake](https://snakemake.readthedocs.io/en/stable/#) workflow that will run steps 2-4 above using MetaBAT2's `jgi_summarize_bam_contig_depths` program for improved counting. Additionally it will run [CheckM](https://ecogenomics.github.io/CheckM/) to estimate completeness and contamination of the resulting bins. It can run both on a local machine, a workstation and a HPC system using `qsub` - it is included in the `workflow` folder.\n"
      },
      "source": "https://raw.githubusercontent.com/zpf0117b/CLMB/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Invoking Vamb",
        "parent_header": [
          "Running"
        ],
        "type": "Text_excerpt",
        "value": "After installation with pip, Vamb will show up in your PATH variable, and you can simply run:\n\n```\nvamb\n```\n\nTo run Vamb with another Python executable (say, if you want to run with `python3.7`) than the default, you can run:\n\n```\npython3.7 -m vamb\n```\n\nYou can also run the inner `vamb` directory as a script. This will work even if you did not install with pip:\n\n```\npython my_scripts/vamb/vamb\n```\n"
      },
      "source": "https://raw.githubusercontent.com/zpf0117b/CLMB/main/README.md",
      "technique": "header_analysis"
    }
  ],
  "somef_missing_categories": [
    "citation",
    "acknowledgement",
    "download",
    "requirements",
    "contact",
    "contributors",
    "documentation",
    "usage",
    "faq",
    "support",
    "identifier",
    "has_build_file"
  ],
  "somef_provenance": {
    "date": "2024-10-06 02:23:06",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 2
      },
      "technique": "GitHub_API"
    }
  ],
  "type": [
    {
      "confidence": 0.82,
      "result": {
        "type": "String",
        "value": "commandline-application"
      },
      "technique": "software_type_heuristics"
    }
  ]
}