{
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/LANL-Bioinformatics/PanGIA"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2019-07-24T19:59:19Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2023-11-14T12:08:30Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 0.970934410379925,
      "result": {
        "original_header": "PanGIA Bioinformatics",
        "type": "Text_excerpt",
        "value": "The bioinformatics pipeline leverages BWA/Minimap2 to identify \u2018where\u2019 reads belong to provides taxonomy identification specific to strain-level. Other than community profiling, PanGIA uses two approaches to obtain a metric of confidence, one that relies on uniqueness of sequences and the other one that relies on comparing test samples with control samples (organism-basis). \nThe software associated a web-based user interface for job submission in docker and interactive result visualization for providing pathogenic information and real-time filtering results. The pipeline was tested and validated using many synthetic datasets ranging in community composition and complexity, and was successfully applied to spiked clinical samples. \nThe docker version is also available at [Docker hub](https://hub.docker.com/r/poeli/pangia). The docker container runs PanGIA-UI that provides a web-based GUI to facilitate users to analyze their datasets through PanGIA and access to results. \n"
      },
      "source": "https://raw.githubusercontent.com/LANL-Bioinformatics/PanGIA/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "download": [
    {
      "confidence": 1,
      "result": {
        "original_header": "DOWNLOAD DATBASE",
        "parent_header": [
          "PanGIA Bioinformatics"
        ],
        "type": "Text_excerpt",
        "value": "PanGIA Database can be downloaded from LANL:\n```\nhttps://edge-dl.lanl.gov/PanGIA/database/\n```\n\n1. Download taxonomy and pathogen metadata:\n    * [metadata-latest.tar.gz](https://edge-dl.lanl.gov/PanGIA/database/PanGIA_20180915_taxonomy.tar.gz)\n\n2. Download BWA index(es) for reference genomes:\n    * NCBI Refseq89 reference and representative genomes -- Bacteria/Archaea/Viruses (BAV) [[tar]](https://edge-dl.lanl.gov/PanGIA/database/PanGIA_20180915_NCBI_genomes_refseq89_BAV.fa.tar)\n    * NCBI Refseq89 complete genomes of CDC biothreat agents (adds) [[tar]](https://edge-dl.lanl.gov/PanGIA/database/PanGIA_20180915_NCBI_genomes_refseq89_adds.fa.tar)\n    * (Optional) NCBI Refseq89 genomes of Plasmodium [[tar]](https://edge-dl.lanl.gov/PanGIA/database/PanGIA_20180915_NCBI_genomes_refseq89_Plasmodium.fa.tar)\n\n3. (Optional) Download BWA indexes for host genomes:\n    * Human genome GRCh38.p12 [[tar]](https://edge-dl.lanl.gov/PanGIA/database/PanGIA_20180915_NCBI_genomes_refseq89_Human_GRCh38.p12.fa.tar)\n    * Human genome alternative assembly CHM1_1.1 [[tar]](https://edge-dl.lanl.gov/PanGIA/database/PanGIA_20180301_NCBI_genomes_refseq86_Human_CHM1_1.1.fa.tar)\n    * JCVI human genome assembly [[tar]](https://edge-dl.lanl.gov/PanGIA/database/PanGIA_20180227_JCVI_human_genome.fa.tar)\n    * Mosquitos genomes [[tar]](https://edge-dl.lanl.gov/PanGIA/database/PanGIA_20180301_NCBI_genomes_refseq86_mosquitos.fa.tar)\n\n4. (Optional) Original sequences databases in FASTA format:\n    * All raw sequences can be found [here](https://edge-dl.lanl.gov/PanGIA/database/FASTA/).\n\n-------------------------------------------------------------------"
      },
      "source": "https://raw.githubusercontent.com/LANL-Bioinformatics/PanGIA/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/LANL-Bioinformatics/PanGIA/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 2
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/LANL-Bioinformatics/PanGIA/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "LANL-Bioinformatics/PanGIA"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "PanGIA Bioinformatics"
      },
      "source": "https://raw.githubusercontent.com/LANL-Bioinformatics/PanGIA/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "has_script_file": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/LANL-Bioinformatics/PanGIA/master/pangia-vis/scripts/depth_scale_down.sh"
      },
      "technique": "file_exploration"
    }
  ],
  "images": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/LANL-Bioinformatics/PanGIA/master/PanGIA Bioinformatics</h1>\n<p>The bioinformatics pipeline leverages BWA/Minimap2 to identify \u2018where\u2019 reads belong to provides taxonomy identification specific to strain-level. Other than community profiling, PanGIA uses two approaches to obtain a metric of confidence, one that relies on uniqueness of sequences and the other one that relies on comparing test samples with control samples (organism-basis).</p>\n<p>The software associated a web-based user interface for job submission in docker and interactive result visualization for providing pathogenic information and real-time filtering results. The pipeline was tested and validated using many synthetic datasets ranging in community composition and complexity, and was successfully applied to spiked clinical samples.</p>\n<p>The docker version is also available at <a href="
      },
      "source": "https://raw.githubusercontent.com/LANL-Bioinformatics/PanGIA/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "installation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "QUICK INSTALLATION",
        "parent_header": [
          "PanGIA Bioinformatics"
        ],
        "type": "Text_excerpt",
        "value": "0. Make sure you have requirements and dependencies installed properly. [Conda](https://conda.io/miniconda.html) is quick way.\n\n1. Retrieving PanGIA:\n```\ngit clone https://github.com/poeli/pangia.git && cd pangia\n```\n\n2. Download databases:\n```\ncurl -O https://edge-dl.lanl.gov/PanGIA/database/PanGIA_20180915_taxonomy.tar.gz\ncurl -O https://edge-dl.lanl.gov/PanGIA/database/PanGIA_20180915_NCBI_genomes_refseq89_BAV.fa.tar\ncurl -O https://edge-dl.lanl.gov/PanGIA/database/PanGIA_20180915_NCBI_genomes_refseq89_adds.fa.tar\ncurl -O https://edge-dl.lanl.gov/PanGIA/database/PanGIA_20180915_NCBI_genomes_refseq89_Human_GRCh38.p12.fa.tar\n```\n\n3. Decompress databases. All files will be decompressed to \"pangia/database\" directory.\n```\ntar -xzf PanGIA_20180915_taxonomy.tar.gz\ntar -xzf PanGIA_20180915_NCBI_genomes_refseq89_BAV.fa.tar\ntar -xzf PanGIA_20180915_NCBI_genomes_refseq89_adds.fa.tar\ntar -xzf PanGIA_20180915_NCBI_genomes_refseq89_Human_GRCh38.p12.fa.tar\n```\n4. Enjoy.\n\n-------------------------------------------------------------------"
      },
      "source": "https://raw.githubusercontent.com/LANL-Bioinformatics/PanGIA/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 0.9959084476721951,
      "result": {
        "original_header": "QUICK PanGIA-VIS",
        "type": "Text_excerpt",
        "value": "0. PanGIA will cleanup the temp directory after the job is done. Run pangia.py with `--keepTemp` if you want PanGIA-VIS to display genome coverage plot. \n1. Install Bokeh >= v1.0.\n```\nconda install -c bokeh bokeh\n```\n2. Run `pangia-vis.pl` with PanGIA result file (*.result.tsv). For example:\nBASH2*\n3. Enjoy! \n"
      },
      "source": "https://raw.githubusercontent.com/LANL-Bioinformatics/PanGIA/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "invocation": [
    {
      "confidence": 0.9061453303739129,
      "result": {
        "original_header": "PanGIA Bioinformatics",
        "type": "Text_excerpt",
        "value": "<p align=\"center\"><img width=\"40%\" height=\"40%\" src='images/pangia-vis-example.png'></p> \n"
      },
      "source": "https://raw.githubusercontent.com/LANL-Bioinformatics/PanGIA/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8281874790123046,
      "result": {
        "original_header": "QUICK PanGIA-VIS",
        "type": "Text_excerpt",
        "value": "0. PanGIA will cleanup the temp directory after the job is done. Run pangia.py with `--keepTemp` if you want PanGIA-VIS to display genome coverage plot. \n"
      },
      "source": "https://raw.githubusercontent.com/LANL-Bioinformatics/PanGIA/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/LANL-Bioinformatics/PanGIA/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ""
      },
      "technique": "GitHub_API"
    }
  ],
  "license": [
    {
      "confidence": 1,
      "result": {
        "name": "Other",
        "spdx_id": "NOASSERTION",
        "type": "License",
        "url": null,
        "value": null
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "type": "File_dump",
        "value": "This software is open source software available under the GPLv3 license.\n \n\u00a9 2019. Triad National Security, LLC. All rights reserved.\nThis program was produced under U.S. Government contract 89233218CNA000001 for Los Alamos National Laboratory (LANL), which is operated by Triad National Security, LLC for the U.S. Department of Energy/National Nuclear Security Administration. This is open source software; you can redistribute it and/or modify it under the terms of the GPLv3 License as published by the Free Software Foundation. If software is modified to produce derivative works modified software should be clearly marked, so as not to confuse it with the version available from LANL.\n"
      },
      "source": "https://raw.githubusercontent.com/LANL-Bioinformatics/PanGIA/master/LICENSE",
      "technique": "file_exploration"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "PanGIA"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "Organization",
        "value": "LANL-Bioinformatics"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 194403,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "JavaScript",
        "size": 1959,
        "type": "Programming_language",
        "value": "JavaScript"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "HTML",
        "size": 1744,
        "type": "Programming_language",
        "value": "HTML"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Perl",
        "size": 1403,
        "type": "Programming_language",
        "value": "Perl"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Shell",
        "size": 368,
        "type": "Programming_language",
        "value": "Shell"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/LANL-Bioinformatics/PanGIA/master/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "requirements": [
    {
      "confidence": 1,
      "result": {
        "original_header": "REQUIREMENT",
        "parent_header": [
          "PanGIA Bioinformatics"
        ],
        "type": "Text_excerpt",
        "value": "Third-party softwares:\n\n* Python >= 3.4\n* BWA >= v0.7\n* Minimap2 >= 2.1\n* samtools >= 1.8\n* GNU parallel\n\nPanGIA requires following Python dependencies:\n\n* Pandas >= 0.22\n* SciPy >= 0.14\n* Bokeh >= 0.13 (optional)\n\n------------------------------------------------------------------"
      },
      "source": "https://raw.githubusercontent.com/LANL-Bioinformatics/PanGIA/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "somef_missing_categories": [
    "citation",
    "acknowledgement",
    "run",
    "contact",
    "contributors",
    "documentation",
    "faq",
    "identifier",
    "has_build_file",
    "executable_example"
  ],
  "somef_provenance": {
    "date": "2024-10-06 16:49:36",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 7
      },
      "technique": "GitHub_API"
    }
  ],
  "support": [
    {
      "confidence": 1,
      "result": {
        "original_header": "REPORT",
        "parent_header": [
          "PanGIA Bioinformatics"
        ],
        "type": "Text_excerpt",
        "value": "| COLUMN | NAME               | DESCRIPTION                                                                                          |\n|--------|--------------------|------------------------------------------------------------------------------------------------------|\n| 1      | LEVEL              | Taxonomic rank                                                                                       |\n| 2      | NAME               | Taxonomic name                                                                                       |\n| 3      | TAXID              | Taxonomic ID                                                                                         |\n| 4      | READ_COUNT         | Number of raw mapped reads                                                                           |\n| 5      | READ_COUNT_RNR     | Number of mapped reads normalized by shared reference                                                |\n| 6      | READ_COUNT_RSNB    | Number of rank-specific mapped reads normalized by identity and # of shared reference                |\n| 7      | LINEAR_COV         | Proportion of covered signatures to total signatures of mapped organism(s)                           |\n| 8      | DEPTH_COV          | Depth of coverage                                                                                    |\n| 9      | DEPTH_COV_NR       | Depth of coverage normalized by # of shared reference                                                |\n| 10     | RS_DEPTH_COV_NR    | Depth of coverage calculated by rank-specific reads normalized by # of shared reference at this rank |\n| 11     | PATHOGEN           | Pathogen or not                                                                                      |\n| 12     | SCORE              | Confidence score                                                                                     |\n| 13     | REL_ABUNDANCE      | Relative abundance                                                                                   |\n| 14     | ABUNDANCE          | Abundance                                                                                            |\n| 15     | TOTAL_BP_MISMATCH  | Total number of mismatch base-pairs                                                                  |\n| 16     | NOTE               | Note                                                                                                 |\n| 17     | RPKM               | Reads Per Kilobase Million                                                                           |\n| 18     | PRI_READ_COUNT     | Number of reads mapped to this organism as a primary alignment                                       |\n| 19     | TOL_RS_READ_CNT    | Total rank specific read count                                                                       |\n| 20     | TOL_NS_READ_CNT    | Total rank non-specific read count                                                                   |\n| 21     | TOL_RS_RNR         | Total rank specific read count                                                                       |\n| 22     | TOL_NS_RNR         | Total rank non-specific read count                                                                   |\n| 23     | TOL_GENOME_SIZE    | Total size of genome(s) belong to this taxa                                                          |\n| 24     | LINEAR_LENGTH      | Number of non-overlapping bases covering the signatures                                              |\n| 25     | TOTAL_BP_MAPPED    | Total bases of mapped reads                                                                          |\n| 26     | RS_DEPTH_COV       | Depth of coverage calculated by rank-specific reads                                                  |\n| 27     | FLAG               | Superkingdom flag                                                                                    |\n| 38-36  | STR - ROOT         | Number of READ_COUNT at each rank (strain to root)                                                   |\n| 37-45  | STR_rnb - ROOT_rnb | Number of READ_COUNT_RSNB at each rank (strain to root)                                              |\n| 46-54  | STR_rnr - ROOT_rnr | Number of READ_COUNT_RNR at each rank (strain to root)                                               |\n| 55-63  | STR_ri - ROOT_ri   | read-mapping identity at each rank (strain to root)                                                  |\n| 64     | SOURCE             | Pathogenic - sample sources                                                                          |\n| 65     | LOCATION           | Pathogenic - sample locations                                                                        |\n| 66     | HOST               | Pathogenic - sample hosts                                                                            |\n| 67     | DISEASE            | Pathogenic - diseases                                                                                |\n| 68     | SCORE_UNIQ         | Score based on uniqueness information among genomes (overall)                                        |\n| 69     | SCORE_BG           | Score based on comparing input dataset with input background                                         |\n| 70     | SCORE_UNIQ_CUR_LVL | Score based on uniqueness information among genomes (rank)                                           |\n\n-------------------------------------------------------------------"
      },
      "source": "https://raw.githubusercontent.com/LANL-Bioinformatics/PanGIA/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "usage": [
    {
      "confidence": 1,
      "result": {
        "original_header": "EXAMPLE USAGE",
        "parent_header": [
          "PanGIA Bioinformatics"
        ],
        "type": "Text_excerpt",
        "value": "```\n./pangia.py \\\n  -i test.1.fastq test.2.fastq\\\n  -db database/NCBI_genomes_refseq89_*.fa  \\\n  -t 24\n```\n\nRun dataset HMP Mock Community even sample (SRR172902) against PanGIA NCBI refseq89 BAV and adds database with 24 threads, save mapping information to JSON file for use as a background later.\n\n```\n./pangia.py \\\n  -i SRR172902.fastq \\\n  -db database/NCBI_genomes_refseq89_BAV.fa database/NCBI_genomes_refseq89_adds.fa \\\n  -sb \\\n  -t 24\n```\n\nRun dataset \"test.fq\" against all PanGIA databases with 24 threads, load QCB_background_REP1 as background and report a \"combined\" score.\n\n```\n./pangia.py \\\n  -i HPV_test.fq \\\n  -db database/NCBI_genomes_*.fa \\\n  -lb background/QCB_background_REP1_allQC.pHostDB_NoHost.pangia.json.gz \\\n  -st combined \\\n  -t 24\n```\n\n-------------------------------------------------------------------"
      },
      "source": "https://raw.githubusercontent.com/LANL-Bioinformatics/PanGIA/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "USAGE",
        "parent_header": [
          "PanGIA Bioinformatics"
        ],
        "type": "Text_excerpt",
        "value": "```\nusage: pangia.py [-h] (-i [FASTQ] [[FASTQ] ...] | -s [SAMFILE])\n                 [-d [[BWA_INDEX] [[BWA_INDEX] ...]]] [-dp [PATH]]\n                 [-asl <INT>] [-ams <INT>] [-ao <STR>] [-se]\n                 [-st {bg,standalone,combined}]\n                 [-m {report,class,extract,lineage}]\n                 [-rf {basic,r,rnb,rnr,ri,patho,score,ref,full,all} [{basic,r,rnb,rnr,ri,patho,score,ref,full,all} ...]]\n                 [-da] [-par <INT>] [-xnm <INT>] [-x [TAXID]] [-r [FIELD]]\n                 [-t <INT>] [-o [DIR]] [-td [DIR]] [-kt] [-p <STR>] [-ps]\n                 [-sb] [-lb [<FILE> [<FILE> ...]]] [-ms <FLOAT>] [-mr <INT>]\n                 [-mb <INT>] [-ml <INT>] [-mc <FLOAT>] [-md <FLOAT>]\n                 [-mrd <FLOAT>] [-np] [-pd] [-if <STR>] [-nc] [-c] [--silent]\n                 [--verbose] [--version]\n\nPanGIA Bioinformatics 1.0.0\n\noptional arguments:\n  -h, --help            show this help message and exit\n  -i [FASTQ] [[FASTQ] ...], --input [FASTQ] [[FASTQ] ...]\n                        Input one or multiple FASTQ file(s). Use space to\n                        separate multiple input files.\n  -s [SAMFILE], --sam [SAMFILE]\n                        Specify the input SAM file. Use '-' for standard\n                        input.\n  -d [[BWA_INDEX] [[BWA_INDEX] ...]], --database [[BWA_INDEX] [[BWA_INDEX] ...]]\n                        Name/path of BWA-MEM index(es). [default: None]\n  -dp [PATH], --dbPath [PATH]\n                        Path of databases. If this option isn't specified but\n                        a path is provided in \"--database\" option, this path\n                        of database will also be used in dbPath. Otherwise,\n                        the program will search \"database/\" in program\n                        directory. [default: database/]\n  -asl <INT>, --alignSeedLength <INT>\n                        Minimum seed length uses in BWA-MEM [default: 40]\n  -ams <INT>, --alignMinScore <INT>\n                        Minimum alignment score (AS:i tag) for BWA-MEM\n                        [default: 60]\n  -ao <STR>, --addOptions <STR>\n                        Additional options for BWA-MEM (no need to add -t)\n                        [default: '-h150 -B2']\n  -se, --singleEnd      Input single-end reads or treat paired-end reads as\n                        single-end [default: False]\n  -st {bg,standalone,combined}, --scoreMethod {bg,standalone,combined}\n                        You can specify one of the following scoring method:\n                        \"bg\"         : compare mapping results with the background;\n                        \"standalone\" : score based on uniqueness;\n                        \"combined\"       : bg * standalone;\n                        [default: 'standalone']\n  -m {report,class,extract,lineage}, --mode {report,class,extract,lineage}\n                        You can specify one of the following output modes:\n                        \"report\"  : report a summary of profiling result;\n                        \"class\"   : output results of classified reads;\n                        \"extract\" : extract mapped reads;\n                        \"lineage\" : output abundance and lineage in a line;\n                        Note that only results/reads belongs to descendants of TAXID will be reported/extracted if option [--taxonomy TAXID] is specified. [default: 'report']\n  -rf {basic,r,rnb,rnr,ri,patho,score,ref,full,all} [{basic,r,rnb,rnr,ri,patho,score,ref,full,all} ...], --reportFields {basic,r,rnb,rnr,ri,patho,score,ref,full,all} [{basic,r,rnb,rnr,ri,patho,score,ref,full,all} ...]\n                        You can specify following set of fields to display in the report:\n                        \"basic\" : essential fields that will display in the reports;\n                        \"r\"     : rank specific read count;\n                        \"rnb\"   : rank specific read count normalized by \n                                  both identity and # of ref (1*identity/num_refs);\n                        \"rnr\"   : rank specific read count normalized by \n                                  the number of references (1/num_refs);\n                        \"ri\"    : rank specific read identity\n                                  (mapped_length-nm)/read_length;\n                        \"patho\" : metadata of pathogen;\n                        \"score\" : detail score information;\n                        \"ref\"   : mapped reference(s) and their locations\n                        \"full\"  : display additional information\n                        \"all\"   : display all of above;\n                        [default: 'all']\n  -da, --displayAll     Display all taxonomies including being filtered out\n                        [default: None]\n  -par <INT>, --procAltRefs <INT>\n                        Process the number of different references in\n                        alternative alignments [default: 30]\n  -xnm <INT>, --extraNM <INT>\n                        Process alternative alignments with extra number of\n                        mismatches than primary alignment [default: 1]\n  -x [TAXID], --taxonomy [TAXID]\n                        Specify a NCBI taxonomy ID. The program will only\n                        report/extract the taxonomy you specified.\n  -r [FIELD], --relAbu [FIELD]\n                        The field will be used to calculate relative\n                        abundance. [default: DEPTH_COV]\n  -t <INT>, --threads <INT>\n                        Number of threads [default: 1]\n  -o [DIR], --outdir [DIR]\n                        Output directory [default: .]\n  -td [DIR], --tempdir [DIR]\n                        Default temporary directory [default:\n                        <OUTDIR>/<PREFIX>_tmp]\n  -kt, --keepTemp       Keep temporary directory after finishing the pipeline.\n  -p <STR>, --prefix <STR>\n                        Prefix of the output file [default:\n                        <INPUT_FILE_PREFIX>]\n  -ps, --pathoScoreOnly\n                        Only calculate score for pathogen under '--scoreMethod\n                        bg'\n  -sb, --saveBg         Save current readmapping result in JSON to\n                        <PREFIX>.json\n  -lb [<FILE> [<FILE> ...]], --loadBg [<FILE> [<FILE> ...]]\n                        Load one or more background JSON gzip file(s)\n                        [default: None\n  -ms <FLOAT>, --minScore <FLOAT>\n                        Minimum score to be considered valid [default: 0]\n  -mr <INT>, --minReads <INT>\n                        Minimum number of reads to be considered valid\n                        [default: 10]\n  -mb <INT>, --minRsnb <INT>\n                        Minimum number of reads to be considered valid\n                        [default: 2.5]\n  -ml <INT>, --minLen <INT>\n                        Minimum linear length to be considered valid [default:\n                        200]\n  -mc <FLOAT>, --minCov <FLOAT>\n                        Minimum linear coverage to be considered a valid\n                        strain [default: 0.004]\n  -md <FLOAT>, --minDc <FLOAT>\n                        Minimum depth of coverage to be considered a valid\n                        strain [default: 0.01]\n  -mrd <FLOAT>, --minRsdcnr <FLOAT>\n                        Minimum rank specific depth of coverage normalized by\n                        the number of mapped references to be considered a\n                        valid strain [default: 0.0009]\n  -np, --nanopore       Input reads is nanopore data. This option is\n                        equivalent to use [-oa='-h 150 -x ont2d' -ms 0 -mr 1\n                        -mb 3 -ml 50 -asl 24 -ams 70]. [default: FALSE]\n  -pd, --pathogenDiscovery\n                        Adjust options for pathogen discovery. This option is\n                        equivalent to use [-ms 0 -mr 3 -mb 1 -ml 50 -asl 24\n                        -ams 50 -mc 0 -md 0 -mrd 0]. [default: FALSE]\n  -if <STR>, --ignoreFlag <STR>\n                        Ignore reads that mapped to the references that have\n                        the flag(s) [default: None]\n  -nc, --noCutoff       Remove all cutoffs. This option is equivalent to use\n                        [-ms 0 -mr 0 -mb 0 -ml 0 -mc 0 -md 0 -mrd 0].\n  -c, --stdout          Write on standard output.\n  --silent              Disable all messages.\n  --verbose             Provide verbose running messages and keep all\n                        temporary files.\n  --version             Print version number.\n"
      },
      "source": "https://raw.githubusercontent.com/LANL-Bioinformatics/PanGIA/master/README.md",
      "technique": "header_analysis"
    }
  ]
}