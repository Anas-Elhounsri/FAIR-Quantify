{
  "application_domain": [
    {
      "confidence": 16.61,
      "result": {
        "type": "String",
        "value": "Computer Vision"
      },
      "technique": "supervised_classification"
    }
  ],
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/shenlab-sinai/DeepRegFinder"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2020-06-08T14:55:10Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2024-04-25T06:10:34Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "DeepRegFinder is a deep learning based program used to identify DNA regulatory elements using ChIP-seq"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 0.85613674573689,
      "result": {
        "original_header": "DeepRegFinder: *Deep* Learning based *Reg*ulatory Elements *Finder*",
        "type": "Text_excerpt",
        "value": "**DeepRegFinder** is a deep learning based program to identify DNA regulatory elements using ChIP-seq. See our paper on *Bioinformatics Advances*:\n- A. Ramakrishnan, G. Wangensteen, S. Kim, E. J. Nestler, and L. Shen, \u201cDeepRegFinder: deep learning-based regulatory elements finder,\u201d Bioinformatics Advances, vol. 4, no. 1, p. vbae007, Jan. 2024, doi: 10.1093/bioadv/vbae007.\n \n"
      },
      "source": "https://raw.githubusercontent.com/shenlab-sinai/DeepRegFinder/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9923830276632866,
      "result": {
        "original_header": "Overview",
        "type": "Text_excerpt",
        "value": "Identifying DNA regulatory elements such as enhancers and promoters has always been an important topic in the epigenomics field. Although certain histone marks are known to exhibit characteristic binding patterns at enhancers and promoters, the exact rules to classify them do not exist. This is where machine learning comes to the rescue. You can train a machine learning model on the ChIP-seq data of the known enhancers and promoters and then use the model to identify them elsewhere.  \nMany machine learning algorithms for enhancer identification exist. However, most of them are designed for reproducing results on paper only. It's a hassle to apply them to your own data considering the most time-consuming part of a machine learning project is often data cleaning and formatting. We developed DeepRegFinder to be a modularized pipeline for you to build training data from aligned reads and genomic annotation easily so that you can use them to train models and make predictions. DeepRegFinder uses two deep neural networks: convolutional neural net (CNN) and recurrent neural net (RNN).\n \n"
      },
      "source": "https://raw.githubusercontent.com/shenlab-sinai/DeepRegFinder/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9739902657871612,
      "result": {
        "original_header": "Benchmarks",
        "type": "Text_excerpt",
        "value": "DeepRegFinder offers users the option to run three different types of classifications. Firstly, 2-way classification distinguishes enhancers from background genomic regions, including both generic background and promoter regions. Secondly, 3-way classification classifies enhancers, promoters, and generic background regions. Thirdly, 5-way classification can further classify enhancers and promoters into active and poised states for a given cell type, a feature which most existing tools lack. The 5-way classification therefore classifies any genomic region into active and poised enhancers (AEs and PEs, respectively), active and poised promoters (ATs and PTs, respectively), and background (Bgd). \nWe conducted a comparative analysis of DeepRegFinder's 3-way classification against five established methods, namely Random-Forest Based Algorithm for Enhancer Identification from Chromatin State (RFECS) (Rajagopal et al., 2013), enhancer HMM (eHMM) (Zehnder et al., 2019), PRobabilistic Enhancer PRedictIoN Tool (PREPRINT) (Osmala and L\u00e4hdesm\u00e4ki, 2020), Enhancer Prediction using Deep Neural Network (EP-DNN or KimNet) (Kim et al., 2016), and ChromHMM (Ernst and Kellis, 2017). Following are the Precision and Recall values for Enhancers and Promoters for all tools - \n\nOverall, both CNN and RNN models of DeepRegFinder compare favorably with the other methods in precision and recall scores across all cell types. Additionally, DeepRegFinder is more parameter efficient than EP-DNN. The CNN and RNN have about 26K and 12K weight parameters, respectively, while EP-DNN has about 500K weight parameters.  \n**References**:\n1. Kim,S.G. et al. (2016) EP-DNN: A Deep Neural Network-Based Global Enhancer Prediction Algorithm. Scientific Reports, 6, 38433.\n2. Rajagopal,N. et al. (2013) RFECS: A Random-Forest Based Algorithm for Enhancer Identification from Chromatin State. PLoS Comput Biol, 9, e1002968.\n3. Zehnder,T. _et al._ (2019) Predicting enhancers in mammalian genomes using supervised hidden Markov models. _BMC Bioinformatics_, **20**, 157.\n4. Osmala,M. and L\u00e4hdesm\u00e4ki,H. (2020) Enhancer prediction in the human genome by probabilistic modelling of the chromatin feature patterns. _BMC Bioinformatics_, **21**, 317.\n5. Ernst,J. and Kellis,M. (2017) Chromatin-state discovery and genome annotation with ChromHMM. _Nat. Protoc._, **12**, 2478\u20132492.\n \n"
      },
      "source": "https://raw.githubusercontent.com/shenlab-sinai/DeepRegFinder/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9819578339042478,
      "result": {
        "original_header": "Visualization of first convolution layer filters",
        "type": "Text_excerpt",
        "value": "One of the advantages of using convolution layers is that they tend to be easy to interpret. The following figure shows the activation patterns of the 32 1D filters of the first convolution layer of the CNN for the five classes (left panel) and the weights for a few example filters (right panel). As you can see, the activations show clear clusterings among the 32 filters and some filters are distinctly associated with certain classes. For example, filter 12 is exclusively associated with the active enhancer class and there is a clear peak detector for the H3K27ac histone mark. \n"
      },
      "source": "https://raw.githubusercontent.com/shenlab-sinai/DeepRegFinder/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9681216856717921,
      "result": {
        "original_header": "Multi-class classification analysis",
        "type": "Text_excerpt",
        "value": "Previous studies tend to focus on binary classifications between enhancer (as positive) and the rest (as negative), where promoters are lumped into the negative class. This can lead to an issue that the performance to distinguish enhancers from other regulatory elements becomes unclear. 5-way classification is used in DeepRegFinder. The following confusion matrix is from CNN predictions on the K562 cell type. We can see that for the active enhancer and promoter classes, the classifier is fairly accurate. However, the poised enhancer and promoter classes are often mistaken with other classes (click to see enlarged version): \n"
      },
      "source": "https://raw.githubusercontent.com/shenlab-sinai/DeepRegFinder/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9030145811660003,
      "result": {
        "type": "Text_excerpt",
        "value": "This work is licensed under a\n[Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License][cc-by-nc-sa]. \n"
      },
      "source": "https://raw.githubusercontent.com/shenlab-sinai/DeepRegFinder/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/shenlab-sinai/DeepRegFinder/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 1
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/shenlab-sinai/DeepRegFinder/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "shenlab-sinai/DeepRegFinder"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "DeepRegFinder: Deep Learning based Regulatory Elements Finder"
      },
      "source": "https://raw.githubusercontent.com/shenlab-sinai/DeepRegFinder/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "has_build_file": [
    {
      "confidence": 1,
      "result": {
        "format": "dockerfile",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/shenlab-sinai/DeepRegFinder/master/Dockerfile"
      },
      "source": "https://raw.githubusercontent.com/shenlab-sinai/DeepRegFinder/master/Dockerfile",
      "technique": "file_exploration"
    }
  ],
  "images": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://licensebuttons.net/l/by-nc-sa/4.0/88x31.png"
      },
      "source": "https://raw.githubusercontent.com/shenlab-sinai/DeepRegFinder/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/shenlab-sinai/DeepRegFinder/master/./figures/conv1%20filters%20acts%20and%20weights.png"
      },
      "source": "https://raw.githubusercontent.com/shenlab-sinai/DeepRegFinder/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/shenlab-sinai/DeepRegFinder/master/./figures/CNN_structure.png"
      },
      "source": "https://raw.githubusercontent.com/shenlab-sinai/DeepRegFinder/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/shenlab-sinai/DeepRegFinder/master/./figures/RNN_structure.png"
      },
      "source": "https://raw.githubusercontent.com/shenlab-sinai/DeepRegFinder/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/shenlab-sinai/DeepRegFinder/master/./figures/test_confusion_matrix_convnet.png"
      },
      "source": "https://raw.githubusercontent.com/shenlab-sinai/DeepRegFinder/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "installation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Installation",
        "parent_header": [
          "DeepRegFinder: *Deep* Learning based *Reg*ulatory Elements *Finder*"
        ],
        "type": "Text_excerpt",
        "value": "DeepRegFinder relies on Python 3 (>=3.6) so make sure that's the Python you are using. There are a number of dependencies that DeepRegFinder needs. You can install them as follows.\n"
      },
      "source": "https://raw.githubusercontent.com/shenlab-sinai/DeepRegFinder/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Install dependencies using Anaconda",
        "parent_header": [
          "DeepRegFinder: *Deep* Learning based *Reg*ulatory Elements *Finder*",
          "Installation"
        ],
        "type": "Text_excerpt",
        "value": "You may install the dependencies using [Anaconda](https://www.anaconda.com/). Download the project repository onto your workstation. Change into the downloaded repository and run the following command:\n\n`conda env create -f environment.yaml`\n\nThis will create a conda environment called *deepregfinder*. Next, you may activate the environment using the following command:\n\n`conda activate deepregfinder`\n"
      },
      "source": "https://raw.githubusercontent.com/shenlab-sinai/DeepRegFinder/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Install dependencies using pip",
        "parent_header": [
          "DeepRegFinder: *Deep* Learning based *Reg*ulatory Elements *Finder*",
          "Installation"
        ],
        "type": "Text_excerpt",
        "value": "First, download the project repository to your workstation. The dependencies and their versions in our development environment are listed in the `requirements.txt`. You may try to automatically install them by:\n\n`pip install -r requirements.txt`\n\nHowever, this approach may fail due to software incompatibility. In that case, you can manually install each package. If a particular version is incompatible or becomes unavailable, you may install the current default version and it shall work just fine.\n"
      },
      "source": "https://raw.githubusercontent.com/shenlab-sinai/DeepRegFinder/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Install featureCounts",
        "parent_header": [
          "DeepRegFinder: *Deep* Learning based *Reg*ulatory Elements *Finder*",
          "Installation"
        ],
        "type": "Text_excerpt",
        "value": "The preprocessing module relies on a program called `featureCounts` from the [Subread](http://subread.sourceforge.net/) package for short read counting. If you install the dependencies using Anaconda, the **Subread** package is already installed and you don't need to do anything. If you install the dependencies using pip, you'll need to install the **Subread** package manually and make sure `featureCounts` is in your `PATH`.\n"
      },
      "source": "https://raw.githubusercontent.com/shenlab-sinai/DeepRegFinder/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Install DeepRegFinder",
        "parent_header": [
          "DeepRegFinder: *Deep* Learning based *Reg*ulatory Elements *Finder*",
          "Installation"
        ],
        "type": "Text_excerpt",
        "value": "After all the dependencies have been installed, go to the project folder and run the following command to install DeepRegFinder:\n\n`pip install -e .`\n"
      },
      "source": "https://raw.githubusercontent.com/shenlab-sinai/DeepRegFinder/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "About Operating Systems",
        "parent_header": [
          "DeepRegFinder: *Deep* Learning based *Reg*ulatory Elements *Finder*",
          "Installation"
        ],
        "type": "Text_excerpt",
        "value": "DeepRegFinder has been tested under Linux and Mac. We never tested it under Windows. You may have to use a simulated terminal such as [Cygwin](https://www.cygwin.com/). \n"
      },
      "source": "https://raw.githubusercontent.com/shenlab-sinai/DeepRegFinder/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 0.9460382171930699,
      "result": {
        "original_header": "DeepRegFinder: *Deep* Learning based *Reg*ulatory Elements *Finder*",
        "type": "Text_excerpt",
        "value": "Shen Lab Website: http://labs.neuroscience.mssm.edu/project/shen-lab/ \n"
      },
      "source": "https://raw.githubusercontent.com/shenlab-sinai/DeepRegFinder/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9913883948134029,
      "result": {
        "type": "Text_excerpt",
        "value": "[cc-by-nc-sa]: http://creativecommons.org/licenses/by-nc-sa/4.0/\n[cc-by-nc-sa-image]: https://licensebuttons.net/l/by-nc-sa/4.0/88x31.png\n[cc-by-nc-sa-shield]: https://img.shields.io/badge/License-CC%20BY--NC--SA%204.0-lightgrey.svg \n"
      },
      "source": "https://raw.githubusercontent.com/shenlab-sinai/DeepRegFinder/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "invocation": [
    {
      "confidence": 0.8088980241162258,
      "result": {
        "original_header": "Visualization of first convolution layer filters",
        "type": "Text_excerpt",
        "value": "<img src=\"./figures/conv1%20filters%20acts%20and%20weights.png\" alt=\"conv1_filters\"/>\n \n"
      },
      "source": "https://raw.githubusercontent.com/shenlab-sinai/DeepRegFinder/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8074169765158009,
      "result": {
        "original_header": "Network structures",
        "type": "Text_excerpt",
        "value": "<img src=\"./figures/RNN_structure.png\" alt=\"rnn_struct\" width=\"200\"/>\n \n"
      },
      "source": "https://raw.githubusercontent.com/shenlab-sinai/DeepRegFinder/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8074169765158009,
      "result": {
        "original_header": "Multi-class classification analysis",
        "type": "Text_excerpt",
        "value": "<img src=\"./figures/test_confusion_matrix_convnet.png\" alt=\"k562_confmat_cnn\" width=\"300\"/>\n \n"
      },
      "source": "https://raw.githubusercontent.com/shenlab-sinai/DeepRegFinder/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/shenlab-sinai/DeepRegFinder/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ""
      },
      "technique": "GitHub_API"
    }
  ],
  "license": [
    {
      "confidence": 1,
      "result": {
        "name": "Other",
        "spdx_id": "NOASSERTION",
        "type": "License",
        "url": null,
        "value": null
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "type": "File_dump",
        "value": "Attribution-NonCommercial-ShareAlike 4.0 International\n\n=======================================================================\n\nCreative Commons Corporation (\"Creative Commons\") is not a law firm and\ndoes not provide legal services or legal advice. Distribution of\nCreative Commons public licenses does not create a lawyer-client or\nother relationship. Creative Commons makes its licenses and related\ninformation available on an \"as-is\" basis. Creative Commons gives no\nwarranties regarding its licenses, any material licensed under their\nterms and conditions, or any related information. Creative Commons\ndisclaims all liability for damages resulting from their use to the\nfullest extent possible.\n\nUsing Creative Commons Public Licenses\n\nCreative Commons public licenses provide a standard set of terms and\nconditions that creators and other rights holders may use to share\noriginal works of authorship and other material subject to copyright\nand certain other rights specified in the public license below. The\nfollowing considerations are for informational purposes only, are not\nexhaustive, and do not form part of our licenses.\n\n     Considerations for licensors: Our public licenses are\n     intended for use by those authorized to give the public\n     permission to use material in ways otherwise restricted by\n     copyright and certain other rights. Our licenses are\n     irrevocable. Licensors should read and understand the terms\n     and conditions of the license they choose before applying it.\n     Licensors should also secure all rights necessary before\n     applying our licenses so that the public can reuse the\n     material as expected. Licensors should clearly mark any\n     material not subject to the license. This includes other CC-\n     licensed material, or material used under an exception or\n     limitation to copyright. More considerations for licensors:\n    wiki.creativecommons.org/Considerations_for_licensors\n\n     Considerations for the public: By using one of our public\n     licenses, a licensor grants the public permission to use the\n     licensed material under specified terms and conditions. If\n     the licensor's permission is not necessary for any reason--for\n     example, because of any applicable exception or limitation to\n     copyright--then that use is not regulated by the license. Our\n     licenses grant only permissions under copyright and certain\n     other rights that a licensor has authority to grant. Use of\n     the licensed material may still be restricted for other\n     reasons, including because others have copyright or other\n     rights in the material. A licensor may make special requests,\n     such as asking that all changes be marked or described.\n     Although not required by our licenses, you are encouraged to\n     respect those requests where reasonable. More considerations\n     for the public:\n    wiki.creativecommons.org/Considerations_for_licensees\n\n=======================================================================\n\nCreative Commons Attribution-NonCommercial-ShareAlike 4.0 International\nPublic License\n\nBy exercising the Licensed Rights (defined below), You accept and agree\nto be bound by the terms and conditions of this Creative Commons\nAttribution-NonCommercial-ShareAlike 4.0 International Public License\n(\"Public License\"). To the extent this Public License may be\ninterpreted as a contract, You are granted the Licensed Rights in\nconsideration of Your acceptance of these terms and conditions, and the\nLicensor grants You such rights in consideration of benefits the\nLicensor receives from making the Licensed Material available under\nthese terms and conditions.\n\n\nSection 1 -- Definitions.\n\n  a. Adapted Material means material subject to Copyright and Similar\n     Rights that is derived from or based upon the Licensed Material\n     and in which the Licensed Material is translated, altered,\n     arranged, transformed, or otherwise modified in a manner requiring\n     permission under the Copyright and Similar Rights held by the\n     Licensor. For purposes of this Public License, where the Licensed\n     Material is a musical work, performance, or sound recording,\n     Adapted Material is always produced where the Licensed Material is\n     synched in timed relation with a moving image.\n\n  b. Adapter's License means the license You apply to Your Copyright\n     and Similar Rights in Your contributions to Adapted Material in\n     accordance with the terms and conditions of this Public License.\n\n  c. BY-NC-SA Compatible License means a license listed at\n     creativecommons.org/compatiblelicenses, approved by Creative\n     Commons as essentially the equivalent of this Public License.\n\n  d. Copyright and Similar Rights means copyright and/or similar rights\n     closely related to copyright including, without limitation,\n     performance, broadcast, sound recording, and Sui Generis Database\n     Rights, without regard to how the rights are labeled or\n     categorized. For purposes of this Public License, the rights\n     specified in Section 2(b)(1)-(2) are not Copyright and Similar\n     Rights.\n\n  e. Effective Technological Measures means those measures that, in the\n     absence of proper authority, may not be circumvented under laws\n     fulfilling obligations under Article 11 of the WIPO Copyright\n     Treaty adopted on December 20, 1996, and/or similar international\n     agreements.\n\n  f. Exceptions and Limitations means fair use, fair dealing, and/or\n     any other exception or limitation to Copyright and Similar Rights\n     that applies to Your use of the Licensed Material.\n\n  g. License Elements means the license attributes listed in the name\n     of a Creative Commons Public License. The License Elements of this\n     Public License are Attribution, NonCommercial, and ShareAlike.\n\n  h. Licensed Material means the artistic or literary work, database,\n     or other material to which the Licensor applied this Public\n     License.\n\n  i. Licensed Rights means the rights granted to You subject to the\n     terms and conditions of this Public License, which are limited to\n     all Copyright and Similar Rights that apply to Your use of the\n     Licensed Material and that the Licensor has authority to license.\n\n  j. Licensor means the individual(s) or entity(ies) granting rights\n     under this Public License.\n\n  k. NonCommercial means not primarily intended for or directed towards\n     commercial advantage or monetary compensation. For purposes of\n     this Public License, the exchange of the Licensed Material for\n     other material subject to Copyright and Similar Rights by digital\n     file-sharing or similar means is NonCommercial provided there is\n     no payment of monetary compensation in connection with the\n     exchange.\n\n  l. Share means to provide material to the public by any means or\n     process that requires permission under the Licensed Rights, such\n     as reproduction, public display, public performance, distribution,\n     dissemination, communication, or importation, and to make material\n     available to the public including in ways that members of the\n     public may access the material from a place and at a time\n     individually chosen by them.\n\n  m. Sui Generis Database Rights means rights other than copyright\n     resulting from Directive 96/9/EC of the European Parliament and of\n     the Council of 11 March 1996 on the legal protection of databases,\n     as amended and/or succeeded, as well as other essentially\n     equivalent rights anywhere in the world.\n\n  n. You means the individual or entity exercising the Licensed Rights\n     under this Public License. Your has a corresponding meaning.\n\n\nSection 2 -- Scope.\n\n  a. License grant.\n\n       1. Subject to the terms and conditions of this Public License,\n          the Licensor hereby grants You a worldwide, royalty-free,\n          non-sublicensable, non-exclusive, irrevocable license to\n          exercise the Licensed Rights in the Licensed Material to:\n\n            a. reproduce and Share the Licensed Material, in whole or\n               in part, for NonCommercial purposes only; and\n\n            b. produce, reproduce, and Share Adapted Material for\n               NonCommercial purposes only.\n\n       2. Exceptions and Limitations. For the avoidance of doubt, where\n          Exceptions and Limitations apply to Your use, this Public\n          License does not apply, and You do not need to comply with\n          its terms and conditions.\n\n       3. Term. The term of this Public License is specified in Section\n          6(a).\n\n       4. Media and formats; technical modifications allowed. The\n          Licensor authorizes You to exercise the Licensed Rights in\n          all media and formats whether now known or hereafter created,\n          and to make technical modifications necessary to do so. The\n          Licensor waives and/or agrees not to assert any right or\n          authority to forbid You from making technical modifications\n          necessary to exercise the Licensed Rights, including\n          technical modifications necessary to circumvent Effective\n          Technological Measures. For purposes of this Public License,\n          simply making modifications authorized by this Section 2(a)\n          (4) never produces Adapted Material.\n\n       5. Downstream recipients.\n\n            a. Offer from the Licensor -- Licensed Material. Every\n               recipient of the Licensed Material automatically\n               receives an offer from the Licensor to exercise the\n               Licensed Rights under the terms and conditions of this\n               Public License.\n\n            b. Additional offer from the Licensor -- Adapted Material.\n               Every recipient of Adapted Material from You\n               automatically receives an offer from the Licensor to\n               exercise the Licensed Rights in the Adapted Material\n               under the conditions of the Adapter's License You apply.\n\n            c. No downstream restrictions. You may not offer or impose\n               any additional or different terms or conditions on, or\n               apply any Effective Technological Measures to, the\n               Licensed Material if doing so restricts exercise of the\n               Licensed Rights by any recipient of the Licensed\n               Material.\n\n       6. No endorsement. Nothing in this Public License constitutes or\n          may be construed as permission to assert or imply that You\n          are, or that Your use of the Licensed Material is, connected\n          with, or sponsored, endorsed, or granted official status by,\n          the Licensor or others designated to receive attribution as\n          provided in Section 3(a)(1)(A)(i).\n\n  b. Other rights.\n\n       1. Moral rights, such as the right of integrity, are not\n          licensed under this Public License, nor are publicity,\n          privacy, and/or other similar personality rights; however, to\n          the extent possible, the Licensor waives and/or agrees not to\n          assert any such rights held by the Licensor to the limited\n          extent necessary to allow You to exercise the Licensed\n          Rights, but not otherwise.\n\n       2. Patent and trademark rights are not licensed under this\n          Public License.\n\n       3. To the extent possible, the Licensor waives any right to\n          collect royalties from You for the exercise of the Licensed\n          Rights, whether directly or through a collecting society\n          under any voluntary or waivable statutory or compulsory\n          licensing scheme. In all other cases the Licensor expressly\n          reserves any right to collect such royalties, including when\n          the Licensed Material is used other than for NonCommercial\n          purposes.\n\n\nSection 3 -- License Conditions.\n\nYour exercise of the Licensed Rights is expressly made subject to the\nfollowing conditions.\n\n  a. Attribution.\n\n       1. If You Share the Licensed Material (including in modified\n          form), You must:\n\n            a. retain the following if it is supplied by the Licensor\n               with the Licensed Material:\n\n                 i. identification of the creator(s) of the Licensed\n                    Material and any others designated to receive\n                    attribution, in any reasonable manner requested by\n                    the Licensor (including by pseudonym if\n                    designated);\n\n                ii. a copyright notice;\n\n               iii. a notice that refers to this Public License;\n\n                iv. a notice that refers to the disclaimer of\n                    warranties;\n\n                 v. a URI or hyperlink to the Licensed Material to the\n                    extent reasonably practicable;\n\n            b. indicate if You modified the Licensed Material and\n               retain an indication of any previous modifications; and\n\n            c. indicate the Licensed Material is licensed under this\n               Public License, and include the text of, or the URI or\n               hyperlink to, this Public License.\n\n       2. You may satisfy the conditions in Section 3(a)(1) in any\n          reasonable manner based on the medium, means, and context in\n          which You Share the Licensed Material. For example, it may be\n          reasonable to satisfy the conditions by providing a URI or\n          hyperlink to a resource that includes the required\n          information.\n       3. If requested by the Licensor, You must remove any of the\n          information required by Section 3(a)(1)(A) to the extent\n          reasonably practicable.\n\n  b. ShareAlike.\n\n     In addition to the conditions in Section 3(a), if You Share\n     Adapted Material You produce, the following conditions also apply.\n\n       1. The Adapter's License You apply must be a Creative Commons\n          license with the same License Elements, this version or\n          later, or a BY-NC-SA Compatible License.\n\n       2. You must include the text of, or the URI or hyperlink to, the\n          Adapter's License You apply. You may satisfy this condition\n          in any reasonable manner based on the medium, means, and\n          context in which You Share Adapted Material.\n\n       3. You may not offer or impose any additional or different terms\n          or conditions on, or apply any Effective Technological\n          Measures to, Adapted Material that restrict exercise of the\n          rights granted under the Adapter's License You apply.\n\n\nSection 4 -- Sui Generis Database Rights.\n\nWhere the Licensed Rights include Sui Generis Database Rights that\napply to Your use of the Licensed Material:\n\n  a. for the avoidance of doubt, Section 2(a)(1) grants You the right\n     to extract, reuse, reproduce, and Share all or a substantial\n     portion of the contents of the database for NonCommercial purposes\n     only;\n\n  b. if You include all or a substantial portion of the database\n     contents in a database in which You have Sui Generis Database\n     Rights, then the database in which You have Sui Generis Database\n     Rights (but not its individual contents) is Adapted Material,\n     including for purposes of Section 3(b); and\n\n  c. You must comply with the conditions in Section 3(a) if You Share\n     all or a substantial portion of the contents of the database.\n\nFor the avoidance of doubt, this Section 4 supplements and does not\nreplace Your obligations under this Public License where the Licensed\nRights include other Copyright and Similar Rights.\n\n\nSection 5 -- Disclaimer of Warranties and Limitation of Liability.\n\n  a. UNLESS OTHERWISE SEPARATELY UNDERTAKEN BY THE LICENSOR, TO THE\n     EXTENT POSSIBLE, THE LICENSOR OFFERS THE LICENSED MATERIAL AS-IS\n     AND AS-AVAILABLE, AND MAKES NO REPRESENTATIONS OR WARRANTIES OF\n     ANY KIND CONCERNING THE LICENSED MATERIAL, WHETHER EXPRESS,\n     IMPLIED, STATUTORY, OR OTHER. THIS INCLUDES, WITHOUT LIMITATION,\n     WARRANTIES OF TITLE, MERCHANTABILITY, FITNESS FOR A PARTICULAR\n     PURPOSE, NON-INFRINGEMENT, ABSENCE OF LATENT OR OTHER DEFECTS,\n     ACCURACY, OR THE PRESENCE OR ABSENCE OF ERRORS, WHETHER OR NOT\n     KNOWN OR DISCOVERABLE. WHERE DISCLAIMERS OF WARRANTIES ARE NOT\n     ALLOWED IN FULL OR IN PART, THIS DISCLAIMER MAY NOT APPLY TO YOU.\n\n  b. TO THE EXTENT POSSIBLE, IN NO EVENT WILL THE LICENSOR BE LIABLE\n     TO YOU ON ANY LEGAL THEORY (INCLUDING, WITHOUT LIMITATION,\n     NEGLIGENCE) OR OTHERWISE FOR ANY DIRECT, SPECIAL, INDIRECT,\n     INCIDENTAL, CONSEQUENTIAL, PUNITIVE, EXEMPLARY, OR OTHER LOSSES,\n     COSTS, EXPENSES, OR DAMAGES ARISING OUT OF THIS PUBLIC LICENSE OR\n     USE OF THE LICENSED MATERIAL, EVEN IF THE LICENSOR HAS BEEN\n     ADVISED OF THE POSSIBILITY OF SUCH LOSSES, COSTS, EXPENSES, OR\n     DAMAGES. WHERE A LIMITATION OF LIABILITY IS NOT ALLOWED IN FULL OR\n     IN PART, THIS LIMITATION MAY NOT APPLY TO YOU.\n\n  c. The disclaimer of warranties and limitation of liability provided\n     above shall be interpreted in a manner that, to the extent\n     possible, most closely approximates an absolute disclaimer and\n     waiver of all liability.\n\n\nSection 6 -- Term and Termination.\n\n  a. This Public License applies for the term of the Copyright and\n     Similar Rights licensed here. However, if You fail to comply with\n     this Public License, then Your rights under this Public License\n     terminate automatically.\n\n  b. Where Your right to use the Licensed Material has terminated under\n     Section 6(a), it reinstates:\n\n       1. automatically as of the date the violation is cured, provided\n          it is cured within 30 days of Your discovery of the\n          violation; or\n\n       2. upon express reinstatement by the Licensor.\n\n     For the avoidance of doubt, this Section 6(b) does not affect any\n     right the Licensor may have to seek remedies for Your violations\n     of this Public License.\n\n  c. For the avoidance of doubt, the Licensor may also offer the\n     Licensed Material under separate terms or conditions or stop\n     distributing the Licensed Material at any time; however, doing so\n     will not terminate this Public License.\n\n  d. Sections 1, 5, 6, 7, and 8 survive termination of this Public\n     License.\n\n\nSection 7 -- Other Terms and Conditions.\n\n  a. The Licensor shall not be bound by any additional or different\n     terms or conditions communicated by You unless expressly agreed.\n\n  b. Any arrangements, understandings, or agreements regarding the\n     Licensed Material not stated herein are separate from and\n     independent of the terms and conditions of this Public License.\n\n\nSection 8 -- Interpretation.\n\n  a. For the avoidance of doubt, this Public License does not, and\n     shall not be interpreted to, reduce, limit, restrict, or impose\n     conditions on any use of the Licensed Material that could lawfully\n     be made without permission under this Public License.\n\n  b. To the extent possible, if any provision of this Public License is\n     deemed unenforceable, it shall be automatically reformed to the\n     minimum extent necessary to make it enforceable. If the provision\n     cannot be reformed, it shall be severed from this Public License\n     without affecting the enforceability of the remaining terms and\n     conditions.\n\n  c. No term or condition of this Public License will be waived and no\n     failure to comply consented to unless expressly agreed to by the\n     Licensor.\n\n  d. Nothing in this Public License constitutes or may be interpreted\n     as a limitation upon, or waiver of, any privileges and immunities\n     that apply to the Licensor or You, including from the legal\n     processes of any jurisdiction or authority.\n\n=======================================================================\n\nCreative Commons is not a party to its public\nlicenses. Notwithstanding, Creative Commons may elect to apply one of\nits public licenses to material it publishes and in those instances\nwill be considered the \u201cLicensor.\u201d The text of the Creative Commons\npublic licenses is dedicated to the public domain under the CC0 Public\nDomain Dedication. Except for the limited purpose of indicating that\nmaterial is shared under a Creative Commons public license or as\notherwise permitted by the Creative Commons policies published at\ncreativecommons.org/policies, Creative Commons does not authorize the\nuse of the trademark \"Creative Commons\" or any other trademark or logo\nof Creative Commons without its prior written consent including,\nwithout limitation, in connection with any unauthorized modifications\nto any of its public licenses or any other arrangements,\nunderstandings, or agreements concerning use of licensed material. For\nthe avoidance of doubt, this paragraph does not form part of the\npublic licenses.\n\nCreative Commons may be contacted at creativecommons.org.\n"
      },
      "source": "https://raw.githubusercontent.com/shenlab-sinai/DeepRegFinder/master/LICENSE",
      "technique": "file_exploration"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "DeepRegFinder"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "Organization",
        "value": "shenlab-sinai"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 110554,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Dockerfile",
        "size": 1233,
        "type": "Programming_language",
        "value": "Dockerfile"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "R",
        "size": 778,
        "type": "Programming_language",
        "value": "R"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/shenlab-sinai/DeepRegFinder/master/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "requirements": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Install dependencies using Anaconda",
        "parent_header": [
          "DeepRegFinder: *Deep* Learning based *Reg*ulatory Elements *Finder*",
          "Installation"
        ],
        "type": "Text_excerpt",
        "value": "You may install the dependencies using [Anaconda](https://www.anaconda.com/). Download the project repository onto your workstation. Change into the downloaded repository and run the following command:\n\n`conda env create -f environment.yaml`\n\nThis will create a conda environment called *deepregfinder*. Next, you may activate the environment using the following command:\n\n`conda activate deepregfinder`\n"
      },
      "source": "https://raw.githubusercontent.com/shenlab-sinai/DeepRegFinder/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Install dependencies using pip",
        "parent_header": [
          "DeepRegFinder: *Deep* Learning based *Reg*ulatory Elements *Finder*",
          "Installation"
        ],
        "type": "Text_excerpt",
        "value": "First, download the project repository to your workstation. The dependencies and their versions in our development environment are listed in the `requirements.txt`. You may try to automatically install them by:\n\n`pip install -r requirements.txt`\n\nHowever, this approach may fail due to software incompatibility. In that case, you can manually install each package. If a particular version is incompatible or becomes unavailable, you may install the current default version and it shall work just fine.\n"
      },
      "source": "https://raw.githubusercontent.com/shenlab-sinai/DeepRegFinder/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "run": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Run DeepRegFinder using the Docker image (recommended)",
        "parent_header": [
          "DeepRegFinder: *Deep* Learning based *Reg*ulatory Elements *Finder*"
        ],
        "type": "Text_excerpt",
        "value": "A Docker Image for DeepRegFinder is available at https://hub.docker.com/r/aarthir239/deepregfinder. Please read the documentation on the Docker Hub page to use the image.\n"
      },
      "source": "https://raw.githubusercontent.com/shenlab-sinai/DeepRegFinder/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Running the pipeline",
        "parent_header": [
          "DeepRegFinder: *Deep* Learning based *Reg*ulatory Elements *Finder*"
        ],
        "type": "Text_excerpt",
        "value": "The pipeline has three modules: preprocessing, training and prediction. You can execute each module separately, which provides a lot of flexibility. The basic procedure for running each step is to first gather all the required input files, fill out a YAML configuration file and then run the corresponding program. We have provided example configuration files for you to easily follow. If you installed DeepRegFinder properly, the three `drfinder-xxx.py` scripts shall already be in your `PATH`. You can go to your own project folder and issue commands from there. Use the configuration files in DeepRegFinder's repository as your starting points.\n"
      },
      "source": "https://raw.githubusercontent.com/shenlab-sinai/DeepRegFinder/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Preprocessing",
        "parent_header": [
          "DeepRegFinder: *Deep* Learning based *Reg*ulatory Elements *Finder*",
          "Running the pipeline"
        ],
        "type": "Text_excerpt",
        "value": "Fill out the configuration file: `preprocessing_data.yaml` and run this command:\n\n`drfinder-preprocessing.py preprocessing_data.yaml <NAME OF OUTPUT FOLDER>`\n\nTo get histone mark ChIP-seq from ENCODE easily, a script (`create_histones_folder.py`) has been provided in the `scripts` folder. In the script, edit the section marked **edit the following** and run the Python script in background as follows:\n\n`nohup python create_histones_folder.py &`\n\nFor your own ChIP-seq data, just follow the same file structure and put your BAM files under corresponding folders. Data for the folders `peak_lists` and `tfbs` may be obtained from [ENCODE](https://www.encodeproject.org/) and data for the `genome` folder may be obtained from [gencode](https://www.gencodegenes.org/). GRO-seq data can be found on [GEO](https://www.ncbi.nlm.nih.gov/geo/). You may have to process the GRO-seq data yourself to obtain the bam files to be used with DeepRegFinder.\n\nAfter preprocessing is finished, the following files will be generated and required for training and prediction:\n\nUnder `tensor_data` directory:\n- all_datasets.pth.tar\n- chann_stats.csv\n\nUnder `histone_data` directory:\n- alltogether_notnormed.txt.gz\n- alltogether_notnormed.txt.gz.tbi\n\nUnder `tss_data` directory:\n- enhancer_slopped_tss.bed\n\nUnder `tpms_data` directory:\n- final_tpms.bed\n\nFollowing are the options available in the preprocessing_data.yaml.  Each option is set to the default value in the file.\n\n1.  **genome**: Specify the genome of interest. For example, hg19, hg38, mm10, rn6, rn7 etc.\n    \n2.  **train_chrom**: Fill this (and the following 2) lists only if you would like to split the train, val and test set by chromosomes. Or else, leave it empty. Specify the chromosomes you would like to include in the training data\n    \n3.  **val_chrom**: Specify the chromosomes you would like to include in the validation data\n    \n4.  **test_chrom**: Specify the chromosomes you would like to include in the testing data\n    \n5.  **window_width**: This is the bin size in bp. Default is 100\n    \n6.  **number_of_windows**: This is the number of bins. Default is 20. The 'window_width' and 'number_of_windows' parameters together define the length of regions for enhancers and promoter prediction (i.e., 20x100=2Kb)\n    \n7.  **num_classes:** There are 3 options for this parameter - 2, 3 or 5. 2-way classifies enhancers from background regions. 3-way classifies enhancers, promoters, and background regions. 5-way classifies active and poised enhancers (AEs and PEs), active and poised promoters (ATs and PTs), and background (Bgd).\n    \n8.  **genome_size_file:** Provide the filename of a tab-delimited text file consisting of chromosome name and the chromosome size. This parameter is used to select a subset of chromosomes. This is an optional argument. The main purpose of this is to allow you to select a subset of the chromosomes to quickly test out the whole pipeline. If this is not specified, the program will use all chromosomes in the following \"valid_chromosomes\" argument.\n    \n9.  **valid_chromosomes:** Specify the \"valid\" chromosomes to remove the unwanted scaffold chromosomes from training and prediction\n    \n10.  **histone_folder**: The path to the folder containing histone marks should be specified. The helper script DeepRegFinder/scripts/create_histones_[folder.py](http://folder.py) can be used to generate this folder. Please follow the following folder structure -\n\n\thistones\n\t\u251c\u2500\u2500 histone1\n\t\u2502 \u251c\u2500\u2500 histone1_rep1.bam\n\t\u2502 \u2514\u2500\u2500 histone1_rep2.bam\n\t\u2514\u2500\u2500 histone2\n\t    \u251c\u2500\u2500 histone2_rep1.bam\n\t    \u2514\u2500\u2500 histone2_rep2.bam\n11.  **histone_log_transformation**: Whether you would like to log-transform the reads used for training and predicting enhancers and promoters.\n    \n12.  **cpu_threads:** Number of CPU cores.\n    \n13.  **generate_prediction_only**: Set this to True if you already have a trained model and wish to only generate data for prediction on the whole genome i.e., only the file alltogether_notnormed.txt.gz.\n    \n14.  **tss_file:** Path to the TSS (transcriptional start site) file in BED format. Coordinates in this file should be 1bp in length. This file may be generated using the helper script make_tss_genebody_txdb.R in DeepRegFinder/scripts\n    \n15.  **distal_bp_distance:** This is the distance used to slop TSS sites.\n    \n16.  **enhancer_distal_bp_distance:** The enhancers must be this distance away from TSS. This distance is also used to select background windows away from DNA regulatory elements.\n    \n17.  **H3K4me3_file**: Path to the peak file (BED) for H3K4me3. These peaks are used in addition to the TSSs so that we don't bump into these potential promoters.\n    \n18.  **DHS_file:** Path to the peak file of DHS (DNase I hypersensitive site) or ATAC-seq (Assay for Transposase-Accessible Chromatin with sequencing) data\n    \n19.  **enhancer_files:** Path to the peak lists used for defining enhancers. E.g. p300, CBP etc. You may specify multiple lists one below the other as follows -\n    \n\n\t- 'example_dat/peak_lists/h1-p300-narrowpeaks.bed'\n\t- 'example_dat/peak_lists/h1-CBP-narrowpeaks.bed'\n\n20.  **TFBS**: Provide the path to the peak lists for TFs that you believe to be enhancer associated. For example, for the H1 cell line, Nanog, Oct4 and Sox2 TFs are considered to be enhancers. Please list multiple files one below the other as for enhancer_files. If there are no TFBS files, you may comment out this field.\n    \n21.  **bkg_samples:** Total no. of background samples.\n    \n22.  **nz_cutoff**: This is the number of non-zero bins in a region. This cutoff is used to discard regions with low information content.\n    \n23.  **val_p**: Proportion of the validation set. Only applies if train_chrom, val_chrom and test_chrom fields are empty\n    \n24.  **test_p**: Proportion of the test set. Only applies if train_chrom, val_chrom and test_chrom fields are empty\n    \n25.  **groseq_bam_file:** Only applicable for 5 cls classification. Else, comment this out. Please specify the BAM file of GRO-seq data. You may also use PRO-seq, NET-seq or any other data that measures transcriptional activity of a DRE (DNA regulatory elements)\n    \n26.  **sense_bam_file:** Only applicable for 5 cls classification. Else, comment this out. If you have strand-specific GRO-seq data, please specify the file path to sense BAM file of GRO-seq data.\n    \n27.  **antisense_bam_file:** Only applicable for 5 cls classification. If you have strand-specific GRO-seq data, please specify the anti-sense BAM file path to anti-sense BAM file of GRO-seq data.\n    \n28.  **groseq_log_transformation:**\n    \n29.  **delete_intermediate_files:** Set to True if you would like to delete intermediate files\n\n"
      },
      "source": "https://raw.githubusercontent.com/shenlab-sinai/DeepRegFinder/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Training",
        "parent_header": [
          "DeepRegFinder: *Deep* Learning based *Reg*ulatory Elements *Finder*",
          "Running the pipeline"
        ],
        "type": "Text_excerpt",
        "value": "Fill out the configuration file: `training_data.yaml` and run this command:\n\n`drfinder-training.py training_data.yaml <NAME OF OUTPUT FOLDER>`\n\nThe trained model, training result summary and confusion matrix are under the `model` directory.\n\nFollowing are the options available in training_data.yaml. Default values for options are specified in the file.\n\n1.  **all_datasets**: Please specify the path to the file named 'all_datasets.pth.tar' generated by the drfinder-preprocessing.py module\n    \n2.  **net_choice**: You may choose one from 'ConvNet', 'KimNet' or 'RecurNet'. ConvNet refers to CNN model of DeepRegFinder. RecurNet refers to the RNN model of DeepRegFinder. The model architectures for both CNN and RNN are preset. KimNet refers to an implementation of the EP-DNN model (https://www.nature.com/articles/srep38433).\n    \n3.  **num_classes**: There are 3 options for this parameter - 2, 3 or 5. Please set the one you chose for the preprocessing module\n    \n4.  **keep_cls_props**: Set this to True if you would like to keep the proportions of the non-background classes in training i.e., do not resample them to balance the classes\n    \n5.  **conv_rnn**: Set this to True if you wish to add a convolutional layer before RNN\n    \n6.  **init_lr**: Set the initial learning rate of the model\n    \n7.  **weight_decay**: Set the weight decay of the model\n    \n8.  **batch_size**: Set the batch size for the model i.e., number of samples in a single batch. It is common to choose the parameter batch size of powers of 2, such as 256\n    \n9.  **cpu_threads:** Number of CPU Threads available for running the training step.\n    \n10.  **best_model_name**: Please specify the name of the file you would like to save the best model in. Should have an extension of .pt\n    \n11.  **num_epochs**: Number of training epochs. One epoch refers to the entire dataset being passed through the neural network once.\n    \n12.  **check_iters:** Number of iterations in between the model performance checks. Iterations are determined based on the number of batches of data.\n    \n13.  **confus_mat_name:** Name of the file the confusion matrix will be saved to\n    \n14.  **pred_out_name:** Name of the file in which you would like to store the predictions made on the test set\n    \n15.  **summary_out_name:** Name of the file in which you would like to store the summary metrics such as the mAP, average precision for each class, precision and recall values for each class etc.\n    \n16.  **precision_recall_curve_name:** Name of the file the precision recall curve is saved to\n    \n17.  **roc_curve_name:** Name of the file the ROC curve is saved to\n    \n18.  **data_augment:** Whether to perform data augmentation. Leave it as False for now.\n\n"
      },
      "source": "https://raw.githubusercontent.com/shenlab-sinai/DeepRegFinder/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Prediction",
        "parent_header": [
          "DeepRegFinder: *Deep* Learning based *Reg*ulatory Elements *Finder*",
          "Running the pipeline"
        ],
        "type": "Text_excerpt",
        "value": "Fill out the configuration file: `wg_prediction_data.yaml` and run this command:\n\n`drfinder-prediction.py wg_prediction_data.yaml <NAME OF OUTPUT FOLDER>`\n\nA prediction summary and the predicted enhancers and promoters are under the `predictions` directory.\n\nFollowing are the options available in wg_prediction_data.yaml. Default values are specified in the file.\n\n1.  **whole_genome_bincnt_file**: Please specify the compressed genomic bin count file generated by the preprocessing module. Make sure the corresponding '.tbi' file is also in the same folder.\n    \n2.  **chann_stats_file**: Specify the file which stores hte mean and standard deviation of the histone marks used for training. This file is also generated by the training module\n    \n3.  **net_choice**: One of 'ConvNet', 'KimNet', 'RecurNet'. Please set this to the same model used in the training module\n    \n4.  **conv_rnn:** Set this to True if you wish to add a convolutional layer before RNN. Same as the value set for training module.\n    \n5.  **num_classes:** There are 3 options for this parameter - 2, 3 or 5. Please set the same one you chose for the preprocessing module\n    \n6.  **window_width:** This is the bin size in bp. Default is 100, same as the value set for preprocessing module\n    \n7.  **number_of_windows:** This is the number of bins. Default is 20, same as the value set for preprocessing module\n    \n8.  **batch_size:** Set the batch size for the model i.e., number of samples in a single batch for prediction\n    \n9.  **prob_conf_cutoff:** Output only the predictions with a probability score above this cutoff\n    \n10.  **data_augment:** Whether to perform data augmentation. Leave it as False for now. Same as training module.\n    \n11.  **known_tss_file:** specify the file containing known TSSs to subtract from predicted enhancers. This file is generated by the preprocessing module and is named 'enhancer_slopped_tss.bed'\n    \n12.  **model_state_dict:** Please specify the .pt file containing the saved model from the training module.\n    \n13.  **output_bed:** Specify the name of the output file to which you would like to save the whole genome predictions.\n    \n14.  **output_txt:** Specify the name of the output file to which you would like to save the whole genome prediction summary i.e., the validation rate for each class\n    \n15.  **tpms_file:** Specify the path to the file named 'final_tpms.bed' generated by the preprocessing pipeline. True positive mark (TPM) file is used to calculate enhancer validation rate. This is an output of the preprocessing module.\n    \n16.  **tpm_bps_added:** distance within TPMs to define \"validated\"\n\n"
      },
      "source": "https://raw.githubusercontent.com/shenlab-sinai/DeepRegFinder/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Running time",
        "parent_header": [
          "DeepRegFinder: *Deep* Learning based *Reg*ulatory Elements *Finder*",
          "Running the pipeline"
        ],
        "type": "Text_excerpt",
        "value": "Approximate time to run the three modules (assume you have a not-too-old GPU and a multi-core CPU):\n- Preprocessing: 2-8h\n- Training: 5 min\n- Prediction: 20 min\n"
      },
      "source": "https://raw.githubusercontent.com/shenlab-sinai/DeepRegFinder/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Cleaning up disk space",
        "parent_header": [
          "DeepRegFinder: *Deep* Learning based *Reg*ulatory Elements *Finder*",
          "Running the pipeline"
        ],
        "type": "Text_excerpt",
        "value": "DeepRegFinder may generate a lot of intermediate files that take up a large amount of disk space. If you are running short on disk space, you may want to delete them. Particularly, two directories - `genome_data` and `histone_data` use the most space. Feel safe to delete the `genome_data` directory. For the `histone_data` directory, only two files are needed: `alltogether_notnormed.txt.gz` and `alltogether_notnormed.txt.gz.tbi`; you may delete everything else.\n"
      },
      "source": "https://raw.githubusercontent.com/shenlab-sinai/DeepRegFinder/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "somef_missing_categories": [
    "citation",
    "acknowledgement",
    "download",
    "contact",
    "contributors",
    "documentation",
    "faq",
    "support",
    "identifier",
    "executable_example"
  ],
  "somef_provenance": {
    "date": "2024-10-06 07:20:00",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 9
      },
      "technique": "GitHub_API"
    }
  ],
  "usage": [
    {
      "confidence": 1,
      "result": {
        "original_header": "An example project",
        "parent_header": [
          "DeepRegFinder: *Deep* Learning based *Reg*ulatory Elements *Finder*",
          "Running the pipeline"
        ],
        "type": "Text_excerpt",
        "value": "I understand how important it is to have an example for people to follow. Therefore I have created an example project with all annotations, bam files and configurations so that you can see how a project shall be structured. It can be accessed at this Google Dirve [folder](https://drive.google.com/drive/folders/1sW9KM9TnK6nqquf7nQniEpfTtiKtWVni?usp=sharing).\n"
      },
      "source": "https://raw.githubusercontent.com/shenlab-sinai/DeepRegFinder/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "TERMS OF USE",
        "type": "Text_excerpt",
        "value": "All data is free to use for non-commercial purposes. For commercial use please contact [MSIP](https://www.ip.mountsinai.org/).\n\n\n"
      },
      "source": "https://raw.githubusercontent.com/shenlab-sinai/DeepRegFinder/master/README.md",
      "technique": "header_analysis"
    }
  ]
}