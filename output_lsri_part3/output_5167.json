{
  "citation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "References",
        "parent_header": [
          "Importing and preprocessing data"
        ],
        "type": "Text_excerpt",
        "value": "1. Bolyen E, Rideout JR, Dillon MR, Bokulich NA, Abnet C, Al-Ghalith GA, Alexander H, Alm EJ, Arumugam M, Asnicar F, Bai Y, Bisanz JE, Bittinger K, Brejnrod A, Brislawn CJ, Brown CT, Callahan BJ, Caraballo-Rodr\u00edguez AM, Chase J, Cope E, Da Silva R, Dorrestein PC, Douglas GM, Durall DM, Duvallet C, Edwardson CF, Ernst M, Estaki M, Fouquier J, Gauglitz JM, Gibson DL, Gonzalez A, Gorlick K, Guo J, Hillmann B, Holmes S, Holste H, Huttenhower C, Huttley G, Janssen S, Jarmusch AK, Jiang L, Kaehler B, Kang KB, Keefe CR, Keim P, Kelley ST, Knights D, Koester I, Kosciolek T, Kreps J, Langille MG, Lee J, Ley R, Liu Y, Loftfield E, Lozupone C, Maher M, Marotz C, Martin BD, McDonald D, McIver LJ, Melnik AV, Metcalf JL, Morgan SC, Morton J, Naimey AT, Navas-Molina JA, Nothias LF, Orchanian SB, Pearson T, Peoples SL, Petras D, Preuss ML, Pruesse E, Rasmussen LB, Rivers A, Robeson, II MS, Rosenthal P, Segata N, Shaffer M, Shiffer A, Sinha R, Song SJ, Spear JR, Swafford AD, Thompson LR, Torres PJ, Trinh P, Tripathi A, Turnbaugh PJ, Ul-Hasan S, van der Hooft JJ, Vargas F, V\u00e1zquez-Baeza Y, Vogtmann E, von Hippel M, Walters W, Wan Y, Wang M, Warren J, Weber KC, Williamson CH, Willis AD, Xu ZZ, Zaneveld JR, Zhang Y, Zhu Q, Knight R, Caporaso JG. 2018. QIIME 2: Reproducible, interactive, scalable, and extensible microbiome data science. PeerJ Preprints 6:e27295v2 https://doi.org/10.7287/peerj.preprints.27295v2\n2. Mirarab, S., Nguyen, N. and Warnow, T., 2012. SEPP: SAT\u00e9-enabled phylogenetic placement. In Biocomputing 2012 (pp. 247-258).\n4. Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., Blondel, M., Prettenhofer, P., Weiss, R., Dubourg, V. and Vanderplas, J., 2011. Scikit-learn: Machine learning in Python. Journal of machine learning research, 12(Oct), pp.2825-2830.\n5. Price, M.N., Dehal, P.S. and Arkin, A.P., 2010. FastTree 2\u2013approximately maximum-likelihood trees for large alignments. PloS one, 5(3), p.e9490.\n6. St\u00e9fan van der Walt, S. Chris Colbert and Ga\u00ebl Varoquaux. The NumPy Array: A Structure for Efficient Numerical Computation, Computing in Science & Engineering, 13, 22-30 (2011), DOI:10.1109/MCSE.2011.37\n7. Travis E, Oliphant. A guide to NumPy, USA: Trelgol Publishing, (2006).\n"
      },
      "source": "https://raw.githubusercontent.com/tada-alg/TADA/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/tada-alg/TADA"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2019-05-24T10:36:37Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2023-10-03T09:49:37Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 0.9971142671215627,
      "result": {
        "original_header": "Abstract",
        "type": "Text_excerpt",
        "value": "TADA is a new data augmentation technique for classifying phenotypes based on the microbiome. \nOur algorithm, TADA, uses available data and a statistical generative model to create new samples augmenting existing ones, addressing issues of low-sample-size. \nIn generating new samples,\nTADA takes into account phylogenetic relationships between microbial species. Adding these synthetic samples to the training set improves the accuracy of downstream classification, especially when the training data have an unbalanced representation of classes.\n \n"
      },
      "source": "https://raw.githubusercontent.com/tada-alg/TADA/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9930751344740414,
      "result": {
        "original_header": "Importing and preprocessing data",
        "type": "Text_excerpt",
        "value": "This tutorial is based on the official [Qiime2](https://docs.qiime2.org/2019.4/tutorials/overview/) tutorials. We also created in-house scripts (all based on Qiime2) to import files from FASTA and FASTQ format to Qiime2 artifacts, denoise them using Deblur, and create the phylogeny. You can read more about them [here](https://github.com/tada-alg/TADA/tree/master/src/utils/shell).  \n"
      },
      "source": "https://raw.githubusercontent.com/tada-alg/TADA/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/tada-alg/TADA/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "executable_example": [
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/tada-alg/TADA/master/src/utils/ipython/make_experiment_Gevers.ipynb"
      },
      "source": "https://raw.githubusercontent.com/tada-alg/TADA/master/src/utils/ipython/make_experiment_Gevers.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/tada-alg/TADA/master/src/utils/ipython/make_experiment_AGP.ipynb"
      },
      "source": "https://raw.githubusercontent.com/tada-alg/TADA/master/src/utils/ipython/make_experiment_AGP.ipynb",
      "technique": "file_exploration"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 1
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/tada-alg/TADA/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "tada-alg/TADA"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ""
      },
      "source": "https://raw.githubusercontent.com/tada-alg/TADA/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "has_script_file": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/tada-alg/TADA/master/src/utils/shell/export_seqs_from_biom.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/tada-alg/TADA/master/src/utils/shell/create_manifest_file.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/tada-alg/TADA/master/src/utils/shell/import_to_qiime.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/tada-alg/TADA/master/src/utils/shell/join_and_quality_control.sh"
      },
      "technique": "file_exploration"
    }
  ],
  "installation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Installation",
        "type": "Text_excerpt",
        "value": "TADA is a python3 package and depends on several other python packages, including i) [numpy](https://www.numpy.org/) ii) [Dendropy](https://dendropy.org/) iii) [scikit-learn](https://scikit-learn.org/stable/install.html) iv) [biom-format](http://biom-format.org/documentation/biom_format.html) v) [pandas](https://pandas.pydata.org/).\n\nTo install these packages using **conda**, first create a conda environment\n\n```\nconda create --name TADA python=3.6\nconda activate TADA\nconda install numpy pandas scikit-learn\nconda install -c bioconda dendropy biom-format \n```\n\nThen clone this [github](git@github.com:tada-alg/TADA.git) repository somewhere on your machine.\n\n"
      },
      "source": "https://raw.githubusercontent.com/tada-alg/TADA/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/tada-alg/TADA/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ""
      },
      "technique": "GitHub_API"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "TADA"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "Organization",
        "value": "tada-alg"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 140690,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "R",
        "size": 33107,
        "type": "Programming_language",
        "value": "R"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Jupyter Notebook",
        "size": 16310,
        "type": "Programming_language",
        "value": "Jupyter Notebook"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Shell",
        "size": 15348,
        "type": "Programming_language",
        "value": "Shell"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/tada-alg/TADA/master/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "run": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Running",
        "type": "Text_excerpt",
        "value": "Input to TADA are\n\n1. A rooted tree in newick format. For microbiome data, you could use this [pipline](https://github.com/qiime2/q2-fragment-insertion) to get the tree.\n2. A count table where each sample is represented with a set of feature (OTU for microbiome). The rows are typically features and columns are samples. This input can be biom format or TSV (Tab Separated Values). The code recognizes if the input count table is in the biom format if the file ends in .biom or TSV format if it ends in .tsv. If the table is in TSV format, columns correspond to samples. The first column is an exception which stores the feature IDs. The first row also stores the sample IDs, and the first string in this file (string at first column, first row) should be a dummy string.\n3. The output directory to store augmented data (and metadata if applicable) in the biom format.\nIf TADA is used for balancing, a metadata file (TSV) format is also needed. In this file, the first column indicates sample IDs, and the second column shows the class labels corresponding to each sample. The first row assumes to be a header with your choice of wording.\n\nThe outputs of the code are (written on the output directory)\n\n1. Augmented data in the biom format\n2. A copy of original data in the biom format\n3. Only for balancing: Metadata for augmented data\n4. Only for balancing: A copy of the metadata for original data\n5. The log file to keep track of progress and errors\n\nLet's assume that you copied [github](git@github.com:tada-alg/TADA.git) repository in a directory **DIR** (e.g., **/home/username/**). You could see the TADA's manual using the following command. \n\n```\npython [DIR]/TADA/src/utils/python/TADA_microbiom.py -h\n```\n\nAnf here is the usage for TADA\n\n```\n\nUsage: TADA_microbiom.py [options]\n\nOptions:\n  -h, --help            show this help message and exit\n  -t TREE_FP, --tree=TREE_FP\n                        Phylogeny file in newick format.\n  -b BIOM_FP, --biom=BIOM_FP\n                        The count table. This can be a biom (file with suffix\n                        .biom) or TSV (Tab Separated Values) file (file with\n                        suffix .tsv). In TSV format rows define features, and\n                        columns define samples.The first column defines the\n                        feature IDs. The first row defines a header where from\n                        the second column sample IDs are listed.\n  -o OUT_DIR, --output=OUT_DIR\n                        The output directory.\n  --seed=SEED_NUM       Seed number. Default is 0.\n  -g GENERATE_STRATEGY, --generate_strategy=GENERATE_STRATEGY\n                        Specifies the generating strategy for either balancing\n                        or data augmentation without balancing. If TADA is\n                        used for augmentation, this shouldn't be passed.\n                        Otherwise, pass a meta data file (in TSV format, a tab\n                        delimited with no header). The first column should be\n                        samples, and second column should be class labels.\n  -x XGEN, --xgen=XGEN  Amount of generation for balancing. If TADA is used\n                        for only balancing (no extra augmentation afterwards),\n                        0 should be passed. In balancing, TADA eventually will\n                        generate new samples until all classes have [xgen+1] *\n                        [maximum class size] samples. Default is 0\n  -k N_BETA, --n_beta=N_BETA\n                        The number of draws from the beta distribution. For\n                        augmentation, TADA will generate [n_binom]*[n_beta]\n                        samples per each sample. Default is 1.\n  -u N_BINOM, --n_binom=N_BINOM\n                        The number of draws from binomial distribution. For\n                        augmentation, TADA will generate [n_binom]*[n_beta]\n                        samples per each sample. Default is 5\n  -v VAR_METHOD, --var_method=VAR_METHOD\n                        Defines how to introduce the variation. Options are\n                        br_penalized and class. The br_penalized can be used\n                        with a monotonically increasing function of branch\n                        length to define the variation. The class options can\n                        be used to use estimate the variation from training\n                        data. We suggest using br_penalized.\n  -z STAT_METHOD, --stat_method=STAT_METHOD\n                        The generative model. Options are binom or beta_binom.\n  -r PRIOR_WEIGHT, --prior_weight=PRIOR_WEIGHT\n                        The class conditional probability weight. The default\n                        is 0.\n  -c COEF, --coef=COEF  The penalty factor in the calculation of nu. This\n                        affects the amount of variation.\n  --exponent=EXPONENT   The exponent in the calculation of nu. This affects\n                        the amount of variation.\n  --br_pseudo=PSEUDO    A pesudo small branch length will be added to all\n                        branches to avoid zero branch length estimate problem.\n  --pseudo_cnt=PSEUDO_CNT\n                        Pseudo count to avoid zero count problem\n  --normalized=NORMALIZED\n                        If set to 1, the OTU counts will be normalized to add\n                        up to one.\n```\n\n"
      },
      "source": "https://raw.githubusercontent.com/tada-alg/TADA/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Using TADA for augmentation",
        "parent_header": [
          "Running"
        ],
        "type": "Text_excerpt",
        "value": "The training data size has a tremendous effect on the machine learning method performance. Generating new samples from the training data can be helpful. To use TADA for data augmentation, you can use the following command\n\n```\npython [DIR]/TADA/src/utils/python/TADA_microbiom.py -t [phylogeny_fp] -b [table_fp] -o [output_dir]\n```\n\nPlease download the example data available [here](data/reference/test.tar.gz). Next unarchive the file and go to the resulting directory\n\n```\ntar xzvf test.tar.gz\ncd test\n```\n\nNext, you can augment data (using hierarchy of binomials) to it using the following command\n\n```\nmkdir binom\npython [DIR]/TADA/src/utils/python/TADA_microbiom.py -t phylogeny.tre -b feature-table.biom -o ./binom\n```\n\n\nThis will create a log file `binom/logfile.log[random suffix]`, and the augmented data file in biom format `binom/augmented_data.biom`. If you wish using beta binomial, you can use the following command\n\n```\nmkdir beta_binom\npython [DIR]/TADA/src/utils/python/TADA_microbiom.py -t phylogeny.tre -b feature-table.biom -o ./beta_binom -z beta_binom\n```\n\nThis will create a log file `beta_binom/logfile.log[random suffix]`, and the augmented data file in biom format `beta_binom/augmented_data.biom`.\n\n"
      },
      "source": "https://raw.githubusercontent.com/tada-alg/TADA/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Using TADA for balancing datasets",
        "parent_header": [
          "Running"
        ],
        "type": "Text_excerpt",
        "value": "In microbiome samples, the distribution of class labels (or cluster labels for unsupervised learning) is often unbalanced. This can cause overfitting and poor generalization of the machine learning method on new samples. You can use TADA to generate new samples for the underrepresented classes to make classes the same size. For this application, you can use TADA with the following command\n\n```\npython [DIR]/TADA/src/utils/python/TADA_microbiom.py -t [phylogeny_fp] -b [table_fp] -o [output_dir] -g [metadata_fp] \n```\nPlease download the example data available [here](data/reference/test.tar.gz). Next unarchive the file and go to the resulting directory\n\n```\ntar xzvf test.tar.gz\ncd test\n```\n\nNext, you can generate synthetic data (using hierarchy of binomials) to create balanced datasets using the following commands\n\n```\nmkdir binom\npython [DIR]/TADA/src/utils/python/TADA_microbiom.py -t phylogeny.tre -b feature-table.biom -o ./binom -g metadata.csv\n```\n\nThis will generate the folder `binom`, and it will create the following files under this directory:\n\n* `augmented_meta_data.csv`: class/cluster labels of the new samples, first column: sample IDs, second column: labels)\n* `augmented_data.biom`: generated features\n* `logfile.log[random suffix]`: log file for generating features\n* `feature-table.biom`: original features\n* `metadata.csv`: original meta data file\n\nIf you wish to use the Beta-Binomial generative model, you can use the following commands respectively\n\n```\nmkdir beta_binom\npython [DIR]/TADA/src/utils/python/TADA_microbiom.py -t phylogeny.tre -b feature-table.biom -o ./beta_binom -g metadata.csv -z beta_binom\n```\n\nThe outputs are similar to what described above. The above command will generate enough number of samples for the least size cluster/class (in provided example, from group `1`) so that both groups have the same size. In this implementation of TADA, user can choose to continue generating samples so that the final size of each group be a multiple of initial size of the most frequent group. For example, if the most frequent gorup has `20` samples, and the least size group has `10` samples, and user wishes to have augmentation level of `5x`, then the final size of both classes will be `120 = (5)*20 + 20`. The augmentation level of `0x` means the user wants both classes the same size and no further augmentation (default). For example, the following command will peform a `5x` augmentation.\n\n```\nmkdir beta_binom\npython [DIR]/TADA/src/utils/python/TADA_microbiom.py -t phylogeny.tre -b feature-table.biom -o ./beta_binom -g metadata.csv -z beta_binom -x 5\n```\n\nThe outpus are similar to what described above. Please note that in the augmented meta data file, there are `110` samples with class `1` and `100` samples with class 0. Overal, you will have `120` samples for both classes. \n"
      },
      "source": "https://raw.githubusercontent.com/tada-alg/TADA/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "somef_missing_categories": [
    "acknowledgement",
    "download",
    "requirements",
    "contact",
    "contributors",
    "documentation",
    "license",
    "usage",
    "faq",
    "support",
    "identifier",
    "has_build_file"
  ],
  "somef_provenance": {
    "date": "2024-10-06 19:00:41",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 5
      },
      "technique": "GitHub_API"
    }
  ]
}