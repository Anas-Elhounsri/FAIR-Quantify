{
  "application_domain": [
    {
      "confidence": 32.72,
      "result": {
        "type": "String",
        "value": "Natural Language Processing"
      },
      "technique": "supervised_classification"
    }
  ],
  "citation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Citation",
        "parent_header": [
          "TALE"
        ],
        "type": "Text_excerpt",
        "value": "```\n@article{10.1093/bioinformatics/btab198,\n    author = {Cao, Yue and Shen, Yang},\n    title = \"{TALE: Transformer-based protein function Annotation with joint sequence\u2013Label Embedding}\",\n    journal = {Bioinformatics},\n    year = {2021},\n    month = {03},\n    issn = {1367-4803},\n    doi = {10.1093/bioinformatics/btab198},\n    url = {https://doi.org/10.1093/bioinformatics/btab198},\n    note = {btab198},\n    eprint = {https://academic.oup.com/bioinformatics/advance-article-pdf/doi/10.1093/bioinformatics/btab198/36671287/btab198.pdf},\n}\n```\n\n"
      },
      "source": "https://raw.githubusercontent.com/Shen-Lab/TALE/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "author": "Cao, Yue and Shen, Yang",
        "doi": "10.1093/bioinformatics/btab198",
        "format": "bibtex",
        "title": "{TALE: Transformer-based protein function Annotation with joint sequence\u2013Label Embedding}",
        "type": "Text_excerpt",
        "url": "https://doi.org/10.1093/bioinformatics/btab198",
        "value": "@article{10.1093/bioinformatics/btab198,\n    eprint = {https://academic.oup.com/bioinformatics/advance-article-pdf/doi/10.1093/bioinformatics/btab198/36671287/btab198.pdf},\n    note = {btab198},\n    url = {https://doi.org/10.1093/bioinformatics/btab198},\n    doi = {10.1093/bioinformatics/btab198},\n    issn = {1367-4803},\n    month = {03},\n    year = {2021},\n    journal = {Bioinformatics},\n    title = {{TALE: Transformer-based protein function Annotation with joint sequence\u2013Label Embedding}},\n    author = {Cao, Yue and Shen, Yang},\n}"
      },
      "source": "https://raw.githubusercontent.com/Shen-Lab/TALE/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/Shen-Lab/TALE"
      },
      "technique": "GitHub_API"
    }
  ],
  "contact": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Contact:",
        "parent_header": [
          "TALE"
        ],
        "type": "Text_excerpt",
        "value": "Yang Shen: yshen@tamu.edu\n\nYue Cao:  cyppsp@tamu.edu\n"
      },
      "source": "https://raw.githubusercontent.com/Shen-Lab/TALE/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2020-03-25T04:00:17Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2024-08-27T03:41:47Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "Transformer-based protein function Annotation with joint feature-Label Embedding"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 0.8375098444275771,
      "result": {
        "original_header": "TALE",
        "type": "Text_excerpt",
        "value": "Input feature: sequence data (using transformer)  \n"
      },
      "source": "https://raw.githubusercontent.com/Shen-Lab/TALE/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8758144204548182,
      "result": {
        "original_header": "Sequence",
        "type": "Text_excerpt",
        "value": "The sequence file is a list, where each element is a directory having the following information:\n* 'ID': The ID of the sequence in Swiss-Prot\n* 'ac': The acession number of the sequence in Swiss-Prot\n* 'date': The date of the sequence released in Swiss-Prot\n* 'seq': The amino acid sequence\n* 'GO':  The GO annotations of the sequence \n"
      },
      "source": "https://raw.githubusercontent.com/Shen-Lab/TALE/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9551105583271877,
      "result": {
        "original_header": "Label",
        "type": "Text_excerpt",
        "value": "* The label file is a list, where each element is a list containing the indexes of labels (GO terms). \n"
      },
      "source": "https://raw.githubusercontent.com/Shen-Lab/TALE/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8858947766644549,
      "result": {
        "original_header": "Ontology",
        "type": "Text_excerpt",
        "value": "The ontology file is a directory, where each key is a GO term (e.g. 'GO:0030234') in the ontology. Each value is also a directory containing the information for that key:\n* 'name': The name of the GO term\n* 'ind':  The index of this GO term\n* 'father': The parent GO terms\n* 'child': The children GO terms\n \n"
      },
      "source": "https://raw.githubusercontent.com/Shen-Lab/TALE/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9521919808662923,
      "result": {
        "original_header": "Training:",
        "type": "Text_excerpt",
        "value": "The above example is to train a model with 32 batch size, 100 epochs, 1e-3 learning rate, MFO ontology, 0 lambda value, with training data path at '../data/Gene_Ontology/EXP_Swiss_Prot/' and save the trained model in './log/'.\n \n"
      },
      "source": "https://raw.githubusercontent.com/Shen-Lab/TALE/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/Shen-Lab/TALE/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 10
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/Shen-Lab/TALE/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "Shen-Lab/TALE"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "TALE"
      },
      "source": "https://raw.githubusercontent.com/Shen-Lab/TALE/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "images": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Shen-Lab/TALE/master//ProteinFuncPred.png"
      },
      "source": "https://raw.githubusercontent.com/Shen-Lab/TALE/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "installation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "If you want to use TALE+ for prediction, prepare your sequence file in the fasta format and go to src/ and run:",
        "parent_header": [
          "TALE",
          "For users"
        ],
        "type": "Text_excerpt",
        "value": "`python predict.py --fasta $path_to_your_fasta_file --on on --out $path_to_your_output_file`\n\nwhere on=mf,bp,cc for MFO,BPO and CCO, respectively.\n"
      },
      "source": "https://raw.githubusercontent.com/Shen-Lab/TALE/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "To get the sequence representation, prepare your sequence file in the fasta format and go to src/ and run:",
        "parent_header": [
          "TALE",
          "For users"
        ],
        "type": "Text_excerpt",
        "value": "`python seq_embedding.py --fasta $path_to_your_fasta_file --on on --out $path_to_your_output_file`\n\nThe output file is a dictionary that contain two keys, \"seq_emb\" and \"final\", while the former refers to the token-wise embedding with a shape of \\[seq_num, 1000 (max_seq_len), dim] and the latter refers to the sequence-wise embedding before the output layer which has a shape of \\[seq_num, dim].\n"
      },
      "source": "https://raw.githubusercontent.com/Shen-Lab/TALE/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "invocation": [
    {
      "confidence": 0.8682766206104612,
      "result": {
        "original_header": "Training:",
        "type": "Text_excerpt",
        "value": "In order to train the model, under src/, run: \n`python train.py --batch_size 32 --epochs 100 --lr 1e-3 --save_path ./log/ --ontology mf --data_path ../data/ --regular_lambda 0` \nThe above example is to train a model with 32 batch size, 100 epochs, 1e-3 learning rate, MFO ontology, 0 lambda value, with training data path at '../data/Gene_Ontology/EXP_Swiss_Prot/' and save the trained model in './log/'.\n \n"
      },
      "source": "https://raw.githubusercontent.com/Shen-Lab/TALE/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/Shen-Lab/TALE/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ""
      },
      "technique": "GitHub_API"
    }
  ],
  "license": [
    {
      "confidence": 1,
      "result": {
        "name": "MIT License",
        "spdx_id": "MIT",
        "type": "License",
        "url": "https://api.github.com/licenses/mit",
        "value": "https://api.github.com/licenses/mit"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "type": "File_dump",
        "value": "MIT License\n\nCopyright (c) 2020 Shen Lab at Texas A&M University\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
      },
      "source": "https://raw.githubusercontent.com/Shen-Lab/TALE/master/LICENSE",
      "technique": "file_exploration"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "TALE"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "User",
        "value": "Shen-Lab"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 59060,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Shen-Lab/TALE/master/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "requirements": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Dependencies",
        "parent_header": [
          "TALE"
        ],
        "type": "Text_excerpt",
        "value": "* TensorFlow >=1.13\n* For TALE+ (TALE+Diamond), please download [Diamond](http://www.diamondsearch.org/index.php) and put the executable file into TALE/diamond/\n\n"
      },
      "source": "https://raw.githubusercontent.com/Shen-Lab/TALE/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "run": [
    {
      "confidence": 1,
      "result": {
        "original_header": "If you want to use TALE+ for prediction, prepare your sequence file in the fasta format and go to src/ and run:",
        "parent_header": [
          "TALE",
          "For users"
        ],
        "type": "Text_excerpt",
        "value": "`python predict.py --fasta $path_to_your_fasta_file --on on --out $path_to_your_output_file`\n\nwhere on=mf,bp,cc for MFO,BPO and CCO, respectively.\n"
      },
      "source": "https://raw.githubusercontent.com/Shen-Lab/TALE/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "To get the sequence representation, prepare your sequence file in the fasta format and go to src/ and run:",
        "parent_header": [
          "TALE",
          "For users"
        ],
        "type": "Text_excerpt",
        "value": "`python seq_embedding.py --fasta $path_to_your_fasta_file --on on --out $path_to_your_output_file`\n\nThe output file is a dictionary that contain two keys, \"seq_emb\" and \"final\", while the former refers to the token-wise embedding with a shape of \\[seq_num, 1000 (max_seq_len), dim] and the latter refers to the sequence-wise embedding before the output layer which has a shape of \\[seq_num, dim].\n"
      },
      "source": "https://raw.githubusercontent.com/Shen-Lab/TALE/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "somef_missing_categories": [
    "acknowledgement",
    "download",
    "contributors",
    "documentation",
    "faq",
    "support",
    "identifier",
    "has_build_file",
    "executable_example"
  ],
  "somef_provenance": {
    "date": "2024-10-06 12:16:45",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 31
      },
      "technique": "GitHub_API"
    }
  ],
  "usage": [
    {
      "confidence": 1,
      "result": {
        "original_header": "If you want to use TALE+ for prediction, prepare your sequence file in the fasta format and go to src/ and run:",
        "parent_header": [
          "TALE",
          "For users"
        ],
        "type": "Text_excerpt",
        "value": "`python predict.py --fasta $path_to_your_fasta_file --on on --out $path_to_your_output_file`\n\nwhere on=mf,bp,cc for MFO,BPO and CCO, respectively.\n"
      },
      "source": "https://raw.githubusercontent.com/Shen-Lab/TALE/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "To get the sequence representation, prepare your sequence file in the fasta format and go to src/ and run:",
        "parent_header": [
          "TALE",
          "For users"
        ],
        "type": "Text_excerpt",
        "value": "`python seq_embedding.py --fasta $path_to_your_fasta_file --on on --out $path_to_your_output_file`\n\nThe output file is a dictionary that contain two keys, \"seq_emb\" and \"final\", while the former refers to the token-wise embedding with a shape of \\[seq_num, 1000 (max_seq_len), dim] and the latter refers to the sequence-wise embedding before the output layer which has a shape of \\[seq_num, dim].\n"
      },
      "source": "https://raw.githubusercontent.com/Shen-Lab/TALE/master/README.md",
      "technique": "header_analysis"
    }
  ]
}