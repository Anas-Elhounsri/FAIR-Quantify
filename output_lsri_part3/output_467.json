{
  "application_domain": [
    {
      "confidence": 0.8892342053719297,
      "result": {
        "type": "String",
        "value": "Graphs"
      },
      "technique": "supervised_classification"
    }
  ],
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/guoyangzou/DeepKme"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2020-11-14T12:50:22Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2022-09-30T09:49:28Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "DeepKme is the predictor for lysine methylation sites in human proteome "
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 0.8906753952537029,
      "result": {
        "original_header": "DeepKme",
        "type": "Text_excerpt",
        "value": "DeepKme is the predictor for lysine methylation sites in human proteome. \nThis package contains five folders and the jupyter notebook file DeepKme.ipynb, described as follows. \nDeepKme.ipynb contain the codes for the data preprocessing, model construction and the experiment-split test. \nThe ID_convert_list folder inlcudes the original datasets derived from PhosphoSite, each of which contains the information of the Kme types and the experiment source. All the data are integrated as PhosphoSitePlus_withEvidence.csv, stored under the datasets folder. \nThe data folder contains temporary files generated during the running of the jupyter notebook for the experiment-split method. These files can be ignored by users. \nThe datasets folder contains the positive and negative datasets as well as the data files used to build both datasets. Please see the readme.txt under this folder for details.  \nThe orig_dataset contains the Kme information directly downloaded from different databases. These files were later proprocessed and the final files were stored in the datasets folder for the generation of positive and negative samples.  \nThe following is the definition of DeepKme using python. \nYou can use it to make prediction:\n    \n    # Load weights to the defined model\n    model.load_weights(\"./Model_split/Km1_CSTCS_3746.hdf5\")  ## you can load any model weights as you need in Model_split folder.\n    \n    # Load the positive samples\n    df_Kme = pd.read_csv(\"./datasets/KmeSites_Collected.csv\")  ## you can prepare your own unlabled datasets for predicting the Km1/2/3/e score. \n    df_Kme_Sites = df_Kme.SeqWin\n    np_data_pos = fun_ser_to_numpy_onehot(df_Kme_Sites,1)\n    x_data_pos = np_data_pos[:,:-1]\n    y_data_pos = np_data_pos[:,-1]  ## If you just make prediction for your own unlabled datasets, this step should be passed. \n    # Make prediction in the positive samples\n    y_pred_pos = model.predict(x_data_pos)  ## If you make prediction for your own unlabled datasets, this step would get the Km1/2/3/e score. \n    # Evaluate the performance. If you just make prediction for your own unlabled datasets, this step should be passed.\n    y_pred = np.concatenate([y_pred_pos,y_pred_neg])\n    y_true = np.concatenate([y_data_pos,y_data_neg])\n    result = tf.metrics.AUC(1000)(y_true,y_pred[:,3])\n    print(\"AUC\uff1a%.3f\"%result) \n"
      },
      "source": "https://raw.githubusercontent.com/guoyangzou/DeepKme/main/README.md",
      "technique": "supervised_classification"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/guoyangzou/DeepKme/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "executable_example": [
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/guoyangzou/DeepKme/main/DeepKme.ipynb"
      },
      "source": "https://raw.githubusercontent.com/guoyangzou/DeepKme/main/DeepKme.ipynb",
      "technique": "file_exploration"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 0
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/guoyangzou/DeepKme/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "guoyangzou/DeepKme"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "DeepKme"
      },
      "source": "https://raw.githubusercontent.com/guoyangzou/DeepKme/main/README.md",
      "technique": "regular_expression"
    }
  ],
  "installation": [
    {
      "confidence": 0.9702038371632564,
      "result": {
        "original_header": "DeepKme",
        "type": "Text_excerpt",
        "value": "This package contains five folders and the jupyter notebook file DeepKme.ipynb, described as follows. \n            self.cnn1 = tf.keras.Sequential([\n                tf.keras.layers.Reshape([61,21]),\n                tf.keras.layers.Conv1D(256,9,1,\"valid\"),\n                tf.keras.layers.BatchNormalization(),\n                tf.keras.layers.ReLU(),\n                tf.keras.layers.MaxPool1D(),\n                tf.keras.layers.Dropout(0.7),\n            ])\n            self.cnn2 = tf.keras.Sequential([\n                tf.keras.layers.Reshape([26,256]),\n                tf.keras.layers.Conv1D(32,7,1,\"valid\"),\n                tf.keras.layers.BatchNormalization(),\n                tf.keras.layers.ReLU(),\n                tf.keras.layers.MaxPool1D(),\n                tf.keras.layers.Dropout(0.5),\n            ])\n            self.simple = tf.keras.Sequential([\n                tf.keras.layers.Reshape([10*32]),\n                tf.keras.layers.Dense(128),\n                tf.keras.layers.ReLU(),\n                tf.keras.layers.Dense(4,activation=\"sigmoid\"),\n            ])\n        def call(self, inputs): \n    # Encoding\n    def fun_ser_to_numpy_onehot(Se,label):\n        AAs = ['Q', 'L', 'N', 'G', 'R', 'F', '_', 'W', 'T', 'E', 'K', 'I', 'D', 'V', 'Y', 'S', 'A', 'C', 'M', 'H', 'P']\n        Se = Se.copy()\n        df = Se.drop_duplicates().apply(lambda x: pd.Series(list(x))).replace(AAs,range(len(AAs))).copy()\n        df[\"label\"] = label\n        se = df.to_numpy()\n        se_x = tf.one_hot(se[:,:-1],21).numpy().reshape([len(se),61*21])\n        se_y = se[:,-1:] \n    df_Kme_Sites = df_Kme.SeqWin\n    np_data_pos = fun_ser_to_numpy_onehot(df_Kme_Sites,1)\n    x_data_pos = np_data_pos[:,:-1]\n    y_data_pos = np_data_pos[:,-1]  ## If you just make prediction for your own unlabled datasets, this step should be passed. \n\nIf you want to replicate the paper, please install conda first (https://conda.io/en/latest/miniconda.html#windows-installers) and ensure it is successful. \nThen run the following to create an environment and open your jupyter notebook in your browser: \n    # terminal\n    conda create -n ML2  -c conda-forge -c pytorch python=3.9 pytorch=1.9 tensorflow=2.6 cudnn=8 cudatoolkit=11 scipy pandas openpyxl xlrd jupyterlab jupyter_contrib_nbextensions\n    conda activate ML2\n    pip install  tensorflow-gpu==2.6  ## if your computer have no gpu, ignore this step.\n    cd [your project dir]\n    jupyter notebook \nOpen the DeepKme.ipynb in your browser where your jupyter notebook works. \n \n"
      },
      "source": "https://raw.githubusercontent.com/guoyangzou/DeepKme/main/README.md",
      "technique": "supervised_classification"
    }
  ],
  "invocation": [
    {
      "confidence": 0.8647504042518745,
      "result": {
        "original_header": "DeepKme",
        "type": "Text_excerpt",
        "value": "    import tensorflow as tf\n    import pandas as pd\n    import numpy as np \n    # Load the negative samples\n    Neg_test = pd.read_csv(\"./datasets/Negative_samples_for_test.csv\")[\"Negative_samples_for_test\"]\n    np_data_neg = fun_ser_to_numpy_onehot(Neg_test,0)\n    x_data_neg, y_data_neg = np_data_neg[:,:-1],np_data_neg[:,-1] \n"
      },
      "source": "https://raw.githubusercontent.com/guoyangzou/DeepKme/main/README.md",
      "technique": "supervised_classification"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/guoyangzou/DeepKme/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ""
      },
      "technique": "GitHub_API"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "DeepKme"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "User",
        "value": "guoyangzou"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Jupyter Notebook",
        "size": 143453,
        "type": "Programming_language",
        "value": "Jupyter Notebook"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/guoyangzou/DeepKme/main/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "somef_missing_categories": [
    "citation",
    "acknowledgement",
    "run",
    "download",
    "requirements",
    "contact",
    "contributors",
    "documentation",
    "license",
    "usage",
    "faq",
    "support",
    "identifier",
    "has_build_file"
  ],
  "somef_provenance": {
    "date": "2024-10-06 01:02:35",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 2
      },
      "technique": "GitHub_API"
    }
  ]
}