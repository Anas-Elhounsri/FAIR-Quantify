{
  "application_domain": [
    {
      "confidence": 16.93,
      "result": {
        "type": "String",
        "value": "Computer Vision"
      },
      "technique": "supervised_classification"
    },
    {
      "confidence": 41.29,
      "result": {
        "type": "String",
        "value": "Natural Language Processing"
      },
      "technique": "supervised_classification"
    }
  ],
  "citation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Citation",
        "parent_header": [
          "VQAMix: Conditional Triplet Mixup for Medical Visual Question Answering <a href=\"https://www.researchgate.net/publication/361364110_VQAMix_Conditional_Triplet_Mixup_for_Medical_Visual_Question_Answering\">paper</a>"
        ],
        "type": "Text_excerpt",
        "value": "Please cite this paper in your publications if it helps your research\n\n```\n@article{gong2022vqamix,\n  title={VQAMix: Conditional Triplet Mixup for Medical Visual Question Answering},\n  author={Haifan Gong and Guanqi Chen and Mingzhi Mao and Zhen Li and Guanbin Li},\n  journal={IEEE Trans. on Medical Imaging},\n  year={2022}\n}\n```\n\n![Overview of the vqamix framework](./fig/vqamix.jpg)\n\nIn VQAMix, two image-question pairs {Vi, Qi} and {Vj, Qj} are mixed. When the mixed sample is  sent to the VQA model, the linguistic feature extracted from Qi will interact with the visual feature extracted from Vj, which constructs a new connection {Vj, Qi}. So is {Vi, Qj}. Thus, the label for the mixed image-question pair consists of four answer labels (Yi for {Vi, Qi}, Yj for {Vj, Qj}, Yk for {Vi, Qj} and Yl for {Vj, Qi}). And the weights of those answer labels are the probabilities of occurrence of those imagequestion pairs. The answer A is encoded as a one-hot vector Y.\n\n![Details of the vqamix framework](./fig/pipeline.jpg)\n\nAn overview of our proposed VQAMix enhanced by Learning with Missing Labels (LML) and Learning with Conditional-mixed Labels (LCL) strategies. Two VQA samples are combined linearly in the training phase. To ensure that the mixed label can be used to supervise the learning of VQA models, both LML and LCL scheme discards those two unspecified labels to solve the missing labels issue. Moreover, to avoid meaningless answers, the LCL scheme further utilizes the category of the question to avoid the model suffering from meaningless mixed labels.\n"
      },
      "source": "https://raw.githubusercontent.com/haifangong/VQAMix/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "author": "Haifan Gong and Guanqi Chen and Mingzhi Mao and Zhen Li and Guanbin Li",
        "format": "bibtex",
        "title": "VQAMix: Conditional Triplet Mixup for Medical Visual Question Answering",
        "type": "Text_excerpt",
        "value": "@article{gong2022vqamix,\n    year = {2022},\n    journal = {IEEE Trans. on Medical Imaging},\n    author = {Haifan Gong and Guanqi Chen and Mingzhi Mao and Zhen Li and Guanbin Li},\n    title = {VQAMix: Conditional Triplet Mixup for Medical Visual Question Answering},\n}"
      },
      "source": "https://raw.githubusercontent.com/haifangong/VQAMix/main/README.md",
      "technique": "regular_expression"
    }
  ],
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/haifangong/VQAMix"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2022-04-24T08:49:17Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2024-08-24T03:48:20Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "[IEEE TMI'22] VQAMix: Conditional Triplet Mixup for Medical Visual Question Answering"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 0.999147804073895,
      "result": {
        "original_header": "IEEE Transaction on Medical Imaging",
        "type": "Text_excerpt",
        "value": "This repository is the official implementation of `VQAMix` for the visual question answering task in medical domain. In this paper, we propose a simple yet effective data augmentation method, VQAMix, to mitigate the data limitation problem. Specifically, VQAMix generates more labeled training samples by linearly combining a pair of VQA samples, which can be easily embedded into any visual-language model to boost performance. \nThis repository is based on and inspired by @Jin-Hwa Kim's [work](https://github.com/jnhwkim/ban-vqa) and @Aizo-ai's [work](https://github.com/aioz-ai/MICCAI19-MedVQA). We sincerely thank for their sharing of the codes. \n"
      },
      "source": "https://raw.githubusercontent.com/haifangong/VQAMix/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8441399567843092,
      "result": {
        "original_header": "Dataset and Pre-trained Models",
        "type": "Text_excerpt",
        "value": "The processed data should be downloaded via [Baidu Drive](https://pan.baidu.com/s/1Q7ag10EjIbpMQXSu9SXKVQ) with the extract code: `ioz1`. \nOr you can download the data from the previous work `MMQ`[link](https://github.com/aioz-ai/MICCAI21_MMQ). The downloaded file should be extracted to `data_RAD/` and `data_PATH` directory. \n"
      },
      "source": "https://raw.githubusercontent.com/haifangong/VQAMix/main/README.md",
      "technique": "supervised_classification"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/haifangong/VQAMix/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 2
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/haifangong/VQAMix/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "haifangong/VQAMix"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "VQAMix: Conditional Triplet Mixup for Medical Visual Question Answering paper"
      },
      "source": "https://raw.githubusercontent.com/haifangong/VQAMix/main/README.md",
      "technique": "regular_expression"
    }
  ],
  "has_script_file": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/haifangong/VQAMix/main/run_rad.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/haifangong/VQAMix/main/run_path.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/haifangong/VQAMix/main/run_eval.sh"
      },
      "technique": "file_exploration"
    }
  ],
  "images": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/haifangong/VQAMix/main/./fig/vqamix.jpg"
      },
      "source": "https://raw.githubusercontent.com/haifangong/VQAMix/main/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/haifangong/VQAMix/main/./fig/pipeline.jpg"
      },
      "source": "https://raw.githubusercontent.com/haifangong/VQAMix/main/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/haifangong/VQAMix/main/./fig/sota.jpg"
      },
      "source": "https://raw.githubusercontent.com/haifangong/VQAMix/main/README.md",
      "technique": "regular_expression"
    }
  ],
  "installation": [
    {
      "confidence": 0.9951199829495663,
      "result": {
        "original_header": "Dataset and Pre-trained Models",
        "type": "Text_excerpt",
        "value": "The processed data should be downloaded via [Baidu Drive](https://pan.baidu.com/s/1Q7ag10EjIbpMQXSu9SXKVQ) with the extract code: `ioz1`. \nOr you can download the data from the previous work `MMQ`[link](https://github.com/aioz-ai/MICCAI21_MMQ). The downloaded file should be extracted to `data_RAD/` and `data_PATH` directory. \n"
      },
      "source": "https://raw.githubusercontent.com/haifangong/VQAMix/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8867993287690388,
      "result": {
        "original_header": "More information",
        "type": "Text_excerpt",
        "value": "If you have any problem, no hesitate contact us at haifangong@outlook.com\n \n"
      },
      "source": "https://raw.githubusercontent.com/haifangong/VQAMix/main/README.md",
      "technique": "supervised_classification"
    }
  ],
  "invocation": [
    {
      "confidence": 0.85520676658385,
      "result": {
        "original_header": "Training and Testing",
        "type": "Text_excerpt",
        "value": "Just run the `run_rad.sh` `run_path.sh` for training and evaluation.\nThe result json file can be found in the directory `results/`.\n \n"
      },
      "source": "https://raw.githubusercontent.com/haifangong/VQAMix/main/README.md",
      "technique": "supervised_classification"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/haifangong/VQAMix/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "medical-vqa, mixup"
      },
      "technique": "GitHub_API"
    }
  ],
  "license": [
    {
      "confidence": 1,
      "result": {
        "original_header": "License",
        "parent_header": [
          "VQAMix: Conditional Triplet Mixup for Medical Visual Question Answering <a href=\"https://www.researchgate.net/publication/361364110_VQAMix_Conditional_Triplet_Mixup_for_Medical_Visual_Question_Answering\">paper</a>"
        ],
        "type": "Text_excerpt",
        "value": "MIT License\n"
      },
      "source": "https://raw.githubusercontent.com/haifangong/VQAMix/main/README.md",
      "technique": "header_analysis"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "VQAMix"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "User",
        "value": "haifangong"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 130696,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Shell",
        "size": 12905,
        "type": "Programming_language",
        "value": "Shell"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/haifangong/VQAMix/main/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "requirements": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Prerequisites",
        "parent_header": [
          "VQAMix: Conditional Triplet Mixup for Medical Visual Question Answering <a href=\"https://www.researchgate.net/publication/361364110_VQAMix_Conditional_Triplet_Mixup_for_Medical_Visual_Question_Answering\">paper</a>"
        ],
        "type": "Text_excerpt",
        "value": "torch                       1.6.0+\ntorchvision                 0.6+\n"
      },
      "source": "https://raw.githubusercontent.com/haifangong/VQAMix/main/README.md",
      "technique": "header_analysis"
    }
  ],
  "somef_missing_categories": [
    "acknowledgement",
    "run",
    "download",
    "contact",
    "contributors",
    "documentation",
    "usage",
    "faq",
    "support",
    "identifier",
    "has_build_file",
    "executable_example"
  ],
  "somef_provenance": {
    "date": "2024-10-05 23:17:51",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 14
      },
      "technique": "GitHub_API"
    }
  ]
}