{
  "acknowledgement": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Acknowledgements",
        "parent_header": [
          "HVF Extraction Script"
        ],
        "type": "Text_excerpt",
        "value": "- PyImageSearch for excellent tutorials on image processing\n"
      },
      "source": "https://raw.githubusercontent.com/msaifee786/hvf_extraction_script/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "application_domain": [
    {
      "confidence": 14.95,
      "result": {
        "type": "String",
        "value": "Computer Vision"
      },
      "technique": "supervised_classification"
    }
  ],
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/msaifee786/hvf_extraction_script"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2020-04-03T04:20:01Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2024-09-25T20:51:27Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "Python scripting framework for extraction data from Humphrey Visual Fields"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 0.9927570150599928,
      "result": {
        "original_header": "HVF Extraction Script",
        "type": "Text_excerpt",
        "value": "Python module for Humphrey Visual Field (HVF) report data extraction. The package can taken in HVF single field analysis report images (from HFA2 or HFA3), and using OCR (tesseract) and image processing techniques (openCV), extracts data into an object oriented format for further processing.\n \n"
      },
      "source": "https://raw.githubusercontent.com/msaifee786/hvf_extraction_script/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.922190707265614,
      "result": {
        "original_header": "Using/Contributing",
        "type": "Text_excerpt",
        "value": "This project was developed in the spirit of facilitating vision research. To that end, we encourage all to download, use, critique and improve upon the project. Fork requests are encouraged. Research collaboration requests are also welcomed.\n \n"
      },
      "source": "https://raw.githubusercontent.com/msaifee786/hvf_extraction_script/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/msaifee786/hvf_extraction_script/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 3
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/msaifee786/hvf_extraction_script/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "msaifee786/hvf_extraction_script"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "HVF Extraction Script"
      },
      "source": "https://raw.githubusercontent.com/msaifee786/hvf_extraction_script/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "installation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Installation",
        "parent_header": [
          "HVF Extraction Script",
          "Getting Started"
        ],
        "type": "Text_excerpt",
        "value": "Note: This software package was developed and tested on an Intel Mac OSX system; while it should work on any platform, its execution is best understood on such systems.\n\nTo use the system, first download and install [Anaconda](https://www.anaconda.com/) (or Miniconda) for Python, a distribution and package manager for Python  specifically geared towards data science. This will help download many of the dependencies for the system.\n\nWithin Anaconda, create a dedicated environment for development and use with HVF Extraction Script:\n\n```shell\n(base) $ conda create --name hvf_env # Replace 'hvf_env' with desired environment name\n```\n\n and switch to that environment:\n\n ```shell\n (base) $ conda activate hvf_env # or the environment name you chose\n ```\n\nWithin your environment, download a few required dependencies with Anaconda, namely PIP (to manage PyPI Package repository) and tesseract:\n\n```shell\n(hvf_env) $ conda install pip\n...\n(hvf_env) $ conda install -c conda-forge tesseract\n...\n```\n\nLastly, use PIP to install hvf-extraction-script, to download the package and all other required dependencies:\n\n```shell\n(hvf_env) $ pip install hvf-extraction-script\n```\n\nOccasionally, installation of hvf-extraction-script has trouble locating some dependencies (specifically tesseract) and fails installation; this may be due to some internal links not refreshing. Try restarting your terminal program and trying again.\n"
      },
      "source": "https://raw.githubusercontent.com/msaifee786/hvf_extraction_script/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 0.97821725942412,
      "result": {
        "original_header": "Authors",
        "type": "Text_excerpt",
        "value": "- Murtaza Saifee, MD - Ophthalmology resident, UCSF. Email: saifeeapps@gmail.com\n \n"
      },
      "source": "https://raw.githubusercontent.com/msaifee786/hvf_extraction_script/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/msaifee786/hvf_extraction_script/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ""
      },
      "technique": "GitHub_API"
    }
  ],
  "license": [
    {
      "confidence": 1,
      "result": {
        "name": "GNU General Public License v3.0",
        "spdx_id": "GPL-3.0",
        "type": "License",
        "url": "https://api.github.com/licenses/gpl-3.0",
        "value": "https://api.github.com/licenses/gpl-3.0"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "License",
        "parent_header": [
          "HVF Extraction Script"
        ],
        "type": "Text_excerpt",
        "value": "GPL License\n"
      },
      "source": "https://raw.githubusercontent.com/msaifee786/hvf_extraction_script/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "hvf_extraction_script"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "User",
        "value": "msaifee786"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 248169,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/msaifee786/hvf_extraction_script/master/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "requirements": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Requirements",
        "parent_header": [
          "HVF Extraction Script",
          "Getting Started"
        ],
        "type": "Text_excerpt",
        "value": "- Python 3.6.7 or higher\n- TesserOCR\n- Regex\n- PyDicom\n- Pillow\n- OpenCV 4.2.0\n- FuzzyWuzzy\n- Fuzzysearch\n"
      },
      "source": "https://raw.githubusercontent.com/msaifee786/hvf_extraction_script/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "run": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Running Unit Tests",
        "parent_header": [
          "HVF Extraction Script",
          "Usage"
        ],
        "type": "Text_excerpt",
        "value": "Single Image Testing:\n\nRunning a single image test performs an extraction of an image report, shows its extraction data in pretty-print, and tests serialization/deserialization procedures\n\n```shell\n>>> from hvf_extraction_script.hvf_manager.hvf_test import Hvf_Test\n>>> from hvf_extraction_script.utilities.file_utils import File_Utils\n\n>>> image_path = \u201cpath/to/image/file.PNG\u201d;\n>>> hvf_image = File_Utils.read_image_from_file(image_path);\n>>> Hvf_Test.test_single_image(hvf_image);\n...\n```\n\nUnit Testing:\n\nThis package comes with the ability to run unit tests, but with no pre-loaded unit tests to run. Unit testing code is under Hvf_Test, with some example code in hvf_object_testers.py (uploaded in GitHub source code). In general, unit testing can perform testing comparison between:\n- Image extraction vs serialized reference\n- Image extraction vs DICOM file reference\n- Serialized text file vs DICOM file reference\n- Serialized text file vs serialized reference\n\nThe image file and reference test files are stored under hvf_test_cases with corresponding names.\n\nAdding unit tests:\n\n```shell\n>>> unit_test_name = \u201cunit_test_name\u201d\n>>> test_type = Hvf_Test.UNIT_TEST_IMAGE_VS_DICOM;\n>>> ref_data_path = \"path/to/dicom/file.dcm\"\n>>> test_data_path = \u201cpath/to/image/file.PNG\u201d;\n>>> Hvf_Test.add_unit_test(test_name, test_type, ref_data_path, test_data_path);\n\n```\n\nRunning unit tests:\n```shell\n>>> Hvf_Test.test_unit_tests(unit_test_nam, test_type)\n...\n[SYSTEM] ================================================================================\n[SYSTEM] Starting test: v2_26\n[SYSTEM] Test v2_26: FAILED ==============================\n[SYSTEM] - Metadata MISMATCH COUNT: 1\n[SYSTEM] --> Key: pupil_diameter - expected: 4.1, actual: 4.7\n[SYSTEM] - Raw Value Plot: FULL MATCH\n[SYSTEM] - Total Deviation Value Plot: FULL MATCH\n[SYSTEM] - Pattern Deviation Value Plot: FULL MATCH\n[SYSTEM] - Total Deviation Percentile Plot: FULL MATCH\n[SYSTEM] - Pattern Deviation Percentile Plot: FULL MATCH\n[SYSTEM] END Test v2_26 FAILURE REPORT =====================\n[SYSTEM] ================================================================================\n[SYSTEM] Starting test: v2_27\n[SYSTEM] Test v2_27: PASSED\n[SYSTEM] ================================================================================\n[SYSTEM] Starting test: v2_28\n[SYSTEM] Test v2_28: PASSED\n[SYSTEM] ================================================================================\n...\n[SYSTEM] ================================================================================\n[SYSTEM] UNIT TEST AGGREGATE METRICS:\n[SYSTEM] Total number of tests: 30\n[SYSTEM] Average extraction time per report: 4741ms\n[SYSTEM]\n[SYSTEM] Total number of metadata fields: 510\n[SYSTEM] Total number of metadata field errors: 7\n[SYSTEM] Metadata field error rate: 0.014\n[SYSTEM]\n[SYSTEM] Total number of value data points: 3817\n[SYSTEM] Total number of value data point errors: 2\n[SYSTEM] Value data point error rate: 0.001\n[SYSTEM]\n[SYSTEM] Total number of percentile data points: 3309\n[SYSTEM] Total number of percentile data point errors: 0\n[SYSTEM] Percentile data point error rate: 0.0\n```\n"
      },
      "source": "https://raw.githubusercontent.com/msaifee786/hvf_extraction_script/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "somef_missing_categories": [
    "citation",
    "download",
    "contact",
    "contributors",
    "documentation",
    "faq",
    "support",
    "identifier",
    "has_build_file",
    "executable_example"
  ],
  "somef_provenance": {
    "date": "2024-10-06 06:55:01",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 18
      },
      "technique": "GitHub_API"
    }
  ],
  "usage": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Overview",
        "parent_header": [
          "HVF Extraction Script",
          "Usage"
        ],
        "type": "Text_excerpt",
        "value": "HVF data can be stored in a variety of formats that can be imported into the hvf_extraction_script platform. The platform can import data from 1) HVF single field analysis report images from HFA2 or HFA3 (PNG, JPG, etc - any file format that openCV can read), 2) HVF DICOM files, and 3) serialized JSON files (produced by the script platform). See below for examples on how to import data from these different sources.\n\nOnce imported, data is managed primarily through the Hvf_Object class, which contains the report metadata (name/ID, test date, field size and strategy, etc), and the 5 data plots (raw sensitivity, total deviation value/percentile plots, and pattern deviation value/percentile plots). Plot data is stored as Hvf_Plot_Array objects (internally as 10x10 Numpy arrays), and individual plot data elements are stored as either Hvf_Value or Hvf_Perc_Icon objects. See below for the basic structure of Hvf_Object (and helper classes).\n\nData modules (which are Hvf_Object, Hvf_Plot_Array, Hvf_Value, Hvf_Perc_Icon) are contained in the subpackage hvf_data. hvf_extraction_script also includes two other subpackages, hvf_manager and utilities, that contain modules to assist in data processing.\n\nSubpackage hvf_manager contains functions to 'manage' or process HVF data. This includes a module for running unit tests for image extraction (hvf_test) and a module for exporting Hvf_Objects to human-readable spreadsheet for further processing (hvf_export). There is also a module for calculating HVF metrics (hvf_metric_calculator), but this module is still under development.\n\nSubpackage utilities contains general purpose utility modules not specific to HVF data. This includes a module for file I/O (file_utils), image processing (image_utils), OCR functions (ocr_utils - essentially a wrapper for TesserOCR), and regex functions (regex_utils).\n"
      },
      "source": "https://raw.githubusercontent.com/msaifee786/hvf_extraction_script/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Importing and exporting data",
        "parent_header": [
          "HVF Extraction Script",
          "Usage"
        ],
        "type": "Text_excerpt",
        "value": "Importing/extracting data from an image:\n\n```shell\n>>> from hvf_extraction_script.hvf_data.hvf_object import Hvf_Object\n>>> from hvf_extraction_script.utilities.file_utils import File_Utils\n\n>>> hvf_img_path = \"path/to/hvf/image/file/to/read\";\n>>> hvf_img = File_Utils.read_image_from_file(hvf_img_path);\n>>> hvf_obj = Hvf_Object.get_hvf_object_from_image(hvf_img);\n```\n\nImporting data from a DICOM file:\n\n```shell\n>>> from hvf_extraction_script.hvf_data.hvf_object import Hvf_Object\n>>> from hvf_extraction_script.utilities.file_utils import File_Utils\n\n>>> hvf_dicom_path = \"path/to/hvf/dicom/file/to/read\";\n>>> hvf_dicom = File_Utils.read_dicom_from_file(hvf_dicom_path);\n>>> hvf_obj = Hvf_Object.get_hvf_object_from_dicom(hvf_dicom);\n```\n\nSaving as a text file:\n```shell\n>>> serialized_string = hvf_obj.serialize_to_json();\n>>> txt_file_path = \u201cpath/to/target/file/to/write\u201d;\n>>> File_Utils.write_string_to_file(serialized_string, target_file_path)\n```\n\nReinstantiating Hvf_Object from text file\n```shell\n>>> hvf_txt = File_Utils.read_text_from_file(txt_file_path);\n>>> hvf_obj = Hvf_Object.get_hvf_object_from_text(hvf_txt);\n```\n\nExport to spreadsheet (tab-separated values):\n```shell\n# Takes in a dictionary of filename_string -> hvf_obj\n>>> from hvf_extraction_script.hvf_manager.hvf_export import Hvf_Export;\n\n>>> dict_of_hvf_objs = {\u201cfile1.PNG\u201d: hvf_obj1, \u201cfile2.PNG\u201d: hvf_obj2, \u201cfile3.PNG\u201d: hvf_obj3 };\n>>> spreadsheet_string = Hvf_Export.export_hvf_list_to_spreadsheet(dict_of_hvf_objs)\n>>> File_Utils.write_string_to_file(return_string, \"output_spreadsheet.tsv\")\n# Saves data in a spreadsheet, with first column as filename\n```\n\nImport Hvf_Objects from outputted spreadsheet (tab-separated values):\n```shell\n>>> tsv_file_string = File_Utils.read_text_from_file(\"output_spreadsheet.tsv\");\n>>> dict_of_hvf_objs = Hvf_Export.import_hvf_list_from_spreadsheet(tsv_file_string);\n# Returns dictionary of filename_string -> hvf_obj\n```\n"
      },
      "source": "https://raw.githubusercontent.com/msaifee786/hvf_extraction_script/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Structure of Hvf_Object and helper classes",
        "parent_header": [
          "HVF Extraction Script",
          "Usage"
        ],
        "type": "Text_excerpt",
        "value": "Hvf_Object contains data from the source HVF study within instance variables. Metadata (including name, ID, field size, reliability indices, etc) strings are stored within a instance variable dictionary; data is accessible using keys stored within Hvf_Object as constants:\n\n- KEYLABEL_LAYOUT # Internal data corresponding to layout of source HVF image\n- KEYLABEL_NAME\n- KEYLABEL_DOB\n- KEYLABEL_ID\n- KEYLABEL_TEST_DATE\n- KEYLABEL_LATERALITY\n- KEYLABEL_FOVEA\n- KEYLABEL_FIXATION_LOSS\n- KEYLABEL_FALSE_POS\n- KEYLABEL_FALSE_NEG\n- KEYLABEL_TEST_DURATION\n- KEYLABEL_FIELD_SIZE\n- KEYLABEL_STRATEGY\n- KEYLABEL_PUPIL_DIAMETER\n- KEYLABEL_RX\n- KEYLABEL_MD\n- KEYLABEL_PSD\n- KEYLABEL_VF\n\nMetadata can be accessed from the object as such:\n\n```shell\n# As example, accessing name:\n>>> hvf_obj.metadata[Hvf_Object.KEYLABEL_NAME];\n  'SMITH, JOHN'\n```\n\nAdditionally, there are 5 plots in every HVF object, represented by Hvf_Plot_Array objects. These can be accessed by:\n\n```shell\n# Raw sensitivity array:\nhvf_obj.raw_value_array\n\n# Total deviation value array:\nhvf_obj.abs_dev_value_array\n\n# Pattern deviation value array:\nhvf_obj.pat_dev_value_array\n\n# Total deviation percentile array:\nhvf_obj.abs_dev_percentile_array\n\n# Pattern deviation percentile array:\nhvf_obj.pat_dev_percentile_array\n```\n\nThe main data in the Hvf_Plot_Array object are:\n\n```shell\narray_obj.plot_type\n# Possible values are Hvf_Plot_Array.PLOT_RAW, Hvf_Plot_Array.PLOT_TOTAL_DEV or Hvf_Plot_Array.PLOT_PATTERN_DEV\n\narray_obj.icon_type\n# Possible values are Hvf_Plot_Array.PLOT_VALUE or, Hvf_Plot_Array.PLOT_PERC\n\narray_obj.plot_array\n# 10x10 Numpy array containing either Hvf_Value or Hvf_Perc_Icon (depending on icon_type) representing the value of the plot in that position  \n```\n\nHvf_Value is essentially a wrapper class for a numerical value in a value plot (only relevant datum in this object is Hvf_Value.value, the number to wrap). There are some special non-numerical values that this object can take in specific circumstances, including:\n\n- Hvf_Value.VALUE_NO_VALUE (ie, a blank value - for areas in the plot that are empty) - ' '\n- Hvf_Value.VALUE_FAILURE (ie, the program was unable to determine was the value was - in other words, an program error) '?'\n- Hvf_Value.VALUE_BELOW_THRESHOLD (the value '<0') - '<0 '\n\nValues from Hvf_Value can be queried by calling the method get_value() (ie, hvf_value_obj.get_value()) to get the raw value wrapped, or get_display_string(), which will convert the above cases to a display character/string version for easy reading.\n\nHvf_Perc_Icon is a similar wrapper class for a percentile icon in a percentile plot (again, only relevant datum in this object is Hvf_Perc_Icon.perc_enum, an enum value corresponding to the icon it represents). The possible values are:\n\n- Hvf_Perc_Icon.PERC_NO_VALUE (ie, a blank value - for areas in the plot that are empty) - ' '\n- Hvf_Perc_Icon.PERC_NORMAL (a 'normal' sensitivity - single dot icon) - '.'\n- Hvf_Perc_Icon.PERC_5_PERCENTILE (lower than 5th percentile) - '5'\n- Hvf_Perc_Icon.PERC_2_PERCENTILE (lower than 2nd percentile) - '2'\n- Hvf_Perc_Icon.PERC_1_PERCENTILE (lower than 1st percentile) - '1'\n- Hvf_Perc_Icon.PERC_HALF_PERCENTILE (lower than 0.5th percentile - full black box) - 'x'\n- Hvf_Perc_Icon.PERC_FAILURE (the program was unable to determine was the value was - in other words, an program error) - '?'\n\nValues from Hvf_Perc_Icon can be queried by calling the method get_enum() to get the enum value, or get_display_string(), which will get a character representing the icon.\n\nFor example, to query for a specific value:\n```shell\n# As example, accessing name:\n>>> hvf_obj.metadata[Hvf_Object.KEYLABEL_NAME]\n  'SMITH, JOHN'\n>>> hvf_obj.metadata[Hvf_Object.KEYLABEL_MD]\n  '-5.54'\n>>> hvf_obj.metadata[Hvf_Object.KEYLABEL_VFI]\n  '87%'\n>>> print(hvf_obj.get_display_raw_val_plot_string())\n  Raw Value Plot:\n\n\n             23  24  28  25            \n\n         29  29  28  29  29  28        \n\n     27  27  29  29  29  29  27  25    \n\n     29  27  30  31  27  27  27  27  23\n\n     29   0  27  32  30  28  15  11  <0\n\n     26  27  25  30  31  28   0  <0    \n\n         29  27  27  15   2  <0        \n\n             26  26  23   0            \n\n>>> hvf_obj.raw_value_array.plot_array[7,7].get_value()\n  -97 # In above plot, refers to <0 - value is Hvf_Value.VALUE_BELOW_THRESHOLD\n>>> hvf_obj.raw_value_array.plot_array[7,7].get_display_string()\n  '<0'\n>>> hvf_obj.pat_dev_percentile_array.plot_array[4,4].get_enum()\n  1 # Enum value for Hvf_Perc_Icon.PERC_NORMAL\n>>> hvf_obj.pat_dev_percentile_array.plot_array[4,4].get_display_string()\n  '.' # Character representation of Hvf_Perc_Icon.PERC_NORMAL\n```\n"
      },
      "source": "https://raw.githubusercontent.com/msaifee786/hvf_extraction_script/master/README.md",
      "technique": "header_analysis"
    }
  ]
}