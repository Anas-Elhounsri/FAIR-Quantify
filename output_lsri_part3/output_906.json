{
  "application_domain": [
    {
      "confidence": 18.29,
      "result": {
        "type": "String",
        "value": "Computer Vision"
      },
      "technique": "supervised_classification"
    }
  ],
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/LDWLab/TwinCons"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2019-02-25T22:58:31Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2024-06-25T18:53:52Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "Alignment score for detection of ancient homologies"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 0.9862824024161516,
      "result": {
        "original_header": "TwinCons: analysis toolkit for two sequence groups within an MSA",
        "type": "Text_excerpt",
        "value": "Conservation score that highlights conserved, variable and diverging (signature) positions between two sequence groups within an alignment. The method mathematically determines a \u2018cost\u2019 of transforming one alignment group to the other. Includes automated parsing protocol for the detection of continuous stretches (segments) of high TwinCons scoring columns within protein alignments to query deep ancestry of short peptides.\n \n"
      },
      "source": "https://raw.githubusercontent.com/LDWLab/TwinCons/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9467926528549706,
      "result": {
        "original_header": "<a href=\"./bin/TwinCons.py\">TwinCons.py</a>",
        "type": "Text_excerpt",
        "value": "Generates data for subsequent scripts or can be used independently. Calculates TwinCons conservation for a given alignment.\n \n"
      },
      "source": "https://raw.githubusercontent.com/LDWLab/TwinCons/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9539032874487537,
      "result": {
        "original_header": "Multiple alignment analysis",
        "type": "Text_excerpt",
        "value": "[CalculateSegments.py](./bin/CalculateSegments.py) executes the [TwinCons.py](./bin/TwinCons.py) script for a given folder with sequence alignments. Calculates length, weight, normalized lengths and positions of high scoring segments from the results of TwinCons. \nTries to guess the type of comparison and color code the included datasets. For lower number of alignments (up to 20) applies different color for each alignment. For greater number of alignments tagged in different groups (e.g. A_alignment-nameX.fas, B_alignment-nameY.fas and so on), uses the viridis colormap to color each group of alignments together. For exactly 10 alignments in a folder assumes they are ordered by similarity and colors them with a Purple Green gradient. \nCan pass all options for calculation already present in TwinCons with the option -co. <span style=\"color:red\">However, as of now it does not support structure mapping of scores or using structure defined matrices</span>.  \n<img src=\"./data/CSV/BBS_cg09_it1_lt3.png\">\n \n"
      },
      "source": "https://raw.githubusercontent.com/LDWLab/TwinCons/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9347178898528715,
      "result": {
        "original_header": "Training a classifier",
        "type": "Text_excerpt",
        "value": "Must include parameters used in TwinCons and CalculateSegments. Use the same format as -co from Calculate segments. For example: \nUsage:\n```\ntwcSVMtrain.py [-h] [-twca TWINCONS_ARGS [TWINCONS_ARGS ...]] [-csa CALCSEGM_ARGS [CALCSEGM_ARGS ...]] [-pd PLOT_DF] [-tp PENALTY] [-k {linear,poly,rbf,sigmoid,precomputed}] [-g {auto,scale}]\n                      [-l {absolute,normalized,cms}] [-ts TOP_SEGMENTS]\n                      csv_path output_path\n\nGenerate SVM from alignment segments.\nComputes a decision function from csv generated with twcCalculateSegments\n\npositional arguments:\n  csv_path              Path to csv file storing alignment segment data\n  output_path           Output path\n\noptional arguments:\n  -h, --help            show this help message and exit\n  -twca TWINCONS_ARGS [TWINCONS_ARGS ...], --twincons_args TWINCONS_ARGS [TWINCONS_ARGS ...]\n                        Arguments used with TwinCons.\n  -csa CALCSEGM_ARGS [CALCSEGM_ARGS ...], --calcsegm_args CALCSEGM_ARGS [CALCSEGM_ARGS ...]\n                        Arguments used with twcCalculateSegments.\n  -pd PLOT_DF, --plot_df PLOT_DF\n                        Path to output plot for the decision function.\n  -tp PENALTY, --penalty PENALTY\n                        Penalty for training algorithm. (Default = 1)\n  -k {linear,poly,rbf,sigmoid,precomputed}, --kernel {linear,poly,rbf,sigmoid,precomputed}\n                        Kernel for the training algorithm\n  -g {auto,scale}, --gamma {auto,scale}\n                        Gamma function for training algorithm\n  -l {absolute,normalized,cms}, --length_type_calculation {absolute,normalized,cms}\n                        Choose what type of segment calculation should be used.        \n                                 absolute:   absolute length of the segments.        \n                                 normalized: length of segments is normalized with the total alignment length.        \n                                 cms:        average position (center of mass) from all segments per alignment.\n  -ts TOP_SEGMENTS, --top_segments TOP_SEGMENTS\n                        Limit input for each alignment to the top segments that cover        \n                        this percentage of the total normalized length and weight. (Default = 0.5)\n``` \nExample output of BaliBASE decision boundary:\n<img src=\"./data/outputs/SVM/BBS.png\">\n \n"
      },
      "source": "https://raw.githubusercontent.com/LDWLab/TwinCons/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9907747834573583,
      "result": {
        "original_header": "Testing a classifier",
        "type": "Text_excerpt",
        "value": "Usage:\n```\ntwcSVMtest.py [-h] [-pd PLOT_DF] [-ts TOP_SEGMENTS] [-l {absolute,normalized,cms}] (-tcp | -tqa) [-dt Start End Step] csv_path output_path pickle\n\nEvaluates alignment entries in csv generated from twcCalculateSegments.\nRequires a decision function and json features generated from SVM_train.\nTrain and test only with the same parameters!\nSuch parameters can be % cutting gaps, center mass segments, top segments.\n\npositional arguments:\n  csv_path              Path to csv file storing alignment segment data\n  output_path           Path to output significant segment results\n  pickle                Provide path to classifier pickle binary file. The script will also search for an identically                                    \n                        named file with extension \".json\" containing parameters used for training the classifier, for example:                                    \n                        pickle file:    random_test.pkl                                    \n                        maximal values: random_test.pkl.maxvals\n\noptional arguments:\n  -h, --help            show this help message and exit\n  -pd PLOT_DF, --plot_df PLOT_DF\n                        Path to output plot for the decision function.\n  -ts TOP_SEGMENTS, --top_segments TOP_SEGMENTS\n                        Limit input for each alignment to the top segments that cover                                    \n                         this percentage of the total normalized length and weight. (Default = 0.5)\n  -l {absolute,normalized,cms}, --length_type_calculation {absolute,normalized,cms}\n                        Choose what type of segment calculation should be used.        \n                                 absolute:   absolute length of the segments.        \n                                 normalized: length of segments is normalized with the total alignment length.        \n                                 cms:        average position (center of mass) from all segments per alignment.\n  -tcp, --test_classifier_precision\n                        Provided csv is annotated for testing the classifier.\n  -tqa, --test_query_alignments\n                        Provided csv is a query and is not annotated for testing the classifier.\n  -dt Start End Step, --range_distance_thresholds Start End Step\n                        Range of distances from the decision boundary to evaluate.                                    \n                        Default for non evalue (-20, 20, 0.05).\n``` \n"
      },
      "source": "https://raw.githubusercontent.com/LDWLab/TwinCons/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8484852155442734,
      "result": {
        "original_header": "Average distance",
        "type": "Text_excerpt",
        "value": "In the case of large segments there will be few segments and they will be far away from the boundary => cost nearing 0. In the case of many small segments their distance to the boundary will be accumulated resulting in big negative number (larger than any segment can attain on it's own) => cost nearing infinity.\n \n"
      },
      "source": "https://raw.githubusercontent.com/LDWLab/TwinCons/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8712366895236738,
      "result": {
        "original_header": "Identifying significant segments",
        "type": "Text_excerpt",
        "value": "<img src=\"./data/outputs/SVM/BBS_vs_BBS.png\">\n \n"
      },
      "source": "https://raw.githubusercontent.com/LDWLab/TwinCons/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/LDWLab/TwinCons/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 1
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/LDWLab/TwinCons/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "LDWLab/TwinCons"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "TwinCons: analysis toolkit for two sequence groups within an MSA"
      },
      "source": "https://raw.githubusercontent.com/LDWLab/TwinCons/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "has_script_file": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/LDWLab/TwinCons/master/crossValidateTests.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/LDWLab/TwinCons/master/twincons/test_parameter.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/LDWLab/TwinCons/master/twincons/test_new_params.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/LDWLab/TwinCons/master/twincons/ROC_crossval.sh"
      },
      "technique": "file_exploration"
    }
  ],
  "images": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/LDWLab/TwinCons/master/./data/CSV/BBS_cg09_it1_lt3.png"
      },
      "source": "https://raw.githubusercontent.com/LDWLab/TwinCons/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/LDWLab/TwinCons/master/./data/outputs/SVM/BBS.png"
      },
      "source": "https://raw.githubusercontent.com/LDWLab/TwinCons/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/LDWLab/TwinCons/master/./data/outputs/SVM/BBS_vs_BBS.png"
      },
      "source": "https://raw.githubusercontent.com/LDWLab/TwinCons/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "invocation": [
    {
      "confidence": 0.880430949663168,
      "result": {
        "original_header": "Multiple alignment analysis",
        "type": "Text_excerpt",
        "value": "Typical usage:\n```\ntwcCalculateSegments.py ./folder_with_alignments/ ./output_file -c -cms 9 -co cg gt_0.9 phy bl\n```\nUsage:\nBASH2* \nSample output: \n<img src=\"./data/CSV/BBS_cg09_it1_lt3.png\">\n \n"
      },
      "source": "https://raw.githubusercontent.com/LDWLab/TwinCons/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.909659486130789,
      "result": {
        "original_header": "Training a classifier",
        "type": "Text_excerpt",
        "value": "\ttwcSVMtrain.py output.csv output.pkl -pd output.png -ts 1 -tp 1 -twca mx_blosum62 gt_0.9 cg -csa lt_3 it_2 \nExample output of BaliBASE decision boundary:\n<img src=\"./data/outputs/SVM/BBS.png\">\n \n"
      },
      "source": "https://raw.githubusercontent.com/LDWLab/TwinCons/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8406204516208453,
      "result": {
        "original_header": "Identifying significant segments",
        "type": "Text_excerpt",
        "value": "<img src=\"./data/outputs/SVM/BBS_vs_BBS.png\">\n \n"
      },
      "source": "https://raw.githubusercontent.com/LDWLab/TwinCons/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/LDWLab/TwinCons/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ""
      },
      "technique": "GitHub_API"
    }
  ],
  "license": [
    {
      "confidence": 1,
      "result": {
        "name": "MIT License",
        "spdx_id": "MIT",
        "type": "License",
        "url": "https://api.github.com/licenses/mit",
        "value": "https://api.github.com/licenses/mit"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "type": "File_dump",
        "value": "Copyright 2020 Petar Penev\n\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
      },
      "source": "https://raw.githubusercontent.com/LDWLab/TwinCons/master/LICENSE",
      "technique": "file_exploration"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "TwinCons"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "Organization",
        "value": "LDWLab"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 388722,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Promela",
        "size": 318323,
        "type": "Programming_language",
        "value": "Promela"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Shell",
        "size": 30340,
        "type": "Programming_language",
        "value": "Shell"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/LDWLab/TwinCons/master/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "requirements": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Dependencies",
        "parent_header": [
          "TwinCons: analysis toolkit for two sequence groups within an MSA"
        ],
        "type": "Text_excerpt",
        "value": "Programs required to be present in the PATH:\n- MAFFT https://mafft.cbrc.jp/alignment/software/\n- DSSP https://swift.cmbi.umcn.nl/gv/dssp/ or in Linux just execute\n\t> apt-get install dssp\n"
      },
      "source": "https://raw.githubusercontent.com/LDWLab/TwinCons/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "somef_missing_categories": [
    "installation",
    "citation",
    "acknowledgement",
    "run",
    "download",
    "contact",
    "contributors",
    "documentation",
    "faq",
    "support",
    "identifier",
    "has_build_file",
    "executable_example"
  ],
  "somef_provenance": {
    "date": "2024-10-06 02:47:03",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 5
      },
      "technique": "GitHub_API"
    }
  ],
  "usage": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Usage",
        "parent_header": [
          "TwinCons: analysis toolkit for two sequence groups within an MSA",
          "<a href=\"./bin/TwinCons.py\">TwinCons.py</a>"
        ],
        "type": "Text_excerpt",
        "value": "1. Input files\n- One fasta alignment file with two defined groups **(Required)**. If no groups are defined a phylogenetic tree can be built from the alignment, the groups are defined by the deepest branching point in the tree. Alternatively two alignment files can be provided, each defining a single group - mafft-merge will be used to merge them in a single alignment.\n- One or two structure files for each group to map data. The name of the file must include the sequence group name as defined in the alignment. (Optional)\n\nExample sequence group definitions in fasta format:\n```\n>GROUP1_TAXID1_SEQNAME1\nMTKF-EVPKEISDKVLQTLELAKNTG\n>GROUP1_TAXID2_SEQNAME2\nMTKF-EVPKEISDKVLQTLELAKNTG\n>GROUP2_TAXID3_SEQNAME3\nMTKF-EVPKEISDKVLQTLELAKNTG\n>GROUP2_TAXID4_SEQNAME4\nMTKF-EVPKEISDKVLQTLELAKNTG\n```\n\nExample structure file naming:\n```\nSEQNAME1_GROUP1.pdb\nSEQNAME3_GROUP2.pdb\n```\n\nTypical usage:\n```\nTwinCons.py -a ./data/ALNS/test_aln.fa -mx blosum62 -csv -o ./test_aln\nTwinCons.py -a ./data/ALNS/casp9-mcasp_struct.fa -pml unix -s ./data/PDB/HUMAN_CASP9.pdb ./data/PDB/YEAST_MCASP.pdb -ssbe -sy ./data/PDB/HUMAN_CASP9.pdb ./data/PDB/YEAST_MCASP.pdb -o ./twc_ssbe_HS-CASP9_SC-MCASP\n```\n\n2. Output files\n\t- **pml file** for all structures with residue colors defined by the score\n\t- **svg** with score trace for alignment position\n\t- **csv** output for [**RiboVision**](http://apollo.chemistry.gatech.edu/RiboVision2/) when provided with structure file\n\t- **csv** output with scores per alignment position\n\t- **optional data** if ran as a module within other python scripts **for multiple alignment analysis**\n\nUsage:\n```\nTwinCons.py [-h] [-o OUTPUT_PATH] (-a ALIGNMENT_PATHS [ALIGNMENT_PATHS ...] | -as ALIGNMENT_STRING) [-bn {uniform,bgfreq}] [-cg] [-gg] [-gt GAP_THRESHOLD] [-s STRUCTURE_PATHS [STRUCTURE_PATHS ...]] [-sy STRUCTURE_PYMOL [STRUCTURE_PYMOL ...]]\n                   [-phy] [-nc] [-w {pairwise,voronoi}] [-ca] (-p | -pml {unix,windows} | -r | -csv | -rv | -jv)\n                   [-mx {benner6,benner22,benner74,blosum100,blosum30,blosum35,blosum40,blosum45,blosum50,blosum55,blosum60,blosum62,blosum65,blosum70,blosum75,blosum80,blosum85,blosum90,blosum95,genetic,gonnet,ident,johnson,levin,miyata,nwsgappep,pam120,pam180,pam250,pam30,pam300,pam60,pam90,risler,structure,blastn,identity,trans} | -cm CUSTOM_MATRIX | -lg | -e | -rs]\n                   [-ss | -be | -ssbe]\n\nCalculate and visualize conservation between two groups of sequences from one alignment\n\noptional arguments:\n  -h, --help            show this help message and exit\n  -o OUTPUT_PATH, --output_path OUTPUT_PATH\n                        Output path\n  -a ALIGNMENT_PATHS [ALIGNMENT_PATHS ...], --alignment_paths ALIGNMENT_PATHS [ALIGNMENT_PATHS ...]\n                        Path to alignment files. If given two files it will use mafft --merge to merge them in single alignment.\n  -as ALIGNMENT_STRING, --alignment_string ALIGNMENT_STRING\n                        Alignment string\n  -bn {uniform,bgfreq}, --baseline {uniform,bgfreq}\n                        Whether to baseline the used matrix with the uniform vector or with the matrix background frequency.\n                                (Default: bgfreq)\n  -cg, --cut_gaps       Remove alignment positions with % gaps greater than the specified value with gap_threshold.\n  -gg, --calculate_group_gaps\n                        Calculate alignment position gaps in 3 groups using 2*gap threshold value:\n                                Ungapped - Aligned positions;\n                                GroupGap - Only one group has sequences;\n                                AllGap - Both groups are gapped.\n  -gt GAP_THRESHOLD, --gap_threshold GAP_THRESHOLD\n                        Specify % gaps per alignment position. (Default = the smaller between ((sequences of group1)/(all sequences) and (sequences of group2)/(all sequences)) minus 0.05)\n  -s STRUCTURE_PATHS [STRUCTURE_PATHS ...], --structure_paths STRUCTURE_PATHS [STRUCTURE_PATHS ...]\n                        Paths to structure files, for score calculation. Does not work with --nucleotide!\n  -sy STRUCTURE_PYMOL [STRUCTURE_PYMOL ...], --structure_pymol STRUCTURE_PYMOL [STRUCTURE_PYMOL ...]\n                        Paths to structure files, for plotting a pml.\n  -phy, --phylo_split   Split the alignment in two groups by constructing a tree instead of looking for _ separated strings.\n  -nc, --nucleotide     Input is nucleotide sequence. Specify nucleotide matrix for score calculation with -mx or entropy calculations with -e or -rs\n  -w {pairwise,voronoi}, --weigh_sequences {pairwise,voronoi}\n                        Weigh sequences within each alignment group.\n  -ca, --compositional_adjustment\n                        Adjust the substitution matrix with residue frequencies computed from the two alignment groups.\n                         Available only for BLOSUM matrices, using the methods decribed in doi.org/10.1073/pnas.2533904100 and doi.org/10.1093/bioinformatics/bti070.\n  -p, --plotit          Plots the calculated score as a bar graph for each alignment position.\n  -pml {unix,windows}, --write_pml_script {unix,windows}\n                        Writes out a PyMOL coloring script for any structure files that have been defined. Choose between unix or windows style paths for the pymol script.\n  -r, --return_within   To be used from within other python programs. Returns dictionary of alnpos->score.\n  -csv, --return_csv    Saves a csv with alignment position -> score.\n  -rv, --ribovision     Saves a csv formatted for RiboVision. Requires at least one structure defined with the -sy argument.\n  -jv, --jalview_output\n                        Saves an annotation file for Jalview.\n  -mx {benner6,benner22,benner74,blosum100,blosum30,blosum35,blosum40,blosum45,blosum50,blosum55,blosum60,blosum62,blosum65,blosum70,blosum75,blosum80,blosum85,blosum90,blosum95,genetic,gonnet,ident,johnson,levin,miyata,nwsgappep,pam120,pam180,pam250,pam30,pam300,pam60,pam90,risler,structure,blastn,identity,trans}, --substitution_matrix {benner6,benner22,benner74,blosum100,blosum30,blosum35,blosum40,blosum45,blosum50,blosum55,blosum60,blosum62,blosum65,blosum70,blosum75,blosum80,blosum85,blosum90,blosum95,genetic,gonnet,ident,johnson,levin,miyata,nwsgappep,pam120,pam180,pam250,pam30,pam300,pam60,pam90,risler,structure,blastn,identity,trans}\n                        Choose a substitution matrix for score calculation.\n  -cm CUSTOM_MATRIX, --custom_matrix CUSTOM_MATRIX\n                        Provide path to a custom PAML format matrix. For example format see the matrices folder.\n  -lg, --leegascuel     Use LG matrix for score calculation\n  -e, --shannon_entropy\n                        Use shannon entropy for conservation calculation.\n  -rs, --reflected_shannon\n                        Use shannon entropy for conservation calculation and reflect the result so that a fully random sequence will be scored as 0.\n  -ss, --secondary_structure\n                        Use substitution matrices derived from data dependent on the secondary structure assignment.\n  -be, --burried_exposed\n                        Use substitution matrices derived from data dependent on the solvent accessability of a residue.\n  -ssbe, --both         Use substitution matrices derived from data dependent on both the secondary structure and the solvent accessability of a residue.\n```\n"
      },
      "source": "https://raw.githubusercontent.com/LDWLab/TwinCons/master/README.md",
      "technique": "header_analysis"
    }
  ]
}