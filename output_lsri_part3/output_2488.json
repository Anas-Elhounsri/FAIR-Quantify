{
  "application_domain": [
    {
      "confidence": 79.17,
      "result": {
        "type": "String",
        "value": "Computer Vision"
      },
      "technique": "supervised_classification"
    }
  ],
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/kamruleee51/ART-Net"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2019-02-05T15:11:38Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2024-09-01T14:27:28Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "This project presents a Single Input Multiple Output (SIMO) deep convolutional neural network, a so-called ART-Net (Augmented Reality Tool Network) consisting of an encoder-decoder architecture to obtain the surgical tool detection, segmentation, and geometric features concurrently in an end-to-end fashion.  "
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 0.9565769455568293,
      "result": {
        "original_header": "<a href=\"https://www.sciencedirect.com/science/article/abs/pii/S1361841521000402\">Detection, Segmentation, and 3D Pose Estimation of Surgical Tools Using Deep Convolutional Neural Networks and Algebraic Geometry</a>",
        "type": "Text_excerpt",
        "value": "This repository contains the source code, results, and annotation details of the proposed dataset for the concurrent detection, segmentation, and 3D pose estimation of surgical tools using deep convolutional neural networks and algebraic geometry. However, the directory tree of this repository is manifested as follows: \nSurgical tool detection, segmentation, and 3D pose estimation are crucial components in Computer-Assisted Laparoscopy (CAL). The existing frameworks have two main limitations. First, they do not integrate all three components. Integration is critical; for instance, one should not attempt computing pose if detection is negative. Second, they have highly specific requirements, such as the availability of a CAD model. We propose an integrated and generic framework whose sole requirement for the 3D pose is that the tool shaft is cylindrical. Our framework makes the most of deep learning and geometric 3D vision by combining a proposed Convolutional Neural Network (CNN) with algebraic geometry.\nWe show two applications of our framework in CAL: tool-aware rendering in Augmented Reality (AR) and tool-based 3D measurement. \nThis project proposed ART-Net to detect, segment, and extract three geometric primitives simultaneously from the laparoscopic images. \nThese primitives are the tool edge-lines, mid-line, and tip. They allow the tool's 3D pose to be estimated by a fast algebraic procedure. The framework only proceeds if a tool is detected. The accuracy of segmentation and geometric primitive extraction is boosted by a new Full resolution feature map Generator (FrG). We extensively evaluate the proposed framework with the  EndoVis and new proposed datasets. \nWe compare the segmentation results against several variants of the Fully Convolutional Network (FCN) and U-Net. Several ablation studies are provided for detection, segmentation, and geometric primitive extraction.\nThe proposed datasets are surgery videos of different patients. \nHowever, more details can be found in the article ([here](https://www.sciencedirect.com/science/article/abs/pii/S1361841521000402)) in Medical Image Analysis (Elsevier).  \n \n"
      },
      "source": "https://raw.githubusercontent.com/kamruleee51/ART-Net/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9832717184687104,
      "result": {
        "original_header": "Network Training",
        "type": "Text_excerpt",
        "value": "Two stages of training and testing were used (section 4.2 of [article](https://www.sciencedirect.com/science/article/abs/pii/S1361841521000402) presents details). In the first stage, referred to as stage-1, we trained and tested only the segmentation sub-network of ART-Net on the EndoVis (robotic) dataset, whereas in the second stage, referred to as stage-2, we trained and tested the whole ART-Net on the combined EndoVis (non-robotic) and our annotated data.\nThe following three sets of datasets are utilized in this [article](https://www.sciencedirect.com/science/article/abs/pii/S1361841521000402).  \n"
      },
      "source": "https://raw.githubusercontent.com/kamruleee51/ART-Net/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9352482060803847,
      "result": {
        "original_header": "Data Annotation",
        "type": "Text_excerpt",
        "value": "Five points are selected and extracted as CSV together with the ROI selection from the ImageJ software, and then basic image processing methods are used to generate the edge-line, mid-line, and tip-point. The selected five points are displayed in the following figure. Those five points are utilized to generate three geometric primitives applying a simple python script. The primitives hold an intensity of bell-shaped Gaussian distribution. \nOur annotated dataset is made publicly available for research or academic purposes only. However, to access our annotated dataset, the audience is requested to fill the following google form.  \n"
      },
      "source": "https://raw.githubusercontent.com/kamruleee51/ART-Net/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/kamruleee51/ART-Net/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "executable_example": [
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/kamruleee51/ART-Net/master/SourceCodes/ART-Net_Performance_Measurement.ipynb"
      },
      "source": "https://raw.githubusercontent.com/kamruleee51/ART-Net/master/SourceCodes/ART-Net_Performance_Measurement.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/kamruleee51/ART-Net/master/SourceCodes/Test_of_ART-Net.ipynb"
      },
      "source": "https://raw.githubusercontent.com/kamruleee51/ART-Net/master/SourceCodes/Test_of_ART-Net.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/kamruleee51/ART-Net/master/SourceCodes/Train_of_ART-Net_Stage-2.ipynb"
      },
      "source": "https://raw.githubusercontent.com/kamruleee51/ART-Net/master/SourceCodes/Train_of_ART-Net_Stage-2.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/kamruleee51/ART-Net/master/SourceCodes/Feature_Approximation.ipynb"
      },
      "source": "https://raw.githubusercontent.com/kamruleee51/ART-Net/master/SourceCodes/Feature_Approximation.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/kamruleee51/ART-Net/master/SourceCodes/.ipynb_checkpoints/Train_of_ART-Net_Stage-2-checkpoint.ipynb"
      },
      "source": "https://raw.githubusercontent.com/kamruleee51/ART-Net/master/SourceCodes/.ipynb_checkpoints/Train_of_ART-Net_Stage-2-checkpoint.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/kamruleee51/ART-Net/master/SourceCodes/.ipynb_checkpoints/Feature_Approximation-checkpoint.ipynb"
      },
      "source": "https://raw.githubusercontent.com/kamruleee51/ART-Net/master/SourceCodes/.ipynb_checkpoints/Feature_Approximation-checkpoint.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/kamruleee51/ART-Net/master/SourceCodes/.ipynb_checkpoints/ART-Net_Performance_Measurement-checkpoint.ipynb"
      },
      "source": "https://raw.githubusercontent.com/kamruleee51/ART-Net/master/SourceCodes/.ipynb_checkpoints/ART-Net_Performance_Measurement-checkpoint.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/kamruleee51/ART-Net/master/SourceCodes/.ipynb_checkpoints/Test_of_ART-Net-checkpoint.ipynb"
      },
      "source": "https://raw.githubusercontent.com/kamruleee51/ART-Net/master/SourceCodes/.ipynb_checkpoints/Test_of_ART-Net-checkpoint.ipynb",
      "technique": "file_exploration"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 4
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/kamruleee51/ART-Net/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "kamruleee51/ART-Net"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ""
      },
      "source": "https://raw.githubusercontent.com/kamruleee51/ART-Net/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "images": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://user-images.githubusercontent.com/32570071/106894583-5dc58080-6719-11eb-8209-8ad723994d10.png"
      },
      "source": "https://raw.githubusercontent.com/kamruleee51/ART-Net/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://user-images.githubusercontent.com/32570071/58099671-6b04a980-7bdc-11e9-83b4-c680de96beba.png"
      },
      "source": "https://raw.githubusercontent.com/kamruleee51/ART-Net/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://user-images.githubusercontent.com/32570071/58098941-dc435d00-7bda-11e9-8845-1f16a9945198.JPG"
      },
      "source": "https://raw.githubusercontent.com/kamruleee51/ART-Net/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://user-images.githubusercontent.com/32570071/58100378-ce430b80-7bdd-11e9-93bd-b573ca924951.jpg"
      },
      "source": "https://raw.githubusercontent.com/kamruleee51/ART-Net/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "installation": [
    {
      "confidence": 0.8770905209425333,
      "result": {
        "original_header": "<a href=\"https://www.sciencedirect.com/science/article/abs/pii/S1361841521000402\">Detection, Segmentation, and 3D Pose Estimation of Surgical Tools Using Deep Convolutional Neural Networks and Algebraic Geometry</a>",
        "type": "Text_excerpt",
        "value": "<img src=\"https://user-images.githubusercontent.com/32570071/106894583-5dc58080-6719-11eb-8209-8ad723994d10.png\" width=\"750\" height=\"500\" /> \n"
      },
      "source": "https://raw.githubusercontent.com/kamruleee51/ART-Net/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9862270212581019,
      "result": {
        "original_header": "Data Annotation",
        "type": "Text_excerpt",
        "value": "<img src=\"https://user-images.githubusercontent.com/32570071/58100378-ce430b80-7bdd-11e9-93bd-b573ca924951.jpg\" width=\"700\" height=\"290\" /> \n"
      },
      "source": "https://raw.githubusercontent.com/kamruleee51/ART-Net/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/kamruleee51/ART-Net/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "art-net, convolutional-neural-network, deep-learning, detection, geometric-features, instrument-physical-properties, segmentation"
      },
      "technique": "GitHub_API"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "ART-Net"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "User",
        "value": "kamruleee51"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Jupyter Notebook",
        "size": 362236,
        "type": "Programming_language",
        "value": "Jupyter Notebook"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/kamruleee51/ART-Net/master/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "somef_missing_categories": [
    "citation",
    "acknowledgement",
    "run",
    "download",
    "requirements",
    "contact",
    "contributors",
    "documentation",
    "license",
    "usage",
    "faq",
    "support",
    "identifier",
    "has_build_file"
  ],
  "somef_provenance": {
    "date": "2024-10-06 09:03:22",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 18
      },
      "technique": "GitHub_API"
    }
  ],
  "type": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "notebook-application"
      },
      "technique": "software_type_heuristics"
    }
  ]
}