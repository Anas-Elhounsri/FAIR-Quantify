{
  "application_domain": [
    {
      "confidence": 65.79,
      "result": {
        "type": "String",
        "value": "Computer Vision"
      },
      "technique": "supervised_classification"
    }
  ],
  "citation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Citation",
        "parent_header": [
          "Relative Neural Architecture Search via Slow-Fast Learning"
        ],
        "type": "Text_excerpt",
        "value": "If you use our code in your research, please cite our [paper](https://arxiv.org/abs/2009.06193):\n```\n@article{tan2020relative,\n  title={RelativeNAS: Relative Neural Architecture Search via Slow-Fast Learning},\n  author={Tan, Hao and Cheng, Ran and Huang, Shihua and He, Cheng and Qiu, Changxiao and Yang, Fan and Luo, Ping},\n  journal={arXiv preprint arXiv:2009.06193},\n  year={2020}\n}\n```\n"
      },
      "source": "https://raw.githubusercontent.com/EMI-Group/RelativeNAS/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "author": "Tan, Hao and Cheng, Ran and Huang, Shihua and He, Cheng and Qiu, Changxiao and Yang, Fan and Luo, Ping",
        "format": "bibtex",
        "title": "RelativeNAS: Relative Neural Architecture Search via Slow-Fast Learning",
        "type": "Text_excerpt",
        "value": "@article{tan2020relative,\n    year = {2020},\n    journal = {arXiv preprint arXiv:2009.06193},\n    author = {Tan, Hao and Cheng, Ran and Huang, Shihua and He, Cheng and Qiu, Changxiao and Yang, Fan and Luo, Ping},\n    title = {RelativeNAS: Relative Neural Architecture Search via Slow-Fast Learning},\n}"
      },
      "source": "https://raw.githubusercontent.com/EMI-Group/RelativeNAS/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/EMI-Group/RelativeNAS"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2020-08-22T02:53:12Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2024-04-10T19:39:58Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "The official implementation of RelativeNAS"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 0.9744510904769704,
      "result": {
        "original_header": "Pretrained models",
        "type": "Text_excerpt",
        "value": "2. \n```\n python test_imagenet.py --auxiliary --model_path ./trained_model/imagenet_model.pt --arch RelativeNAS --gpus 0,1 --data_path 'the path of your image data (lmdb)'\n```\n* Expected result: 24.88% top-1 error and 7.7% top-5 with 5.05M model params.\n \n"
      },
      "source": "https://raw.githubusercontent.com/EMI-Group/RelativeNAS/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9585751744136837,
      "result": {
        "original_header": "Architecture search (using small proxy models)",
        "type": "Text_excerpt",
        "value": "In detail, ```model_search.py``` is used to define the model. \nIt uses BASH3* to contain all the possible operations and only initial its own operations.\nBASH4* attribute is used to specify what operations the model has.\n```slow_fast_learning.py``` defines all the tools for the slow-fast learning, such as population initialization, architecture decoding, et. al.\nThe rule to update the weight set is also defined.\n \n"
      },
      "source": "https://raw.githubusercontent.com/EMI-Group/RelativeNAS/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8710770829035455,
      "result": {
        "original_header": "Architecture evaluation (using full-sized models)",
        "type": "Text_excerpt",
        "value": "Please refer to the [TrasferLearning-Tasks](https://github.com/EMI-Group/TransferLearning-Tasks) for the trasfer learning tasks in our RelativeNAS.   \n"
      },
      "source": "https://raw.githubusercontent.com/EMI-Group/RelativeNAS/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/EMI-Group/RelativeNAS/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 5
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/EMI-Group/RelativeNAS/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "EMI-Group/RelativeNAS"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "Relative Neural Architecture Search via Slow-Fast Learning"
      },
      "source": "https://raw.githubusercontent.com/EMI-Group/RelativeNAS/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "images": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/EMI-Group/RelativeNAS/master/./img/slow_fast_learning.png"
      },
      "source": "https://raw.githubusercontent.com/EMI-Group/RelativeNAS/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "invocation": [
    {
      "confidence": 0.8879751407852439,
      "result": {
        "original_header": "Pretrained models",
        "type": "Text_excerpt",
        "value": "2. \n```\n python test_imagenet.py --auxiliary --model_path ./trained_model/imagenet_model.pt --arch RelativeNAS --gpus 0,1 --data_path 'the path of your image data (lmdb)'\n```\n* Expected result: 24.88% top-1 error and 7.7% top-5 with 5.05M model params.\n \n"
      },
      "source": "https://raw.githubusercontent.com/EMI-Group/RelativeNAS/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8732729366087555,
      "result": {
        "original_header": "Architecture evaluation (using full-sized models)",
        "type": "Text_excerpt",
        "value": "To evaluate our architecture by training from scratch, run\n```\npython train.py --auxiliary --cutout --set cifar10\n```\nCustomized architectures are supported through the `--arch` flag once specified in `genotypes.py`. \nTraining the searched model over ImageNet dataset with the following script.<br>\n```\npython train_imagenet.py --data_path 'The path of ImageNet lmdb data' --init_channels 46 --layers 14 --arch RelativeNAS --gpus 0,1,2,3\n``` \n"
      },
      "source": "https://raw.githubusercontent.com/EMI-Group/RelativeNAS/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/EMI-Group/RelativeNAS/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ""
      },
      "technique": "GitHub_API"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "RelativeNAS"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "Organization",
        "value": "EMI-Group"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 121547,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/EMI-Group/RelativeNAS/master/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "related_papers": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://arxiv.org/abs/2009.06193_.\n\n<p align=\"center\">\n  <img src=\"./img/slow_fast_learning.png\" alt=\"slow_fast_learning\" width=\"95%\">\n</p>\n\n## Requirements\n```\nPython >= 3.6, PyTorch == 1.3.0, torchvision >= 0.2\n```\n\n**RelativeNAS** is based on continuous encoding in cell-based search space. \nBesides, it uses a slow-fast learning paradigm to iteratively update the architecture vectors in the population.\nA weight set is also contained to reduce the cost for performance estimations of candidate architectures.\nTherefore, it can efficiently design high-performance convolutional architectures for image classification.\nThe architecture directly searched on CIFAR-10 can transfer into other intra- and inter-tasks, such as CIFAR-100, ImageNet, and PASCAL VOC 2007 et al.\nThe search process only requires a single GPU (1080 Ti) for nine hours.\n\n**This code is based on the implementation of  [DARTS](https://github.com/quark0/darts) and [DenseNAS](https://github.com/JaminFong/DenseNAS.git).**\n\n\n## Pretrained models\nOur pretrained models are provided for evaluation.\n\n**CIFAR-10** ([cifar10.pt](./trained_model/cifar10_model.pt))\n```\n python test.py --auxiliary --model_path ./trained_model/cifar10_model.pt --set cifar10\n```\n* Expected result: 2.26% test error rate with 3.93M model params.\n\n**CIFAR-100** ([cifar100_model.pt](./trained_model/cifar100_model.pt))\n```\n python test.py --auxiliary --model_path ./trained_model/cifar100_model.pt --set cifar100\n```\n* Expected result: 15.86% test error rate with 3.98M model params.\n\n**ImageNet** ([imagenet.pt](./trained_model/imagenet_model.pt))\n1. We pack the ImageNet data as the lmdb file for faster IO. The lmdb files can be made as follows. \n\n    1). Generate the list of the image data.<br>\n    ```\n    python dataset/mk_img_list.py --image_path 'the path of your image data' --output_path 'the path to output the list file'\n    ```\n    2). Use the image list obtained above to make the lmdb file.<br>\n    ```\n    python dataset/img2lmdb.py --image_path 'the path of your image data' --list_path 'the path of your image list' --output_path 'the path to output the lmdb file' --split 'split folder (train/val)'\n    ```\n\n2. \n```\n python test_imagenet.py --auxiliary --model_path ./trained_model/imagenet_model.pt --arch RelativeNAS --gpus 0,1 --data_path 'the path of your image data (lmdb)'\n```\n* Expected result: 24.88% top-1 error and 7.7% top-5 with 5.05M model params.\n\n## Architecture search (using small proxy models)\nTo carry out architecture search on CIFAR-10, run\n```\npython train_search.py     # for conv cells on CIFAR-10\n```\n\nIn detail, ```model_search.py``` is used to define the model. \nIt uses ```nn.ModuleList()``` to contain all the possible operations and only initial its own operations.\n```arch_info``` attribute is used to specify what operations the model has.\n\n```slow_fast_learning.py``` defines all the tools for the slow-fast learning, such as population initialization, architecture decoding, et. al.\nThe rule to update the weight set is also defined.\n\n## Architecture evaluation (using full-sized models)\nTo evaluate our architecture by training from scratch, run\n```\npython train.py --auxiliary --cutout --set cifar10\n```\nCustomized architectures are supported through the `--arch` flag once specified in `genotypes.py`.\n\n**ImageNet**\n\nTraining the searched model over ImageNet dataset with the following script.<br>\n```\npython train_imagenet.py --data_path 'The path of ImageNet lmdb data' --init_channels 46 --layers 14 --arch RelativeNAS --gpus 0,1,2,3\n```\n\n**TransferLearning Tasks**\n\nPlease refer to the [TrasferLearning-Tasks](https://github.com/EMI-Group/TransferLearning-Tasks) for the trasfer learning tasks in our RelativeNAS.  \n\n\n## Citation\nIf you use our code in your research, please cite our [paper](https://arxiv.org/abs/2009.06193):\n```\n@article{tan2020relative,\n  title={RelativeNAS: Relative Neural Architecture Search via Slow-Fast Learning"
      },
      "source": "https://raw.githubusercontent.com/EMI-Group/RelativeNAS/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://arxiv.org/abs/2009.06193"
      },
      "source": "https://raw.githubusercontent.com/EMI-Group/RelativeNAS/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "requirements": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Requirements",
        "parent_header": [
          "Relative Neural Architecture Search via Slow-Fast Learning"
        ],
        "type": "Text_excerpt",
        "value": "```\nPython >= 3.6, PyTorch == 1.3.0, torchvision >= 0.2\n```\n\n**RelativeNAS** is based on continuous encoding in cell-based search space. \nBesides, it uses a slow-fast learning paradigm to iteratively update the architecture vectors in the population.\nA weight set is also contained to reduce the cost for performance estimations of candidate architectures.\nTherefore, it can efficiently design high-performance convolutional architectures for image classification.\nThe architecture directly searched on CIFAR-10 can transfer into other intra- and inter-tasks, such as CIFAR-100, ImageNet, and PASCAL VOC 2007 et al.\nThe search process only requires a single GPU (1080 Ti) for nine hours.\n\n**This code is based on the implementation of  [DARTS](https://github.com/quark0/darts) and [DenseNAS](https://github.com/JaminFong/DenseNAS.git).**\n\n"
      },
      "source": "https://raw.githubusercontent.com/EMI-Group/RelativeNAS/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "somef_missing_categories": [
    "installation",
    "acknowledgement",
    "run",
    "download",
    "contact",
    "contributors",
    "documentation",
    "license",
    "usage",
    "faq",
    "support",
    "identifier",
    "has_build_file",
    "executable_example"
  ],
  "somef_provenance": {
    "date": "2024-10-06 05:24:55",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 46
      },
      "technique": "GitHub_API"
    }
  ]
}