{
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/ernstlab/X-CNN"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2019-01-17T22:52:30Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2021-06-03T09:55:29Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "Computational method for fine-mapping chromatin interactions, e.g., Hi-C"
      },
      "technique": "GitHub_API"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/ernstlab/X-CNN/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 1
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/ernstlab/X-CNN/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "ernstlab/X-CNN"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "Running X-CNN"
      },
      "source": "https://raw.githubusercontent.com/ernstlab/X-CNN/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "installation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Preparation",
        "parent_header": [
          "Running X-CNN"
        ],
        "type": "Text_excerpt",
        "value": "You will first need to either (1) create a database file using ChIP db or (2) create numpy matrices for training.\n"
      },
      "source": "https://raw.githubusercontent.com/ernstlab/X-CNN/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "ChIP-seq track files",
        "parent_header": [
          "Running X-CNN",
          "Preparation"
        ],
        "type": "Text_excerpt",
        "value": "These are feature tracks to be used for training the model and fine-mapping. The format should be either bedgraph or wig files. To create the database, simply run\n\n`python3 chip_db.py [cell_type] [data_res] [/path/to/hg19.chrom.sizes] [track1 track2 ...]`\n\nThe `cell_type` argument is simply the name of the cell or tissue type. The `data_res` argument is the resolution of the data when binning. We recommend using either 50 or 100. You will also need a file with the size of the chromosomes (e.g., http://hgdownload.cse.ucsc.edu/goldenPath/hg19/bigZips/hg19.chrom.sizes). This is simply a two-column text file, where the first column is a chromosome name, and the second column is the length of the chromosome. When running the above script, it may take a while, but once built, you can easily use it with X-CNN or for your own purposes.\n\nThe interaction peaks can all be of the same size (as in FitHiC) or different sizes (as in HiCCUPs). X-CNN will extend them all to the same size. Modifying the method to train on different size peaks is to be implemented at a later date.\n\n## Running X-CNN\n\nTo run X-CNN, you will need to provide it either (1) a database file, explained above, or (2) numpy matrices representing ChIP / DNase data. Either way, you will need and a chromatin interaction peak file.\n"
      },
      "source": "https://raw.githubusercontent.com/ernstlab/X-CNN/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/ernstlab/X-CNN/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ""
      },
      "technique": "GitHub_API"
    }
  ],
  "license": [
    {
      "confidence": 1,
      "result": {
        "name": "MIT License",
        "spdx_id": "MIT",
        "type": "License",
        "url": "https://api.github.com/licenses/mit",
        "value": "https://api.github.com/licenses/mit"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "type": "File_dump",
        "value": "MIT License\n\nCopyright (c) 2019 ernstlab\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
      },
      "source": "https://raw.githubusercontent.com/ernstlab/X-CNN/master/LICENSE",
      "technique": "file_exploration"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "X-CNN"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "Organization",
        "value": "ernstlab"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 62331,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/ernstlab/X-CNN/master/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "run": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Running X-CNN",
        "parent_header": [
          "Running X-CNN"
        ],
        "type": "Text_excerpt",
        "value": "X-CNN (X here is the lowercase Greek letter 'chi') is a method for computationally fine-mapping chromatin interactions, e.g., Hi-C, using ChIP-seq and/or DNase data. The published manuscript can be accessed here: https://doi.org/10.1093/bioinformatics/btz843. \n\n**Citation**: Jaroszewicz, A., & Ernst, J. (2019). An Integrative Approach for Fine-Mapping Chromatin Interactions. Bioinformatics. doi: 10.1093/bioinformatics/btz843\n\nX-CNN requires Python 3 and several easy-to-install packages, including numpy, h5py, pandas, keras, and Integrated Gradients (included in repo). I have written a small database package called chip_db to handle the potentially large amounts of data, though it is not necessary to use if you're handy with Python. Since X-CNN needs to randomly access different parts of the genome and extract potentially on the order of 100 ChIP seq tracks, it can be quite cumbersome to keep all these tracks in memory. Chip_db overcomes this challenge by building a database using an hdf5 backend, allowing random access of regions of the genome. It's easy to use and somewhat flexible in how you handle your data. \n"
      },
      "source": "https://raw.githubusercontent.com/ernstlab/X-CNN/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "ChIP-seq track files",
        "parent_header": [
          "Running X-CNN",
          "Preparation"
        ],
        "type": "Text_excerpt",
        "value": "These are feature tracks to be used for training the model and fine-mapping. The format should be either bedgraph or wig files. To create the database, simply run\n\n`python3 chip_db.py [cell_type] [data_res] [/path/to/hg19.chrom.sizes] [track1 track2 ...]`\n\nThe `cell_type` argument is simply the name of the cell or tissue type. The `data_res` argument is the resolution of the data when binning. We recommend using either 50 or 100. You will also need a file with the size of the chromosomes (e.g., http://hgdownload.cse.ucsc.edu/goldenPath/hg19/bigZips/hg19.chrom.sizes). This is simply a two-column text file, where the first column is a chromosome name, and the second column is the length of the chromosome. When running the above script, it may take a while, but once built, you can easily use it with X-CNN or for your own purposes.\n\nThe interaction peaks can all be of the same size (as in FitHiC) or different sizes (as in HiCCUPs). X-CNN will extend them all to the same size. Modifying the method to train on different size peaks is to be implemented at a later date.\n\n## Running X-CNN\n\nTo run X-CNN, you will need to provide it either (1) a database file, explained above, or (2) numpy matrices representing ChIP / DNase data. Either way, you will need and a chromatin interaction peak file.\n"
      },
      "source": "https://raw.githubusercontent.com/ernstlab/X-CNN/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Database method",
        "parent_header": [
          "Running X-CNN",
          "Running X-CNN"
        ],
        "type": "Text_excerpt",
        "value": "Running X-CNN using a database requires passing the `--database flag`. Here is an example:\n\n```\npython3 train_X-CNN.py \\\nGM12878 \\  # Name of cell type, used for the database query\n100 \\  # This is the resolution desired. Cannot be finer resolution than database resolution\n/path/to/interaction_file.txt \\\n--database /path/to/database/ChIP_db.hdf5 \\\n--two_random 1 \\  # number of negative samples to create per positive sample\n--chr_size /home/aku/3DP/hg19.chrom.sizes \\\n--autoencoder 26 \\\n--filter_len 8 \\\n--conv_kernel 16 \\\n--dense_kernel 16 \\\n--dense_dropout 0.25 \\\n--regularizer 0 \\\n--out_dir /home/aku/3DP/current_analyses/GM12878/HiCCUPs/genomic_bgd_25kb \\\n--intn_len 25000  # Size to extend peaks to\n```\n\nIf you would like to train on more data, at the cost of not assessing classification performance, add the `--final` flag. This builds a \"final\" model, and can be used for optimizing fine-mapping performance.\n\nX-CNN includes code specifically designed to handle large genomic data. The difficulty is that when many ChIP-seq datasets are available (say, 10s to 100s), accessing random positions in the genome becomes very difficult for un-indexed files. Instead of having to read in these individual files, we have built code to generate a database, called `chip_db`. It is built on top of HDF5, and implemented in Python. In order to build this database, you will need bedgraph wig files containing the ChIP-seq and DNase data. It builds a rather large file containing a binarized and indexed representation of this data, which can then be used alone using the API or with X-CNN to access all available data at any position in constant time, greatly speeding up computation overall. More information is available at https://github.com/ernstlab/chip_db.\n"
      },
      "source": "https://raw.githubusercontent.com/ernstlab/X-CNN/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Chromatin interaction peak file",
        "parent_header": [
          "Running X-CNN",
          "Running X-CNN"
        ],
        "type": "Text_excerpt",
        "value": "This should be a tab-delimited text file with six columns and no header of the form: \nchromosome_A, start_A, end_A, chromosome_B, start_B, end_B\n\nFor example:\n\n```\nchr1    1580000 1585000 chr1    1645000 1650000\nchr1    1710000 1720000 chr1    1830000 1840000\nchr1    1890000 1895000 chr1    1965000 1970000\nchr1    2130000 2135000 chr1    2315000 2320000\nchr1    2345000 2350000 chr1    2480000 2485000\nchr1    2350000 2375000 chr1    3325000 3350000\n...\n```\n"
      },
      "source": "https://raw.githubusercontent.com/ernstlab/X-CNN/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Numpy matrix method",
        "parent_header": [
          "Running X-CNN",
          "Running X-CNN"
        ],
        "type": "Text_excerpt",
        "value": "Create two numpy matrices of size `(num_interactions, 2, num_tracks, length)`. The first represents positive interactions, the second is negative interactions. You do not need the same number of interactions in each. The `2` has to do with the two sides of the interaction, the first index being the left side of the interaction, the second being the right. X-CNN will automatically reverse the data as well to increase the size of the training data. We have included generated files for both K562 and GM12878, and are available for download in Google Drive at https://drive.google.com/drive/folders/1SlQHF6SSc-lp-jT7yjeriM7eAjX8NHPb?usp=sharing.\n"
      },
      "source": "https://raw.githubusercontent.com/ernstlab/X-CNN/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Fine-mapping",
        "parent_header": [
          "Running X-CNN"
        ],
        "type": "Text_excerpt",
        "value": "Fine-mapping is straightforward. Simply call the `fine_map.py` script along with a trained model and data. For example:\n\n```\npython3 fine_map.py \\\n--model final_model.hdf5 \\\n--data GM12878:all:log:100bp.npy\n```\n\nThis outputs five files:\n1. A binary gradient file `gradients.npy` of the same shape as the input data `(num_interactions, 2, num_tracks, length)`\n2. A binary importances file `importances.npy` of size `(num_interactions, 2, length)`\n3. A tab-delimited importance file `importances.left.txt` with `num interactions` rows and `length` columns. These are the importances of the left interacting regions.\n4. A tab-delimited importance file `importances.right.txt` with `num interactions` rows and `length` columns. These are the importances of the right interacting regions.\n5. A tab-delimited file of the fine-mapped positions `fine-mapping.txt` for each interacting region. These are the positions with the highest importance scores and X-CNN fine-mapped positions. These are in genomic coordinates.\n"
      },
      "source": "https://raw.githubusercontent.com/ernstlab/X-CNN/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "somef_missing_categories": [
    "citation",
    "acknowledgement",
    "download",
    "requirements",
    "contact",
    "contributors",
    "documentation",
    "usage",
    "faq",
    "support",
    "identifier",
    "has_build_file",
    "executable_example"
  ],
  "somef_provenance": {
    "date": "2024-10-06 17:49:54",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 7
      },
      "technique": "GitHub_API"
    }
  ]
}