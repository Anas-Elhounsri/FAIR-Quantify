{
  "citation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Barcode file using the Reference branch",
        "parent_header": [
          "Manual epiGBS2",
          "Example Data and Config Files"
        ],
        "type": "Text_excerpt",
        "value": "```\n# path to output directory\noutput_dir: \"/home/maarten/test_data/epigbs2/output\"\n\n# input directory where raw reads are\ninput_dir       : \"/home/maarten/test_data/data\"\n\n# name of sequence read files\nRead1 : \"test_data_R1.fq.gz\"\nRead2 : \"test_data_R2.fq.gz\"\n\n# number of sequencing cycles (the same as read length in Illumina sequencing)\ncycles        : 150\n\n# barcode file(barcode file should be kept inside input directory) and enzymes will be included in barcode file\nbarcodes: \"barcodes.tsv\"\n\n# the pipeline produces some temporary files. Please indicate the tmp location on your server (in most cases /tmp)\ntmpdir        : \"/tmp\"\n\n# mode of running pipeline (set denovo, reference or legacy. PLEASE NOTE: legacy is not supported)\nmode: \"reference\"\n\n# genome directory (leaave it blank in denovo mode)\nref_dir: \"/home/maarten/test_data/ref/\"\n\n# genome name (leaave it blank in denovo mode)\ngenome: \"ref.fa\"\n\n# advanced users have the possibility to change different parameter, leave them blank or write \"default\" to run them in default mode\n\n# parameters in the denovo reference creation:\n# identity: percentage of sequence identity in the last clustering step, in decimal number e.g. for 90% identity write 0.90, default 0.97\n# min-depth: minimal cluster depth in the first clustering step to include a cluster, default 10\n# max-depth: maximal cluster depth in the first clustering step to include a cluster, default 10000\nparam_denovo:\n  identity: \"\"\n  min-depth: \"\"\n  max-depth: \"\"\n\n\n\n```\n"
      },
      "source": "https://raw.githubusercontent.com/nioo-knaw/epiGBS2/epiGBS2v3/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Software",
        "parent_header": [
          "Manual epiGBS2",
          "List of used software and references"
        ],
        "type": "Text_excerpt",
        "value": "- [epiGBS2](https://github.com/nioo-knaw/epiGBS2.git)\n- [Snakemake 5.4.5](https://snakemake.readthedocs.io/en/stable/)\n- [Conda](https://docs.conda.io/en/latest/index.html)\n- [Stacks](http://catchenlab.life.illinois.edu/stacks/)\n- [Python 3.7](https://www.python.org/)\n- [R + R package to render Rmd](https://www.r-project.org/)\n- [FastQC](http://www.bioinformatics.babraham.ac.uk/projects/fastqc)\n- [Cutadapt](https://cutadapt.readthedocs.io/en/stable/)\n- [Pear](https://cme.h-its.org/exelixis/web/software/pear/)\n- [Seqtk](https://github.com/lh3/seqtk)\n- [Bismark](https://www.bioinformatics.babraham.ac.uk/projects/bismark/)\n- [vsearch](https://github.com/torognes/vsearch)\n- [Samtools](http://www.htslib.org/)\n- [Freebayes](https://github.com/freebayes/freebayes)\n- [epiDiverse SNP calling](https://github.com/EpiDiverse/snp)\n"
      },
      "source": "https://raw.githubusercontent.com/nioo-knaw/epiGBS2/epiGBS2v3/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "References",
        "parent_header": [
          "Manual epiGBS2",
          "List of used software and references"
        ],
        "type": "Text_excerpt",
        "value": "1.\tManuscript on bioRxiv\n1.\tK\u00f6ster, J. & Rahmann, S. Snakemake-a scalable bioinformatics workflow engine. Bioinformatics 28, 2520-2522 (2012).\n2.\tGr\u00fcning, B. et al. Bioconda: sustainable and comprehensive software distribution for the life sciences. Nat. Methods 15, 475-476 (2018).\n3.\tCatchen, J., Hohenlohe, P. A., Bassham, S., Amores, A. & Cresko, W. A. Stacks: an analysis tool set for population genomics. Mol. Ecol. 22, 3124-3140 (2013).\n4.\tCatchen, J. M., Amores, A., Hohenlohe, P., Cresko, W. & Postlethwait, J. H. Stacks: Building and Genotyping Loci De Novo From Short-Read Sequences. G3 Genes Genomes Genet. 1, 171-182 (2011).\n5.\tStacks 2: Analytical Methods for Paired-end Sequencing Improve RADseq-based Population Genomics | bioRxiv. Available at: https://www.biorxiv.org/content/10.1101/615385v1. (Accessed: 27th August 2019)\n6.\tAndrews, Simon. FastQC: a quality control tool for high throughput sequence data. Available online at: http://www.bioinformatics.babraham.ac.uk/projects/fastqc. (2010).\n7.\tZhang, J., Kobert, K., Flouri, T. & Stamatakis, A. PEAR: a fast and accurate Illumina Paired-End reAd mergeR. Bioinformatics 30, 614-620 (2014).\n9.\tRognes, T., Flouri, T., Nichols, B., Quince, C. & Mah\u00e9, F. VSEARCH: a versatile open source tool for metagenomics. PeerJ 4, (2016).\n10.\tLepais, O. & Weir, J. T. SimRAD: an R package for simulation-based prediction of the number of loci expected in RADseq and similar genotyping by sequencing approaches. Mol. Ecol. Resour. 14, 1314-1321 (2014).\n11. Krueger F, Andrews SR. Bismark: a flexible aligner and methylation caller for Bisulfite-Seq applications. Bioinformatics. 27(11):1571-2. (2011)\n12. Garrison, E., Marth, G. Haplotype-based variant detection from short-read sequencing. arXiv:1207.3907 (2012)\n13. Martin, M. Cutadapt removes adapter sequences from high-throughput sequencing reads. EMBnet.journal 17 1, 10-1 (2011)\n14. Nunn, A., Otto, C., Stadler, P.F., Langenberger, D. Manipulating base quality scores enables variant calling from bisulfite sequencing alignments using conventional Bayesian approaches bioRxiv 2021.01.11.425926; doi: https://doi.org/10.1101/2021.01.11.425926 (2021)\n"
      },
      "source": "https://raw.githubusercontent.com/nioo-knaw/epiGBS2/epiGBS2v3/README.md",
      "technique": "header_analysis"
    }
  ],
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/nioo-knaw/epiGBS2"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2020-03-18T13:48:49Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2022-11-15T11:57:21Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "This is the epiGBS2 snakemake pipeline as published in a preprint version."
      },
      "technique": "GitHub_API"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/nioo-knaw/epiGBS2/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "faq": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Quality control or \"How to discover errors?\"",
        "parent_header": [
          "Manual epiGBS2"
        ],
        "type": "Text_excerpt",
        "value": "Recommendation: Run fastq-screen in bisulphite mode on raw data to determine sources of contamination (e.g. by sharing a lane with other customers, human DNA, phiX, vectors and adapters). https://www.bioinformatics.babraham.ac.uk/projects/fastq_screen/_build/html/index.html and https://www.bioinformatics.babraham.ac.uk/projects/fastq_screen/fastq_screen_documentation.html\n"
      },
      "source": "https://raw.githubusercontent.com/nioo-knaw/epiGBS2/epiGBS2v3/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Problem:",
        "parent_header": [
          "Manual epiGBS2",
          "Fix errors",
          "Demultiplexing"
        ],
        "type": "Text_excerpt",
        "value": "The clone_filter process does not proceed due insufficient memory availability on the server\n"
      },
      "source": "https://raw.githubusercontent.com/nioo-knaw/epiGBS2/epiGBS2v3/README.md",
      "technique": "header_analysis"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 6
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/nioo-knaw/epiGBS2/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "nioo-knaw/epiGBS2"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "Manual epiGBS2"
      },
      "source": "https://raw.githubusercontent.com/nioo-knaw/epiGBS2/epiGBS2v3/README.md",
      "technique": "regular_expression"
    }
  ],
  "installation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Manual epiGBS2",
        "type": "Text_excerpt",
        "value": "- [Prerequisites for running the pipeline](#prerequisites-for-running-the-pipeline)\n- [Preparation to run the pipeline](#preparation-to-run-the-pipeline)\n- [Start the pipeline](#start-the-pipeline)\n- [Explanation of files in the output directory](#explanation-of-files-in-the-output-directory)\n- [When not to run the pipeline?](#when-not-to-run-the-pipeline)\n- [Quality control or \"How to discover errors?\"](#quality-control-or-how-to-discover-errors)\n- [Fix errors](#fix-errors)\n- [Example Data and Config Files](#example-data-and-config-files)\n- [List of used software and references](#list-of-used-software-and-references)\n"
      },
      "source": "https://raw.githubusercontent.com/nioo-knaw/epiGBS2/epiGBS2v3/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Preparation to run the pipeline",
        "parent_header": [
          "Manual epiGBS2"
        ],
        "type": "Text_excerpt",
        "value": "- Make a conda environment for snakemake if snakemake is not installed globally on the server. You do not need administrator rights to do this but conda has to be installed (see [Prerequisites for running the pipeline](#prerequisites-for-running-the-pipeline)).\n\t- `conda create -n snake`\n\t- `conda activate snake`\n\t- `conda install -c conda-forge mamba`\n\t- `mamba install -c bioconda snakemake=6.1.1`\n- Make a copy of the pipeline\n\t- `git clone https://github.com/nioo-knaw/epiGBS2.git`\n- Enter the created directory:\n\t- `cd epiGBS2`\n- Open and adjust the config file: __All paths are full paths, no relative paths allowed.__ For examples, please see [Example Config Files](#example-config-files)\n\t- `nano config.yaml`\n\t- output_dir: Path of directory to store all output files and directory. Path will be created by the pipeline and should not pre-exist. E.g. if the path of the cloned directory is `/fleurg/projects/epiGBS2`, then use `/fleurg/projects/epiGBS2/output`.\n\t- input_dir: Path of directory containing raw data (e.g. fastq.gz, or fq.gz) and barcode file\n\t- read1: Name of the read file containing forward (R1) reads\n\t- read2: Name of the read file containing reverse (R2) reads\n\t- cycles: read length\n\t- barcodes: Filename of the barcode file (do not include the path!)\n\t- tmpdir: Path to the directory where temporary files will be stored. For most systems this will be /tmp\n\t- threads: number of available computing threads on your system\n\t- mode: choice between \"denovo\", \"reference\" or \"legacy\"\n\t- ref_dir: Only needed for reference-based analysis. Path to directory containing a reference genome\n\t- Genome: Only needed for reference-based analysis. Name of the genome file (prefix .fa)\n\t- Param_denovo: Optional and only relevant for analysis in denovo mode. To run on default choose \"\" or \"default\", otherwise enter a number\n\t\t- Identity: percentage of sequence identity in the last clustering step, in decimal number e.g. for 90% identity write 0.90, default: \"0.97\"\n\t\t- Min-depth: minimal cluster depth in the first clustering step to include a cluster, default 10\n\t\t- Max-depth: maximal cluster depth in the first clustering step to include a cluster, default 10000\n\n- Make a barcode file: The barcode file is tab-delimited and contains at least the following columns: Flowcell, Lane, Barcode_R1, Barcode_R2, Sample, ENZ_R1, ENZ_R2, Wobble_R1, Wobble_R2. All other fields are optional. Make sure that the sample name does not only contain numbers but also letters. If you prepare the barcode file in Excel, make sure that no `^M` are present after uploading the file to the Linux server. You can check this by opening the barcode file with `cat -A barcode.tsv` on a Linux server. You can remove the `^M` with `sed -e \"s/^M//\" filename > newfilename`. To enter ^M, type CTRL-V, then CTRL-M. That is, hold down the CTRL key then press V and M in succession. If this is not working, and you have PC you can remove the `^M` with `dos2unix barcodes.tsv`. You can check the removal with `cat -A barcode.tsv`.\n\nThe Flowcellname can be found in the fastq headers of the read file, e.g. `@ST-E00317:403:H53KHCCXY:5:1101:5660:1309 1:N:0:NCAATCAC` translates to `@ST-E00317:403:FLOWCELL:LANE-NUMBER:1101:5660:1309 1:N:0:NCAATCAC`. ENZ_R1/2 expects the names of the restriction enzymes and Wobble_R1/2 is the length of the unique molecular identifier (\"Wobble\") sequence (usually 3).\nIt is important that the restriction enzyme names are spelled correctly, so the end of the restriction enzyme names are capital i (I) and not an l (lowercase L) or an 1 (number).\n\nAt the moment it is not supported to process **multiple lanes** at the same time. Limiting step is the demultiplexing. If you want to analyse more than one lane, please first run demultiplexing per lane, merge demultiplexed files and then run the rest of the pipeline.\n\n```\n# barcodes.tsv\nFlowcell        Lane    Barcode_R1      Barcode_R2      Sample  history Country PlateName       Row     Column  ENZ_R1  ENZ_R2  Wobble_R1       Wobble_R2       Species\nH53KHCCXY       5       AACT    CCAG    BUXTON_178      C       BUXTON  BUXTON_WUR_AseI_NsiI_final_run1 1       2       AseI    NsiI    3       3       Scabiosa columbaria\nH53KHCCXY       5       CCTA    CCAG    WUR_178 C       WUR     BUXTON_WUR_AseI_NsiI_final_run1 2       2       AseI    NsiI    3       3       Scabiosa columbaria\nH53KHCCXY       5       TTAC    CCAG    BUXTON_169      C       BUXTON  BUXTON_WUR_AseI_NsiI_final_run1 3       2       AseI    NsiI    3       3       Scabiosa columbaria\nH53KHCCXY       5       AGGC    CCAG    WUR_169 C       WUR     BUXTON_WUR_AseI_NsiI_final_run1 4       2       AseI    NsiI    3       3       Scabiosa columbaria\nH53KHCCXY       5       GAAGA   CCAG    BUXTON_175      SD      BUXTON  BUXTON_WUR_AseI_NsiI_final_run1 5       2       AseI    NsiI    3       3       Scabiosa columbaria\nH53KHCCXY       5       CCTTC   CCAG    WUR_175 SD      WUR     BUXTON_WUR_AseI_NsiI_final_run1 6       2       AseI    NsiI    3       3       Scabiosa columbaria\n```\n"
      },
      "source": "https://raw.githubusercontent.com/nioo-knaw/epiGBS2/epiGBS2v3/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Explanation of files in the output directory",
        "parent_header": [
          "Manual epiGBS2"
        ],
        "type": "Text_excerpt",
        "value": "It follows a description of all output files. Files that are important for downstream analysis are highlighted in bold. Files or Directories in italics are specific for the de-novo and reference branch respectively.\n\n- __multiQC_report.html__:  report summarizing all stats from the epiGBS analysis. Absolutely crucial to determine, whether your analysis ran successfully or not. However, this file gives only a first impression and further analysis is necessary to confirm the quality of your analysis. Can be opened in any webbrowser. This file can be very large. Hide parts of the files to make loading easier, e.g. filter out all files containing \"rem\"\n- output_demultiplex:\n\t- barcode_stacks.tsv: barcode file converted to the required stacks format  \n\t- clone: Directory containing read files from which PCR duplicates were removed  \n\t- clone-stacks: Directory containing demultiplexed and Watson-Crick separated read files. File names start with sample names. Files with *rem* in the name contain reads that failed the RAD-tag check.\n\t\t- process_radtags.clone.log: Log file containing stats from demultiplexing, also contains information about eventually discovered *de novo* barcodes\n\t- crick_R1.fq.gz: All filtered and demultiplexed crick forward reads, input for denovo creation \n\t- crick_R2.fq.gz: All filtered and demultiplexed crick reverse reads, input for denovo creation\n\t- demultiplex.log: Log file containing stats from clone-removal  \n\t- Watson_R1.fq.gz: All filtered and demultiplexed watson forward reads, input for denovo creation    \n\t- Watson_R2.fq.gz: All filtered and demultiplexed watson reverse reads, input for denovo creation  \n- *output_denovo*: Containing all files created during de-novo reference creation. Skipped, if running in reference-mode.\n\t- Assembled.fq.gz: All read pairs (forward/R1 and reverse/R2), that were assembled/merged using Pear\n\t- Unassembled.R1.fq.gz: All forward/R1 reads that could not be assembled/merged  \n\t- Unassembled.R2.fq.gz: All reverse/R2 reads that could not be assembled/merged  \n\t- consensus.fa: sequence file. outputfile from second clustering step, in which binary watson and crick reads are matched, and after reference reconstruction\n\t- consensus_cluster.fa: De novo reference sequence file. Outputfile from third clustering step, in which sequences from previous steps were clustered based on identity  \n\t- __consensus_cluster.renamed.fa__: sequences are identical to consensus_cluster.fa but fasta names were renamed. Input for mapping.\n\t- consensus_cluster.renamed.fa.fai: Indexed *de novo* reference sequences.\n\t- make_reference.log: Log file containing some stats about the clustering.  \n- cutadapt: \n\t- contains the output of the trimming steps performed using cutadapt, which are used for the alignment step\n- alignment:\n\t- {sample}_trimmed_filt_merged.1_bismark_bt2_pe.bam: Alignemnt file per individual of reads against the reference, created by bismark. Can be used as input for most bisulphite sensitive SNP and methylation callers.\n\t- {sample}_trimmed_filt_merged.1_bismark_bt2_PE_report.txt: report file describing mapping performance per individual.\n\t- {sample}_trimmed_filter_merged{1,2}_{ambigious,unmapped}.fq.gz: contains the reads that did not map or mapped ambigiously to the reference genome.\n- methylation_calling:\n\t- {sample}_bismark_bt2_pe.CX_report_txt.gz: Main output file of the bismark methylation calling,  a genome-wide methylation report for all\ncytosines in the genome. Uses 1-based chromosome coordinates, and outputs context, fraction methylated, number of methylated bases and total number of bases.\n\t- {sample}_trimmed_filt_merged.1_bismark_bt2_pe.bismark.cov.gz: Output with coverage and number of called bases.\n\t- {sample}_trimmed_filt_merged.1_bismark_bt2_pe.bedGraph.gz: Output that reports the position of a given cytosine and its methylation state using 0-based genomic start and 1-based end coordinates.\n\t- {sample}_trimmed_filt_merged.1_bismark_bt2_pe.cytosine_context_summary.txt: a file summarizing the methylation in the different cytosine contexts found within the individual.\n\t- {sample}_trimmed_filt_merged.1_bismark_bt2_pe.M-bias.txt: file shows the methylation proportion across each possible position in the read. Is summarized in the multiQC report.\n\t- {sample}_trimmed_filt_merged.1_bismark_bt2_pe_splitting_report.txt: Shows stats of the methylation calling. Is summarized in the multiQC file\n\n- snp_calling:\n\t- masked.bam: Input file for freebayes. Can be used to run any SNP_caller supporting multicohort SNP_calling\n\t- snp.vcf.gz: combined file containing all SNPs for all individuals. \n- multiQC_report_data: Directory containing all log and intermediary files that are created by MultiQC\n- fastqc: Directory containing individual FastQC reports is summarized in the multiQC report\n- log: Directory containing log-files. Is summarized in the multiQC report\n"
      },
      "source": "https://raw.githubusercontent.com/nioo-knaw/epiGBS2/epiGBS2v3/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Fix:",
        "parent_header": [
          "Manual epiGBS2",
          "Fix errors",
          "Demultiplexing"
        ],
        "type": "Text_excerpt",
        "value": "- Run clone_filter outside of the pipeline using the following command: \n\t- `clone_filter -1 R1.fq.gz -2 R2.fq.gz -o ./ --inline_inline -igzfastq --oligo_len_1 3 --oligo_len_2 3 `\n- Change the values of Wobble_R1/Wobble_R2 in the barcode file to 0 and in the config.yaml file set the input_dir to the output directory of the command above.\n- If the previous solution does not work, NGSReadsTreatment can be used instead. (paper: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6690869/) (download: https://sourceforge.net/projects/ngsreadstreatment/)\n- The following command filters the clone reads: \n\t- `java -Xmx32g -jar NgsReadsTreatment_v1.3.jar prefix_R1.fastq prefix_R2.fastq 32`\n- Then the wobble sequence has to be removed manually. You can use [fastp](https://github.com/OpenGene/fastp)\n\t- `fastp --trim_front1 3 --trim_front2 3 --disable_adapter_trimming --disable_trim_poly_g --disable_quality_filtering --in1 prefix_R1_1_trated.fastq --in2 prefix_R2_2_trated.fastq --out1 prefix_R1.deRepNoWobble.fq.gz --out2 prefix_R2.deRepNoWobble.fq.gz` \n- After changing the values for Wobble_R1/Wobble_R2 to 0 in the barcode file, the `prefix_R1.deRepNoWobble.fq.gz`/ `prefix_R2.deRepNoWobble.fq.gz` files can be used as input for the pipeline.\n\n\n#### Problem:\nI have a very high percentage of clone reads\n\n#### Fix:\n\n- Check the length of the Wobble in your adapter sequence and the number in the barcode file.\n- Check the quality and quantity of input DNA during the wetlab procedure.\n"
      },
      "source": "https://raw.githubusercontent.com/nioo-knaw/epiGBS2/epiGBS2v3/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Barcode file using the de novo branch",
        "parent_header": [
          "Manual epiGBS2",
          "Example Data and Config Files"
        ],
        "type": "Text_excerpt",
        "value": "```\n# path to output directory\noutput_dir: \"/home/maarten/test_data/epigbs2/output\"\n\n# input directory where raw reads are\ninput_dir       : \"/home/maarten/test_data/data\"\n\n# name of sequence read files\nRead1 : \"test_data_R1.fq.gz\"\nRead2 : \"test_data_R2.fq.gz\"\n\n# number of sequencing cycles (the same as read length in Illumina sequencing)\ncycles        : 150\n\n# barcode file(barcode file should be kept inside input directory) and enzymes will be included in barcode file\nbarcodes: \"barcodes.tsv\"\n\n# the pipeline produces some temporary files. Please indicate the tmp location on your server (in most cases /tmp)\ntmpdir        : \"/tmp\"\n\n# mode of running pipeline (set denovo, reference or legacy. PLEASE NOTE: legacy is not supported)\nmode: \"denovo\"\n\n# genome directory (leaave it blank in denovo mode)\nref_dir: \"\"\n\n# genome name (leaave it blank in denovo mode)\ngenome: \"\"\n\n# advanced users have the possibility to change different parameter, leave them blank or write \"default\" to run them in default mode\n\n# parameters in the denovo reference creation:\n# identity: percentage of sequence identity in the last clustering step, in decimal number e.g. for 90% identity write 0.90, default 0.97\n# min-depth: minimal cluster depth in the first clustering step to include a cluster, default 10\n# max-depth: maximal cluster depth in the first clustering step to include a cluster, default 10000\nparam_denovo:\n  identity: \"0.97\"\n  min-depth: \"10\"\n  max-depth: \"10000\"\n\n\n```\n\n"
      },
      "source": "https://raw.githubusercontent.com/nioo-knaw/epiGBS2/epiGBS2v3/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Software",
        "parent_header": [
          "Manual epiGBS2",
          "List of used software and references"
        ],
        "type": "Text_excerpt",
        "value": "- [epiGBS2](https://github.com/nioo-knaw/epiGBS2.git)\n- [Snakemake 5.4.5](https://snakemake.readthedocs.io/en/stable/)\n- [Conda](https://docs.conda.io/en/latest/index.html)\n- [Stacks](http://catchenlab.life.illinois.edu/stacks/)\n- [Python 3.7](https://www.python.org/)\n- [R + R package to render Rmd](https://www.r-project.org/)\n- [FastQC](http://www.bioinformatics.babraham.ac.uk/projects/fastqc)\n- [Cutadapt](https://cutadapt.readthedocs.io/en/stable/)\n- [Pear](https://cme.h-its.org/exelixis/web/software/pear/)\n- [Seqtk](https://github.com/lh3/seqtk)\n- [Bismark](https://www.bioinformatics.babraham.ac.uk/projects/bismark/)\n- [vsearch](https://github.com/torognes/vsearch)\n- [Samtools](http://www.htslib.org/)\n- [Freebayes](https://github.com/freebayes/freebayes)\n- [epiDiverse SNP calling](https://github.com/EpiDiverse/snp)\n"
      },
      "source": "https://raw.githubusercontent.com/nioo-knaw/epiGBS2/epiGBS2v3/README.md",
      "technique": "header_analysis"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/nioo-knaw/epiGBS2/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ""
      },
      "technique": "GitHub_API"
    }
  ],
  "license": [
    {
      "confidence": 1,
      "result": {
        "name": "MIT License",
        "spdx_id": "MIT",
        "type": "License",
        "url": "https://api.github.com/licenses/mit",
        "value": "https://api.github.com/licenses/mit"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "type": "File_dump",
        "value": "The MIT License (MIT)\n\nCopyright (c) 2015 thomasvangurp\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n\n"
      },
      "source": "https://raw.githubusercontent.com/nioo-knaw/epiGBS2/epiGBS2v3/LICENSE",
      "technique": "file_exploration"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "epiGBS2"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "Organization",
        "value": "nioo-knaw"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 136665,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "R",
        "size": 1002,
        "type": "Programming_language",
        "value": "R"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/nioo-knaw/epiGBS2/epiGBS2v3/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "related_documentation": [
    {
      "confidence": 1,
      "result": {
        "format": "readthedocs",
        "type": "Url",
        "value": "https://snakemake.readthedocs.io/"
      },
      "source": "https://raw.githubusercontent.com/nioo-knaw/epiGBS2/epiGBS2v3/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "format": "readthedocs",
        "type": "Url",
        "value": "https://cutadapt.readthedocs.io/"
      },
      "source": "https://raw.githubusercontent.com/nioo-knaw/epiGBS2/epiGBS2v3/README.md",
      "technique": "regular_expression"
    }
  ],
  "related_papers": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://arxiv.org/abs/1207.3907 (2012)\n13. Martin, M. Cutadapt removes adapter sequences from high-throughput sequencing reads. EMBnet.journal 17 1, 10-1 (2011)\n14. Nunn, A., Otto, C., Stadler, P.F., Langenberger, D. Manipulating base quality scores enables variant calling from bisulfite sequencing alignments using conventional Bayesian approaches bioRxiv 2021.01.11.425926; doi: https://doi.org/10.1101/2021.01.11.425926 (2021)"
      },
      "source": "https://raw.githubusercontent.com/nioo-knaw/epiGBS2/epiGBS2v3/README.md",
      "technique": "regular_expression"
    }
  ],
  "releases": [
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "mdehollander",
          "type": "User"
        },
        "date_created": "2022-01-26T15:15:01Z",
        "date_published": "2023-11-10T15:36:27Z",
        "description": "- Improved performance of clone_filter by using a newer version of stacks\r\n- Added polyG problem and clone_filter memory issues to the error section of the readme",
        "html_url": "https://github.com/nioo-knaw/epiGBS2/releases/tag/v3.1.0",
        "name": "epiGBS2v3.1",
        "release_id": 128931707,
        "tag": "v3.1.0",
        "tarball_url": "https://api.github.com/repos/nioo-knaw/epiGBS2/tarball/v3.1.0",
        "type": "Release",
        "url": "https://api.github.com/repos/nioo-knaw/epiGBS2/releases/128931707",
        "value": "https://api.github.com/repos/nioo-knaw/epiGBS2/releases/128931707",
        "zipball_url": "https://api.github.com/repos/nioo-knaw/epiGBS2/zipball/v3.1.0"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "FleurGaBru",
          "type": "User"
        },
        "date_created": "2021-10-12T12:37:28Z",
        "date_published": "2021-10-15T11:43:41Z",
        "description": "src/rules/denovo.rules: \r\n- library is now always directional\r\n- to save space, six output files were made temporary\r\n\r\nsrc/rules/reference.rules: \r\n- library is now always directional\r\n- to save space, six output files were made temporary\r\n- added flag \u201c\u2014scaffolds\u201d during methylation calling to allow compatibility with reference genome assemblies with contigs \r\n- removed MQ parameter in rule SNP calling\r\n \r\nsrc/env/bismark.yaml : \r\n- fixed problems with the environment files \r\n  \r\nsrc/parameter_test/paramTest.tsv : \r\n- improved default parameters\r\n \r\nsrc/rules/paramTest.rules: \r\n- fixed bugs",
        "html_url": "https://github.com/nioo-knaw/epiGBS2/releases/tag/v3.0.0",
        "name": "epiGBS2 release with some bug fixes",
        "release_id": 51426257,
        "tag": "v3.0.0",
        "tarball_url": "https://api.github.com/repos/nioo-knaw/epiGBS2/tarball/v3.0.0",
        "type": "Release",
        "url": "https://api.github.com/repos/nioo-knaw/epiGBS2/releases/51426257",
        "value": "https://api.github.com/repos/nioo-knaw/epiGBS2/releases/51426257",
        "zipball_url": "https://api.github.com/repos/nioo-knaw/epiGBS2/zipball/v3.0.0"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "FleurGaBru",
          "type": "User"
        },
        "date_created": "2021-05-09T21:15:00Z",
        "date_published": "2021-05-15T14:54:46Z",
        "description": "This release includes several major changes:\r\n\r\n- usage of Bismark for mapping and methylation calling\r\n- usage of Freebayes for SNP calling\r\n- creation of a report file using multiQC\r\n- split conda environments\r\n- compatibility with snakemake 6.1.1\r\n",
        "html_url": "https://github.com/nioo-knaw/epiGBS2/releases/tag/v2.0.0",
        "name": "epiGBS2 release with Bismark and Freebayes",
        "release_id": 42998502,
        "tag": "v2.0.0",
        "tarball_url": "https://api.github.com/repos/nioo-knaw/epiGBS2/tarball/v2.0.0",
        "type": "Release",
        "url": "https://api.github.com/repos/nioo-knaw/epiGBS2/releases/42998502",
        "value": "https://api.github.com/repos/nioo-knaw/epiGBS2/releases/42998502",
        "zipball_url": "https://api.github.com/repos/nioo-knaw/epiGBS2/zipball/v2.0.0"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "FleurGaBru",
          "type": "User"
        },
        "date_created": "2020-05-01T11:35:38Z",
        "date_published": "2020-05-11T10:40:24Z",
        "description": "This is the first realease of epiGBS2. It is an update of the software described in van Gurp et al. (2016, https://doi.org/10.1038/nmeth.3763). \r\n\r\n- software is now integrated with conda and snakemake\r\n- execution and error handling is documented\r\n- the demultiplexing is increased in speed and is executed by stacks\r\n- mapping is done by STAR\r\n- variant calling is performed by samtools mpileup\r\n- methylation calling and SNP calling is done by customised scripts\r\n- report files for quality checks are added\r\n- several minor bug-fixes\r\n\r\n- pipeline has to be benchmarked in more detail",
        "html_url": "https://github.com/nioo-knaw/epiGBS2/releases/tag/v1.0.0",
        "name": "First release of epiGBS2",
        "release_id": 26374091,
        "tag": "v1.0.0",
        "tarball_url": "https://api.github.com/repos/nioo-knaw/epiGBS2/tarball/v1.0.0",
        "type": "Release",
        "url": "https://api.github.com/repos/nioo-knaw/epiGBS2/releases/26374091",
        "value": "https://api.github.com/repos/nioo-knaw/epiGBS2/releases/26374091",
        "zipball_url": "https://api.github.com/repos/nioo-knaw/epiGBS2/zipball/v1.0.0"
      },
      "technique": "GitHub_API"
    }
  ],
  "requirements": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Prerequisites for running the pipeline",
        "parent_header": [
          "Manual epiGBS2"
        ],
        "type": "Text_excerpt",
        "value": "- A basic knowledge of Linux:\n\t- Knowledge, about how to work with files and directories (cd, ls, nano)\n\t- Being able to execute commands (git, conda, snakemake)\n- Knowledge about the statistical analysis of e.g. differential methylation. This is not included in the pipeline.\n- Linux server:\n\t- e.g. Ubuntu 16.04\n\t- Sudo rights not necessary\n\t- Miniconda installed or\n\t\t- Download with `wget` https://docs.conda.io/en/latest/miniconda.html\n\t\t- Installing like described [here](https://docs.conda.io/projects/conda/en/latest/user-guide/install/linux.html), can be installed in user's home without sudo\n\t\t\t- `bash Miniconda3-latest-Linux-x86_64.sh`\n- Adapters include:\n\t- Control nucleotide\n\t- Wobble (running without is also possible)\n- Sequencing:\n\t- paired-end Illumina-sequencing\n\t- adjust output (number of reads) according to your genome size and expected number of fragments (e.g. based on an *in silico* digest)\n- Readfiles:\n\t- un-demultiplexed but standard Illumina adapter trimmed (usually already done by sequencing agency)\n- No reference genome required\n\n"
      },
      "source": "https://raw.githubusercontent.com/nioo-knaw/epiGBS2/epiGBS2v3/README.md",
      "technique": "header_analysis"
    }
  ],
  "run": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Prerequisites for running the pipeline",
        "parent_header": [
          "Manual epiGBS2"
        ],
        "type": "Text_excerpt",
        "value": "- A basic knowledge of Linux:\n\t- Knowledge, about how to work with files and directories (cd, ls, nano)\n\t- Being able to execute commands (git, conda, snakemake)\n- Knowledge about the statistical analysis of e.g. differential methylation. This is not included in the pipeline.\n- Linux server:\n\t- e.g. Ubuntu 16.04\n\t- Sudo rights not necessary\n\t- Miniconda installed or\n\t\t- Download with `wget` https://docs.conda.io/en/latest/miniconda.html\n\t\t- Installing like described [here](https://docs.conda.io/projects/conda/en/latest/user-guide/install/linux.html), can be installed in user's home without sudo\n\t\t\t- `bash Miniconda3-latest-Linux-x86_64.sh`\n- Adapters include:\n\t- Control nucleotide\n\t- Wobble (running without is also possible)\n- Sequencing:\n\t- paired-end Illumina-sequencing\n\t- adjust output (number of reads) according to your genome size and expected number of fragments (e.g. based on an *in silico* digest)\n- Readfiles:\n\t- un-demultiplexed but standard Illumina adapter trimmed (usually already done by sequencing agency)\n- No reference genome required\n\n"
      },
      "source": "https://raw.githubusercontent.com/nioo-knaw/epiGBS2/epiGBS2v3/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Preparation to run the pipeline",
        "parent_header": [
          "Manual epiGBS2"
        ],
        "type": "Text_excerpt",
        "value": "- Make a conda environment for snakemake if snakemake is not installed globally on the server. You do not need administrator rights to do this but conda has to be installed (see [Prerequisites for running the pipeline](#prerequisites-for-running-the-pipeline)).\n\t- `conda create -n snake`\n\t- `conda activate snake`\n\t- `conda install -c conda-forge mamba`\n\t- `mamba install -c bioconda snakemake=6.1.1`\n- Make a copy of the pipeline\n\t- `git clone https://github.com/nioo-knaw/epiGBS2.git`\n- Enter the created directory:\n\t- `cd epiGBS2`\n- Open and adjust the config file: __All paths are full paths, no relative paths allowed.__ For examples, please see [Example Config Files](#example-config-files)\n\t- `nano config.yaml`\n\t- output_dir: Path of directory to store all output files and directory. Path will be created by the pipeline and should not pre-exist. E.g. if the path of the cloned directory is `/fleurg/projects/epiGBS2`, then use `/fleurg/projects/epiGBS2/output`.\n\t- input_dir: Path of directory containing raw data (e.g. fastq.gz, or fq.gz) and barcode file\n\t- read1: Name of the read file containing forward (R1) reads\n\t- read2: Name of the read file containing reverse (R2) reads\n\t- cycles: read length\n\t- barcodes: Filename of the barcode file (do not include the path!)\n\t- tmpdir: Path to the directory where temporary files will be stored. For most systems this will be /tmp\n\t- threads: number of available computing threads on your system\n\t- mode: choice between \"denovo\", \"reference\" or \"legacy\"\n\t- ref_dir: Only needed for reference-based analysis. Path to directory containing a reference genome\n\t- Genome: Only needed for reference-based analysis. Name of the genome file (prefix .fa)\n\t- Param_denovo: Optional and only relevant for analysis in denovo mode. To run on default choose \"\" or \"default\", otherwise enter a number\n\t\t- Identity: percentage of sequence identity in the last clustering step, in decimal number e.g. for 90% identity write 0.90, default: \"0.97\"\n\t\t- Min-depth: minimal cluster depth in the first clustering step to include a cluster, default 10\n\t\t- Max-depth: maximal cluster depth in the first clustering step to include a cluster, default 10000\n\n- Make a barcode file: The barcode file is tab-delimited and contains at least the following columns: Flowcell, Lane, Barcode_R1, Barcode_R2, Sample, ENZ_R1, ENZ_R2, Wobble_R1, Wobble_R2. All other fields are optional. Make sure that the sample name does not only contain numbers but also letters. If you prepare the barcode file in Excel, make sure that no `^M` are present after uploading the file to the Linux server. You can check this by opening the barcode file with `cat -A barcode.tsv` on a Linux server. You can remove the `^M` with `sed -e \"s/^M//\" filename > newfilename`. To enter ^M, type CTRL-V, then CTRL-M. That is, hold down the CTRL key then press V and M in succession. If this is not working, and you have PC you can remove the `^M` with `dos2unix barcodes.tsv`. You can check the removal with `cat -A barcode.tsv`.\n\nThe Flowcellname can be found in the fastq headers of the read file, e.g. `@ST-E00317:403:H53KHCCXY:5:1101:5660:1309 1:N:0:NCAATCAC` translates to `@ST-E00317:403:FLOWCELL:LANE-NUMBER:1101:5660:1309 1:N:0:NCAATCAC`. ENZ_R1/2 expects the names of the restriction enzymes and Wobble_R1/2 is the length of the unique molecular identifier (\"Wobble\") sequence (usually 3).\nIt is important that the restriction enzyme names are spelled correctly, so the end of the restriction enzyme names are capital i (I) and not an l (lowercase L) or an 1 (number).\n\nAt the moment it is not supported to process **multiple lanes** at the same time. Limiting step is the demultiplexing. If you want to analyse more than one lane, please first run demultiplexing per lane, merge demultiplexed files and then run the rest of the pipeline.\n\n```\n# barcodes.tsv\nFlowcell        Lane    Barcode_R1      Barcode_R2      Sample  history Country PlateName       Row     Column  ENZ_R1  ENZ_R2  Wobble_R1       Wobble_R2       Species\nH53KHCCXY       5       AACT    CCAG    BUXTON_178      C       BUXTON  BUXTON_WUR_AseI_NsiI_final_run1 1       2       AseI    NsiI    3       3       Scabiosa columbaria\nH53KHCCXY       5       CCTA    CCAG    WUR_178 C       WUR     BUXTON_WUR_AseI_NsiI_final_run1 2       2       AseI    NsiI    3       3       Scabiosa columbaria\nH53KHCCXY       5       TTAC    CCAG    BUXTON_169      C       BUXTON  BUXTON_WUR_AseI_NsiI_final_run1 3       2       AseI    NsiI    3       3       Scabiosa columbaria\nH53KHCCXY       5       AGGC    CCAG    WUR_169 C       WUR     BUXTON_WUR_AseI_NsiI_final_run1 4       2       AseI    NsiI    3       3       Scabiosa columbaria\nH53KHCCXY       5       GAAGA   CCAG    BUXTON_175      SD      BUXTON  BUXTON_WUR_AseI_NsiI_final_run1 5       2       AseI    NsiI    3       3       Scabiosa columbaria\nH53KHCCXY       5       CCTTC   CCAG    WUR_175 SD      WUR     BUXTON_WUR_AseI_NsiI_final_run1 6       2       AseI    NsiI    3       3       Scabiosa columbaria\n```\n"
      },
      "source": "https://raw.githubusercontent.com/nioo-knaw/epiGBS2/epiGBS2v3/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "When not to run the pipeline?",
        "parent_header": [
          "Manual epiGBS2"
        ],
        "type": "Text_excerpt",
        "value": "- If you want to determine methylation in restriction enzyme overhang. The original sequence will be replaced by the expected overhang during demultiplexing if a mismatch between expected and actual overhang sequence occurs. Hence, C-T conversions are replaced by a C and methylation would be artifically set to 100%.\n- there is no full support for running multiple lanes at one (see comment above, where barcode file is described)\n"
      },
      "source": "https://raw.githubusercontent.com/nioo-knaw/epiGBS2/epiGBS2v3/README.md",
      "technique": "header_analysis"
    }
  ],
  "somef_missing_categories": [
    "acknowledgement",
    "download",
    "contact",
    "contributors",
    "documentation",
    "identifier",
    "has_build_file",
    "executable_example"
  ],
  "somef_provenance": {
    "date": "2024-10-06 11:13:03",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 2
      },
      "technique": "GitHub_API"
    }
  ],
  "support": [
    {
      "confidence": 1,
      "result": {
        "original_header": "MultiQC report:",
        "parent_header": [
          "Manual epiGBS2",
          "Quality control or \"How to discover errors?\""
        ],
        "type": "Text_excerpt",
        "value": "- MultiQC wraps the FastQC, demultiplexing, denovo creation, mapping and aligning reports of all samples and gives you the possibility to compare the quality plots of all or specific samples directly with each other. All functions of MultiQC are explained in a tutorial video that is provided as a link in the report.\n- you can consider the FastQC documentation to understand most of the FastQC plots: https://www.bioinformatics.babraham.ac.uk/projects/fastqc/Help/3%20Analysis%20Modules/. However, epiGBS libraries have the following specific characteristics that will be reflected in the quality reports. You can also compare this with the RRBS example from the FastQC website: https://www.bioinformatics.babraham.ac.uk/projects/fastqc/RRBS_fastqc.html\n\t- The sequence duplication levels will be higher than average because restriction enzymes were used to create the libraries versus random shearing for e.g. whole genome sequencing.\n\t- The per base sequence content of the first nucleotides will re-construct the overhang of the used restriction enzyme after demultiplexing the reads. The \"C\" content is usually low and \"T\" is high.\n\t- The 3'-end adapter content is usually high\n"
      },
      "source": "https://raw.githubusercontent.com/nioo-knaw/epiGBS2/epiGBS2v3/README.md",
      "technique": "header_analysis"
    }
  ],
  "usage": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Start the pipeline",
        "parent_header": [
          "Manual epiGBS2"
        ],
        "type": "Text_excerpt",
        "value": "**Running the pipeline with `--use-conda` is important!**\n\n- Dry-run:\n\t- `snakemake -n --use-conda`\n- everythin green? Then...\n- run the pipeline:\n\t`snakemake -j <threads> -p --use-conda` Replace <threads> by number of CPU's to use on your server, e.g. `snakemake -j 12 -p --use-conda`\n- if you want to run without SNP calling you can add `output/path/as/in/config/multiQC_report.html` at the end of the snakemake command"
      },
      "source": "https://raw.githubusercontent.com/nioo-knaw/epiGBS2/epiGBS2v3/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Example Data",
        "parent_header": [
          "Manual epiGBS2",
          "Example Data and Config Files"
        ],
        "type": "Text_excerpt",
        "value": "\t\n### Example Data\n\t\nAn example data set and barcode file are available at [Zenodo](https://zenodo.org/record/5878925).\n"
      },
      "source": "https://raw.githubusercontent.com/nioo-knaw/epiGBS2/epiGBS2v3/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Barcode file using the de novo branch",
        "parent_header": [
          "Manual epiGBS2",
          "Example Data and Config Files"
        ],
        "type": "Text_excerpt",
        "value": "```\n# path to output directory\noutput_dir: \"/home/maarten/test_data/epigbs2/output\"\n\n# input directory where raw reads are\ninput_dir       : \"/home/maarten/test_data/data\"\n\n# name of sequence read files\nRead1 : \"test_data_R1.fq.gz\"\nRead2 : \"test_data_R2.fq.gz\"\n\n# number of sequencing cycles (the same as read length in Illumina sequencing)\ncycles        : 150\n\n# barcode file(barcode file should be kept inside input directory) and enzymes will be included in barcode file\nbarcodes: \"barcodes.tsv\"\n\n# the pipeline produces some temporary files. Please indicate the tmp location on your server (in most cases /tmp)\ntmpdir        : \"/tmp\"\n\n# mode of running pipeline (set denovo, reference or legacy. PLEASE NOTE: legacy is not supported)\nmode: \"denovo\"\n\n# genome directory (leaave it blank in denovo mode)\nref_dir: \"\"\n\n# genome name (leaave it blank in denovo mode)\ngenome: \"\"\n\n# advanced users have the possibility to change different parameter, leave them blank or write \"default\" to run them in default mode\n\n# parameters in the denovo reference creation:\n# identity: percentage of sequence identity in the last clustering step, in decimal number e.g. for 90% identity write 0.90, default 0.97\n# min-depth: minimal cluster depth in the first clustering step to include a cluster, default 10\n# max-depth: maximal cluster depth in the first clustering step to include a cluster, default 10000\nparam_denovo:\n  identity: \"0.97\"\n  min-depth: \"10\"\n  max-depth: \"10000\"\n\n\n```\n\n"
      },
      "source": "https://raw.githubusercontent.com/nioo-knaw/epiGBS2/epiGBS2v3/README.md",
      "technique": "header_analysis"
    }
  ]
}