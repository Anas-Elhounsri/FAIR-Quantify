{
  "application_domain": [
    {
      "confidence": 42.63,
      "result": {
        "type": "String",
        "value": "Natural Language Processing"
      },
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9982789530360838,
      "result": {
        "type": "String",
        "value": "Semantic web"
      },
      "technique": "supervised_classification"
    }
  ],
  "citation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "References",
        "parent_header": [
          "NLIMED"
        ],
        "type": "Text_excerpt",
        "value": "The main reference of this work is: https://doi.org/10.3389/fphys.2022.820683\n```\n@article{munarko_nlimed_2022,\n  title = {{{NLIMED}}: {{Natural Language Interface}} for {{Model Entity Discovery}} in {{Biosimulation Model Repositories}}},\n  shorttitle = {{{NLIMED}}},\n  author = {Munarko, Yuda and Sarwar, Dewan M. and Rampadarath, Anand and Atalag, Koray and Gennari, John H. and Neal, Maxwell L. and Nickerson, David P.},\n  year = {2022},\n  journal = {Frontiers in Physiology},\n  volume = {13},\n  issn = {1664-042X},\n}\n```\n\n\n\nCite the following works when you implement NLIMED with parser or nlp of:\n1. CoreNLP: https://stanfordnlp.github.io/CoreNLP/citing.html\n2. Benepar: https://arxiv.org/abs/1805.01052\n3. NCBO: https://www.ncbi.nlm.nih.gov/pubmed/21347171\n4. Stanza and xStanza: http://arxiv.org/abs/2007.14640\n"
      },
      "source": "https://raw.githubusercontent.com/napakalas/NLIMED/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "author": "Munarko, Yuda and Sarwar, Dewan M. and Rampadarath, Anand and Atalag, Koray and Gennari, John H. and Neal, Maxwell L. and Nickerson, David P.",
        "format": "bibtex",
        "title": "{{NLIMED}}: {{Natural Language Interface}} for {{Model Entity Discovery}} in {{Biosimulation Model Repositories}}",
        "type": "Text_excerpt",
        "value": "@article{munarko_nlimed_2022,\n    issn = {1664-042X},\n    volume = {13},\n    journal = {Frontiers in Physiology},\n    year = {2022},\n    author = {Munarko, Yuda and Sarwar, Dewan M. and Rampadarath, Anand and Atalag, Koray and Gennari, John H. and Neal, Maxwell L. and Nickerson, David P.},\n    shorttitle = {{{NLIMED}}},\n    title = {{{NLIMED}}: {{Natural Language Interface}} for {{Model Entity Discovery}} in {{Biosimulation Model Repositories}}},\n}"
      },
      "source": "https://raw.githubusercontent.com/napakalas/NLIMED/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/napakalas/NLIMED"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2019-08-07T23:37:02Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2023-07-26T05:27:30Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "This project is to convert user query to SPARQL in the Physiome Model Repository. The information looking by users usually is model entities."
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 0.9574222431036666,
      "result": {
        "original_header": "NLIMED",
        "type": "Text_excerpt",
        "value": "Natural Language Interface for Model Entity Discovery (NLIMED) is an interface to search model entities (i.e. flux of sodium across the basolateral plasma membrane, the concentration of potassium in the portion of tissue fluid) in the biosimulation models in repositories. The interface utilises the RDF inside biosimulation models and metadata from BioPortal. Currently, the interface can retrieve model entities from the Physiome Model Repository (PMR, https://models.physiomeproject.org) and the BioModels (https://www.ebi.ac.uk/biomodels/). \n"
      },
      "source": "https://raw.githubusercontent.com/napakalas/NLIMED/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9263987997117551,
      "result": {
        "original_header": "Issues",
        "type": "Text_excerpt",
        "value": "For any issues please follows and reports [issues](https://github.com/napakalas/NLIMED/issues).\n \n"
      },
      "source": "https://raw.githubusercontent.com/napakalas/NLIMED/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9292461518496712,
      "result": {
        "original_header": "Experiment",
        "type": "Text_excerpt",
        "value": "We conducted an experiment to measure NLIMED performance in term of:\n1. Annotating natural language query to ontology classes\n2. NLIMED behaviour to native query in PMR \n"
      },
      "source": "https://raw.githubusercontent.com/napakalas/NLIMED/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9607742793641081,
      "result": {
        "original_header": "How NLIMED works?",
        "type": "Text_excerpt",
        "value": "Here is the process inside NLIMED converting natural language query (NLQ) and SPARQL and then retrieving model entities from biomodel repositories:\n1. NLQ Annotation -- Annotating NLQ to ontology classes \n    - NLQ is parsed using selected parser (CoreNLP, Benepar, NCBO, Stanza, or xStanza), resulting candidate noun phrases (CNPs).\n    - Measuring association level of each CNP to ontology classes. The measurement utilises five textual features, i.e. preferred label, synonym, definition,, parent label (from ontology class) and local definition (from biosimulation model)\n    - Select CNPs with highest association, having longest term, and not overlapping with other CNP. The selected CNPs should cover all terms in NLQ.\n    - Filter out CNP having low association to ontology class (<cutoff)\n    - Select the top pl of ontology classes from selected CNPs\n    - Combine all possible ontology classes with no overlapping CNPs \n"
      },
      "source": "https://raw.githubusercontent.com/napakalas/NLIMED/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9770132358732491,
      "result": {
        "original_header": "Utilising NLIMED in your Python code",
        "type": "Text_excerpt",
        "value": "The main class for retrieving model entities from repositories is NLIMED in NLIMED.py. Utilising this class, we can annotate query into ontology classes, get all possible SPARQL, and get model entities. We suggest you to create one NLIMED object for all your queries since it will reuse the loaded indexes so it can save your device resources.\n \n"
      },
      "source": "https://raw.githubusercontent.com/napakalas/NLIMED/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9137541095224577,
      "result": {
        "original_header": "Indexing the pmr",
        "type": "Text_excerpt",
        "value": "Download all required ontology dictionaries for indexing from (https://bioportal.bioontology.org/).\nPreferably is csv files but obo files are working.\nList of ontology dictionaries:\n'SO','PW','PSIMOD','PR','PATO','OPB','NCBITAXON','MAMO',\n'FMA','EFO','EDAM','ECO','CL','CHEBI','BTO','SBO',\n'UNIPROT','KEGG','EC-CODE','ENSEMBL','GO'\n```\nNLIMED --build-index pmr \"{location-of-ontology-files}\"\n```\n \n"
      },
      "source": "https://raw.githubusercontent.com/napakalas/NLIMED/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/napakalas/NLIMED/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "executable_example": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://colab.research.google.com/drive/1xq3ewKIT9pHD0AveWuYy2cpJvG4oLjDR#scrollTo=VYv3uMcMt6HJ"
      },
      "source": "https://raw.githubusercontent.com/napakalas/NLIMED/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://colab.research.google.com/drive/1xq3ewKIT9pHD0AveWuYy2cpJvG4oLjDR#scrollTo=KwQAqORxsnk_"
      },
      "source": "https://raw.githubusercontent.com/napakalas/NLIMED/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://colab.research.google.com/drive/1xq3ewKIT9pHD0AveWuYy2cpJvG4oLjDR#scrollTo=qsEFA2pGtVZH"
      },
      "source": "https://raw.githubusercontent.com/napakalas/NLIMED/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 0
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/napakalas/NLIMED/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "napakalas/NLIMED"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "NLIMED"
      },
      "source": "https://raw.githubusercontent.com/napakalas/NLIMED/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "installation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Installation",
        "parent_header": [
          "NLIMED"
        ],
        "type": "Text_excerpt",
        "value": "We sugest you to install NLIMED from PyPI. If you already installed [pip](https://pip.pypa.io/en/stable/installing/), run the following command:\n  ```\n  pip install NLIMED\n  ```\nAs an alternative, you can clone and download this github repository and use the following command:\n  ```\n  pip install git+https://github.com/napakalas/NLIMED.git\n  ```\n\nFollow this [Colab](https://colab.research.google.com/drive/1xq3ewKIT9pHD0AveWuYy2cpJvG4oLjDR#scrollTo=VYv3uMcMt6HJ) tutorial for easy step by step installation and utilisation.\n"
      },
      "source": "https://raw.githubusercontent.com/napakalas/NLIMED/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 0.9998832585321398,
      "result": {
        "original_header": "Configuration",
        "type": "Text_excerpt",
        "value": "  * It is also possible to run configuration from command prompt or terminal: \n      ```\n      NLIMED --config --apikey {your-ncbo-api-key} --corenlp-home {installation-location}\n      ```\n \n"
      },
      "source": "https://raw.githubusercontent.com/napakalas/NLIMED/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9999998290770269,
      "result": {
        "original_header": "Recreate Indexes (RDF Graph Index and Text Feature Index)",
        "type": "Text_excerpt",
        "value": "All indexes are already provided in this project. However, if you want to recreate all indexes you can use the following script on command prompt or terminal. Please be patient, it may take times to be finished.\n \n"
      },
      "source": "https://raw.githubusercontent.com/napakalas/NLIMED/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.999226509755447,
      "result": {
        "original_header": "Indexing the pmr",
        "type": "Text_excerpt",
        "value": "Download all required ontology dictionaries for indexing from (https://bioportal.bioontology.org/).\nPreferably is csv files but obo files are working.\nList of ontology dictionaries:\n'SO','PW','PSIMOD','PR','PATO','OPB','NCBITAXON','MAMO',\n'FMA','EFO','EDAM','ECO','CL','CHEBI','BTO','SBO',\n'UNIPROT','KEGG','EC-CODE','ENSEMBL','GO'\n```\nNLIMED --build-index pmr \"{location-of-ontology-files}\"\n```\n \n"
      },
      "source": "https://raw.githubusercontent.com/napakalas/NLIMED/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9794140321255512,
      "result": {
        "original_header": "Indexing biomodels",
        "type": "Text_excerpt",
        "value": "1. Download all RDF files (ftp://ftp.ebi.ac.uk/pub/databases/RDF/biomodels/r31/biomodels-rdf.tar.bz2) as a compressed file from BioModels. Extract the compressed file at your convenience directory. \n2. Run the following code:\n    ```\n    NLIMED --build-index bm \"{location-of-ontology-files}\" \"{location-of-RDF-files}\"\n    ```\n \n"
      },
      "source": "https://raw.githubusercontent.com/napakalas/NLIMED/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "invocation": [
    {
      "confidence": 0.8937855574154361,
      "result": {
        "original_header": "Indexing biomodels",
        "type": "Text_excerpt",
        "value": "1. Download all RDF files (ftp://ftp.ebi.ac.uk/pub/databases/RDF/biomodels/r31/biomodels-rdf.tar.bz2) as a compressed file from BioModels. Extract the compressed file at your convenience directory. \n"
      },
      "source": "https://raw.githubusercontent.com/napakalas/NLIMED/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/napakalas/NLIMED/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ""
      },
      "technique": "GitHub_API"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "NLIMED"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "User",
        "value": "napakalas"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 190067,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/napakalas/NLIMED/master/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "related_papers": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://arxiv.org/abs/1805.01052\n3. NCBO: https://www.ncbi.nlm.nih.gov/pubmed/21347171\n4. Stanza and xStanza: http://arxiv.org/abs/2007.14640\n\n## Installation\nWe sugest you to install NLIMED from PyPI. If you already installed [pip](https://pip.pypa.io/en/stable/installing/"
      },
      "source": "https://raw.githubusercontent.com/napakalas/NLIMED/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "somef_missing_categories": [
    "acknowledgement",
    "run",
    "download",
    "requirements",
    "contact",
    "contributors",
    "documentation",
    "license",
    "faq",
    "support",
    "identifier",
    "has_build_file"
  ],
  "somef_provenance": {
    "date": "2024-10-06 18:09:39",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 2
      },
      "technique": "GitHub_API"
    }
  ],
  "usage": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Demo",
        "parent_header": [
          "NLIMED"
        ],
        "type": "Text_excerpt",
        "value": "1. Online web: [http://130.216.217.30/nlimed](http://130.216.217.30/nlimed)\n2. Online tutorial: [Colab](https://colab.research.google.com/drive/1xq3ewKIT9pHD0AveWuYy2cpJvG4oLjDR#scrollTo=VYv3uMcMt6HJ)\n"
      },
      "source": "https://raw.githubusercontent.com/napakalas/NLIMED/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Get Model Entities",
        "parent_header": [
          "NLIMED",
          "Utilising NLIMED in your Python code"
        ],
        "type": "Text_excerpt",
        "value": "The following codes are used to retrieve model entities from the PMR or Biomodels.\n* Returning model entities from the PMR using CoreNLP parser with standard setting for query: \"mitochondrial calcium ion transmembrane transport\"\n  ```python\n  from NLIMED import NLIMED\n  nlimed = NLIMED(repo='pmr', parser='CoreNLP')\n  query = 'mitochondrial calcium ion transmembrane transport'\n  result = nlimed.getModels(query=query,format='json')\n\n  \"\"\"\n  where:\n  - repo : repository {'pmr', 'bm', 'bm-omex'}\n  - parser : parser tool {'CoreNLP', 'Benepar', 'xStanza', 'Stanza', 'ncbo'}\n  - query : query text\n  - format : the returning format data {'json','print'}\n  \"\"\"\n  ```\n  The code resulting a json format data consisting 27 model entities related to the query\n  ```\n  {\n    'vars': ['graph', 'Model_entity', 'desc'],\n    'results': [{\n      'graph': 'https://models.physiomeproject.org/workspace/colegrove_albrecht_friel_2000',\n      'Model_entity': 'colegrove_albrecht_friel_2000.cellml#id_00011'\n    },\n      ....\n    , {\n      'graph': 'https://models.physiomeproject.org/workspace/marhl_haberichter_brumen_heinrich_2000',\n      'Model_entity': 'marhl_haberichter_brumen_heinrich_2000.cellml#id_000000025'\n    },\n      ...\n    ]\n  }\n  ```\n\n* It also possible to increase the precision level, so NLIMED can show more results. Here we are returning model entities from the PMR using CoreNLP parser and precision level 2, alpha=4, beta=0.7, gamma=0.5, delta=0.8, theta=0.01.\n  ```python\n  from NLIMED import NLIMED\n  nlimed = NLIMED(repo='pmr', parser='CoreNLP', pl=2, alpha=4, beta=0.7, gamma=0.5, delta=0.8, theta=0.1, cutoff=1, tfMode=3)\n  query = 'mitochondrial calcium ion transmembrane transport'\n  result = nlimed.getModels(query=query,format='json')\n\n  \"\"\"\n  where:\n  - repo (mandatory) : repository {'pmr', 'bm', 'bm-omex'}\n  - parser : parser tool {'CoreNLP', 'Benepar', 'Stanza', 'xStanza', 'ncbo'}\n  - pl (optional) : precision level, the minimum value is 1\n  - alpha (optional) : preffered label weight, the minimum value is 0\n  - beta (optional) : synonym weight, the minimum value is 0\n  - gamma (optional) : definition weight, the minimum value is 0\n  - delta (optional) : parent labels weight, the minimum value is 0\n  - theta (optional) : description weight, the minimum value is 0\n  - cutoff (optional) : minimum degree of asociation, the minimum value is 0\n  - tfMode (optional) : the term frequency calculation mode, [1,2,3]\n  - query : query text\n  - format : the returning format data {'json','print'}\n  \"\"\"\n  ```\n  The code resulting a json format data consisting 141 model entities related to the query\n  ```\n  {\n    'vars': ['graph', 'Model_entity', 'desc'],\n    'results': [{\n      'graph': 'https://models.physiomeproject.org/workspace/colegrove_albrecht_friel_2000',\n      'Model_entity': 'colegrove_albrecht_friel_2000.cellml#id_00011'\n    },\n      ...\n    , {\n      'graph': 'https://models.physiomeproject.org/workspace/marhl_haberichter_brumen_heinrich_2000',\n      'Model_entity': 'marhl_haberichter_brumen_heinrich_2000.cellml#id_000000025'\n    },\n      ...\n    , {\n      'graph': 'https://models.physiomeproject.org/workspace/winslow_rice_jafri_marban_ororke_1999',\n      'Model_entity': 'winslow_rice_jafri_marban_ororke_1999.cellml#sarcolemmal_calcium_pump_i_p_Ca'\n    },\n      ...\n    , {\n      'graph': 'https://models.physiomeproject.org/workspace/michailova_mcculloch_2001',\n      'Model_entity': 'michailova_mcculloch_2001.cellml#id_00118'\n    },\n      ...\n    , {\n      'graph': 'https://models.physiomeproject.org/workspace/hinch_greenstein_tanskanen_xu_winslow_2004',\n      'Model_entity': 'hinch_greenstein_tanskanen_xu_winslow_2004.cellml#id_00038'\n    },\n      ...\n    , {\n      'graph': 'https://models.physiomeproject.org/w/andre/SAN-ORd',\n      'Model_entity': 'Ohara_Rudy_2011.cellml#id_00011'\n    },\n      ...\n    , {\n      'graph': 'https://models.physiomeproject.org/workspace/bertram_satin_zhang_smolen_sherman_2004',\n      'Model_entity': 'bertram_satin_zhang_smolen_sherman_2004_a.cellml#calcium_handling_Jserca'\n    },\n      ...\n    , {\n      'graph': 'https://models.physiomeproject.org/workspace/bertram_sherman_2004',\n      'Model_entity': 'bertram_sherman_2004.cellml#id_00029'\n    }, {\n      'graph': 'https://models.physiomeproject.org/workspace/noble_2000',\n      'Model_entity': 'noble_2000_a.cellml#id_00024'\n    },\n      ...\n    , {\n      'graph': 'https://models.physiomeproject.org/workspace/bindschadler_sneyd_2001',\n      'Model_entity': 'bindschadler_sneyd_2001.cellml#id_00003'\n    },\n      ...\n    , {\n      'graph': 'https://models.physiomeproject.org/workspace/fridlyand_tamarina_philipson_2003',\n      'Model_entity': 'fridlyand_tamarina_philipson_2003.cellml#id_00025'\n    },\n      ...\n    , {\n      'graph': 'https://models.physiomeproject.org/workspace/puglisi_bers_2001',\n      'Model_entity': 'puglisi_bers_2001.cellml#id_00112'\n    },\n      ...\n    , {\n      'graph': 'https://models.physiomeproject.org/workspace/terkildsen_niederer_crampin_hunter_smith_2008',\n      'Model_entity': 'Hinch_et_al_2004.cellml#id_00010'\n    },\n      ...\n    , {\n      'graph': 'https://models.physiomeproject.org/workspace/55c',\n      'Model_entity': 'Hinch_et_al_2004.cellml#id_00010'\n    },\n      ...\n    , {\n      'graph': 'https://models.physiomeproject.org/workspace/luo_rudy_1994',\n      'Model_entity': 'luo_rudy_1994.cellml#id_00019'\n    },\n      ...\n    , {\n      'graph': 'https://models.physiomeproject.org/workspace/viswanathan_shaw_rudy_1999',\n      'Model_entity': 'viswanathan_shaw_rudy_1999_a.cellml#sarcolemmal_calcium_pump_i_p_Ca'\n    }, {\n      'graph': 'https://models.physiomeproject.org/workspace/viswanathan_shaw_rudy_1999',\n      'Model_entity': 'viswanathan_shaw_rudy_1999_a.cellml#id_00078'\n    },\n      ...\n    , {\n      'graph': 'https://models.physiomeproject.org/workspace/goforth_bertram_khan_zhang_sherman_satin_2002',\n      'Model_entity': 'goforth_bertram_khan_zhang_sherman_satin_2002.cellml#id_00041'\n    },\n      ...\n    , {\n      'graph': 'https://models.physiomeproject.org/workspace/albrecht_colegrove_friel_2002',\n      'Model_entity': 'albrecht_colegrove_friel_2002.cellml#id_00030'\n    },\n      ...\n    , {\n      'graph': 'https://models.physiomeproject.org/workspace/marhl_haberichter_brumen_heinrich_2000',\n      'Model_entity': 'marhl_haberichter_brumen_heinrich_2000.cellml#id_000000019'\n    },\n      ...\n    , {\n      'graph': 'https://models.physiomeproject.org/workspace/albrecht_colegrove_hongpaisan_pivovarova_andrews_friel_2001',\n      'Model_entity': 'albrecht_colegrove_hongpaisan_pivovarova_andrews_friel_2001.cellml#id_00021'\n    },\n      ...\n    , {\n      'graph': 'https://models.physiomeproject.org/workspace/riemer_sobie_tung_1998',\n      'Model_entity': 'riemer_sobie_tung_1998.cellml#id_00063'\n    },\n      ...\n    , {\n      'graph': 'https://models.physiomeproject.org/workspace/faber_rudy_2000',\n      'Model_entity': 'faber_rudy_2000.cellml#id_00074'\n    },\n      ...\n    , {\n      'graph': 'https://models.physiomeproject.org/workspace/jafri_rice_winslow_1998',\n      'Model_entity': 'jafri_rice_winslow_1998_a.cellml#id_00017'\n    },\n      ...\n    , {\n      'graph': 'https://models.physiomeproject.org/workspace/tentusscher_noble_noble_panfilov_2004',\n      'Model_entity': 'tentusscher_noble_noble_panfilov_2004_c.cellml#id_00050'\n    },\n      ...\n    , {\n      'graph': 'https://models.physiomeproject.org/workspace/viswanathan_shaw_rudy_1999',\n      'Model_entity': 'viswanathan_shaw_rudy_1999_c.cellml#id_00095'\n    }]\n  }\n  ```\n* Get model entities from BioModels with standard setting using Benepar Parser:\n  ```python\n  from NLIMED import NLIMED\n  nlimed = NLIMED(repo='bm', parser='Benepar')\n  query = 'mitochondrial calcium ion transmembrane transport'\n  result = nlimed.getModels(query=query,format='json')\n  ```\n  The code produce 6 model entities:\n  ```\n  {\n  'vars': ['model', 'type', 'element', 'notes', 'name'],\n    'results': [{\n      'model': 'http://identifiers.org/biomodels.db/BIOMD0000000354',\n      'type': 'http://identifiers.org/biomodels.vocabulary#reaction',\n      'element': 'http://identifiers.org/biomodels.db/BIOMD0000000354#_982817',\n      'name': 'UniporterFromCytosol'\n    },\n      ...\n    , {\n      'model': 'http://identifiers.org/biomodels.db/BIOMD0000000355',\n      'type': 'http://identifiers.org/biomodels.vocabulary#reaction',\n      'element': 'http://identifiers.org/biomodels.db/BIOMD0000000355#_032020',\n      'name': 'CytToMito'\n    },\n      ...\n    ]\n  }\n  ```\n* Get model entities from BioModels with precision level 2, alpha=4, beta=0.7, gamma=0.5, delta=0.8, theta=0.01 and Beneparvv parser\n```python\nfrom NLIMED import NLIMED\nnlimed = NLIMED(repo='bm', parser='Benepar', pl=2, alpha=4, beta=0.7, gamma=0.5, delta=0.8, theta=0.01)\nquery = 'mitochondrial calcium ion transmembrane transport'\nresult = nlimed.getModels(query=query,format='json')\n```\nResulting 12 model entities:\n```\n'vars': ['model', 'type', 'element', 'notes', 'name'],\n  'results': [{\n    'model': 'http://identifiers.org/biomodels.db/BIOMD0000000354',\n    'type': 'http://identifiers.org/biomodels.vocabulary#reaction',\n    'element': 'http://identifiers.org/biomodels.db/BIOMD0000000354#_982817',\n    'name': 'UniporterFromCytosol'\n  },\n    ...\n  , {\n    'model': 'http://identifiers.org/biomodels.db/BIOMD0000000355',\n    'type': 'http://identifiers.org/biomodels.vocabulary#reaction',\n    'element': 'http://identifiers.org/biomodels.db/BIOMD0000000355#_032020',\n    'name': 'CytToMito'\n  },\n    ...\n  , {\n    'model': 'http://identifiers.org/biomodels.db/BIOMD0000000354#_982817',\n    'type': 'http://biomodels.net/biology-qualifiers#isVersionOf',\n    'element': 'http://purl.obolibrary.org/obo/GO:0006851'\n  },\n    ...\n  , {\n    'model': 'http://identifiers.org/biomodels.db/BIOMD0000000355#_032020',\n    'type': 'http://biomodels.net/biology-qualifiers#isVersionOf',\n    'element': 'http://purl.obolibrary.org/obo/GO:0006851'\n  },\n    ...\n  ]\n}\n```"
      },
      "source": "https://raw.githubusercontent.com/napakalas/NLIMED/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Get Query Annotation",
        "parent_header": [
          "NLIMED",
          "Utilising NLIMED in your Python code"
        ],
        "type": "Text_excerpt",
        "value": "In a case you just need to utilise the annotation function, you can use getAnnotated function. By this, the system will not request Internet connection for SPARQL request. However, if you use NCBO Annotator, Internet connection is still required.\n* Code example to annotated query \"concentration of potassium in the portion of tissue fluid\" in the PMR using CoreNLP parser\n  ```python\n  from NLIMED import NLIMED\n  nlimed = NLIMED(repo='pmr', parser='CoreNLP', pl=2, alpha=4, beta=0.7, gamma=0.5, delta=0.8, theta=0.01)\n  query = 'concentration of potassium in the portion of tissue fluid'\n  result = nlimed.getAnnotated(query=query,format='json')\n  ```\n  Result:\n  ```\n  {\n    'phrases': ['concentration', 'potassium', 'portion tissue fluid'],\n    'result': [\n      [\n        ['http://identifiers.org/opb/OPB_00340', 'http://purl.obolibrary.org/obo/CHEBI_29103', 'http://purl.obolibrary.org/obo/FMA_9673'], 5.061734018829371\n      ]\n    ]\n  }\n  ```\n  The query is separated into three phrases, then each phrase is classify into ontology classes. There is a score 5.061734018829371 indicating the weight of ontology classes combination.\n\n* Code example to annotated query \"concentration of potassium in the portion of tissue fluid\" in the PMR using CoreNLP parser, pl=2, alpha=4, beta=0.7, gamma=0.5, delta=0.8, theta=0.01\n  ```python\n  from NLIMED import NLIMED\n  nlimed = NLIMED(repo='pmr', parser='CoreNLP', pl=2, alpha=4, beta=0.7, gamma=0.5, delta=0.8, theta=0.01)\n  query = 'flux of sodium'\n  result = nlimed.getAnnotated(query=query,format='json')\n  ```\n  Result:\n  ```\n  {\n    'phrases': ['concentration', 'potassium', 'portion tissue fluid'],\n    'result': [\n      [\n        ['http://identifiers.org/opb/OPB_00340', 'http://purl.obolibrary.org/obo/CHEBI_29103', 'http://purl.obolibrary.org/obo/FMA_9673'], 5.061734018829371\n      ],\n      [\n        ['https://identifiers.org/opb/OPB_00340', 'http://purl.obolibrary.org/obo/CHEBI_29103', 'http://purl.obolibrary.org/obo/FMA_9673'], 5.020508088576971\n      ],\n      [\n        ['http://identifiers.org/opb/OPB_00340', 'http://identifiers.org/chebi/CHEBI:29103', 'http://purl.obolibrary.org/obo/FMA_9673'], 5.06090745289317\n      ],\n      [\n        ['https://identifiers.org/opb/OPB_00340', 'http://identifiers.org/chebi/CHEBI:29103', 'http://purl.obolibrary.org/obo/FMA_9673'], 5.019681522640769\n      ],\n      [\n        ['http://identifiers.org/opb/OPB_00340', 'http://purl.obolibrary.org/obo/CHEBI_29103', 'http://purl.obolibrary.org/obo/FMA_280556'], 4.307255058507058\n      ],\n      [\n        ['https://identifiers.org/opb/OPB_00340', 'http://purl.obolibrary.org/obo/CHEBI_29103', 'http://purl.obolibrary.org/obo/FMA_280556'], 4.266029128254657\n      ],\n      [\n        ['http://identifiers.org/opb/OPB_00340', 'http://identifiers.org/chebi/CHEBI:29103', 'http://purl.obolibrary.org/obo/FMA_280556'], 4.3064284925708565\n      ],\n      [\n        ['https://identifiers.org/opb/OPB_00340', 'http://identifiers.org/chebi/CHEBI:29103', 'http://purl.obolibrary.org/obo/FMA_280556'], 4.265202562318455\n      ]\n    ]\n  }\n  ```\n  Just the same as the previous result, the query is separated into three phrases, then each phrase is classify into ontology classes. Since we use higher precisin level, the function presents more ontology classes combination with a different score. Higher score means higher probability of relevant annotation.\n"
      },
      "source": "https://raw.githubusercontent.com/napakalas/NLIMED/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Get SPARQL",
        "parent_header": [
          "NLIMED",
          "Utilising NLIMED in your Python code"
        ],
        "type": "Text_excerpt",
        "value": "It is also possible to get SPARQL only without model entities. It utilise getSparql function which generated all possible SPARQL based on annotation results.\n\n* Get SPARQL code for query \"concentration of potassium in the portion of tissue fluid\" in the PMR using CoreNLP parser\n  ```python\n  from NLIMED import NLIMED\n  nlimed = NLIMED(repo='pmr', parser='CoreNLP')\n  query = 'flux of sodium'\n  result = nlimed.getSparql(query=query,format='json')\n  ```\n  Resulting a list of SPARQL:\n  ```\n  [\n    'SELECT ?graph ?Model_entity ?desc\n      WHERE { GRAPH ?graph {\n        ?e  <http://www.bhi.washington.edu/SemSim#hasPhysicalDefinition> <http://purl.obolibrary.org/obo/FMA_9673> .\n        ?c  <http://www.bhi.washington.edu/SemSim#hasPhysicalDefinition> <http://purl.obolibrary.org/obo/CHEBI_29103> .\n        ?a  <http://www.bhi.washington.edu/SemSim#hasPhysicalDefinition> <http://identifiers.org/opb/OPB_00340> .\n        ?Model_entity  <http://www.bhi.washington.edu/SemSim#isComputationalComponentFor> ?a .\n        ?a  <http://www.bhi.washington.edu/SemSim#physicalPropertyOf> ?c .\n        ?c  <http://www.obofoundry.org/ro/ro.owl#part_of> ?e .\n        OPTIONAL{?Model_entity <http://purl.org/dc/terms/description> ?desc .} }}'\n  ]\n  ```\n* Get SPARQL code for query \"concentration of potassium in the portion of tissue fluid\" in the PMR using CoreNLP parser with precision level 2, alpha=4, beta=0.7, gamma=0.5, delta=0.8, theta=0.01 and CoreNLP parser\n  ```python\n  from NLIMED import NLIMED\n  nlimed = NLIMED(repo='pmr', parser='CoreNLP', pl=2, alpha=4, beta=0.7, gamma=0.5, delta=0.8, theta=0.01)\n  query = 'flux of sodium'\n  result = nlimed.getSparql(query=query,format='json')\n  ```\n  The result can be 0 or more than one SPARQL based on the RDF Graph Index.\n  ```\n  [\n  'SELECT ?graph ?Model_entity ?desc\n    WHERE { GRAPH ?graph {  ?c  <http://www.bhi.washington.edu/SemSim#hasPhysicalDefinition> <http://purl.obolibrary.org/obo/CHEBI_29103> .\n      ?e  <http://www.bhi.washington.edu/SemSim#hasPhysicalDefinition> <http://purl.obolibrary.org/obo/FMA_9673> .\n      ?a  <http://www.bhi.washington.edu/SemSim#hasPhysicalDefinition> <http://identifiers.org/opb/OPB_00340> .\n      ?Model_entity  <http://www.bhi.washington.edu/SemSim#isComputationalComponentFor> ?a .\n      ?a  <http://www.bhi.washington.edu/SemSim#physicalPropertyOf> ?c .\n      ?c  <http://www.obofoundry.org/ro/ro.owl#part_of> ?e .\n      OPTIONAL{?Model_entity <http://purl.org/dc/terms/description> ?desc .} }}'\n  ]\n  ```\n\n  ## Running NLIMED from console (query to get model entities)\n  NLIMED can be run directly on command prompt or terminal. There are 2 mandatory arguments and 7 optional arguments. To get help about the required arguments, run:\n  ```terminal\n  NLIMED -h\n  ```\n  then you will get:\n  ```terminal\n  usage: NLIMED [-h] -r {pmr,bm,all} -p {CoreNLP,Benepar,ncbo} -q QUERY\n                   [-pl PL] [-s {models,sparql,annotation,verbose}] [-a ALPHA]\n                   [-b BETA] [-g GAMMA] [-d DELTA] [-t THETA]\n\n  optional arguments:\n    -h, --help            show this help message and exit\n    -r {pmr,bm,all}, --repo {pmr,bm,all}\n                          repository name\n    -p {corenlp,benepar,stanza,xstanza,ncbo}, --parser {corenlp,benepar,stanza,xstanza,ncbo}\n                          parser tool\n    -q QUERY, --query QUERY\n                          query -- any text containing words\n    -pl PL                precision level, >=1\n    -s {models,sparql,annotation,verbose}, --show {models,sparql,annotation,verbose}\n                          results presentation type\n    -a ALPHA, --alpha ALPHA\n                          Minimum alpha is 0\n    -b BETA, --beta BETA  Minimum beta is 0\n    -g GAMMA, --gamma GAMMA\n                          Minimum gamma is 0\n    -d DELTA, --delta DELTA\n                          Minimum delta is 0\n    -t THETA, --theta THETA\n                          Minimum theta is 0\n    -c CUTOFF, --cutoff CUTOFF\n                          Minimum cutoff is 0\n    -tf TFMODE, --tfMode TFMODE\n                          tf mode calculation, [1,2,3]\n  ```\n  Here is the description of those arguments:\n  * -r {pmr,bm,all} or --repo {pmr,bm,all} (mandatory) is the name of repository. pmr is the Physiome Repository Model, bm is BioSimulations, all is for both repositories\n  * -p {corenlp,benepar,stanza,xstanza,ncbo} or --parser {CoreNLP,Benepar,ncbo} (mandatory) is the type of parser for query annotation.\n  * -q QUERY or --query QUERY (mandatory) is the query text. For a multi words query, the words should be double quoted.\n  * -pl PL (optional) is precision level indicating the number of ontology classes used to construct SPARQL. Larger number will utilised more ontology cllasses which may generate more SPARQL and produce more results. Minimum value is 1. Default value is 1.\n  * -s {models,sparql,annotation,verbose} or --show {models,sparql,annotation,verbose} (optional) is for selecting presented results. models shows models, sparql shows all possible SPARQLs, annotation shows annotation results, and verbore shows annotation results, SPARQLs, and models\n  * -a ALPHA or --alpha ALPHA (optional) is to set up the weight of preffered label feature. Minimum alpha is 0. Default value is 3.0.\n  * -b BETA or --beta BETA (optional) is to set up the weight of synonym feature. Minimum beta is 0. Default value is 3.0.\n  * -g GAMMA or --gamma GAMMA (optional) is to set up the weight of definition feature. Minimum gamma is 0. Default value is 0.1.\n  * -d DELTA, --delta DELTA (optional) is to set up the weight of parent labels feature. Minimum gamma is 0. Default value is 0.1.\n  * -t THETA, --theta THETA (optional) is to set up the weight of description feature. Minimum theta is 0. Default value is 0.38.\n  * -c CUTOFF, --cutoff (optional) is the minimum degree of association between a phrases and a ontology class used. Minimum cutoff is 0. Default value is 1.\n  * -tf tfMode, --tfMode (optional) is the term frequency calculation mode, 1 = all features with dependency term, 2 = all features without dependency term, 3 = highest feature with dependency term. Devault value is 3.\n\n  ### Running example\n  * running with minimum setup for repository = Physiome Model Repository, parser = Benepar, query = \"flux of sodium\", and other default arguments values:\n    ```\n    NLIMED -r pmr -p Benepar -q \"flux of sodium\"\n    ```\n  * running with full setup for repository=BioModels, parser=CoreNLP, query=\"flux of sodium\", precision level = 2, alpha = 2, beta = 1, gamma = 1, and delta = 1, theta = 0.4, cutoff = 1.0, tfMode = 3\n    ```\n    NLIMED -r bm -p CoreNLP -q \"flux of sodium\" -pl 2 -a 2 -b 1 -g 1 -d 1 -t 0.4 -c 1 -tf 3\n    ```\n    Note: running with CoreNLP parser may cause delay local server startup for the first run. However, for the next run, the delay is disappeared.\n\n  * running for repository = Physiome Model Repository, parser = NCBO, query = \"flux of sodium\", precision level = 3,and other default arguments\n\n    ```\n    NLIMED -r pmr -p ncbo -q \"flux of sodium\" -pl 3\n    ```\n    Note: running with NCBO Parser parser is slower than other parsers because it is using a web service depended on the Internet connection.\n"
      },
      "source": "https://raw.githubusercontent.com/napakalas/NLIMED/master/README.md",
      "technique": "header_analysis"
    }
  ]
}