{
  "acknowledgement": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Acknowledgements",
        "parent_header": [
          "s-LWSR: Super Lightweight Super-Resolution Network"
        ],
        "type": "Text_excerpt",
        "value": "This code is built on [EDSR (PyTorch)](https://github.com/thstkdgus35/EDSR-PyTorch) and [RCAN(Pytorch)](https://github.com/yulunzhang/RCAN). We greatly thank the authors for sharing their codes of EDSR [Torch version](https://github.com/LimBee/NTIRE2017) and [RCAN(Pytorch)](https://github.com/yulunzhang/RCAN).\n\n"
      },
      "source": "https://raw.githubusercontent.com/Sudo-Biao/s-LWSR/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "application_domain": [
    {
      "confidence": 48.11,
      "result": {
        "type": "String",
        "value": "Computer Vision"
      },
      "technique": "supervised_classification"
    }
  ],
  "citation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Citation",
        "parent_header": [
          "s-LWSR: Super Lightweight Super-Resolution Network"
        ],
        "type": "Text_excerpt",
        "value": "If you find the code helpful in your resarch or work, please cite the following papers.\n```\n@InProceedings{Lim_2017_CVPR_Workshops,\n  author = {Lim, Bee and Son, Sanghyun and Kim, Heewon and Nah, Seungjun and Lee, Kyoung Mu},\n  title = {Enhanced Deep Residual Networks for Single Image Super-Resolution},\n  booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops},\n  month = {July},\n  year = {2017}\n}\n\n@inproceedings{zhang2018rcan,\n    title={Image Super-Resolution Using Very Deep Residual Channel Attention Networks},\n    author={Zhang, Yulun and Li, Kunpeng and Li, Kai and Wang, Lichen and Zhong, Bineng and Fu, Yun},\n    booktitle={ECCV},\n    year={2018}\n}\n\n@article{li2019s,\n  title={s-LWSR: Super Lightweight Super-Resolution Network},\n  author={Li, Biao and Liu, Jiabin and Wang, Bo and Qi, Zhiquan and Shi, Yong},\n  journal={arXiv preprint arXiv:1909.10774},\n  year={2019}\n}\n```"
      },
      "source": "https://raw.githubusercontent.com/Sudo-Biao/s-LWSR/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "author": "Lim, Bee and Son, Sanghyun and Kim, Heewon and Nah, Seungjun and Lee, Kyoung Mu",
        "format": "bibtex",
        "title": "Enhanced Deep Residual Networks for Single Image Super-Resolution",
        "type": "Text_excerpt",
        "value": "@inproceedings{Lim_2017_CVPR_Workshops,\n    year = {2017},\n    month = {July},\n    booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops},\n    title = {Enhanced Deep Residual Networks for Single Image Super-Resolution},\n    author = {Lim, Bee and Son, Sanghyun and Kim, Heewon and Nah, Seungjun and Lee, Kyoung Mu},\n}"
      },
      "source": "https://raw.githubusercontent.com/Sudo-Biao/s-LWSR/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "author": "Zhang, Yulun and Li, Kunpeng and Li, Kai and Wang, Lichen and Zhong, Bineng and Fu, Yun",
        "format": "bibtex",
        "title": "Image Super-Resolution Using Very Deep Residual Channel Attention Networks",
        "type": "Text_excerpt",
        "value": "@inproceedings{zhang2018rcan,\n    year = {2018},\n    booktitle = {ECCV},\n    author = {Zhang, Yulun and Li, Kunpeng and Li, Kai and Wang, Lichen and Zhong, Bineng and Fu, Yun},\n    title = {Image Super-Resolution Using Very Deep Residual Channel Attention Networks},\n}"
      },
      "source": "https://raw.githubusercontent.com/Sudo-Biao/s-LWSR/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "author": "Li, Biao and Liu, Jiabin and Wang, Bo and Qi, Zhiquan and Shi, Yong",
        "format": "bibtex",
        "title": "s-LWSR: Super Lightweight Super-Resolution Network",
        "type": "Text_excerpt",
        "value": "@article{li2019s,\n    year = {2019},\n    journal = {arXiv preprint arXiv:1909.10774},\n    author = {Li, Biao and Liu, Jiabin and Wang, Bo and Qi, Zhiquan and Shi, Yong},\n    title = {s-LWSR: Super Lightweight Super-Resolution Network},\n}"
      },
      "source": "https://raw.githubusercontent.com/Sudo-Biao/s-LWSR/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/Sudo-Biao/s-LWSR"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2019-09-07T04:45:18Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2024-09-09T13:46:02Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "s-LWSR:  A Super Lightweight Super-Resolution Network"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Introduction",
        "parent_header": [
          "s-LWSR: Super Lightweight Super-Resolution Network"
        ],
        "type": "Text_excerpt",
        "value": "Deep learning (DL) architectures for superresolution (SR) normally contain tremendous parameters, which has been regarded as the crucial advantage for obtaining satisfying performance. However, with the widespread use of mobile phones for taking and retouching photos, this character greatly hampers the deployment of DL-SR models on the mobile devices. To address this problem, in this paper, we propose a super lightweight SR network: s-LWSR. There are mainly three contributions in our work. Firstly, in order to efficiently abstract features from the low resolution image, we build an information pool to mix multi-level information from the first half part of the pipeline. Accordingly, the information pool feeds the second half part with the combination of hierarchical features from the previous layers. Secondly, we employ a compression module to further decrease the size of parameters. Intensive analysis confirms its capacity of trade-off between model complexity and accuracy. Thirdly, by revealing the specific role of activation in deep models, we remove several activation layers in our SR model to retain more information for performance improvement. Extensive experiments show that our s-LWSR, with limited parameters and operations, can achieve similar performance to other cumbersome DL-SR methods.\n\n"
      },
      "source": "https://raw.githubusercontent.com/Sudo-Biao/s-LWSR/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 0.9361651756367636,
      "result": {
        "original_header": "s-LWSR: Super Lightweight Super-Resolution Network",
        "type": "Text_excerpt",
        "value": "This is the code of the paper in following: \n[Biao Li](https://github.com/Sudo-Biao), [Bo Wang](http://it.uibe.edu.cn/szdw/dsjkxyjzx/50452.htm), [Jiabin Liu](https://github.com/liujiabin008), [Zhiquan Qi](https://github.com/qizhiquan) and [Yong Shi](http://www.feds.ac.cn/index.php/zh-cn/zxjs/zxld/1447-sy)\"s-LWSR: Super Lightweight Super-Resolution Network\", [[arXiv]](https://arxiv.org/abs/1909.10774) [Accepted by IEEE Transactions on Image Processing] \n\nThe code is built on [EDSR (PyTorch)](https://github.com/thstkdgus35/EDSR-PyTorch) and [RCAN(Pytorch)](https://github.com/yulunzhang/RCAN), and tested on Ubuntu 18.04 environment (Python3.7, PyTorch_1.0) with Titan Xp GPU. \n \n"
      },
      "source": "https://raw.githubusercontent.com/Sudo-Biao/s-LWSR/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8648893847449981,
      "result": {
        "original_header": "Model structure",
        "type": "Text_excerpt",
        "value": "![Model structure](/Figs/stru.PNG)\nThe figure of our proposed s-LWSR. \n"
      },
      "source": "https://raw.githubusercontent.com/Sudo-Biao/s-LWSR/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/Sudo-Biao/s-LWSR/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 5
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/Sudo-Biao/s-LWSR/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "Sudo-Biao/s-LWSR"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "s-LWSR: Super Lightweight Super-Resolution Network"
      },
      "source": "https://raw.githubusercontent.com/Sudo-Biao/s-LWSR/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "has_script_file": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Sudo-Biao/s-LWSR/master/Train/code/Train.sh"
      },
      "technique": "file_exploration"
    }
  ],
  "images": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Sudo-Biao/s-LWSR/master//Figs/Cont1.PNG"
      },
      "source": "https://raw.githubusercontent.com/Sudo-Biao/s-LWSR/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Sudo-Biao/s-LWSR/master//Figs/Cont2.PNG"
      },
      "source": "https://raw.githubusercontent.com/Sudo-Biao/s-LWSR/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Sudo-Biao/s-LWSR/master//Figs/Cont3.PNG"
      },
      "source": "https://raw.githubusercontent.com/Sudo-Biao/s-LWSR/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Sudo-Biao/s-LWSR/master//Figs/stru.PNG"
      },
      "source": "https://raw.githubusercontent.com/Sudo-Biao/s-LWSR/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "installation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Prepare training data",
        "parent_header": [
          "s-LWSR: Super Lightweight Super-Resolution Network",
          "Train"
        ],
        "type": "Text_excerpt",
        "value": "Our  experiments  are  similar  as  RCAN:\n1. Download DIV2K training data (800 training + 100 validtion images) from [DIV2K dataset](https://data.vision.ee.ethz.ch/cvl/DIV2K/) and put in the file DIV2K.\n\n2. Carefully check the dir of HR  and  LR images following the option file. Moreover, '--ext' of  option.py is set as 'sep_reset', which firstly convert .png to .npy. If all the training images (.png) are converted to .npy files, then set '--ext sep' to skip converting files.\n\nFor more informaiton, please refer to [EDSR(PyTorch)](https://github.com/thstkdgus35/EDSR-PyTorch) and [RCAN(Pytorch)](https://github.com/yulunzhang/RCAN).\n"
      },
      "source": "https://raw.githubusercontent.com/Sudo-Biao/s-LWSR/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 0.9999596609751485,
      "result": {
        "original_header": "s-LWSR: Super Lightweight Super-Resolution Network",
        "type": "Text_excerpt",
        "value": "\nThe code is built on [EDSR (PyTorch)](https://github.com/thstkdgus35/EDSR-PyTorch) and [RCAN(Pytorch)](https://github.com/yulunzhang/RCAN), and tested on Ubuntu 18.04 environment (Python3.7, PyTorch_1.0) with Titan Xp GPU. \n \n"
      },
      "source": "https://raw.githubusercontent.com/Sudo-Biao/s-LWSR/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "invocation": [
    {
      "confidence": 0.8766586648378583,
      "result": {
        "original_header": "The whole test pipeline",
        "type": "Text_excerpt",
        "value": "1. Prepare test data. \n"
      },
      "source": "https://raw.githubusercontent.com/Sudo-Biao/s-LWSR/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8300406276608013,
      "result": {
        "original_header": "Quantitative Results",
        "type": "Text_excerpt",
        "value": "![Visual_PSNR_SSIM](/Figs/Cont1.PNG)\n![Visual_PSNR_SSIM](/Figs/Cont2.PNG)\n![Visual_PSNR_SSIM](/Figs/Cont3.PNG)\nQuantitative conparing results.All images are chosen from four mentioned test datasets. \n"
      },
      "source": "https://raw.githubusercontent.com/Sudo-Biao/s-LWSR/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/Sudo-Biao/s-LWSR/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ""
      },
      "technique": "GitHub_API"
    }
  ],
  "license": [
    {
      "confidence": 1,
      "result": {
        "name": "MIT License",
        "spdx_id": "MIT",
        "type": "License",
        "url": "https://api.github.com/licenses/mit",
        "value": "https://api.github.com/licenses/mit"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "type": "File_dump",
        "value": "MIT License\n\nCopyright (c) 2019 Biao\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
      },
      "source": "https://raw.githubusercontent.com/Sudo-Biao/s-LWSR/master/LICENSE",
      "technique": "file_exploration"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "s-LWSR"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "User",
        "value": "Sudo-Biao"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 182749,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "MATLAB",
        "size": 9227,
        "type": "Programming_language",
        "value": "MATLAB"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Shell",
        "size": 3513,
        "type": "Programming_language",
        "value": "Shell"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/Sudo-Biao/s-LWSR/master/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "related_papers": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://arxiv.org/abs/1909.10774"
      },
      "source": "https://raw.githubusercontent.com/Sudo-Biao/s-LWSR/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "somef_missing_categories": [
    "run",
    "download",
    "requirements",
    "contact",
    "contributors",
    "documentation",
    "faq",
    "support",
    "identifier",
    "has_build_file",
    "executable_example"
  ],
  "somef_provenance": {
    "date": "2024-10-06 14:32:57",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 37
      },
      "technique": "GitHub_API"
    }
  ],
  "usage": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Begin to train",
        "parent_header": [
          "s-LWSR: Super Lightweight Super-Resolution Network",
          "Train"
        ],
        "type": "Text_excerpt",
        "value": "1. Cd to 'Train/code', run the following scripts to train models.\n\n    **You can use scripts in file 'Train' to train models as paper. If you want to  more  about  our  model  setting,  you  can  check  in  the  model  folder..**\n\n    ```bash\n\n    BI, scale 2, 3, 4, 8\n    #s-LWSR_BIX2_P48, input=48x48, output=96x96\n    CUDA_VISIBLE_DEVICES=0 python main.py --model LWSR --save s-LWSR_BIX2_P48 --scale 2 --n_feats 32  --reset --chop --save_results --print_model --patch_size 96 2>&1 | tee $LOG\n\n    #s-LWSR_BIX3_P48, input=48x48, output=144x144\n    CUDA_VISIBLE_DEVICES=0 python main.py --model LWSR --save s-LWSR_BIX3_P48 --scale 3 --n_feats 32  --reset --chop --save_results --print_model --patch_size 144 2>&1 | tee $LOG\n\n    #s-LWSR_BIX4_P48, input=48x48, output=192x192\n    CUDA_VISIBLE_DEVICES=0 python main.py --model LWSR --save s-LWSR_BIX4_P48 --scale 4  --n_feats 32  --reset --chop --save_results --print_model --patch_size 192 2>&1 | tee $LOG\n\n    #s-LWSR_BIX8_P48, input=48x48, output=384x384\n    CUDA_VISIBLE_DEVICES=0 python main.py --model RCAN --save s-LWSR_BIX8_P48 --scale 8  --n_feats 32  --reset --chop --save_results --print_model --patch_size 384 2>&1 | tee $LOG\n\n    ```\n"
      },
      "source": "https://raw.githubusercontent.com/Sudo-Biao/s-LWSR/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Quick start",
        "parent_header": [
          "s-LWSR: Super Lightweight Super-Resolution Network",
          "Test"
        ],
        "type": "Text_excerpt",
        "value": "1. Download our  pre-trained  models [s-LWSR(PyTorch)](https://drive.google.com/drive/folders/11eqKn1PsLXRtbrbh_LhJ7WxHtU8Ih2ym?usp=sharing) and place them in '/Test/model'. Please be make sure that the code and its corresponding pre-trained model are consistant, because there are several different settings contained in our files. \n\n    We just  train  our  model on X4 task and  more  information  will  be released soon.\n\n2. Cd to '/Test/code', run the following scripts.\n\n    **You can use scripts in file 'Test' to produce results for our paper.**\n\n    ```bash\n    # No self-ensemble: RCAN\n    # BI degradation model, X2, X3, X4, X8\n    #s-LWSR_BIX2\n    CUDA_VISIBLE_DEVICES=0 python main.py --data_test MyImage --scale 2 --model LWSR --n_feats 32 --pre_train ../model/model_latest.pt --test_only --save_results --chop --save 'LWSR' --testpath /home/li/\u684c\u9762/s-LWSR/Test/LR/LRBI --testset Set5\n    #s-LWSR_BIX3\n    CUDA_VISIBLE_DEVICES=0 python main.py --data_test MyImage --scale 3 --model LWSR --n_feats 32 --pre_train ../model/model_latest.pt --test_only --save_results --chop --save 'LWSR' --testpath /home/li/\u684c\u9762/s-LWSR/Test/LR/LRBI --testset Set5\n    #s-LWSR_BIX4\n    CUDA_VISIBLE_DEVICES=0 python main.py --data_test MyImage --scale 4 --model LWSR --n_feats 32 --pre_train ../model/model_latest.pt --test_only --save_results --chop --save 'LWSR' --testpath /home/li/\u684c\u9762/s-LWSR/Test/LR/LRBI --testset Set5\t\t\t\t\n    #RCAN_BIX8\n    CUDA_VISIBLE_DEVICES=0 python main.py --data_test MyImage --scale 8 --model LWSR --n_feats 32 --pre_train ../model/model_latest.pt --test_only --save_results --chop --save 'LWSR' --testpath /home/li/\u684c\u9762/s-LWSR/Test/LR/LRBI --testset Set5\n    \n    #s-LWSRplus_BIX2\n    CUDA_VISIBLE_DEVICES=0 python main.py --data_test MyImage --scale 2 --model LWSR --n_feats 32 --pre_train ../model/model_latest.pt --test_only --save_results --chop --self_ensemble --save 'LWSRplus' --testpath /home/li/\u684c\u9762/s-LWSR/Test/LR/LRBI --testset Set5\n    #s-LWSRplus_BIX3\n    CUDA_VISIBLE_DEVICES=0 python main.py --data_test MyImage --scale 3 --model LWSR --n_feats 32 --pre_train ../model/model_latest.pt --test_only --save_results --chop --self_ensemble --save 'LWSRplus' --testpath /home/li/\u684c\u9762/s-LWSR/Test/LR/LRBI --testset Set5\n    #s-LWSRplus_BIX4\n    CUDA_VISIBLE_DEVICES=0 python main.py --data_test MyImage --scale 4 --model LWSR --n_feats 32 --pre_train ../model/model_latest.pt --test_only --save_results --chop --self_ensemble --save 'LWSRplus' --testpath /home/li/\u684c\u9762/s-LWSR/Test/LR/LRBI --testset Set5\n    #s-LWSRplus_BIX8\n    CUDA_VISIBLE_DEVICES=0 python main.py --data_test MyImage --scale 8 --model LWSR --n_feats 32 --pre_train ../model/model_latest.pt --test_only --save_results --chop --self_ensemble --save 'LWSRplus' --testpath /home/li/\u684c\u9762/s-LWSR/Test/LR/LRBI --testset Set5\n    ```"
      },
      "source": "https://raw.githubusercontent.com/Sudo-Biao/s-LWSR/master/README.md",
      "technique": "header_analysis"
    }
  ]
}