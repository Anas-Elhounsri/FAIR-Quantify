{
  "application_domain": [
    {
      "confidence": 19.55,
      "result": {
        "type": "String",
        "value": "Computer Vision"
      },
      "technique": "supervised_classification"
    }
  ],
  "citation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "References:",
        "parent_header": [
          ":snowflake::dragon: cryoDRGN: Deep Reconstructing Generative Networks for cryo-EM and cryo-ET heterogeneous reconstruction"
        ],
        "type": "Text_excerpt",
        "value": "For a complete description of the method, see:\n\n* CryoDRGN: reconstruction of heterogeneous cryo-EM structures using neural networks\nEllen D. Zhong, Tristan Bepler, Bonnie Berger*, Joseph H Davis*\nNature Methods 2021, https://doi.org/10.1038/s41592-020-01049-4 [pdf](https://ezlab.princeton.edu/assets/pdf/2021_cryodrgn_nature_methods.pdf)\n\nAn earlier version of this work appeared at ICLR 2020:\n\n* Reconstructing continuous distributions of protein structure from cryo-EM images\nEllen D. Zhong, Tristan Bepler, Joseph H. Davis*, Bonnie Berger*\nICLR 2020, Spotlight, https://arxiv.org/abs/1909.05215\n\nCryoDRGN2's ab initio reconstruction algorithms were published at ICCV:\n\n* CryoDRGN2: Ab Initio Neural Reconstruction of 3D Protein Structures From Real Cryo-EM Images\nEllen D. Zhong, Adam Lerer, Joseph H Davis, and Bonnie Berger\nInternational Conference on Computer Vision (ICCV) 2021, [paper](https://openaccess.thecvf.com/content/ICCV2021/papers/Zhong_CryoDRGN2_Ab_Initio_Neural_Reconstruction_of_3D_Protein_Structures_From_ICCV_2021_paper.pdf)\n\nA protocols paper that describes the analysis of the EMPIAR-10076 assembling ribosome dataset:\n\n* Uncovering structural ensembles from single particle cryo-EM data using cryoDRGN\nLaurel Kinman, Barrett Powell, Ellen D. Zhong*, Bonnie Berger*, Joseph H Davis*\nNature Protocols 2023, https://doi.org/10.1038/s41596-022-00763-x\n\nHeterogeneous subtomogram averaging:\n\n* Deep reconstructing generative networks for visualizing dynamic biomolecules inside cells\nRangan et al.\nbioRxiv 2023, https://www.biorxiv.org/content/10.1101/2023.08.18.553799v1\n"
      },
      "source": "https://raw.githubusercontent.com/zhonge/cryodrgn/main/README.md",
      "technique": "header_analysis"
    }
  ],
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/ml-struct-bio/cryodrgn"
      },
      "technique": "GitHub_API"
    }
  ],
  "contact": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Contact",
        "parent_header": [
          ":snowflake::dragon: cryoDRGN: Deep Reconstructing Generative Networks for cryo-EM and cryo-ET heterogeneous reconstruction"
        ],
        "type": "Text_excerpt",
        "value": "Please submit any bug reports, feature requests, or general usage feedback as a github issue or discussion.\n"
      },
      "source": "https://raw.githubusercontent.com/zhonge/cryodrgn/main/README.md",
      "technique": "header_analysis"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2019-11-25T20:26:34Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2024-10-03T01:14:50Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "Neural networks for cryo-EM reconstruction"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 0.9701017506025592,
      "result": {
        "original_header": ":snowflake::dragon: cryoDRGN: Deep Reconstructing Generative Networks for cryo-EM and cryo-ET heterogeneous reconstruction",
        "type": "Text_excerpt",
        "value": "CryoDRGN is a neural network based algorithm for heterogeneous cryo-EM reconstruction. In particular, the method models\na *continuous* distribution over 3D structures by using a neural network based representation for the volume. \n"
      },
      "source": "https://raw.githubusercontent.com/zhonge/cryodrgn/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9465032250506071,
      "result": {
        "original_header": "Previous versions",
        "type": "Text_excerpt",
        "value": "<details><summary>Version 3.3</summary><ul>\n  <li>[NEW] <code>cryodrgn direct_traversal</code> to generate interpolations in the conformation latent space\nbetween two points</li>\n  <li>support for .txt files in <code>write_star</code></li>\n  <li>adding <code>--datadir</code> to <code>cryodrgn abinit_homo</code> for use with .star files</li>\n  <li>fixing various bugs in <code>backproject_voxel</code>, Jupyter demonstration notebooks</li>\n  <li>support for TestPyPI beta release deployments via <code>pip</code></li>\n</ul></details> \n<details><summary>Version 3.2</summary><ul>\n  <li>[NEW] <code>cryodrgn_utils clean</code> for removing extraneous output files from completed experiments</li>\n  <li>[NEW] <code>cryodrgn_utils fsc</code>, <code>cryodrgn_utils fsc_plot</code>,\n<code>cryodrgn_utils gen_mask</code>adapted from existing scripts \u2014 for calculating FSCs, plotting them, and\ngenerating masks for volumes respectively</li>\n  <li><code>cryodrgn backproject_voxel</code> now produces half-maps and a half-map FSC</li>\n  <li>fixing <code>filter_star</code> to accept tilt series as well</li>\n  <li>fixing assorted bugs in e.g. <code>write_star</code>, <code>invert_constrast</code>, and\n<code>train_vae</code> (see release notes)\n</ul></details> \n<details><summary>Version 3.1</summary><ul>\n  <li><code>cryodrgn filter</code> interface for interactive filtering of particles as an alternative to the\ncryoDRGN_filter Jupyter notebook</li>\n</ul></details> \n<details><summary>Version 2.2</summary><ul>\n  <li>[NEW] Tools for ab initio homogeneous and heterogeneous reconstruction: \n\n    (cryodrgn) $ cryodrgn_utils write_cs\n  </li>\n  <li>[Improved plotting](https://github.com/zhonge/cryodrgn/issues/219) in <code>cryodrgn analyze</code></li>\n  <li>Many codebase improvements with open-source software development practices (e.g. continuous integration tests,\nblack, flake8, pyright, logging, and PyPi packaging).</li>\n</ul></details> \n<details><summary>Version 1.1.x</summary>\nUpdated default parameters for <code>cryodrgn train_vae</code> with modified positional encoding, larger model\narchitecture, and accelerated mixed-precision training turned on by default:\n<ul>\n  <li>Mixed precision training is now turned on by default (Use <code>--no-amp</code> to revert to single precision\ntraining)</li>\n  <li>Encoder/decoder architecture is now 1024x3 by default (Use <code>--enc-dim 256</code> and <code>--dec-dim\n256</code> to revert)\n</li>\n  <li>Gaussian Fourier featurization for faster training and higher resolution density maps (Use <code>--pe-type\ngeom_lowf</code>\nto revert)</li>\n</ul></details> \n<details><summary>Version 1.0.x</summary>\nThe official version 1.0 release. This version introduces several new tools for analysis of the reconstructed ensembles,\nand adds functionality for calling utility scripts with <code>cryodrgn_utils {command}</code>.\n<ul>\n  <li>NEW: <code>cryodrgn analyze_landscape</code> and <code>cryodrgn analyze_landscape_full</code> for automatic\nassignment of classes and conformational landscape visualization. Documentation for this new feature is here:\nhttps://www.notion.so/cryodrgn-conformational-landscape-analysis-a5af129288d54d1aa95388bdac48235a.</li>\n  <li>NEW: Faster training and higher resolution model\nwith Gaussian Fourier featurization (Use <code>--pe-type gaussian</code>)</li>\n  <li>NEW: <code>cryodrgn_utils {command} -h</code> for standalone utility scripts</li>\n  <li>NEW: <code>cryodrgn_utils write_star</code> for converting cryoDRGN particle selections to .star files</li>\n  <li>Add pytorch native mixed precision training and fix support for pytorch 1.9+</li>\n</ul></details> \n<details><summary>Version 0.3.4</summary><ul>\n    <li>FIX: Bug in write_starfile.py when provided particle stack is chunked (.txt file)</li>\n    <li>Support micrograph coordinates and additional column headers to write_starfile.py</li>\n    <li>New helper scripts: analyze_convergence.py (<i>in beta testing</i>) contributed by <a href=\"bmp@mit.\nedu\">Barrett\nPowell</a> (thanks!) and make_random_selection.py for splitting up particle stacks for training</li>\n</ul></details> \n<details><summary>Version 0.3.3</summary><ul>\n    <li>Faster image preprocessing and smaller memory footprint</li>\n    <li>New: <code>cryodrgn preprocess</code> for large datasets (<i>in beta testing</i> - see\n<a href=\"https://www.notion.so/cryodrgn-preprocess-d84a9d9df8634a6a8bfd32d6b5e737ef\">this Notion doc</a> for details)\n</li>\n    <li>* Known <a href=\"https://github.com/zhonge/cryodrgn/issues/66\">issue</a> with PyTorch version 1.9+</li>\n</ul></details> \n<details><summary>Version 0.3.2</summary><ul>\n    <li>New: cryoDRGN_filtering.ipynb for interactive filtering and selection of images from the dataset</li>\n    <li>New: <code>cryodrgn view_config</code></li>\n    <li>Minor performance improvements and compatibility fixes</li>\n</ul></details> \n<details><summary>Version 0.3.1</summary><ul>\n    <li>New: Script write_starfile.py to convert (filtered) particle selection to a .star file</li>\n    <li>More visualizations in <code>cryodrgn analyze</code></li>\n</ul></details> \n<details><summary>Version 0.3.0</summary><ul>\n    <li>New: GPU parallelization with flag <code>--multigpu</code></li>\n    <li>New: Mode for accelerated mixed precision training with flag <code>--amp</code>, available for NVIDIA\ntensor core GPUs</li>\n    <li>Interface update: renamed encoder arguments <code>--qdim</code> and <code>--qlayers</code> to\n<code>--enc-dim</code> and <code>--enc-layers</code>; renamed decoder arguments <code>--pdim</code> and\n<code>--players</code> to <code>--dec-dim</code> and <code>--dec-layers</code></li>\n    <li>Argument default changes: flipped the default for <code>--invert-data</code> to True by default, and\nflipped the default for <code>--window</code> to True by default</li>\n    <li>Updated training recommendations in below quick start guide</li>\n    <li>Updates to cryodrgn analyze: more visualizations, ordering kmeans volumes according to distances in latent\nspace (previously random), and more features for particle selection and filtering in the Jupiter notebook</li>\n</ul></details> \n<details><summary>Version 0.2.1</summary><ul>\n    <li>New: Parsing of RELION 3.1 files</li>\n    <li>Fix: Compatibility with pytorch 1.5</li>\n</ul></details> \n<details><summary>Version 0.2.0</summary><ul>\n    <li>New interface and proper python packaging with setup.py. This version has identical functionality and\nargument usage as previous versions, however tools are now available from a common entry point. See: \n</li>\n<li>New analysis pipeline <code>cryodrgn analyze</code></li>\n<li>New latent space traversal scripts with\n<code>cryodrgn graph_traversal</code> and <code>cryodrgn pc_traversal</code>.</li>\n</ul></details> \n"
      },
      "source": "https://raw.githubusercontent.com/zhonge/cryodrgn/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9108061955625947,
      "result": {
        "original_header": "1. Preprocess image stack",
        "type": "Text_excerpt",
        "value": "<details><summary><code>$ cryodrgn downsample -h</code></summary> \n    optional arguments:\n      -h, --help         show this help message and exit\n      -D D               New box size in pixels, must be even\n      -o MRCS            Output image stack (.mrcs) or volume (.mrc)\n      --is-vol           Flag if input .mrc is a volume\n      --chunk CHUNK      Chunksize (in # of images) to split particle stack when\n                         saving\n      --relion31         Flag for relion3.1 star format\n      --datadir DATADIR  Optionally provide path to input .mrcs if loading from a\n                         .star or .cs file\n      --max-threads MAX_THREADS\n                         Maximum number of CPU cores for parallelization (default: 16)\n      --ind PKL          Filter image stack by these indices \nThe maximum recommended image size is D=256, so we also recommend downsampling your images to D=256 if your images\nare larger than 256x256: \nIf there are memory issues with downsampling large particle stacks, add the `--chunk 10000` argument to\nsave images as separate `.mrcs` files of 10k images.\n \n"
      },
      "source": "https://raw.githubusercontent.com/zhonge/cryodrgn/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8338361151281284,
      "result": {
        "original_header": "2. Parse image poses from a consensus homogeneous reconstruction",
        "type": "Text_excerpt",
        "value": "**Note:** The `-D` argument should be the box size of the consensus refinement (and not the downsampled\nimages from step 1) so that the units for translation shifts are parsed correctly.\n \n"
      },
      "source": "https://raw.githubusercontent.com/zhonge/cryodrgn/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9008403851949088,
      "result": {
        "original_header": "3. Parse CTF parameters from a .star/.cs file",
        "type": "Text_excerpt",
        "value": "If the box size and Angstrom/pixel values are not included in the .star file under fields `_rlnImageSize` and\n`_rlnImagePixelSize` respectively, the `-D` and `--Apix` arguments to `parse_ctf_star` should be used instead to\nprovide the original parameters of the input file (before any downsampling): \n"
      },
      "source": "https://raw.githubusercontent.com/zhonge/cryodrgn/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8782182964344983,
      "result": {
        "original_header": "4. (Optional) Test pose/CTF parameters parsing",
        "type": "Text_excerpt",
        "value": "**Note:** If the volume does not resemble your structure, you may need to use the flag `--uninvert-data`.\nThis flips the data sign (e.g. light-on-dark or dark-on-light), which may be needed depending on the\nconvention used in upstream processing tools.\n \n"
      },
      "source": "https://raw.githubusercontent.com/zhonge/cryodrgn/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9278613963725025,
      "result": {
        "original_header": "Accelerated training with GPU parallelization",
        "type": "Text_excerpt",
        "value": "We recommend using `--multigpu` for large images, e.g. D=256.\nNote that GPU computation may not be the training bottleneck for smaller images (D=128).\nIn this case, `--multigpu` may not speed up training (while taking up additional compute resources). \nWith `--multigpu`, the batch size is multiplied by the number of available GPUs to better utilize GPU resources.\nWe note that GPU utilization may be further improved by increasing the batch size (e.g. `-b 16`), however,\nfaster wall-clock time per epoch does not necessarily lead to faster *model training* since the training dynamics\nare affected (fewer model updates per epoch with larger `-b`),\nand using `--multigpu` may require increasing the total number of epochs.\n \n"
      },
      "source": "https://raw.githubusercontent.com/zhonge/cryodrgn/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8378379132066132,
      "result": {
        "original_header": "Local pose refinement -- *beta*",
        "type": "Text_excerpt",
        "value": "Depending on the quality of the consensus reconstruction, image poses may contain errors.\nImage poses may be *locally* refined using the `--do-pose-sgd` flag, however, we recommend reaching out to the\ndevelopers for recommended training settings.\n \n"
      },
      "source": "https://raw.githubusercontent.com/zhonge/cryodrgn/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8811757745470566,
      "result": {
        "original_header": "6. Analysis of results",
        "type": "Text_excerpt",
        "value": "Once the model has finished training, the output directory will contain a configuration file `config.yaml`,\nneural network weights `weights.pkl`, image poses (if performing pose sgd) `pose.pkl`,\nand the latent embeddings for each image `z.pkl`.\nThe latent embeddings are provided in the same order as the input particles.\nTo analyze these results, use the `cryodrgn analyze` command to visualize the latent space and generate structures.\n`cryodrgn analyze` will also provide a template jupyter notebook for further interactive visualization and analysis. \n"
      },
      "source": "https://raw.githubusercontent.com/zhonge/cryodrgn/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9220333295747215,
      "result": {
        "original_header": "cryodrgn analyze",
        "type": "Text_excerpt",
        "value": "<details><summary><code>$ cryodrgn analyze -h</code></summary> \n\tVisualize latent space and generate volumes \n\tExtra arguments for volume generation:\n\t  --Apix APIX           Pixel size to add to .mrc header (default: 1 A/pix)\n\t  --flip                Flip handedness of output volumes\n\t  --invert              Invert contrast of output volumes\n\t  -d DOWNSAMPLE, --downsample DOWNSAMPLE\n\t                        Downsample volumes to this box size (pixels)\n\t  --pc PC               Number of principal component traversals to generate\n\t                        (default: 2)\n\t  --ksample KSAMPLE     Number of kmeans samples to generate (default: 20) \nThis script runs a series of standard analyses: \n* PCA visualization of the latent embeddings\n* UMAP visualization of the latent embeddings\n* Generation of volumes. See note [1].\n* Generation of trajectories along the first and second principal components of the latent embeddings\n* Generation of template jupyter notebooks that may be used for further interactive analyses, visualization, and volume generation \n    $ cryodrgn analyze 01_cryodrgn256 24 --Apix 1.31 # 24 for 0-based indexing of epoch numbers \n[1] Volumes are generated after k-means clustering of the latent embeddings with k=20 by default.\nNote that we use k-means clustering here not to identify clusters, but to segment the latent space and\ngenerate structures from different regions of the latent space.\nThe number of structures that are generated may be increased with the option `--ksample`. \n[2] The `cryodrgn analyze` command chains together a series of calls to `cryodrgn eval_vol` and other scripts\nthat can be run separately for more flexibility.\nThese scripts are located in the `analysis_scripts` directory within the source code. \n[3] In particular, you may find it useful to perform filtering of particles separately from other analyses. This can\ndone using our interactive interface available from the command line: `cryodrgn filter 01_cryodrgn256`. \n[4] `--Apix` only needs to be given if it is not present (or not accurate) in the CTF file that was used in training. \n"
      },
      "source": "https://raw.githubusercontent.com/zhonge/cryodrgn/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.911173863481426,
      "result": {
        "original_header": "Generating additional volumes",
        "type": "Text_excerpt",
        "value": "A simple way of generating additional volumes is to increase the number of k-means samples in `cryodrgn analyze`\nby using the flag `--ksample 100` (for 100 structures).\nFor additional flexibility, `cryodrgn eval_vol` may be called directly: \n<details><summary><code>$ cryodrgn eval_vol -h</code></summary> \n\tVolume arguments:\n\t  --Apix APIX           Pixel size to add to .mrc header (default: 1 A/pix)\n\t  --flip                Flip handedness of output volume\n\t  -d DOWNSAMPLE, --downsample DOWNSAMPLE\n\t                        Downsample volumes to this box size (pixels) \n\tOverwrite architecture hyperparameters in config.yaml:\n\t  --norm NORM NORM\n\t  -D D                  Box size\n\t  --enc-layers QLAYERS  Number of hidden layers\n\t  --enc-dim QDIM        Number of nodes in hidden layers\n\t  --zdim ZDIM           Dimension of latent variable\n\t  --encode-mode {conv,resid,mlp,tilt}\n\t                        Type of encoder network\n\t  --dec-layers PLAYERS  Number of hidden layers\n\t  --dec-dim PDIM        Number of nodes in hidden layers\n\t  --enc-mask ENC_MASK   Circular mask radius for image encoder\n\t  --pe-type {geom_ft,geom_full,geom_lowf,geom_nohighf,linear_lowf,none}\n\t                        Type of positional encoding\n\t  --pe-dim PE_DIM       Num sinusoid features in positional encoding (default:\n\t                        D/2)\n\t  --domain {hartley,fourier}\n\t  --l-extent L_EXTENT   Coordinate lattice size\n\t  --activation {relu,leaky_relu}\n\t                        Activation (default: relu) \nTo generate a volume at a single value of the latent variable: \nThe number of inputs for `-z` must match the dimension of your latent variable. \nOr to generate a trajectory of structures from a defined start and ending point,\nuse the `--z-start` and `--z-end` arugments: \nFinally, a series of structures can be generated using values of z given in a file specified by the arugment `--zfile`: \nThe input to `--zfile` is expected to be an array of dimension (N_volumes x zdim), loaded with np.loadtxt.\n \n"
      },
      "source": "https://raw.githubusercontent.com/zhonge/cryodrgn/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9298780847008912,
      "result": {
        "original_header": "Making trajectories",
        "type": "Text_excerpt",
        "value": "Two additional commands can be used in conjunction with `cryodrgn eval_vol` to generate trajectories: \nThese scripts produce a text file of z values that can be input to `cryodrgn eval_vol` to generate a series of\nstructures that can be visualized as a trajectory in ChimeraX (https://www.cgl.ucsf.edu/chimerax). \n"
      },
      "source": "https://raw.githubusercontent.com/zhonge/cryodrgn/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9899083356435363,
      "result": {
        "original_header": "cryodrgn analyze_landscape",
        "type": "Text_excerpt",
        "value": "NEW in version 1.0: There are two additional tools `cryodrgn analyze_landscape` and `cryodrgn analyze_landscape_full`\nfor more comprehensive and automated analyses of cryodrgn results. \n"
      },
      "source": "https://raw.githubusercontent.com/zhonge/cryodrgn/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9139407897609284,
      "result": {
        "original_header": "CryoDRGN-ET for subtomogram analysis",
        "type": "Text_excerpt",
        "value": "Available in beta release starting in version 3.x. Documentation for getting started can be found\nin the [user guide](https://ez-lab.gitbook.io/cryodrgn/cryodrgn-et-subtomogram-analysis). Please reach out if you have any questions!\n \n"
      },
      "source": "https://raw.githubusercontent.com/zhonge/cryodrgn/main/README.md",
      "technique": "supervised_classification"
    }
  ],
  "documentation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Documentation",
        "parent_header": [
          ":snowflake::dragon: cryoDRGN: Deep Reconstructing Generative Networks for cryo-EM and cryo-ET heterogeneous reconstruction"
        ],
        "type": "Text_excerpt",
        "value": "The latest documentation for cryoDRGN is available in our [user guide](https://ez-lab.gitbook.io/cryodrgn/), including an overview and walkthrough of\ncryoDRGN installation, training and analysis. A brief quick start is provided below.\n\nFor any feedback, questions, or bugs, please file a Github issue or start a Github discussion.\n\n"
      },
      "source": "https://raw.githubusercontent.com/zhonge/cryodrgn/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "New in Version 3.4.0",
        "parent_header": [
          ":snowflake::dragon: cryoDRGN: Deep Reconstructing Generative Networks for cryo-EM and cryo-ET heterogeneous reconstruction",
          "Documentation"
        ],
        "type": "Text_excerpt",
        "value": "* [NEW] `cryodrgn plot_classes` for analysis visualizations colored by a given set of class labels\n* full support for RELION 3.1 .star files with separate optics tables\n* `cryodrgn backproject_voxel` produces cryoSPARC-style FSC curve plots with phase-randomization correction of\n  automatically generated tight masks\n* `cryodrgn downsample` can create a new .star or .txt image stack from the corresponding stack format instead of\n  always writing to an .mrcs stack; now also always puts output files into a folder\n* fixing issues with `cryodrgn filter` such as less intrusive annotation text and `np.array` instead of `list` output\n  format\n* official support for Python 3.11\n\n"
      },
      "source": "https://raw.githubusercontent.com/zhonge/cryodrgn/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "New in Version 3.x",
        "parent_header": [
          ":snowflake::dragon: cryoDRGN: Deep Reconstructing Generative Networks for cryo-EM and cryo-ET heterogeneous reconstruction",
          "Documentation"
        ],
        "type": "Text_excerpt",
        "value": "The official release of [cryoDRGN-ET](https://www.biorxiv.org/content/10.1101/2023.08.18.553799v1) for heterogeneous subtomogram analysis.\n\n* [NEW] Heterogeneous reconstruction of subtomograms. See documentation [on gitbook](https://ez-lab.gitbook.io/cryodrgn/)\n* Updated `cryodrgn backproject_voxel` for voxel-based homogeneous reconstruction\n* Major refactor of dataset loading for handling large datasets\n\n"
      },
      "source": "https://raw.githubusercontent.com/zhonge/cryodrgn/main/README.md",
      "technique": "header_analysis"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/zhonge/cryodrgn/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "executable_example": [
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/zhonge/cryodrgn/main/cryodrgn/templates/cryoDRGN_viz_template.ipynb"
      },
      "source": "https://raw.githubusercontent.com/zhonge/cryodrgn/main/cryodrgn/templates/cryoDRGN_viz_template.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/zhonge/cryodrgn/main/cryodrgn/templates/cryoDRGN_filtering_template.ipynb"
      },
      "source": "https://raw.githubusercontent.com/zhonge/cryodrgn/main/cryodrgn/templates/cryoDRGN_filtering_template.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/zhonge/cryodrgn/main/cryodrgn/templates/cryoDRGN_figures_template.ipynb"
      },
      "source": "https://raw.githubusercontent.com/zhonge/cryodrgn/main/cryodrgn/templates/cryoDRGN_figures_template.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/zhonge/cryodrgn/main/cryodrgn/templates/cryoDRGN_analyze_landscape_template.ipynb"
      },
      "source": "https://raw.githubusercontent.com/zhonge/cryodrgn/main/cryodrgn/templates/cryoDRGN_analyze_landscape_template.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/zhonge/cryodrgn/main/cryodrgn/templates/cryoDRGN_ET_viz_template.ipynb"
      },
      "source": "https://raw.githubusercontent.com/zhonge/cryodrgn/main/cryodrgn/templates/cryoDRGN_ET_viz_template.ipynb",
      "technique": "file_exploration"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 75
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/ml-struct-bio/cryodrgn/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "ml-struct-bio/cryodrgn"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ":snowflake::dragon: cryoDRGN: Deep Reconstructing Generative Networks for cryo-EM and cryo-ET heterogeneous reconstruction"
      },
      "source": "https://raw.githubusercontent.com/zhonge/cryodrgn/main/README.md",
      "technique": "regular_expression"
    }
  ],
  "has_script_file": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/zhonge/cryodrgn/main/sweep.sh"
      },
      "technique": "file_exploration"
    }
  ],
  "installation": [
    {
      "confidence": 1,
      "result": {
        "type": "File_dump",
        "value": "# cryoDRGN Installation\n\nWe provide installation instructions assuming an **Anaconda** environment for managing dependencies. Anaconda is a\npython package/environment manager which can handle complex dependencies between Python packages through the creation\nof python environments. We recommended creating a separate environment for cryodrgn to prevent any conflicts among\ndependencies with other software packages.\n\n**Compute/hardware requirements:**\n\n- High performance linux workstation or cluster\n- NVIDIA GPUs\n\n**Dependencies:**\n\n- python\n- pytorch\n- cudatoolkit\n- numpy\n- pandas\n\n**Additional dependencies for visualization:**\n\n- matplotlib\n- seaborn\n- scipy 1.4.0+\n- scikit-learn\n- umap\n- jupterlab\n- ipywidgets\n- plotly and cufflinks\n\nThe software has been tested on Python 3.7-3.9 and pytorch 1.0-1.7, 1.12.\n\n---\n\n## 1) Install anaconda\n\n- For most platforms, the installation typically consists of a shell script\n  (e.g. [Anaconda Installers](https://www.anaconda.com/products/distribution)) that you execute on the command line\n  which will prompt you to install and choose a base directory where all the downloaded software and environments will\n  go.\n\n  See the official Anaconda documentation and follow their installation instructions\n  [here](https://docs.anaconda.com/anaconda/install/).\n\n- Once your anaconda environment is activated, your anaconda environment should be indicated on the command line, e.g.:\n    - `(base) $`\n\n## 2) Setting up the cryoDRGN environment\n\n- First, create a new conda environment named `cryodrgn` (or renamed as appropriate):\n\n    ```bash\n    (base) $ conda create --name cryodrgn python=3.9\n    ```\n\n- Activate the environment. Your command prompt will usually indicate the environment you are in with\n  `(environment name)` before the prompt:\n\n    ```bash\n    (base) $ conda activate cryodrgn\n    (cryodrgn) $\n    ```\n\n- Install pytorch and cudatoolkit into your new cryodrgn environment:\n\n    ```bash\n    (cryodrgn) $ conda install pytorch cudatoolkit=11.7 -c pytorch\n    ```\n\n- Replace the cudatoolkit version with the appropriate version of CUDA installed with the GPU drivers. You can\n  check the CUDA version with `nvidia-smi`.\n  ```\n  +-----------------------------------------------------------------------------+\n  | NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |\n  |-------------------------------+----------------------+----------------------+\n  | GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n  | Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n  |                               |                      |               MIG M. |\n  |===============================+======================+======================|\n  |   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0 Off |                  N/A |\n  | N/A   41C    P0    N/A /  N/A |      5MiB /  4096MiB |      0%      Default |\n  |                               |                      |                  N/A |\n  +-------------------------------+----------------------+----------------------+\n\n  +-----------------------------------------------------------------------------+\n  | Processes:                                                                  |\n  |  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n  |        ID   ID                                                   Usage      |\n  |=============================================================================|\n  |    0   N/A  N/A      1420      G   /usr/lib/xorg/Xorg                  4MiB |\n  +-----------------------------------------------------------------------------+\n    ```\n  - Don't forget to include `-c pytorch` to get the software from the official pytorch channel\n  - To customize the installation line depending on your situation, look at Pytorch's\n    [Start locally](https://pytorch.org/get-started/locally/).\n\n- Optional step for older pytorch versions (pre-version 1.6). (Newer versions of pytorch natively support mixed\n  precision training.)\n    - For accelerated training speeds (~3x faster) on GPUs with tensor cores (Nvidia Volta, Turing, and Ampere GPU\n      architectures), install the apex package into the active conda environment. See their official documentation and\n      installation instructions [here](https://github.com/NVIDIA/apex#quick-start).\n\n    ```bash\n    git clone https://github.com/NVIDIA/apex\n    cd apex\n    pip install -v --disable-pip-version-check --no-cache-dir ./\n    ```\n\n## 3) Install cryoDRGN\n\n- Obtain cryodrgn source code by cloning the git repository, and then doing a `pip install .` in the checkout folder.\n  This will also install dependencies that `cryoDRGN` depends on.\n\n```bash\n# Clone source code and install\n(cryodrgn) $ git clone https://github.com/zhonge/cryodrgn.git\n(cryodrgn) $ cd cryodrgn\n(cryodrgn) $ pip install .\n```\n\n- Alternatively, if you prefer not to use git, you can directly download a ZIP file of the latest release from\n  [https://github.com/zhonge/cryodrgn/releases](https://github.com/zhonge/cryodrgn/releases). For example, if the latest\n  release is `cryodrgn-1.1.0.zip`:\n\n```bash\n(cryodrgn) $ unzip cryodrgn-1.1.0.zip\n(cryodrgn) $ cd cryodrgn-1.1.0\n(cryodrgn) $ pip install .\n```\n\n## 4) Testing the Installation\n\nOnce installed, you should be able to call the `cryodrgn` executable and see a list of commands:\n\n```bash\n(cryodrgn) $ cryodrgn -h\n```\n\nThere is a small testing dataset in the source code that you can use to run cryodrgn and verify that all the\ndependencies were installed correctly:\n\n```bash\n(cryodrgn) $ cd [sourcecode directory]/testing\n(cryodrgn) $ ./quicktest.sh\n```\n\nIt should take ~20 seconds to run and reach a final loss around 0.08 in version 1.0 and 0.03 in version 1.1+. The\noutput should look something like:\n\n```\n+ cryodrgn train_vae data/hand.mrcs -o output/toy_recon_vae --lr .0001 --seed 0 --poses data/hand_rot.pkl --zdim 10 --pe-type gaussian\n2022-09-20 16:30:05     /home/vineetb/.conda/envs/cryodrgn/bin/cryodrgn train_vae data/hand.mrcs -o output/toy_recon_vae --lr .0001 --seed 0 --poses data/hand_rot.pkl --zdim 10 --pe-type gaussian\n2022-09-20 16:30:05     Namespace(particles='/home/vineetb/cryodrgn/cryodrgn/testing/data/hand.mrcs', outdir='/home/vineetb/cryodrgn/cryodrgn/testing/output/toy_recon_vae', zdim=10, poses='/home/vineetb/cryodrgn/cryodrgn/testing/data/hand_rot.pkl', ctf=None, load=None, checkpoint=1, log_interval=1000, verbose=False, seed=0, ind=None, invert_data=True, window=True, window_r=0.85, datadir=None, lazy=False, preprocessed=False, max_threads=16, tilt=None, tilt_deg=45, num_epochs=20, batch_size=8, wd=0, lr=0.0001, beta=None, beta_control=None, norm=None, amp=True, multigpu=False, do_pose_sgd=False, pretrain=1, emb_type='quat', pose_lr=0.0003, qlayers=3, qdim=1024, encode_mode='resid', enc_mask=None, use_real=False, players=3, pdim=1024, pe_type='gaussian', feat_sigma=0.5, pe_dim=None, domain='fourier', activation='relu', func=<function main at 0x7f47d8676790>)\n2022-09-20 16:30:06     Use cuda True\n2022-09-20 16:30:06     Loading dataset from /home/vineetb/cryodrgn/cryodrgn/testing/data/hand.mrcs\n2022-09-20 16:30:06     Loaded 100 64x64 images\n2022-09-20 16:30:06     Windowing images with radius 0.85\n2022-09-20 16:30:06     Computing FFT\n2022-09-20 16:30:06     Spawning 16 processes\n2022-09-20 16:30:06     Symmetrizing image data\n2022-09-20 16:30:06     Normalized HT by 0 +/- 94.426513671875\n2022-09-20 16:30:06     WARNING: No translations provided\n2022-09-20 16:30:07     Using circular lattice with radius 32\n2022-09-20 16:30:07     HetOnlyVAE(\n  (encoder): ResidLinearMLP(\n    (main): Sequential(\n      (0): Linear(in_features=3208, out_features=1024, bias=True)\n      (1): ReLU()\n      (2): ResidLinear(\n        (linear): Linear(in_features=1024, out_features=1024, bias=True)\n      )\n      (3): ReLU()\n      (4): ResidLinear(\n        (linear): Linear(in_features=1024, out_features=1024, bias=True)\n      )\n      (5): ReLU()\n      (6): ResidLinear(\n        (linear): Linear(in_features=1024, out_features=1024, bias=True)\n      )\n      (7): ReLU()\n      (8): Linear(in_features=1024, out_features=20, bias=True)\n    )\n  )\n  (decoder): FTPositionalDecoder(\n    (decoder): ResidLinearMLP(\n      (main): Sequential(\n        (0): Linear(in_features=202, out_features=1024, bias=True)\n        (1): ReLU()\n        (2): ResidLinear(\n          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n        )\n        (3): ReLU()\n        (4): ResidLinear(\n          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n        )\n        (5): ReLU()\n        (6): ResidLinear(\n          (linear): Linear(in_features=1024, out_features=1024, bias=True)\n        )\n        (7): ReLU()\n        (8): Linear(in_features=1024, out_features=2, bias=True)\n      )\n    )\n  )\n)\n2022-09-20 16:30:07     9814038 parameters in model\n2022-09-20 16:30:07     6455316 parameters in encoder\n2022-09-20 16:30:07     3358722 parameters in decoder\n2022-09-20 16:30:07     Warning: z dimension is not a multiple of 8 -- AMP training speedup is not optimized\n2022-09-20 16:30:08     # =====> Epoch: 1 Average gen loss = 1.10873, KLD = 3.386924, total loss = 1.108840; Finished in 0:00:01.346893\n2022-09-20 16:30:09     # =====> Epoch: 2 Average gen loss = 0.740441, KLD = 8.101010, total loss = 0.740694; Finished in 0:00:00.542031\n2022-09-20 16:30:09     # =====> Epoch: 3 Average gen loss = 0.535575, KLD = 10.675920, total loss = 0.535908; Finished in 0:00:00.541637\n2022-09-20 16:30:10     # =====> Epoch: 4 Average gen loss = 0.368407, KLD = 13.592397, total loss = 0.368831; Finished in 0:00:00.541102\n2022-09-20 16:30:11     # =====> Epoch: 5 Average gen loss = 0.234344, KLD = 16.974737, total loss = 0.234873; Finished in 0:00:00.544139\n2022-09-20 16:30:11     # =====> Epoch: 6 Average gen loss = 0.140454, KLD = 19.307134, total loss = 0.141056; Finished in 0:00:00.541751\n2022-09-20 16:30:12     # =====> Epoch: 7 Average gen loss = 0.0899037, KLD = 20.093284, total loss = 0.090530; Finished in 0:00:00.544378\n2022-09-20 16:30:13     # =====> Epoch: 8 Average gen loss = 0.0641149, KLD = 20.714445, total loss = 0.064761; Finished in 0:00:00.543761\n2022-09-20 16:30:13     # =====> Epoch: 9 Average gen loss = 0.0496119, KLD = 20.798030, total loss = 0.050260; Finished in 0:00:00.545478\n2022-09-20 16:30:14     # =====> Epoch: 10 Average gen loss = 0.0408589, KLD = 21.089181, total loss = 0.041516; Finished in 0:00:00.548600\n2022-09-20 16:30:15     # =====> Epoch: 11 Average gen loss = 0.0338546, KLD = 21.053582, total loss = 0.034511; Finished in 0:00:00.560902\n2022-09-20 16:30:15     # =====> Epoch: 12 Average gen loss = 0.0290218, KLD = 21.509603, total loss = 0.029692; Finished in 0:00:00.549171\n2022-09-20 16:30:16     # =====> Epoch: 13 Average gen loss = 0.0252569, KLD = 21.402734, total loss = 0.025924; Finished in 0:00:00.554416\n2022-09-20 16:30:17     # =====> Epoch: 14 Average gen loss = 0.0222708, KLD = 21.686829, total loss = 0.022947; Finished in 0:00:00.549451\n2022-09-20 16:30:17     # =====> Epoch: 15 Average gen loss = 0.0196031, KLD = 21.829715, total loss = 0.020284; Finished in 0:00:00.547152\n2022-09-20 16:30:18     # =====> Epoch: 16 Average gen loss = 0.0175662, KLD = 21.648027, total loss = 0.018241; Finished in 0:00:00.548684\n2022-09-20 16:30:19     # =====> Epoch: 17 Average gen loss = 0.0159719, KLD = 21.876881, total loss = 0.016654; Finished in 0:00:00.540562\n2022-09-20 16:30:19     # =====> Epoch: 18 Average gen loss = 0.0147737, KLD = 21.754937, total loss = 0.015452; Finished in 0:00:00.541675\n2022-09-20 16:30:20     # =====> Epoch: 19 Average gen loss = 0.0133148, KLD = 21.684366, total loss = 0.013991; Finished in 0:00:00.543656\n2022-09-20 16:30:20     # =====> Epoch: 20 Average gen loss = 0.0124398, KLD = 21.621814, total loss = 0.013114; Finished in 0:00:00.543454\n2022-09-20 16:30:21     Finished in 0:00:15.839427 (0:00:00.791971 per epoch)\n```\n\n- You will want to verify that the output contains  `Use cuda True` in the first few lines to ensure that `cryoDRGN`\n  will be using your GPU for training.\n\n## Updating cryoDRGN\n\nTo update to a later version, you need to obtain the updated software either with `git checkout <version>` or direct\ndownload from [https://github.com/zhonge/cryodrgn](https://github.com/zhonge/cryodrgn), then rerun `$ pip install .`\nin your cryodrgn anaconda environment:\n\n```bash\n(cryodrgn) $ cd /path/to/repo\n(cryodrgn) $ git checkout 1.1.0  # or `git pull origin master` to get the latest sw\n(cryodrgn) $ pip install .\n```\n\nTo keep multiple versions of cryoDRGN in parallel, you will need to create a new anaconda environment and re-install\nall the dependencies.\n\n## Known Issues\n\n1. [Jupyter notebook widget not showing up](https://github.com/zhonge/cryodrgn/issues/34)\n2. In the jupyter notebook: no attribute `from_dcm` or `from_matrix`:\n    - e.g. `AttributeError: type object 'scipy.spatial.transform.rotation.Rotation' has no attribute 'from_dcm'`\n    - Make sure you are using scipy version 1.4.0 or later.\n    - If you are using scipy version 1.6.0 or later, make sure you are using cryodrgn version 0.3.2 or later.\n    - [https://github.com/zhonge/cryodrgn/issues/39](https://github.com/zhonge/cryodrgn/issues/39)\n3. In `cryodrgn analyze`: Running UMAP hangs for certain versions of umap\n    - Under active investigation [here](https://github.com/zhonge/cryodrgn/issues/53)\n\nIf you run into any issues getting cryoDRGN installed, please file a\n[github issue](http://www.github.com/zhonge/cryodrgn), including all the commands you used and their output.\n"
      },
      "source": "https://raw.githubusercontent.com/zhonge/cryodrgn/main/docs/pages/installation.md",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Installation",
        "parent_header": [
          ":snowflake::dragon: cryoDRGN: Deep Reconstructing Generative Networks for cryo-EM and cryo-ET heterogeneous reconstruction"
        ],
        "type": "Text_excerpt",
        "value": "`cryodrgn` may be installed via `pip`, and we recommend installing `cryodrgn` in a clean conda environment.\n\n    # Create and activate conda environment\n    (base) $ conda create --name cryodrgn python=3.9\n    (cryodrgn) $ conda activate cryodrgn\n\n    # install cryodrgn\n    (cryodrgn) $ pip install cryodrgn\n\nYou can alternatively install a newer, less stable, development version of `cryodrgn` using our beta release channel:\n\n    (cryodrgn) $ pip install -i https://test.pypi.org/simple/ --extra-index-url https://pypi.org/simple/ cryodrgn --pre\n\nMore installation instructions are found in the [documentation](https://ez-lab.gitbook.io/cryodrgn/installation).\n"
      },
      "source": "https://raw.githubusercontent.com/zhonge/cryodrgn/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 0.9819015096695592,
      "result": {
        "original_header": "Previous versions",
        "type": "Text_excerpt",
        "value": "<details><summary>Version 2.3</summary><ul>\n  <li>Model configuration files are now saved as human-readable config.yaml files\n(https://github.com/zhonge/cryodrgn/issues/235)</li>\n  <li>Fix machine stamp in output .mrc files for better compatibility with downstream tools\n(https://github.com/zhonge/cryodrgn/pull/260)</li>\n  <li>Better documentation of help flags in ab initio reconstruction tools\n(https://github.com/zhonge/cryodrgn/issues/258)</li>\n  <li>[FIX] By default, window images in <code>cryodrgn abinit_homo</code> (now consistent with other reconstruction\ntools) (https://github.com/zhonge/cryodrgn/issues/258)</li>\n  <li>[FIX] Reduce memory usage when using <code>--preprocessed</code>\nand <code>--ind</code> (https://github.com/zhonge/cryodrgn/pull/272)</li>\n</ul></details> \n<details><summary>Version 0.2.0</summary><ul>\n    <li>New interface and proper python packaging with setup.py. This version has identical functionality and\nargument usage as previous versions, however tools are now available from a common entry point. See: \n"
      },
      "source": "https://raw.githubusercontent.com/zhonge/cryodrgn/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8532044352655722,
      "result": {
        "original_header": "4. (Optional) Test pose/CTF parameters parsing",
        "type": "Text_excerpt",
        "value": "**Note:** If the volume does not resemble your structure, you may need to use the flag `--uninvert-data`.\nThis flips the data sign (e.g. light-on-dark or dark-on-light), which may be needed depending on the\nconvention used in upstream processing tools.\n \n"
      },
      "source": "https://raw.githubusercontent.com/zhonge/cryodrgn/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9875986480395584,
      "result": {
        "original_header": "Accelerated training with GPU parallelization",
        "type": "Text_excerpt",
        "value": "Use cryoDRGN's `--multigpu` flag to enable parallelized training across all detected GPUs on the machine.\nTo select specific GPUs for cryoDRGN to run on, use the environmental variable `CUDA_VISIBLE_DEVICES`, e.g.: \n    $ cryodrgn train_vae ... # Run on GPU 0\n    $ cryodrgn train_vae ... --multigpu # Run on all GPUs on the machine\n    $ CUDA_VISIBLE_DEVICES=0,3 cryodrgn train_vae ... --multigpu # Run on GPU 0,3 \n"
      },
      "source": "https://raw.githubusercontent.com/zhonge/cryodrgn/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8385305226363254,
      "result": {
        "original_header": "cryodrgn analyze",
        "type": "Text_excerpt",
        "value": "\toptional arguments:\n\t  -h, --help            show this help message and exit\n\t  --device DEVICE       Optionally specify CUDA device\n\t  -o OUTDIR, --outdir OUTDIR\n\t                        Output directory for analysis results (default:\n\t                        [workdir]/analyze.[epoch])\n\t  --skip-vol            Skip generation of volumes\n\t  --skip-umap           Skip running UMAP \n"
      },
      "source": "https://raw.githubusercontent.com/zhonge/cryodrgn/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9709004290590283,
      "result": {
        "original_header": "Generating additional volumes",
        "type": "Text_excerpt",
        "value": "\toptional arguments:\n\t  -h, --help             show this help message and exit\n\t  -c YAML, --config YAML CryoDRGN config.yaml file\n\t  -o O                   Output .mrc or directory\n\t  --prefix PREFIX        Prefix when writing out multiple .mrc files (default: vol_)\n\t  -v, --verbose          Increase verbosity \n    $ cryodrgn eval_vol [YOUR_WORKDIR]/weights.pkl --config [YOUR_WORKDIR]/config.yaml -z ZVALUE -o reconstruct.mrc \n    $ cryodrgn eval_vol [WORKDIR]/weights.pkl --config [WORKDIR]/config.yaml --zfile zvalues.txt -o [WORKDIR]/trajectory \n"
      },
      "source": "https://raw.githubusercontent.com/zhonge/cryodrgn/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9043624759340624,
      "result": {
        "original_header": "Making trajectories",
        "type": "Text_excerpt",
        "value": "Documentation: https://ez-lab.gitbook.io/cryodrgn/cryodrgn-graph-traversal-for-making-long-trajectories\n \n"
      },
      "source": "https://raw.githubusercontent.com/zhonge/cryodrgn/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9822066475525296,
      "result": {
        "original_header": "cryodrgn analyze_landscape",
        "type": "Text_excerpt",
        "value": "Documentation: https://ez-lab.gitbook.io/cryodrgn/cryodrgn-conformational-landscape-analysis\n \n"
      },
      "source": "https://raw.githubusercontent.com/zhonge/cryodrgn/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9917082398336787,
      "result": {
        "original_header": "CryoDRGN2 for *Ab Initio* Reconstruction",
        "type": "Text_excerpt",
        "value": "Documentation: https://ez-lab.gitbook.io/cryodrgn/cryodrgn2-ab-initio-reconstruction\n \n"
      },
      "source": "https://raw.githubusercontent.com/zhonge/cryodrgn/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9943972796238733,
      "result": {
        "original_header": "CryoDRGN-ET for subtomogram analysis",
        "type": "Text_excerpt",
        "value": "Available in beta release starting in version 3.x. Documentation for getting started can be found\nin the [user guide](https://ez-lab.gitbook.io/cryodrgn/cryodrgn-et-subtomogram-analysis). Please reach out if you have any questions!\n \n"
      },
      "source": "https://raw.githubusercontent.com/zhonge/cryodrgn/main/README.md",
      "technique": "supervised_classification"
    }
  ],
  "invocation": [
    {
      "confidence": 0.8808779583107232,
      "result": {
        "original_header": "3. Parse CTF parameters from a .star/.cs file",
        "type": "Text_excerpt",
        "value": "Example usage for a .star file: \nExample usage for a .cs file: \n"
      },
      "source": "https://raw.githubusercontent.com/zhonge/cryodrgn/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8607682183892681,
      "result": {
        "original_header": "4. (Optional) Test pose/CTF parameters parsing",
        "type": "Text_excerpt",
        "value": "Example usage: \n"
      },
      "source": "https://raw.githubusercontent.com/zhonge/cryodrgn/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8012545801533387,
      "result": {
        "original_header": "cryodrgn analyze",
        "type": "Text_excerpt",
        "value": "Example usage to analyze results from the direction `01_cryodrgn256` containing results after 25 epochs of training: \n"
      },
      "source": "https://raw.githubusercontent.com/zhonge/cryodrgn/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8404564882362,
      "result": {
        "original_header": "Generating additional volumes",
        "type": "Text_excerpt",
        "value": "\toptional arguments:\n\t  -h, --help             show this help message and exit\n\t  -c YAML, --config YAML CryoDRGN config.yaml file\n\t  -o O                   Output .mrc or directory\n\t  --prefix PREFIX        Prefix when writing out multiple .mrc files (default: vol_)\n\t  -v, --verbose          Increase verbosity \n**Example usage:** \n"
      },
      "source": "https://raw.githubusercontent.com/zhonge/cryodrgn/main/README.md",
      "technique": "supervised_classification"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/ml-struct-bio/cryodrgn/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ""
      },
      "technique": "GitHub_API"
    }
  ],
  "license": [
    {
      "confidence": 1,
      "result": {
        "name": "GNU General Public License v3.0",
        "spdx_id": "GPL-3.0",
        "type": "License",
        "url": "https://api.github.com/licenses/gpl-3.0",
        "value": "https://api.github.com/licenses/gpl-3.0"
      },
      "technique": "GitHub_API"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "cryodrgn"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "Organization",
        "value": "ml-struct-bio"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 771530,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Jupyter Notebook",
        "size": 97063,
        "type": "Programming_language",
        "value": "Jupyter Notebook"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Shell",
        "size": 9569,
        "type": "Programming_language",
        "value": "Shell"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/zhonge/cryodrgn/main/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "related_papers": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://arxiv.org/abs/1909.05215\n\nCryoDRGN2's ab initio reconstruction algorithms were published at ICCV:\n\n* CryoDRGN2: Ab Initio Neural Reconstruction of 3D Protein Structures From Real Cryo-EM Images\nEllen D. Zhong, Adam Lerer, Joseph H Davis, and Bonnie Berger\nInternational Conference on Computer Vision (ICCV"
      },
      "source": "https://raw.githubusercontent.com/zhonge/cryodrgn/main/README.md",
      "technique": "regular_expression"
    }
  ],
  "releases": [
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "michal-g",
          "type": "User"
        },
        "date_created": "2024-09-11T14:14:40Z",
        "date_published": "2024-09-11T22:02:26Z",
        "description": "In this minor release we are adding several new features and commands, as well as expanding a few existing ones and introducing some key refactorings to the codebase to make these changes easier to implement.\r\n\r\n## New features\r\n- full support for RELION 3.1 `.star` files with optics values stored in a separate grouped table before or after the main table (#241, #40, #10)\r\n    - refactored `Starfile` class now has properties `.apix` and `.resolution` that return particle-wise optics values for commonly used parameters, as well as methods `.get_optics_values()` and `.set_optics_values()` for any parameter\r\n        - these methods automatically use the optics table if available\r\n    - `cryodrgn parse_ctf_star` can now load all particle-wise optics values from the .star file itself instead of the current behavior of relying upon user input for parameters such as A/px, resolution, voltage, spherical aberration, etc., or just taking the first value found in the file\r\n- `backproject_voxel` now computes FSC threshold values corrected for mask overfitting using [high resolution phase randomization](https://guide.cryosparc.com/processing-data/tutorials-and-case-studies/tutorial-common-cryosparc-plots#fsc-fourier-shell-correlation-plots) as done in cryoSPARC, as well as showing FSC curves and threshold values for various types of masks:\r\n![tight-mask](https://github.com/user-attachments/assets/e7a87891-7206-4f5d-861a-2412f0bac1b9)\r\n\r\n- `cryodrgn_utils plot_classes` for creating plots of cryoDRGN results colored by a given set of particle class labels\r\n    - for now, only creates 2D kernel density plots of the latent space embeddings clustered using UMAP and PCA, but more plots will be added in the future:\r\n        \r\n        ```bash\r\n        $ cryodrgn_utils plot_classes 002_train-vae_dim.256 9 --labels published_labels_major.pkl --palette viridis --svg\r\n        ```\r\n        \r\n        `analyze.9/umap_kde_classes.png` \r\n\r\n![umap_kde_classes](https://github.com/user-attachments/assets/5fb5b054-5a74-48c5-aa2a-0a177c2bc8cc)\r\n\r\n## Improvements to existing features\r\n- `backproject_voxel` also now creates a new directory using `-o/--outdir` into which it places output files, instead of naming all files after the output reconstructed volume `-o/--outfile`\r\n    - files within this directory will always have the same names across runs:\r\n        - `backproject.mrc` the full reconstructed volume\r\n        - `half_map_a.mrc`, `half_map_b.mrc` reconstructed half-maps using an odd/even particle split\r\n        - `fsc-vals.txt` all five FSC curves in space-delimited format\r\n        - `fsc-plot.png` a plot of these five FSC curves as shown above\r\n- `downsample` can now downsample each of the individual files in a stack referenced by a .star or .txt file, returning a new .star file or .txt file referencing the new downsampled stack\r\n    - used by specifying a .star or .txt file as `-o/--outfile` when using a .star or .txt file as input:\r\n        ```python\r\n        cryodrgn downsample my_particle_stack.star -D 128 -o particles.128.star --datadir folder_with_subtilts/ --outdir my_new_datadir/\r\n        ```\r\n        \r\n- `cryodrgn_utils fsc` can now take three volumes as input, in which case the first volume will be used to generate masks to produce cryoSPARC-style FSC curve plots including phase randomization for the \u201ctight\u201d mask (see **New features** above)\r\n- `cryodrgn_utils plot_fsc` is now more flexible with the types of input files it can accept for plotting, including `.txt` files with the new type of cryoSPARC-style FSC curve output from `backproject_voxel`\r\n- `cryodrgn filter --force` for less interactivity after the selection has been made\r\n- `filter_mrcs` prints both original and new number of particles; generates output file name automatically if not given\r\n- `cryodrgn abinit_het` saves `configs` alongside model weights in `weights.pkl` for easier access and output checkpoint identification\r\n\r\n## Addressing bugs and other issues\r\n- better axis labels for FSC plotting, passing Apix values from `backproject_voxel` (#385)\r\n- `cryodrgn filter` doesn\u2019t show particle indices in hover text anymore, as this proved visually distracting; we now show these indices in a text box in the corner of the plot\r\n- `cryodrgn filter` saves chosen indices as a `np.array` instead of Python standard `list` to prevent type issues in downstream analyses\r\n- `commands_utils.translate_mrcs` was not working (was assuming `particles.images()` returned a numpy array instead of a torch Tensor) \u2014 this has been fixed and tests added for translations of image stacks\r\n- going back to listing modules to be included in the `cryodrgn` and `cryodrgn_utils` command line interfaces explicitly, as Python will sometimes install older modules into the corresponding folders which confuses automated scanning for command modules\r\n- fixing parsing of 8bit and 16bit .mrc files produced using e.g. `--outmode=int8` in EMAN2 (#113)\r\n- adding support and continuous integration testing for Python 3.11\r\n\r\n## Refactoring classes that parse input files\r\n\r\nThere were some updates we wanted to make to the `ImageSource` class and its children which was introduced in a refactoring of the processes used to load and parse input datasets in v3.0.0. We also sought to simplify and clean up the code in the methods used to parse .star file and .mrcs file data in `cryodrgn.starfile` and `cryodrgn.mrc` respectively.\r\n\r\n- the code for the `ImageSource` base class and its children classes in `cryodrgn.source` have been cleaned up to improve code style, remove redundancies, and support the `Starfile` and `mrcfile` refactorings described below\r\n    - more consistent and sensible parsing of filenames with `datadir` for `_MRCDataFrameSource` classes such as `TxtFileSource` and `StarfileSource` (#386)\r\n        - all of this logic is now contained in a new method `_MRCDataFrameSource.parse_filename` which is applied in `__init__`:\r\n            1. If the `filename` by itself points to a file that exists, use `filename`.\r\n            2. Otherwise, if `os.path.join(datadir, newname)` exists, use that.\r\n            3. Finally, try `os.path.join(datadir, os.path.basename(newname))`.\r\n            4. If that doesn\u2019t exist, throw an error!\r\n    - adding `ImageSource.orig_n` attribute which is often useful for accessing the original number of particles in the stack before filtering was applied\r\n    - adding `ImageSource.write_mrc()`, to avoid having to use `MRCFile.write()` for `ImageSource` objects; `MRCFile.write()` use case for arrays has been replaced by `mrcfile.write_mrc` (see below)\r\n        - see use in a refactored `cryodrgn downsample` for batch writing to `.mrc` output\r\n    - adding `MRCFileSource.write()`, a wrapper for `mrcfile.write_mrc()`\r\n    - adding `MRCFileSource.apix` property for convenient access to header metadata\r\n    - getting rid of `ArraySource`, whose behavior can be subsumed into `ImageSource` with `lazy=False`\r\n    - improving error messages in `ImageSource.from_file()`, `._convert_to_ndarray()`, `images()`\r\n    - `ImageSource.lazy` is now a property, not an attribute, and is dynamically dependent on whether `self.data` has actually been loaded or not\r\n    - adding `_MRCDataFrameSource.sources` convenience iterator property\r\n    - `StarfileSource` now inherits directly from the `Starfile` class (as well as `_MRCDataFrameSource`) for better access to .star utilities than using a `Starfile` object as an attribute (`.df` in the old v3.3.3 class)\r\n- .star file methods have been refactored to establish three clear ways of accessing and manipulating .star data for different levels of features, with RELION3.1 operations now implemented in `Starfile` class methods:\r\n    - `cryodrgn.starfile.parse_star` and `write_star` to get and perform simple operations on the main data table and/or the optics table\r\n    e.g. in `filter_star`:\r\n        \r\n        ```python\r\n        stardf, data_optics = parse_star(args.input)\r\n        ...\r\n        write_star(args.o, data=filtered_df, data_optics=new_optics)\r\n        ```\r\n        \r\n    - `cryodrgn.starfile.Starfile` for access to .star file utilities like generating optics values for each particle in the main data table using parameters saved in the optics table\r\n    e.g. in `parse_ctf_star`:\r\n        \r\n        ```python\r\n        stardata = Starfile(args.star)\r\n        logger.info(f\"{len(stardata)} particles\")\r\n        apix = stardata.apix\r\n        resolution = stardata.resolution\r\n        ...\r\n        ctf_params[:, i + 2] = (\r\n            stardata.get_optics_values(header)\r\n            if header not in overrides\r\n            else overrides[header]\r\n        )\r\n        ```\r\n        \r\n    - `cryodrgn.source.StarfileSource` for access to .star file utilities along with access to the images themselves using `ImageSource` methods like `.images()`\r\n    - see our more detailed write-up for more information:\r\n        [Starfile Refactor](https://www.notion.so/Starfile-Refactor-32192f647afe4d1e9bb7dd1b5c0a7565?pvs=21)\r\n        \r\n- for .mrc files, we removed `MRCFile` as there are no analogues presently for the kinds of methods supported by `Starfile`; the operations on the image array requiring data from the image header are presently contained within `MRCFileSource`, reflecting the fact that .mrcs files are the image data themselves and not pointers to other files containing the data\r\n    - `MRCFile`, which consisted solely of static `parse` and `write` methods, has been replaced by the old names of these methods (`parse_mrc` and `write_mrc`)\r\n        - `MRCFile.write(out_mrc, vol)` \u2192 `write_mrc(out_mrc, vol)`\r\n        - in the case of when `vol` is an `ImageSource` object, we now do `ImageSource.write_mrc()`\r\n    - in general, `parse_mrc` and `write_mrc` are for using the entire image stack as an array, while `MRCFileSource` is for accessing batches of images as tensors\r\n    - `mrc` module is now named `mrcfile` for better verbosity and to match `starfile` module which is its parallel for processing input files\r\n    - examples from across the codebase:\r\n        - `commands_utils.add_psize`\r\n            \r\n            old:\r\n            \r\n            ```python\r\n            from cryodrgn.mrc import MRCFile, MRCHeader\r\n            from cryodrgn.source import ImageSource\r\n            \r\n            header = MRCHeader.parse(args.input)\r\n            header.update_apix(args.Apix)\r\n            \r\n            src = ImageSource.from_file(args.input)\r\n            MRCFile.write(args.o, src, header=header)\r\n            ```\r\n            \r\n            new:\r\n            \r\n            ```python\r\n            from cryodrgn.mrcfile import parse_mrc, write_mrc\r\n            \r\n            vol, header = parse_mrc(args.input)\r\n            header.apix = args.Apix\r\n            write_mrc(args.o, vol, header=header)\r\n            ```\r\n            \r\n        - `commands_utils.flip_hand` \r\n        old:\r\n            \r\n            ```python\r\n            src = ImageSource.from_file(args.input)\r\n            # Note: Proper flipping (compatible with legacy implementation) only happens when chunksize is equal to src.n\r\n            MRCFile.write(\r\n                outmrc,\r\n                src,\r\n                transform_fn=lambda data, indices: np.array(data.cpu())[::-1],\r\n                chunksize=src.n,\r\n            )\r\n            ```\r\n            \r\n            *Note that the awkward combination of `MRCFileSource` and `MRCFile` above meant having to cast the images from tensors to arrays after they were loaded!*\r\n            \r\n            new:\r\n            \r\n            ```python\r\n            vol, header = parse_mrc(args.input)\r\n            vol = vol[::-1]\r\n            write_mrc(outmrc, vol, header=header)\r\n            ```\r\n            \r\n    - also made some updates to `MRCHeader` for ease of use:\r\n        - making `mrc` module variables like `DTYPE_FOR_MODE` header class attributes\r\n        - creating properties `apix` and `origin` with `.getter` and `.setter` methods, simplifying retrieval of these values\r\n            - e.g. `header.origin = (0, -1, 0)` instead of `header.update_origin(0, -1, 0)` , with `header.origin` instead of `header.get_origin()` to get values\r\n\r\n## Code Quality Control\r\n\r\n- improving module-level docstrings with more info and usage examples\r\n    - better parsing of multi-line example usage commands split up by `\\` in `cryodrgn.command_line` when producing help messages for `-h`\r\n    - see e.g. `cryodrgn.dataset`, `cryodrgn.starfile`, `cryodrgn.source`, `cryodrgn filter`, `cryodrgn filter_mrcs`\r\n- in automated CI testing, we now test `3.9 + 1.12`, `3.10 + 2.1`, and `3.11 + 2.4` in terms of Python version + PyTorch version, instead of doing all pairs of `{3.9, 3.10}` and `{1.12, 2.1, 2.3}`, allowing for CI testing to be expanded into Python 3.11 without running too many test jobs\r\n- better error messages for `cryodrgn.pose` and `cryodrgn.ctf` when inputs don\u2019t match in dimension or have an unexpected format\r\n- creating new module `cryodrgn.masking`, moving e.g. `utils.window_mask()` to `masking.spherical_window_mask()`\r\n- bringing back [`unittest.sh`](http://unittest.sh), a set of smoke tests for reconstruction commands that can be run outside of `pytest` and regular automated CI testing, by replacing outdated commands (#267)\r\n- first release with regression pipeline testing, confirming that outputs of key reconstruction commands has remained unchanged: see summary [here](https://fluff-hero-b57.notion.site/cryoDRGN-v3-4-0-Replication-Testing-0fe31153834580d39387d9d74d3c4180?pvs=4)\r\n",
        "html_url": "https://github.com/ml-struct-bio/cryodrgn/releases/tag/3.4.0",
        "name": "v3.4.0: Plotting class labels, RELION 3.1 support, and phase-randomization for FSCs",
        "release_id": 174647953,
        "tag": "3.4.0",
        "tarball_url": "https://api.github.com/repos/ml-struct-bio/cryodrgn/tarball/3.4.0",
        "type": "Release",
        "url": "https://api.github.com/repos/ml-struct-bio/cryodrgn/releases/174647953",
        "value": "https://api.github.com/repos/ml-struct-bio/cryodrgn/releases/174647953",
        "zipball_url": "https://api.github.com/repos/ml-struct-bio/cryodrgn/zipball/3.4.0"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "michal-g",
          "type": "User"
        },
        "date_created": "2024-06-25T22:04:24Z",
        "date_published": "2024-06-25T22:05:07Z",
        "description": "This **patch release** fixes several outstanding issues:\r\n\r\n - the `--ntilts` argument to `backproject_voxel` did not do anything, and all tilts were always used; this flag now behaves as expected #379\r\n - `cryodrgn_utils filter_star` now includes the (filtered) input optics table in the output if present in the input #370\r\n - `cryodrgn filter` now accepts experiment outputs using tilt series particles #335\r\n - fixing a numerical rounding bug showing up in transformations to poses used by `backproject_voxel` #380\r\n\r\nWe have also done more work to consolidate and expand our CI testing suite, with all of the `pytest` tests under `tests/` now using new data loading fixtures that allow for tests to be run in parallel using `pytest-xdist`. Datasets used in testing have also been moved from `testing/data/` to `tests/data/` to reflect that the old tests run using command-line under the former are now deprecated and are being replaced and rewritten as `pytest` tests in the latter folder.\r\n\r\nFinally, we removed some remaining vestiges of the old way of handling large datasets difficult to fit into memory via `cryodrgn preprocess` (#348) as well as improving the docstrings for several modules.\r\n ",
        "html_url": "https://github.com/ml-struct-bio/cryodrgn/releases/tag/3.3.3",
        "name": "v3.3.3: RELION3.1 .star filtering, interactive tilt series filtering, and fixes to backprojection",
        "release_id": 162395371,
        "tag": "3.3.3",
        "tarball_url": "https://api.github.com/repos/ml-struct-bio/cryodrgn/tarball/3.3.3",
        "type": "Release",
        "url": "https://api.github.com/repos/ml-struct-bio/cryodrgn/releases/162395371",
        "value": "https://api.github.com/repos/ml-struct-bio/cryodrgn/releases/162395371",
        "zipball_url": "https://api.github.com/repos/ml-struct-bio/cryodrgn/zipball/3.3.3"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "michal-g",
          "type": "User"
        },
        "date_created": "2024-05-26T06:33:51Z",
        "date_published": "2024-05-26T19:33:04Z",
        "description": "This **patch release** makes some improvements to tools used in writing and parsing .star files, as well as addressing a few bugs that have recently come to our attention:\r\n\r\n- the filtering notebook `cryoDRGN_filtering` was very slow to run when applied to experiments using `--ind`; we tracked this down to using an incorrect approach to loading the dataset (#374)\r\n- nicer FSC plots in `backproject_voxel` using code refactored to apply the methods used in `fsc` and `plot_fsc`\r\n- fixing an issue when the total particle count was module one the batch size, causing dimensionality errors with the final singleton batch due to how some `torch` and `numpy` operations handle singleton dimensions (#351)\r\n- creating a stopgap for #346 while we figure out what upstream problems could be causing these issues with `analyze`\r\n- adding `linspace=True` to the `np.linspace` operation in `pc_traversal` for completeness\r\n- properly supporting `.txt` files for `write_star`, with the correct file names now being written to the output, as well as `--ind` working correctly\r\n- adding support for RELION 3.1 input files with multiple optics groups in `parse_pose_star`\r\n\r\nWe have also consolidated and improved upon several aspects of our continuous integration testing setup, including new tests covering the cases described above, refactoring the data fixtures used in existing tests, and testing across multiple `torch` versions after finding issues specific to `v1.8` in `analyze_landscape_full`.",
        "html_url": "https://github.com/ml-struct-bio/cryodrgn/releases/tag/3.3.2",
        "name": "v3.3.2: fixing notebook filtering, parse_pose_star optics groups, .txt inputs for write_star",
        "release_id": 157532020,
        "tag": "3.3.2",
        "tarball_url": "https://api.github.com/repos/ml-struct-bio/cryodrgn/tarball/3.3.2",
        "type": "Release",
        "url": "https://api.github.com/repos/ml-struct-bio/cryodrgn/releases/157532020",
        "value": "https://api.github.com/repos/ml-struct-bio/cryodrgn/releases/157532020",
        "zipball_url": "https://api.github.com/repos/ml-struct-bio/cryodrgn/zipball/3.3.2"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "michal-g",
          "type": "User"
        },
        "date_created": "2024-05-09T16:22:29Z",
        "date_published": "2024-05-09T16:54:42Z",
        "description": "This is **a patch release to address several bugs and issues** that have come to our attention:\r\n\r\n- adding `--micrograph-files` argument to `filter_star` to create separate output files for each `_rlnMicroGraphName` encountered in the file\r\n- `--ind` with `--encode-mode=tilt` wasn\u2019t working in the case where all particles had the same number of tilts due to `dtype=object` patch introduced earlier\r\n    - fixed by storing particle\u2192tilt index produced by `TiltSeriesData.parse_particle_tilt()` as a list instead of an array; this is more robust in general and all downstream cases are agnostic (see tests below)\r\n- `backproject_voxel` was producing errors when trying to calculate threshold FSC values due to deprecated code used to parse FSC matrix (#371)\r\n    - fixed by copying over code already used in `commands/fsc`\r\n- `train_nn` and `train_vae` would error out if inputs were not divisible by 8 when using AMP optimization (e.g. #353)\r\n    - a warning here suffices as AMP optimization is the default and this is frustrating for many users\r\n- better error message when CTF file is missing from `write_star` inputs\r\n- better error message when `backproject_voxel` output is not `.mrc`\r\n- bug in `ET_viz` notebook when `--ind` not specified caused by inconsistent definition of `ind0`\r\n- bug in filtering notebook caused by using `ind=ind_orig` when loading dataset and then trying to filter again (#363)\r\n- `ZeroDivisionError` bugs in all notebooks when using small training datasets\r\n- updating template analysis notebooks to use the given `kmeans` value in the copied-over notebook, similarly to out auto-updating of notebook epoch numbers\r\n\r\nIn addition to making the required fixes, we have **expanded and improved our deployment tests** to cover these cases and close some gaps in our testing coverage:\r\n\r\n- adding a stand-alone test of backprojection under `test_reconstruct` applying both `.mrcs` and `.star` inputs\r\n- more testing of `train_nn` cases with different `--amp`, `--batch-size`, `--poses` values\r\n- fixing `check=True` issue in `utils.run_command()` that was allowing tests of backprojection to fail silently\r\n- new deployment task schedule\r\n    - the `main` deployment task has been split into `tests` and `style` for tests of code integrity and code linting respectively\r\n    - run `tests` and `style` along with `beta-release` any time a patch version tag `[0-9]+\\.[0-9]+\\.[0-9]+-*` is pushed to any branch to trigger a verified upload to TestPyPI\r\n        - also run `tests` and `style` for any push to `develop` branch to allow for testing before beta release\r\n    - update `release` to only run when a stable version tag (`^[0-9]+\\.[0-9]+\\.[0-9]+$`) is pushed to `main`\r\n        - `tests` and `style` run on any push to `main` to allow for testing prior to release\r\n\r\n**Other changes include:**\r\n\r\n- applying `tmpdir_factory` to improve the `train_dir` and `AbinitioDir` fixtures used in tests with more robust setup and teardowns\r\n- CodeFactor badge and nicer TestPyPI installation command in `README`\r\n- dynamic update of plotted point sizes in `cryoDRGN_filtering.ipynb` interactive filtering widget, useful for smaller datasets for which the default is too small for points to be seen\r\n- using `plt.close()` after `analyze` plotting for better memory management",
        "html_url": "https://github.com/ml-struct-bio/cryodrgn/releases/tag/3.3.1",
        "name": "v3.3.1: fixes to backprojection and tilt with indices; per tomo star filtering",
        "release_id": 154978614,
        "tag": "3.3.1",
        "tarball_url": "https://api.github.com/repos/ml-struct-bio/cryodrgn/tarball/3.3.1",
        "type": "Release",
        "url": "https://api.github.com/repos/ml-struct-bio/cryodrgn/releases/154978614",
        "value": "https://api.github.com/repos/ml-struct-bio/cryodrgn/releases/154978614",
        "zipball_url": "https://api.github.com/repos/ml-struct-bio/cryodrgn/zipball/3.3.1"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "michal-g",
          "type": "User"
        },
        "date_created": "2024-04-30T01:01:34Z",
        "date_published": "2024-04-30T01:05:16Z",
        "description": "### New Features\r\n- `cryodrgn direct_traversal`, a tool for interpolating a path in the latent conformation space connecting two points in a direct line\r\n- making the package available for installation using the TestPyPI distribution service:\r\n```pip install -i https://test.pypi.org/simple/ --extra-index-url https://pypi.org/simple/ \"cryodrgn<=3.3.0\" --pre```\r\n    - this will let us to make both the development and stable versions of the package available for easy download using `pip`, as opposed to having to use `git clone` for the former.\r\n\r\n### Improving Existing Features\r\n- updated interfaces for `cryodrgn graph_traversal` and `cryodrgn pc_traversal` so that the arguments, argument formats, and help docstrings between all three traversal methods are as clear and consistent as possible\r\n    - `--ind` in `direct_traversal` is replaced with `--anchors` as in `graph_traversal`, allowing both to take a list of integers as well as files containing lists of integers\r\n    - `-o` now also has a more verbose alias `--outtxt` in `graph_traversal` and `direct_traversal`; updating its behavior in `graph` to save the latent space co-ordinates and updating `--outind` to save path indices; similarly verbose alias `--outdir` in `pc_traversal`\r\n    - `-o` now also has a default value that is used when the flag is given with no argument across all three traversal commands to mean that we want to save output but don't have a file name\r\n    - when `-o` is *not* given, all three commands display a prettier log message to screen with traversal output\r\n- epoch numbers are automatically updated to the epoch used in `cryodrgn analyze` in copied-over demo notebooks\r\n- improving package status badges shown in GitHub README: available versions, PyPI downloads\r\n\r\n### Addressing Issues and Bugs\r\n- adding the `--datadir` flag to `cryodrgn abinit_homo`, addressing an oversight that complicated using `.star` files with this command (#343)\r\n- fixing bugs and other issues found in our demonstration Jupyter notebooks (#363)\r\n    - `analysis.plot_projections()` doesn't fail if # of imgs is two or one\r\n- makeover of GitHub deployment workflow actions to fix errors and simplify release infrastructure\r\n    - `master`->`main` branch names\r\n    - removing remaining errors in continuous integration testing action so that it is again a useful tool for checking pull requests and protecting our `main` branch, especially with the now expanded coverage of notebooks, traversal, etc.\r\n        - last `pytest` bug fixed (`n=tilts` in `eval_images`)\r\n        - switching off `pyright` for now as type checks are not essential\r\n        - leftover `pre-commit` formatting issue in `commands.filter`\r\n    - more lightweight Docs action by only releasing new Sphinx autodocs version when a new version tag is pushed \u2014 not nuking these docs for now (#350)\r\n    - new Beta Release action for automatically deploying a release to TestPyPI whenever a new version tag is pushed\r\n    - existing Release action still not working (needs updated credentials) but is now also only deployed automatically when a new version tag is pushed\r\n- fixing `ntilts=10` default behaviour bug in `eval_images` which was activating tilt mode\r\n- officially removing support for outdated Python versions 3.7 and 3.8 (already implicitly not supported)\r\n\r\n### Testing\r\n- renaming `test_quick` to `test_integration` and improving the coverage of the reconstruction pipeline integration tests contained therein\r\n    - adding integration tests for Jupyter demonstration notebooks to check that they execute successfully upon running `cryodrgn analyze` after `cryodrgn train_vae` with different types of inputs and parameters\r\n- expanded fidelity and unit tests for all three traversal commands\r\n- adding `CODEOWNERS` letting @michal-g be e.g. automatically added to new issues",
        "html_url": "https://github.com/ml-struct-bio/cryodrgn/releases/tag/3.3.0",
        "name": "v3.3.0: direct traversal, improved notebooks, TestPyPI auto-deployment",
        "release_id": 153153574,
        "tag": "3.3.0",
        "tarball_url": "https://api.github.com/repos/ml-struct-bio/cryodrgn/tarball/3.3.0",
        "type": "Release",
        "url": "https://api.github.com/repos/ml-struct-bio/cryodrgn/releases/153153574",
        "value": "https://api.github.com/repos/ml-struct-bio/cryodrgn/releases/153153574",
        "zipball_url": "https://api.github.com/repos/ml-struct-bio/cryodrgn/zipball/3.3.0"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "michal-g",
          "type": "User"
        },
        "date_created": "2024-04-01T18:12:35Z",
        "date_published": "2024-04-01T18:21:27Z",
        "description": "### New Features\r\n\r\n- introducing\u00a0`cryodrgn_utils clean`, a new tool for removing extraneous output files from completed experiments (#297)\r\n- `backproject_voxel`\u00a0now produces half-maps and a half-map FSC by default (#329)\r\n- creating\u00a0`cryodrgn_utils fsc`\u00a0from the\u00a0`fsc`\u00a0analysis script for calculating Fourier shell correlations between two\u00a0`.mrc`\u00a0volume files, and likewise `cryodrgn_utils plot_fsc` based on `plotfsc`; making the latter available through the former using `-p`\r\n- creating `cryodrgn_utils gen_mask` based on `cryoem_tools.gen_mask.py`, now with reparametrization in Angstroms\r\n\r\n### Addressing Issues and Bugs\r\n\r\n- fixing #358 and improving the I/O interface in both `cryodrgn_utils flip_hand` and `cryodrgn_utils invert_contrast` so that the name of the output file and any parent directories are created automatically, with more unit tests for each\r\n- making\u00a0`write_star`\u00a0use RELION 3.1 format by default with optics groups generated from image size, pixel size, voltage, spherical aberration, and amplitude contrast;\u00a0`-relion30`\u00a0to use old format (#324)\r\n- updating install setup to prevent use of Python 3.11 (#306)\r\n- `abinit_homo`\u00a0now saves a\u00a0`config.yaml`\u00a0with a summary of parameters used, like\u00a0`abinit_het`,\u00a0`train_vae`, and\u00a0`train_nn`\r\n- fixing\u00a0`filter_star`\u00a0to accept tilt series as well (#335)\r\n- fixing\u00a0`affinity`\u00a0bug in\u00a0`analyze_landscape`\u00a0(#345)\r\n- fixing beta value bug in `train_vae` (#356)\r\n- removing references to\u00a0`scipy.ndimage.morphology`\u00a0which is deprecated\r\n- fixing\u00a0`dtype=object`\u00a0warning message in\u00a0`TiltSeries.parse_particle_tilt()`\r\n\r\n### User Interface\r\n\r\n- cleaner implementation of command-line interface, defining both `cryodrgn` and `cryodrgn_utils` commands in one file `cryodrgn/command_line.py`, and removing e.g. manually defined lists of modules with commands in them\r\n- better doc strings with some usage examples for commands (e.g. `cryodrgn abinit_homo -h`), with module-level doc strings being included explicitly in the automatically generated help screen\r\n\r\n### Testing\r\n\r\n- using `conftest.py` to define a new setup/teardown routine for experiment output directories created by tests\r\n- writing new tests for `abinit` and `train` methods by applying these routines\r\n- fixing `test_dataset` to account for changes within `make_dataloader`\r\n- updating unit tests that use `argparse.ArgumentParser()` directly for commands in which the `__main__` method was removed\r\n- updating tests for new and updated commands `fsc`, `clean`, `gen_mask`, etc.",
        "html_url": "https://github.com/ml-struct-bio/cryodrgn/releases/tag/3.2.0-beta",
        "name": "Version 3.2.0-beta: cleaning, half-map FSCs, mask generation, and RELION 3.1",
        "release_id": 149269709,
        "tag": "3.2.0-beta",
        "tarball_url": "https://api.github.com/repos/ml-struct-bio/cryodrgn/tarball/3.2.0-beta",
        "type": "Release",
        "url": "https://api.github.com/repos/ml-struct-bio/cryodrgn/releases/149269709",
        "value": "https://api.github.com/repos/ml-struct-bio/cryodrgn/releases/149269709",
        "zipball_url": "https://api.github.com/repos/ml-struct-bio/cryodrgn/zipball/3.2.0-beta"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "michal-g",
          "type": "User"
        },
        "date_created": "2024-03-29T20:15:48Z",
        "date_published": "2024-03-31T05:07:31Z",
        "description": "We have introduced a number of small fixes and feature updates since our last release `v3.0.1-beta`:\r\n\r\n- creating a new interactive command-line interface `cryodrgn filter` as an alternative to the buggy interface in the Jupyter filtering notebook (https://github.com/ml-struct-bio/cryodrgn/issues/323)\r\n- making `cryodrgn analyze` produce a plot of the learning curve (https://github.com/ml-struct-bio/cryodrgn/issues/304)\r\n- adding cell in `cryoDRGN_filtering` jupyter notebook returned by `cryodrgn analyze` for filtering by UMAP/PC values (https://github.com/ml-struct-bio/cryodrgn/pull/313)\r\n- fixing bugs with deprecated signatures in plotting functions (https://github.com/ml-struct-bio/cryodrgn/issues/322) and numpy dependency versioning (https://github.com/ml-struct-bio/cryodrgn/issues/318)",
        "html_url": "https://github.com/ml-struct-bio/cryodrgn/releases/tag/v3.1.0-beta",
        "name": "Version 3.1.0-b: interactive filtering",
        "release_id": 135388176,
        "tag": "v3.1.0-beta",
        "tarball_url": "https://api.github.com/repos/ml-struct-bio/cryodrgn/tarball/v3.1.0-beta",
        "type": "Release",
        "url": "https://api.github.com/repos/ml-struct-bio/cryodrgn/releases/135388176",
        "value": "https://api.github.com/repos/ml-struct-bio/cryodrgn/releases/135388176",
        "zipball_url": "https://api.github.com/repos/ml-struct-bio/cryodrgn/zipball/v3.1.0-beta"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "michal-g",
          "type": "User"
        },
        "date_created": "2024-03-29T20:15:48Z",
        "date_published": "2024-03-31T05:07:10Z",
        "description": "This is a patch release to address #312 and #310 found in v3.0.0-beta by updating the list of dependencies and making some updates to the analysis Jupyter notebooks produced by experiments.",
        "html_url": "https://github.com/ml-struct-bio/cryodrgn/releases/tag/v3.0.1-beta",
        "name": "Version 3.0.1-beta",
        "release_id": 127879296,
        "tag": "v3.0.1-beta",
        "tarball_url": "https://api.github.com/repos/ml-struct-bio/cryodrgn/tarball/v3.0.1-beta",
        "type": "Release",
        "url": "https://api.github.com/repos/ml-struct-bio/cryodrgn/releases/127879296",
        "value": "https://api.github.com/repos/ml-struct-bio/cryodrgn/releases/127879296",
        "zipball_url": "https://api.github.com/repos/ml-struct-bio/cryodrgn/zipball/v3.0.1-beta"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "zhonge",
          "type": "User"
        },
        "date_created": "2023-09-06T07:15:01Z",
        "date_published": "2023-09-06T07:20:22Z",
        "description": "The official [cryoDRGN-ET](https://www.biorxiv.org/content/10.1101/2023.08.18.553799v1) release for heterogeneous subtomogram analysis.\r\n\r\n- [NEW] Heterogeneous reconstruction of subtomograms. See documentation [on gitbook](https://ez-lab.gitbook.io/cryodrgn/)\r\n- [NEW] cryodrgn `direct_traversal` for making movies\r\n- Updated `cryodrgn backproject_voxel` for voxel-based homogeneous reconstruction\r\n- Major refactor of dataset loading for handling large datasets",
        "html_url": "https://github.com/ml-struct-bio/cryodrgn/releases/tag/3.0.0-beta",
        "name": "Version 3.0.0-beta",
        "release_id": 120065360,
        "tag": "3.0.0-beta",
        "tarball_url": "https://api.github.com/repos/ml-struct-bio/cryodrgn/tarball/3.0.0-beta",
        "type": "Release",
        "url": "https://api.github.com/repos/ml-struct-bio/cryodrgn/releases/120065360",
        "value": "https://api.github.com/repos/ml-struct-bio/cryodrgn/releases/120065360",
        "zipball_url": "https://api.github.com/repos/ml-struct-bio/cryodrgn/zipball/3.0.0-beta"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "zhonge",
          "type": "User"
        },
        "date_created": "2023-05-02T14:20:34Z",
        "date_published": "2023-05-02T14:24:56Z",
        "description": "- Model configuration files are now saved as human-readable config.yaml files (https://github.com/zhonge/cryodrgn/issues/235)\r\n- Fix machine stamp in output .mrc files for better compatibility with downstream tools (https://github.com/zhonge/cryodrgn/pull/260)\r\n- Better documentation of help flags in ab initio reconstruction tools (https://github.com/zhonge/cryodrgn/issues/258)\r\n- [FIX] By default, window images in cryodrgn abinit_homo (now consistent with other reconstruction tools) (https://github.com/zhonge/cryodrgn/issues/258)\r\n- [FIX] Reduce memory usage when using --preprocessed and --ind (https://github.com/zhonge/cryodrgn/pull/272)\r\n- Updated functionality in `cryodrgn_utils filter_star`\r\n- Upcoming in the next minor version (v2.4):\r\n\r\n    - We are working on a major refactor of data loading for handling large datasets. This will entail an API change for the `mrc.py` library module",
        "html_url": "https://github.com/ml-struct-bio/cryodrgn/releases/tag/2.3.0",
        "name": "Version 2.3.0",
        "release_id": 101588922,
        "tag": "2.3.0",
        "tarball_url": "https://api.github.com/repos/ml-struct-bio/cryodrgn/tarball/2.3.0",
        "type": "Release",
        "url": "https://api.github.com/repos/ml-struct-bio/cryodrgn/releases/101588922",
        "value": "https://api.github.com/repos/ml-struct-bio/cryodrgn/releases/101588922",
        "zipball_url": "https://api.github.com/repos/ml-struct-bio/cryodrgn/zipball/2.3.0"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "zhonge",
          "type": "User"
        },
        "date_created": "2023-03-26T03:06:54Z",
        "date_published": "2023-01-21T14:27:39Z",
        "description": "- New ab initio reconstruction tools:\r\n\r\n    - `cryodrgn abinit_homo`\r\n    - `cryodrgn abinit_het`\r\n\r\n- New utility script for writing cryoSPARC `.cs` files:\r\n\r\n    - `cryodrgn_utils write_cs`\r\n\r\n- Improved plotting in `cryodrgn analyze`\r\n\r\n- Documentation and tutorial converted to sphinx docs: https://zhonge.github.io/cryodrgn/\r\n\r\n- Many codebase improvements with open-source software development practices (e.g. continuous integration tests, `black`, `flake8`, `pyright`, `logging`, and PyPi packaging).\r\n",
        "html_url": "https://github.com/ml-struct-bio/cryodrgn/releases/tag/2.2.0",
        "name": "Version 2.2.0",
        "release_id": 89805451,
        "tag": "2.2.0",
        "tarball_url": "https://api.github.com/repos/ml-struct-bio/cryodrgn/tarball/2.2.0",
        "type": "Release",
        "url": "https://api.github.com/repos/ml-struct-bio/cryodrgn/releases/89805451",
        "value": "https://api.github.com/repos/ml-struct-bio/cryodrgn/releases/89805451",
        "zipball_url": "https://api.github.com/repos/ml-struct-bio/cryodrgn/zipball/2.2.0"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "zhonge",
          "type": "User"
        },
        "date_created": "2022-09-22T13:44:17Z",
        "date_published": "2022-10-24T21:09:29Z",
        "description": "Minor release with updated documentation (and testing PyPI packing).",
        "html_url": "https://github.com/ml-struct-bio/cryodrgn/releases/tag/1.1.2",
        "name": "Version 1.1.2",
        "release_id": 80842122,
        "tag": "1.1.2",
        "tarball_url": "https://api.github.com/repos/ml-struct-bio/cryodrgn/tarball/1.1.2",
        "type": "Release",
        "url": "https://api.github.com/repos/ml-struct-bio/cryodrgn/releases/80842122",
        "value": "https://api.github.com/repos/ml-struct-bio/cryodrgn/releases/80842122",
        "zipball_url": "https://api.github.com/repos/ml-struct-bio/cryodrgn/zipball/1.1.2"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "zhonge",
          "type": "User"
        },
        "date_created": "2022-07-15T23:06:27Z",
        "date_published": "2022-07-15T23:17:40Z",
        "description": "Updated default settings to larger model architecture, modified positional encoding, and accelerated training:\r\n\r\n* Mixed precision training is now turned on by default (Use `--no-amp` to revert to single precision training)\r\n* Encoder/decoder architecture is now 1024x3 by default (Use `--enc-dim 256` and `--dec-dim 256` to revert)\r\n* Gaussian Fourier featurization for faster training and higher resolution density maps (Use `--pe-type geom_lowf` to revert)",
        "html_url": "https://github.com/ml-struct-bio/cryodrgn/releases/tag/1.1.0",
        "name": "Version 1.1.0",
        "release_id": 72130852,
        "tag": "1.1.0",
        "tarball_url": "https://api.github.com/repos/ml-struct-bio/cryodrgn/tarball/1.1.0",
        "type": "Release",
        "url": "https://api.github.com/repos/ml-struct-bio/cryodrgn/releases/72130852",
        "value": "https://api.github.com/repos/ml-struct-bio/cryodrgn/releases/72130852",
        "zipball_url": "https://api.github.com/repos/ml-struct-bio/cryodrgn/zipball/1.1.0"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "zhonge",
          "type": "User"
        },
        "date_created": "2022-07-15T21:32:58Z",
        "date_published": "2022-05-16T13:49:20Z",
        "description": "Release for version 1.0.0\r\n\r\nNEW: `cryodrgn analyze_landscape` for automatic classification and energy landscape inference\r\nNEW: Faster training and higher resolution model with Gaussian Fourier featurization (Use `--pe-type gaussian`)\r\nNEW: `cryodrgn_utils <command>` -h for standalone utility scripts\r\nNEW: `cryodrgn_utils write_star` for converting cryoDRGN particle selections to `.star` files\r\nAdd pytorch native mixed precision training and fix support for pytorch 1.9+",
        "html_url": "https://github.com/ml-struct-bio/cryodrgn/releases/tag/1.0.0",
        "name": "Version 1.0.0",
        "release_id": 66966200,
        "tag": "1.0.0",
        "tarball_url": "https://api.github.com/repos/ml-struct-bio/cryodrgn/tarball/1.0.0",
        "type": "Release",
        "url": "https://api.github.com/repos/ml-struct-bio/cryodrgn/releases/66966200",
        "value": "https://api.github.com/repos/ml-struct-bio/cryodrgn/releases/66966200",
        "zipball_url": "https://api.github.com/repos/ml-struct-bio/cryodrgn/zipball/1.0.0"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "zhonge",
          "type": "User"
        },
        "date_created": "2022-01-07T23:49:07Z",
        "date_published": "2022-01-07T23:57:27Z",
        "description": "Updates to auxiliary scripts\r\n\r\n- FIX: Bug in `write_starfile.py` when provided particle stack is chunked (.txt file)\r\n- Support micrograph coordinates and additional column headers to `write_starfile.py`\r\n- New helper scripts: `analyze_convergence.py` (in beta testing) contributed by Barrett Powell (thanks!) and `make_train_test.py` for splitting up particle stacks for training",
        "html_url": "https://github.com/ml-struct-bio/cryodrgn/releases/tag/0.3.4",
        "name": "Version 0.3.4",
        "release_id": 56647045,
        "tag": "0.3.4",
        "tarball_url": "https://api.github.com/repos/ml-struct-bio/cryodrgn/tarball/0.3.4",
        "type": "Release",
        "url": "https://api.github.com/repos/ml-struct-bio/cryodrgn/releases/56647045",
        "value": "https://api.github.com/repos/ml-struct-bio/cryodrgn/releases/56647045",
        "zipball_url": "https://api.github.com/repos/ml-struct-bio/cryodrgn/zipball/0.3.4"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "zhonge",
          "type": "User"
        },
        "date_created": "2021-11-05T18:12:49Z",
        "date_published": "2021-10-27T12:42:27Z",
        "description": "cryoDRGN version 0.3.3b\r\n\r\n* Faster image preprocessing and smaller memory footprint\r\n* New: cryodrgn preprocess for large datasets (in beta testing - see [here](https://www.notion.so/cryodrgn-preprocess-d84a9d9df8634a6a8bfd32d6b5e737ef) for details)\r\n* Known [issue](https://github.com/zhonge/cryodrgn/issues/66) with PyTorch version 1.9+\r\n\r\n(Version 0.3.3b patches a minor argument naming bug for `--lazy`)",
        "html_url": "https://github.com/ml-struct-bio/cryodrgn/releases/tag/0.3.3b",
        "name": "Version 0.3.3",
        "release_id": 52137177,
        "tag": "0.3.3b",
        "tarball_url": "https://api.github.com/repos/ml-struct-bio/cryodrgn/tarball/0.3.3b",
        "type": "Release",
        "url": "https://api.github.com/repos/ml-struct-bio/cryodrgn/releases/52137177",
        "value": "https://api.github.com/repos/ml-struct-bio/cryodrgn/releases/52137177",
        "zipball_url": "https://api.github.com/repos/ml-struct-bio/cryodrgn/zipball/0.3.3b"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "zhonge",
          "type": "User"
        },
        "date_created": "2021-03-26T20:12:12Z",
        "date_published": "2021-03-26T20:21:43Z",
        "description": "Minor updates to 0.3.1 software\r\n* New: Additional Jupyter notebook for particles filtering, `cryoDRGN_filtering.ipynb`\r\n* New: `cryodrgn view_config` \r\n* Fix: Compatibility and deprecation fixes with pytorch 1.7 (#29), scipy (#39), and seaborn (3111efdc4c147716fd34e6a860ddf6d512f17fdb)\r\n* Updated: More functionality for converting to starfiles with `write_starfile.py` (#44)\r\n* Performance improvements to `cryodrgn eval_vol` and a minor fix for a corner case (#33)\r\n* Note: The logged KL divergence in stdout is no longer scaled by beta, however the default objective is identical\r\n",
        "html_url": "https://github.com/ml-struct-bio/cryodrgn/releases/tag/v0.3.2",
        "name": "Version 0.3.2",
        "release_id": 40562503,
        "tag": "v0.3.2",
        "tarball_url": "https://api.github.com/repos/ml-struct-bio/cryodrgn/tarball/v0.3.2",
        "type": "Release",
        "url": "https://api.github.com/repos/ml-struct-bio/cryodrgn/releases/40562503",
        "value": "https://api.github.com/repos/ml-struct-bio/cryodrgn/releases/40562503",
        "zipball_url": "https://api.github.com/repos/ml-struct-bio/cryodrgn/zipball/v0.3.2"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "zhonge",
          "type": "User"
        },
        "date_created": "2021-01-03T06:01:19Z",
        "date_published": "2021-01-03T06:10:49Z",
        "description": "Minor update to v0.3 software:\r\n* New script `write_starfile.py` to save selected particles as a .star file for use in other tools\r\n* Improvements to `cryodrgn analyze`",
        "html_url": "https://github.com/ml-struct-bio/cryodrgn/releases/tag/0.3.1",
        "name": "Version 0.3.1",
        "release_id": 35919455,
        "tag": "0.3.1",
        "tarball_url": "https://api.github.com/repos/ml-struct-bio/cryodrgn/tarball/0.3.1",
        "type": "Release",
        "url": "https://api.github.com/repos/ml-struct-bio/cryodrgn/releases/35919455",
        "value": "https://api.github.com/repos/ml-struct-bio/cryodrgn/releases/35919455",
        "zipball_url": "https://api.github.com/repos/ml-struct-bio/cryodrgn/zipball/0.3.1"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "zhonge",
          "type": "User"
        },
        "date_created": "2020-09-28T16:58:47Z",
        "date_published": "2021-01-03T06:13:21Z",
        "description": "* New: GPU parallelization with flag `--multigpu`\r\n* New: Mode for accelerated mixed precision training with flag `--amp`, available for NVIDIA tensor core GPUs\r\n* Interface update:\r\n    * Renamed encoder arguments `--qdim` and `--qlayers` to `--enc-dim` and `--enc-layers`\r\n    * Renamed decoder arguments `--pdim` and `--players` to `--dec-dim` and `--dec-layers`\r\n* Argument default changes:\r\n    * Flipped the default for `--invert-data` to True by default\r\n    * Flipped the default for `--window` to True by default\r\n* Updated training recommendations in below quick start guide\r\n* Updates to cryodrgn analyze\r\n    * More visualizations\r\n    * Order kmeans volumes according to distances in latent space (previously random)\r\n    * More features for particle selection and filtering in the Jupiter notebook",
        "html_url": "https://github.com/ml-struct-bio/cryodrgn/releases/tag/0.3.0b",
        "name": "Version 0.3.0",
        "release_id": 35919482,
        "tag": "0.3.0b",
        "tarball_url": "https://api.github.com/repos/ml-struct-bio/cryodrgn/tarball/0.3.0b",
        "type": "Release",
        "url": "https://api.github.com/repos/ml-struct-bio/cryodrgn/releases/35919482",
        "value": "https://api.github.com/repos/ml-struct-bio/cryodrgn/releases/35919482",
        "zipball_url": "https://api.github.com/repos/ml-struct-bio/cryodrgn/zipball/0.3.0b"
      },
      "technique": "GitHub_API"
    }
  ],
  "run": [
    {
      "confidence": 1,
      "result": {
        "original_header": "5. Running cryoDRGN heterogeneous reconstruction",
        "parent_header": [
          ":snowflake::dragon: cryoDRGN: Deep Reconstructing Generative Networks for cryo-EM and cryo-ET heterogeneous reconstruction",
          "Quickstart: heterogeneous reconstruction with consensus poses"
        ],
        "type": "Text_excerpt",
        "value": "When the input images (.mrcs), poses (.pkl), and CTF parameters (.pkl) have been prepared, a cryoDRGN model\ncan be trained with following command:\n\n<details><summary><code>$ cryodrgn train_vae -h</code></summary>\n\n\tusage: cryodrgn train_vae [-h] -o OUTDIR --zdim ZDIM --poses POSES [--ctf pkl]\n\t                          [--load WEIGHTS.PKL] [--checkpoint CHECKPOINT]\n\t                          [--log-interval LOG_INTERVAL] [-v] [--seed SEED]\n\t                          [--ind PKL] [--uninvert-data] [--no-window]\n\t                          [--window-r WINDOW_R] [--datadir DATADIR] [--lazy]\n\t                          [--max-threads MAX_THREADS]\n\t                          [--tilt TILT] [--tilt-deg TILT_DEG] [-n NUM_EPOCHS]\n\t                          [-b BATCH_SIZE] [--wd WD] [--lr LR] [--beta BETA]\n\t                          [--beta-control BETA_CONTROL] [--norm NORM NORM]\n\t                          [--no-amp] [--multigpu] [--do-pose-sgd]\n\t                          [--pretrain PRETRAIN] [--emb-type {s2s2,quat}]\n\t                          [--pose-lr POSE_LR] [--enc-layers QLAYERS]\n\t                          [--enc-dim QDIM]\n\t                          [--encode-mode {conv,resid,mlp,tilt}]\n\t                          [--enc-mask ENC_MASK] [--use-real]\n\t                          [--dec-layers PLAYERS] [--dec-dim PDIM]\n\t                          [--pe-type {geom_ft,geom_full,geom_lowf,geom_nohighf,linear_lowf,gaussian,none}]\n\t                          [--feat-sigma FEAT_SIGMA] [--pe-dim PE_DIM]\n\t                          [--domain {hartley,fourier}]\n\t                          [--activation {relu,leaky_relu}]\n\t                          particles\n\n\tTrain a VAE for heterogeneous reconstruction with known pose\n\n\tpositional arguments:\n\t  particles             Input particles (.mrcs, .star, .cs, or .txt)\n\n\toptional arguments:\n\t  -h, --help            show this help message and exit\n\t  -o OUTDIR, --outdir OUTDIR\n\t                        Output directory to save model\n\t  --zdim ZDIM           Dimension of latent variable\n\t  --poses POSES         Image poses (.pkl)\n\t  --ctf pkl             CTF parameters (.pkl)\n\t  --load WEIGHTS.PKL    Initialize training from a checkpoint\n\t  --checkpoint CHECKPOINT\n\t                        Checkpointing interval in N_EPOCHS (default: 1)\n\t  --log-interval LOG_INTERVAL\n\t                        Logging interval in N_IMGS (default: 1000)\n\t  -v, --verbose         Increaes verbosity\n\t  --seed SEED           Random seed\n\n\tDataset loading:\n\t  --ind PKL             Filter particle stack by these indices\n\t  --uninvert-data       Do not invert data sign\n\t  --no-window           Turn off real space windowing of dataset\n\t  --window-r WINDOW_R   Windowing radius (default: 0.85)\n\t  --datadir DATADIR     Path prefix to particle stack if loading relative\n\t                        paths from a .star or .cs file\n\t  --lazy                Lazy loading if full dataset is too large to fit in\n\t                        memory (Should copy dataset to SSD)\n\t  --max-threads MAX_THREADS\n\t                        Maximum number of CPU cores for FFT parallelization\n\t                        (default: 16)\n\n\tTilt series:\n\t  --tilt TILT           Particles (.mrcs)\n\t  --tilt-deg TILT_DEG   X-axis tilt offset in degrees (default: 45)\n\n\tTraining parameters:\n\t  -n NUM_EPOCHS, --num-epochs NUM_EPOCHS\n\t                        Number of training epochs (default: 20)\n\t  -b BATCH_SIZE, --batch-size BATCH_SIZE\n\t                        Minibatch size (default: 8)\n\t  --wd WD               Weight decay in Adam optimizer (default: 0)\n\t  --lr LR               Learning rate in Adam optimizer (default: 0.0001)\n\t  --beta BETA           Choice of beta schedule or a constant for KLD weight\n\t                        (default: 1/zdim)\n\t  --beta-control BETA_CONTROL\n\t                        KL-Controlled VAE gamma. Beta is KL target. (default:\n\t                        None)\n\t  --norm NORM NORM      Data normalization as shift, 1/scale (default: 0, std\n\t                        of dataset)\n\t  --no-amp              Do not use mixed-precision training\n\t  --multigpu            Parallelize training across all detected GPUs\n\n\tPose SGD:\n\t  --do-pose-sgd         Refine poses with gradient descent\n\t  --pretrain PRETRAIN   Number of epochs with fixed poses before pose SGD\n\t                        (default: 1)\n\t  --emb-type {s2s2,quat}\n\t                        SO(3) embedding type for pose SGD (default: quat)\n\t  --pose-lr POSE_LR     Learning rate for pose optimizer (default: 0.0003)\n\n\tEncoder Network:\n\t  --enc-layers QLAYERS  Number of hidden layers (default: 3)\n\t  --enc-dim QDIM        Number of nodes in hidden layers (default: 1024)\n\t  --encode-mode {conv,resid,mlp,tilt}\n\t                        Type of encoder network (default: resid)\n\t  --enc-mask ENC_MASK   Circular mask of image for encoder (default: D/2; -1\n\t                        for no mask)\n\t  --use-real            Use real space image for encoder (for convolutional\n\t                        encoder)\n\n\tDecoder Network:\n\t  --dec-layers PLAYERS  Number of hidden layers (default: 3)\n\t  --dec-dim PDIM        Number of nodes in hidden layers (default: 1024)\n\t  --pe-type {geom_ft,geom_full,geom_lowf,geom_nohighf,linear_lowf,gaussian,none}\n\t                        Type of positional encoding (default: gaussian)\n\t  --feat-sigma FEAT_SIGMA\n\t                        Scale for random Gaussian features\n\t  --pe-dim PE_DIM       Num features in positional encoding (default: image D)\n\t  --domain {hartley,fourier}\n\t                        Decoder representation domain (default: fourier)\n\t  --activation {relu,leaky_relu}\n\t                        Activation (default: relu)\n\n</details>\n\nMany of the parameters of this script have sensible defaults. The required arguments are:\n\n* an input image stack (`.mrcs` or other listed file types)\n* `--poses`, image poses (`.pkl`) that correspond to the input images\n* `--ctf`, ctf parameters (`.pkl`), unless phase-flipped images are used\n* `--zdim`, the dimension of the latent variable\n* `-o`, a clean output directory for saving results\n\nAdditional parameters which are typically set include:\n\n* `-n`, Number of epochs to train\n* `--uninvert-data`, Use if particles are dark on light (negative stain format)\n* Architecture parameters with `--enc-layers`, `--enc-dim`, `--dec-layers`, `--dec-dim`\n* `--multigpu` to enable parallelized training across multiple GPUs\n"
      },
      "source": "https://raw.githubusercontent.com/zhonge/cryodrgn/main/README.md",
      "technique": "header_analysis"
    }
  ],
  "somef_missing_categories": [
    "acknowledgement",
    "download",
    "requirements",
    "contributors",
    "faq",
    "support",
    "identifier",
    "has_build_file"
  ],
  "somef_provenance": {
    "date": "2024-10-06 08:33:15",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 311
      },
      "technique": "GitHub_API"
    }
  ],
  "type": [
    {
      "confidence": 0.82,
      "result": {
        "type": "String",
        "value": "commandline-application"
      },
      "technique": "software_type_heuristics"
    }
  ],
  "usage": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Recommended usage:",
        "parent_header": [
          ":snowflake::dragon: cryoDRGN: Deep Reconstructing Generative Networks for cryo-EM and cryo-ET heterogeneous reconstruction",
          "Quickstart: heterogeneous reconstruction with consensus poses"
        ],
        "type": "Text_excerpt",
        "value": "1) It is highly recommended to first train on lower resolution images (e.g. D=128) to sanity check results\n2) and perform any particle filtering.\n\nExample command to train a cryoDRGN model for 25 epochs on an image dataset `projections.128.mrcs`\nwith poses `pose.pkl` and ctf parameters `ctf.pkl`:\n\n    # 8-D latent variable model, small images\n    $ cryodrgn train_vae projections.128.mrcs \\\n            --poses pose.pkl \\\n            --ctf ctf.pkl \\\n            --zdim 8 -n 25 \\\n            -o 00_cryodrgn128\n\n2) After validation, pose optimization, and any necessary particle filtering,\nthen train on the full resolution images (up to D=256):\n\nExample command to train a cryoDRGN model for 25 epochs on an image dataset `projections.256.mrcs`\nwith poses `pose.pkl` and ctf parameters `ctf.pkl`:\n\n    # 8-D latent variable model, larger images\n    $ cryodrgn train_vae projections.256.mrcs \\\n            --poses pose.pkl \\\n            --ctf ctf.pkl \\\n            --zdim 8 -n 25 \\\n            -o 01_cryodrgn256\n\nThe number of epochs `-n` refers to the number of full passes through the dataset for training, and should be modified\ndepending on the number of particles in the dataset. For a 100k particle dataset on 1 V100 GPU,\nthe above settings required ~12 min/epoch for D=128 images and ~47 min/epoch for D=256 images.\n\nIf you would like to train longer, a training job can be extended with the `--load` argument.\nFor example to extend the training of the previous example to 50 epochs:\n\n    $ cryodrgn train_vae projections.256.mrcs \\\n            --poses pose.pkl \\\n            --ctf ctf.pkl \\\n            --zdim 8 -n 50 \\\n            -o 01_cryodrgn256 \\\n            --load 01_cryodrgn256/weights.24.pkl # 0-based indexing\n"
      },
      "source": "https://raw.githubusercontent.com/zhonge/cryodrgn/main/README.md",
      "technique": "header_analysis"
    }
  ]
}