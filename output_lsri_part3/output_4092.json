{
  "citation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Cite",
        "type": "Text_excerpt",
        "value": "If you use this tool, please cite:\n\nChristian Tischer, Ashis Ravindran, Sabine Reither, Nicolas Chiaruttini, Rainer Pepperkok, Nils Norlin, BigDataProcessor2: A free and open-source Fiji plugin for inspection and processing of TB sized image data, Bioinformatics, 2021; https://doi.org/10.1093/bioinformatics/btab106\n\n(or our bioRxiv preprint: https://www.biorxiv.org/content/10.1101/2020.09.23.244095v1)\n"
      },
      "source": "https://raw.githubusercontent.com/bigdataprocessor/bigdataprocessor2/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/bigdataprocessor/bigdataprocessor2"
      },
      "technique": "GitHub_API"
    }
  ],
  "contributing_guidelines": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Contribute",
        "type": "Text_excerpt",
        "value": "[How to contribute.](https://github.com/bigdataprocessor/bigdataprocessor2/blob/master/CONTRIBUTE.md)\n"
      },
      "source": "https://raw.githubusercontent.com/bigdataprocessor/bigdataprocessor2/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2018-12-13T09:08:07Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2024-03-24T17:46:03Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 0.9992494085198077,
      "result": {
        "original_header": "Hardware recommendations",
        "type": "Text_excerpt",
        "value": "It is recommended that the image data is accessed via a local area network (LAN) cable. For example, accessing the data over a slow (few MB/s) internet connection (e.g., in a home office scenario) can result in update rates of the currently viewed image plane of less than once per second, which is not ideal for interactive browsing of the data. For a good user experience tens of MB/s data transfer rate or above is recommended for typical data sets with image planes that are about 2k x 2k pixels in size.\nRAM is in general not limiting even for processing of the full data set, because the application tries to only keep the volumes (channels) for one time point in RAM, which typically does not exceed the RAM of a modern laptop (e.g., 16 GB). However, BDP2 offers the option to employ multiple I/O threads (if either the input or output format is HDF5 based). We currently do not recommend using multiple I/O threads as the HDF5 library that we currently use is not capable of multithreading. If multiple I/O threads are chosen, BDP2 processes multiple time points in parallel and the RAM requirements increase linearly as the corresponding data needs to be kept in RAM simultaneously. In practice, finding the optimal number of I/O threads to speed up the processing is hardware and data set dependent and should be tested for each setup. \nRegarding the CPU, the processing time will be faster with increasing CPU cores as the processing (e.g. binning) is multi-threaded. In practice, adding more cores may at some point be of limited use, as the overall processing time may become limited by I/O operations.\nOverall, in our experience, the ideal scenario is to use the BDP2 UI to record the processing as a script (currently IJ Macro or Jython) and then execute this script on a computer cluster, parallelising over the time-points to be processed. In order to enable this, we have added a [ Record only ] button to the saving menu. We already have successfully tested this on a Slurm (Yoo et al. 2003) computer cluster and are happy to consult interested users.\n \n"
      },
      "source": "https://raw.githubusercontent.com/bigdataprocessor/bigdataprocessor2/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9833811587496193,
      "result": {
        "type": "Text_excerpt",
        "value": "BigDataProcessor2 (BDP2) is a  plugin for interactive processing of TB-sized image data. \nBDP2 uses  for rendering and the  library for image processing.  \nThe BDP2 is the new version of .  \nMain features:\n-  of TB sized image data\n-  of TB sized image data\n-  scripting support \n**Schematic representation of a lazy-processing workflow in BDP2:** Dashed arrows represent lazy-computation, where only the currently viewed image plane is processed. A complete data browsing, data selection and data processing workflow can be configured in a few minutes even for TB-sized image data. Only the final saving to disk requires processing of the whole data set and will take a correspondingly long time (up to hours). \n\n** of a typical BDP2 workflow:** The movie shows a screen recording of a basic processing workflow of an 250 GB image data set acquired by light-sheet microscopy and saved in an HDF5 based file format. The following steps are demonstrated: `Open -> Brightness & Color Adjustment -> Set Voxel Size -> Align Channels -> Crop -> Bin -> Save`. The 2 color early mouse embryo data were kindly provided by Manuel Eguren, Ellenberg group, EMBL Heidelberg. \n"
      },
      "source": "https://raw.githubusercontent.com/bigdataprocessor/bigdataprocessor2/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "documentation": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/bigdataprocessor/bigdataprocessor2/tree/master/docs"
      },
      "technique": "file_exploration"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/bigdataprocessor/bigdataprocessor2/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 4
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/bigdataprocessor/bigdataprocessor2/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "bigdataprocessor/bigdataprocessor2"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ""
      },
      "source": "https://raw.githubusercontent.com/bigdataprocessor/bigdataprocessor2/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "has_script_file": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/bigdataprocessor/bigdataprocessor2/master/.github/build.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/bigdataprocessor/bigdataprocessor2/master/.github/setup.sh"
      },
      "technique": "file_exploration"
    }
  ],
  "identifier": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://zenodo.org/badge/latestdoi/161612516"
      },
      "source": "https://raw.githubusercontent.com/bigdataprocessor/bigdataprocessor2/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "images": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/bigdataprocessor/bigdataprocessor2/master/./docs/images/BDP2-icon.png"
      },
      "source": "https://raw.githubusercontent.com/bigdataprocessor/bigdataprocessor2/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/bigdataprocessor/bigdataprocessor2/master/./docs/images/BDP2-SIFigure_1.jpg"
      },
      "source": "https://raw.githubusercontent.com/bigdataprocessor/bigdataprocessor2/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://img.youtube.com/vi/OixZ0ILbkvc/0.jpg"
      },
      "source": "https://raw.githubusercontent.com/bigdataprocessor/bigdataprocessor2/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/bigdataprocessor/bigdataprocessor2/master/./docs/images/BDP2-MainUI.png"
      },
      "source": "https://raw.githubusercontent.com/bigdataprocessor/bigdataprocessor2/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/bigdataprocessor/bigdataprocessor2/master/./docs/images/Process_Track.png"
      },
      "source": "https://raw.githubusercontent.com/bigdataprocessor/bigdataprocessor2/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/bigdataprocessor/bigdataprocessor2/master/./docs/images/Process_Bin.png"
      },
      "source": "https://raw.githubusercontent.com/bigdataprocessor/bigdataprocessor2/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/bigdataprocessor/bigdataprocessor2/master/./docs/images/Process_Crop.png"
      },
      "source": "https://raw.githubusercontent.com/bigdataprocessor/bigdataprocessor2/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/bigdataprocessor/bigdataprocessor2/master/./docs/images/Process_ChannelShift.png"
      },
      "source": "https://raw.githubusercontent.com/bigdataprocessor/bigdataprocessor2/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/bigdataprocessor/bigdataprocessor2/master/./docs/images/Process_SplitChip.png"
      },
      "source": "https://raw.githubusercontent.com/bigdataprocessor/bigdataprocessor2/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/bigdataprocessor/bigdataprocessor2/master/./docs/images/Process_Transform.png"
      },
      "source": "https://raw.githubusercontent.com/bigdataprocessor/bigdataprocessor2/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/bigdataprocessor/bigdataprocessor2/master/./docs/images/2.png"
      },
      "source": "https://raw.githubusercontent.com/bigdataprocessor/bigdataprocessor2/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/bigdataprocessor/bigdataprocessor2/master/./docs/images/3.png"
      },
      "source": "https://raw.githubusercontent.com/bigdataprocessor/bigdataprocessor2/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/bigdataprocessor/bigdataprocessor2/master/./docs/images/4.png"
      },
      "source": "https://raw.githubusercontent.com/bigdataprocessor/bigdataprocessor2/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "installation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Install",
        "type": "Text_excerpt",
        "value": "BigDataProcessor2 is a Fiji plugin and can be installed via an update site.\n\n- Please download a new [Fiji](fiji.sc)\n- Within Fiji, please enable the following [Update Site](https://imagej.net/Update_Sites): \n    - [X] BigDataProcessor\n    - Note: The (deprecated) EMBL-CBA update site must **not** be checked because of compatibility issues!\n- Restart Fiji\n"
      },
      "source": "https://raw.githubusercontent.com/bigdataprocessor/bigdataprocessor2/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Main user interface",
        "parent_header": [
          "User Guide"
        ],
        "type": "Text_excerpt",
        "value": "<img width=\"350\" alt=\"image\" src=\"./docs/images/BDP2-MainUI.png\">\n\nBDP2 comes with its own a user interface (UI) where all functionality can be accessed (the menus in the ImageJ UI will typically not work here). \nThe UI shows information about the currently active image as well as the current and average image data reading speed.\nIt is possible to have multiple images (BigDataViewer windows) open at the same time. Following the usual ImageJ convention, the \"active\" image is the one that you clicked on last.\n"
      },
      "source": "https://raw.githubusercontent.com/bigdataprocessor/bigdataprocessor2/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Script recording",
        "parent_header": [
          "User Guide"
        ],
        "type": "Text_excerpt",
        "value": "Script recording is one of ImageJ\u2019s greatest features as it allows users without programming experience to record reusable scripts, which can be used for automation but also for documentation. Thus, also BDP2 supports the recording of scripts in a couple of popular scripting languages.\n"
      },
      "source": "https://raw.githubusercontent.com/bigdataprocessor/bigdataprocessor2/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Record Menu",
        "parent_header": [
          "User Guide",
          "Script recording"
        ],
        "type": "Text_excerpt",
        "value": "**Record > Record...**\nEnable/ disable macro recording. The user can choose to turn script recording on and off and also select from three recording languages, namely the IJ1 Macro language, Jython (Juneau et al. 2010) and JavaScript (https://en.wikipedia.org/wiki/JavaScript).\nMotivation: Macro recording is one of ImageJ\u2019s greatest features as it allows users without programming experience to record reusable scripts. It can be used for automation but also for sharing, documentation and publishing.  In our experience, next to the IJ1 Macro language, Jython is the second most popular scripting language for ImageJ, most likely due to the overall popularity of python (https://insights.stackoverflow.com/survey/2019#most-popular-technologies). We also support JavaScript due to its increasing popularity and importance in web based applications. ImageJ supports many more scripting languages, however, we decided to limit our support to a few in order to guide the user in their choice.\n\nYou can find several [example scripts here](https://github.com/bigdataprocessor/bigdataprocessor2/tree/master/scripts).\n"
      },
      "source": "https://raw.githubusercontent.com/bigdataprocessor/bigdataprocessor2/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Open",
        "parent_header": [
          "User Guide"
        ],
        "type": "Text_excerpt",
        "value": "We currently support opening of\n1. TIFF or HDF5 based images files series\n2. Everything that can be opened with Bio-Formats\n"
      },
      "source": "https://raw.githubusercontent.com/bigdataprocessor/bigdataprocessor2/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Open Menu",
        "parent_header": [
          "User Guide",
          "Open"
        ],
        "type": "Text_excerpt",
        "value": "**Open > Help**\nProvides detailed information about below menu items for loading big image data. In particular, it provides a list of regular expressions that can be used to open custom image file series.\n\n**Open > Open Bio-Formats\u2026**\nUses the Bio-Formats library (Linkert et al. 2010) to read from 140+ image file formats. It tries to do so lazily and can thus also work for TB sized data, but performance may depend on the image data type. If you want to read from multi file series TIFF or HDF5 data with high performance we recommend using [ Open Custom File Series\u2026 ] (see below).\n\n**Open > Open Custom File Series\u2026**\nOpen datasets consisting of a collection of TIFF or HDF5 volumes. The assignment of each file (volume) to a channel and time point can be specified by a regular expression. Please see [ Open > Help ] for more detailed information. Motivation: TIFF and HDF5 are common file formats for big image data. For example, Viventis Microscopy (https://www.viventis-microscopy.com) and Luxendo (https://luxendo.eu) save their light sheet data in multi file TIFF and HDF5 series, respectively. With this menu item we support efficient lazy loading from data saved in such file formats. As determining the correct regular expression can be somewhat cumbersome, we provide convenience menu items for prevalent cases (see below [ Open > Open Predefined File Series ]).\n\n**Open > Open Predefined File Series > Open EM TIFF Plane File Series...**\nOpens a single folder with TIFF single plane files. Each file will be assigned to one z-plane in a dataset with one color and one time point. Motivation: This is a typical format for volume EM data to be stored in and we wanted to relieve users from the burden to type in the regular expression for this.\n\n**Open > Open Predefined File Series > Open Leica DSL TIFF File Series...**\nOpens datasets acquired with Leica DSL microscopes, choosing \u201cAuto-Save, Data type: Tif, Compression: Uncompressed\u201d as an option within the Leica acquisition software. Motivation: Leica\u2019s naming scheme would require entering a complex regular expression and we thus implemented this convenience opening functionality. \n\n**Open > Open Predefined File Series > Open Luxendo HDF5 File Series...**\nOpen datasets acquired with Luxendo (https://luxendo.eu) light sheet microscopes. Motivation: Luxendo uses an HDF5 based file format. We added convenience functionality for opening those files without the need to enter complex regular expressions. \n\n**Open > Open Predefined File Series > Open Viventis TIFF File Series...**\nOpen datasets acquired with Viventis Microscopy (https://www.viventis-microscopy.com) light sheet microscopes. Motivation: Viventis uses a TIFF based file format. We added convenience functionality for opening those files without the need to enter regular expressions. \n\n**Open > Download and Open Sample Data...**\nDownload and open sample data stored in the BioStudies archive (Sarkans et al. 2017). \nAccess data directly in the archive via this link: https://www.ebi.ac.uk/biostudies/studies/S-BSST417?query=bigdataprocessor2\nMotivation: Conveniently accessible example data is useful to explore and teach BigDataProcessor2 functionality without the need to prepare suitable input data. \n\n\n"
      },
      "source": "https://raw.githubusercontent.com/bigdataprocessor/bigdataprocessor2/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Process &gt; Rename\u2026",
        "parent_header": [
          "User Guide",
          "Process",
          "Process Menu"
        ],
        "type": "Text_excerpt",
        "value": "Rename the data set and channels.\n"
      },
      "source": "https://raw.githubusercontent.com/bigdataprocessor/bigdataprocessor2/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Process &gt; Set Voxel Size\u2026",
        "parent_header": [
          "User Guide",
          "Process",
          "Process Menu"
        ],
        "type": "Text_excerpt",
        "value": "Changes the voxel size. Motivation: The voxel size may not always be read correctly from the data set, thus it is useful to have the option to set it manually. \n"
      },
      "source": "https://raw.githubusercontent.com/bigdataprocessor/bigdataprocessor2/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Process &gt; Correct Drift",
        "parent_header": [
          "User Guide",
          "Process",
          "Process Menu"
        ],
        "type": "Text_excerpt",
        "value": "Correct sample motion by interactively creating a 3D track, which will be applied such that the image is stationary relative to the track positions.\nMotivation: For time lapse data there is a risk that a sample moves during acquisition. To accommodate for either sample or microscope drift it is common to choose a field of view to encompass expected drift at the expense of larger data footprint. This can be compensated by cropping the data. However, applying a static volumetric crop over the whole time lapse is suboptimal. Therefore an ideal crop would be on drift corrected data (see Supplementary Movie 2). Additional applications can be, e.g., tracking motile cells in tissues. \n"
      },
      "source": "https://raw.githubusercontent.com/bigdataprocessor/bigdataprocessor2/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Process &gt; Correct Drift &gt; Create Track\u2026",
        "parent_header": [
          "User Guide",
          "Process",
          "Process Menu"
        ],
        "type": "Text_excerpt",
        "value": "Create a 3D track by manually placing anchor points in a subset of time points (track positions in the other time-points will be automatically added by linear interpolation). When done, save the track as a Json file to disk, to be used in [ Process > Correct Drift > Apply Track\u2026].\n\n<img src=\"./docs/images/Process_Track.png\" width=\"1000\">\n"
      },
      "source": "https://raw.githubusercontent.com/bigdataprocessor/bigdataprocessor2/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Process &gt; Bin\u2026",
        "parent_header": [
          "User Guide",
          "Process",
          "Process Menu"
        ],
        "type": "Text_excerpt",
        "value": "<img src=\"./docs/images/Process_Bin.png\" width=\"1000\">\n\nPerforms arbitrary binning along x y and z coordinates.\nMotivation: For camera-based microscopy systems the effective pixel size often cannot be freely chosen during acquisition. Thus, the user may be forced to over-sample, leading to large data volumes with noise since the information is spread across many pixels and therefore resulting in (vastly) increased image processing times. Thus, binning the data post-acquisition is can be very useful as it both reduces data size and noise, often without compromising scientific accuracy.\nMotivation: For camera-based microscopy systems the effective pixel size often cannot be freely chosen during acquisition. Thus, the user may be forced to over-sample, leading to large data volumes and potentially with noise since the information is spread across many pixels and therefore resulting in (vastly) increased image processing times. Thus, binning the data post-acquisition can be very useful as it both reduces data size (and noise), often without compromising scientific accuracy.\nThe BigDataProcessor2 makes it possible to develop different binnings interactively, thereby providing an efficient means to \nattain a binning at which the corresponding scientific question can be efficiently addressed. See also [video_example_binning](#binninglink)  \n"
      },
      "source": "https://raw.githubusercontent.com/bigdataprocessor/bigdataprocessor2/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Process &gt; Crop\u2026",
        "parent_header": [
          "User Guide",
          "Process",
          "Process Menu"
        ],
        "type": "Text_excerpt",
        "value": "<img src=\"./docs/images/Process_Crop.png\" width=\"1000\">\n\nInteractively specify a 4D (x,y,z,t) subset of the data to be displayed in a new viewer window.\nMotivation: Imaging processes in living samples require setting up imaging parameters before knowing exactly when and where the process of interest takes place. Therefore the imaging field of view (x,y,z) and temporal extent (t) are usually set generously to accommodate sample drift, motion, or growth. Using the crop function one can reduce the dataset to the necessary spatial and temporal dimensions.\nsee also the [video_example_cropping](#croppinglink) demonstrating how the BigDataProcessor2 can be interactively used to crop the data to only contain the relevant parts.\n"
      },
      "source": "https://raw.githubusercontent.com/bigdataprocessor/bigdataprocessor2/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Process &gt; Convert to 8-bit\u2026",
        "parent_header": [
          "User Guide",
          "Process",
          "Process Menu"
        ],
        "type": "Text_excerpt",
        "value": "Convert the data set from 16 to 8-bit depth. \nMotivation: Cameras typically produce image data at 12, 14, or 16 bit-depths. For many image analysis tasks, 8-bit depth is sufficient affording the user to reduce data size by a factor of 2. However, converting 16-bit to 8-bit data is not trivial as it entails deciding on a specific mapping from the higher to the lower bit-depth, which will lose information. Choosing a mapping of 65535 to 255 and 0 to 0 can lead to a low dynamic range in the 8-bit range especially when the input contains only a subset of the full 16-bit range. Also mapping max(image) to 255 and min(image) to 0 can be sub-optimal if there are spurious pixels with very high values, again leading to a low dynamic range for the relevant grey values in the 8-bit converted data. We thus provide the possibility to freely specify a mapping while browsing the data set to inspect at each position current result of the conversion. See also [video_example_convert_to_8-bit](#bitdepthlink)\n"
      },
      "source": "https://raw.githubusercontent.com/bigdataprocessor/bigdataprocessor2/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Process &gt; Align Channels\u2026",
        "parent_header": [
          "User Guide",
          "Process",
          "Process Menu"
        ],
        "type": "Text_excerpt",
        "value": "<img src=\"./docs/images/Process_ChannelShift.png\" width=\"1000\">\n\nShift one channel in relation to the other to compensate pixel offsets e.g. due to chromatic shifts. \nMotivation: Chromatic shifts either due to optics being corrected only for a given wavelength range, or parallel acquisition of two channels on two cameras can lead to offsets between the two channels/ images. We, therefore, provide the functionality to correct for such channel shifts in x,y and z. \n"
      },
      "source": "https://raw.githubusercontent.com/bigdataprocessor/bigdataprocessor2/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Process &gt; Align Channels Split Chip\u2026",
        "parent_header": [
          "User Guide",
          "Process",
          "Process Menu"
        ],
        "type": "Text_excerpt",
        "value": "<img src=\"./docs/images/Process_SplitChip.png\" width=\"1000\">\n\nSpecify two crop regions in one channel and convert those regions into two channels, i.e. the number of channels of the resulting image is increased by one.\nMotivation: For the sake of acquisition speed, some fluorescence microscope systems acquire the signal of several fluorescence channels simultaneously on the same camera chip. Thus, we provide the functionality to convert such data into a conventional multi-channel data set by aligning the channels from a \u201csplit chip\u201d. \n"
      },
      "source": "https://raw.githubusercontent.com/bigdataprocessor/bigdataprocessor2/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Process &gt; Transform &gt; Affine Transform...",
        "parent_header": [
          "User Guide",
          "Process",
          "Process Menu"
        ],
        "type": "Text_excerpt",
        "value": "<img src=\"./docs/images/Process_Transform.png\" width=\"1000\">\n\nRenders an affine view of the data. The transformation must be given as a comma separated list of 12 values defining an affine transformation, in a so-called row-packed format: `m11,m12,m13,t1,m21,m22,m23,t2,m31,m32,m33,t3`, where the matrix `M` specifies scaling, rotation and shear and the vector `t` specifies the translation. Given a 3D input coordinate `x`, the transformed coordinate `x'` is computed as follows:\n\n```\n\nx' = M x + t\n    \n    x1\nx = x2  \n    x3\n\n    m11 m12 m13\nM = m21 m22 m23    \n    m31 m32 m33  \n    \n    t1\nt = t2\n    t3\n```\n\nMotivation: This is useful when data is warped due to an acquisition process that renders x-y-z non-orthogonal. Examples are when a stage movement is not orthogonal to the field of view. Also useful in single objective light sheet microscopy.  \n"
      },
      "source": "https://raw.githubusercontent.com/bigdataprocessor/bigdataprocessor2/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Process &gt; Transform &gt; Manual Transform",
        "parent_header": [
          "User Guide",
          "Process",
          "Process Menu"
        ],
        "type": "Text_excerpt",
        "value": "Instead of entering an affine transformation one can also interactively transform an image:\n\n- select the BDV window and press `T`: it will start the manual transform\n- e.g. press `Z` to make the Z axis the axis of rotation\n- e.g. use the arrow keys to rotate your image\n- press `T` again to fix the transformation\n\nThen your image will be transformed.\n"
      },
      "source": "https://raw.githubusercontent.com/bigdataprocessor/bigdataprocessor2/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Save",
        "parent_header": [
          "User Guide"
        ],
        "type": "Text_excerpt",
        "value": "We currently support saving to\n1. TIFF stack or plane files series\n2. HDF5 chunked multi-resolution file series \n"
      },
      "source": "https://raw.githubusercontent.com/bigdataprocessor/bigdataprocessor2/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Save Menu",
        "parent_header": [
          "User Guide",
          "Save"
        ],
        "type": "Text_excerpt",
        "value": "***Save > Save as Imaris Volumes\u2026***\nSave data set as an hdf5 based pyramidal Imaris file (http://open.bitplane.com/ims), with each channel and time point saved as an individual .h5 file and one .ims header file that can be used to view the data both in Fiji\u2019s BigDataViewer and in the commercial Imaris software.\nMotivation: The low data overhead of a pyramidal scheme (in 3D for binning 2 x 2 x 2 at each pyramidal level  ~14%) is a marginal cost for a substantially improved user experience when viewing the data. We, therefore, provide saving data in an open file format that offers this functionality based on hdf5, which means that it can be handled with all common programming languages.\n\n***Save > Save as BigDataViewer XML/HDF5\u2026***\nSave data set as an hdf5 based pyramidal file, all channels and time points will be within one HDF5 file.\nMotivation: This is the standard file format used by essentially all BigDataViewer applications and thus provides good compatibility for downstream processing.\n\n***Save > Save as TIFF Volumes...***\nSave the dataset as a series of TIFF stacks with each channel and time point saved as an individual .tif file.\nMotivation: TIFF stacks are still the most used and compatible file format that can be easily opened by all software for downstream analysis. \n\n***Save > Save as TIFF Planes...***\nSave the dataset as a series of TIFF planes, where each z-slice, channel and time point are saved as an individual .tif file.\nMotivation: Saving a volume as a series of TIFF planes is popular e.g. in the EM community.\n"
      },
      "source": "https://raw.githubusercontent.com/bigdataprocessor/bigdataprocessor2/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Misc Menu",
        "parent_header": [
          "User Guide",
          "Misc"
        ],
        "type": "Text_excerpt",
        "value": "**Misc > Configure Lazy Loading...**\nConfigure the x, y, and z dimensions of the lazy loading chunks. Motivation: BDP2 lazy loads small chunks from the big image data set, enabling interactive processing of TB sized image data on a standard computer with only a few GB of random access memory. Here, the size of these chunks can be configured. Normally the default values are good and we do not recommend changing them. This menu item has mainly been implemented to facilitate teaching about how different lazy loading schemes affect the performance for different file formats. If the data is loaded via Bio-Formats this setting is currently ignored.\n\n**Misc > Show in Hyperstack Viewer**\nOpens the current image virtually in the \u201cclassic\u201d ImageJ hyperstack viewer. Motivation: BigDataViewer is a relatively recent addition to the ImageJ ecosystem  and many users are more comfortable using the ImageJ hyperstack viewer. In addition, with the data being displayed in the hyperstack viewer, one has access to many useful ImageJ inspection tools such as intensity histograms and intensity line profiles.\n\n**Misc > Configure Logging...**\nPresents different logging levels, currently: Normal, Debug, and Benchmark. Motivation: For debugging and benchmarking it is very useful to see additional information, which would however distract in daily routine use. Please be careful using the Benchmark mode, because additional code is executed that may slow down the application.\n\n"
      },
      "source": "https://raw.githubusercontent.com/bigdataprocessor/bigdataprocessor2/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/bigdataprocessor/bigdataprocessor2/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ""
      },
      "technique": "GitHub_API"
    }
  ],
  "license": [
    {
      "confidence": 1,
      "result": {
        "name": "BSD 2-Clause \"Simplified\" License",
        "spdx_id": "BSD-2-Clause",
        "type": "License",
        "url": "https://api.github.com/licenses/bsd-2-clause",
        "value": "https://api.github.com/licenses/bsd-2-clause"
      },
      "technique": "GitHub_API"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "bigdataprocessor2"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "Organization",
        "value": "bigdataprocessor"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Java",
        "size": 1212147,
        "type": "Programming_language",
        "value": "Java"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "HTML",
        "size": 9255,
        "type": "Programming_language",
        "value": "HTML"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "ImageJ Macro",
        "size": 4748,
        "type": "Programming_language",
        "value": "ImageJ Macro"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "JavaScript",
        "size": 1400,
        "type": "Programming_language",
        "value": "JavaScript"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/bigdataprocessor/bigdataprocessor2/master/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "releases": [
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "tischi",
          "type": "User"
        },
        "date_created": "2021-01-08T09:12:15Z",
        "date_published": "2021-01-08T09:13:22Z",
        "html_url": "https://github.com/bigdataprocessor/bigdataprocessor2/releases/tag/0.5.7",
        "name": "0.5.7",
        "release_id": 36132329,
        "tag": "0.5.7",
        "tarball_url": "https://api.github.com/repos/bigdataprocessor/bigdataprocessor2/tarball/0.5.7",
        "type": "Release",
        "url": "https://api.github.com/repos/bigdataprocessor/bigdataprocessor2/releases/36132329",
        "value": "https://api.github.com/repos/bigdataprocessor/bigdataprocessor2/releases/36132329",
        "zipball_url": "https://api.github.com/repos/bigdataprocessor/bigdataprocessor2/zipball/0.5.7"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "tischi",
          "type": "User"
        },
        "date_created": "2020-12-30T13:19:56Z",
        "date_published": "2020-12-30T13:20:51Z",
        "description": "version 0.5.6",
        "html_url": "https://github.com/bigdataprocessor/bigdataprocessor2/releases/tag/0.5.6",
        "name": "v0.5.6",
        "release_id": 35840351,
        "tag": "0.5.6",
        "tarball_url": "https://api.github.com/repos/bigdataprocessor/bigdataprocessor2/tarball/0.5.6",
        "type": "Release",
        "url": "https://api.github.com/repos/bigdataprocessor/bigdataprocessor2/releases/35840351",
        "value": "https://api.github.com/repos/bigdataprocessor/bigdataprocessor2/releases/35840351",
        "zipball_url": "https://api.github.com/repos/bigdataprocessor/bigdataprocessor2/zipball/0.5.6"
      },
      "technique": "GitHub_API"
    }
  ],
  "somef_missing_categories": [
    "acknowledgement",
    "run",
    "download",
    "requirements",
    "contact",
    "contributors",
    "faq",
    "support",
    "has_build_file",
    "executable_example"
  ],
  "somef_provenance": {
    "date": "2024-10-06 15:07:43",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 20
      },
      "technique": "GitHub_API"
    }
  ],
  "usage": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Start",
        "type": "Text_excerpt",
        "value": "[ Fiji > Plugins > BigDataProcessor > BigDataProcessor2 ]\n"
      },
      "source": "https://raw.githubusercontent.com/bigdataprocessor/bigdataprocessor2/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Quick start",
        "type": "Text_excerpt",
        "value": "The easiest way to explore BDP2's functionality is to download and open a small example data set and explore the processing options.\n\n[ BigDataProcessor2 > Open > Download and Open Sample Data ]\n"
      },
      "source": "https://raw.githubusercontent.com/bigdataprocessor/bigdataprocessor2/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "<a name=\"binninglink\"></a>Binning",
        "parent_header": [
          "Additional information",
          "More example videos"
        ],
        "type": "Text_excerpt",
        "value": "    \n[<img width=\"300\" alt=\"image\" src=\"./docs/images/2.png\">](https://drive.google.com/open?id=1AVFW3M5QYEDH9XUgR-q2LWUsuy16zF1A)\n"
      },
      "source": "https://raw.githubusercontent.com/bigdataprocessor/bigdataprocessor2/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "<a name=\"croppinglink\"></a>Cropping",
        "parent_header": [
          "Additional information",
          "More example videos"
        ],
        "type": "Text_excerpt",
        "value": "[<img width=\"300\" alt=\"image\" src=\"./docs/images/3.png\">](https://drive.google.com/open?id=1iabVP9jbISI1WclMRjtDHvcNWxMTC95-)\n"
      },
      "source": "https://raw.githubusercontent.com/bigdataprocessor/bigdataprocessor2/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "<a name=\"bitdepthlink\"></a>Bit-depth conversion",
        "parent_header": [
          "Additional information",
          "More example videos"
        ],
        "type": "Text_excerpt",
        "value": "[<img width=\"300\" alt=\"image\" src=\"./docs/images/4.png\">](https://drive.google.com/open?id=1jRZEepD1C8rM5t2gDi7tYnFh092vUztm)\n"
      },
      "source": "https://raw.githubusercontent.com/bigdataprocessor/bigdataprocessor2/master/README.md",
      "technique": "header_analysis"
    }
  ]
}