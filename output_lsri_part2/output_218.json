{
  "application_domain": [
    {
      "confidence": 27.42,
      "result": {
        "type": "String",
        "value": "Computer Vision"
      },
      "technique": "supervised_classification"
    }
  ],
  "citation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "How to cite",
        "type": "Text_excerpt",
        "value": "```\n@article {\n\tTHINGSdata,\n\tarticle_type = {journal},\n\ttitle = {THINGS-data, a multimodal collection of large-scale datasets for investigating object representations in human brain and behavior},\n\tauthor = {Hebart, Martin N and Contier, Oliver and Teichmann, Lina and Rockter, Adam H and Zheng, Charles Y and Kidder, Alexis and Corriveau, Anna and Vaziri-Pashkam, Maryam and Baker, Chris I},\n\teditor = {Barense, Morgan},\n\tvolume = 12,\n\tyear = 2023,\n\tmonth = {feb},\n\tpub_date = {2023-02-27},\n\tpages = {e82580},\n\tcitation = {eLife 2023;12:e82580},\n\tdoi = {10.7554/eLife.82580},\n\turl = {https://doi.org/10.7554/eLife.82580},\n\tjournal = {eLife},\n\tissn = {2050-084X},\n\tpublisher = {eLife Sciences Publications, Ltd},\n}\n```"
      },
      "source": "https://raw.githubusercontent.com/ViCCo-Group/THINGS-data/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "author": "Hebart, Martin N and Contier, Oliver and Teichmann, Lina and Rockter, Adam H and Zheng, Charles Y and Kidder, Alexis and Corriveau, Anna and Vaziri-Pashkam, Maryam and Baker, Chris I",
        "doi": "10.7554/eLife.82580",
        "format": "bibtex",
        "title": "THINGS-data, a multimodal collection of large-scale datasets for investigating object representations in human brain and behavior",
        "type": "Text_excerpt",
        "url": "https://doi.org/10.7554/eLife.82580",
        "value": "@article{THINGSdata,\n    publisher = {eLife Sciences Publications, Ltd},\n    issn = {2050-084X},\n    journal = {eLife},\n    url = {https://doi.org/10.7554/eLife.82580},\n    doi = {10.7554/eLife.82580},\n    citation = {eLife 2023;12:e82580},\n    pages = {e82580},\n    pub_date = {2023-02-27},\n    month = {feb},\n    year = {2023},\n    volume = {12},\n    editor = {Barense, Morgan},\n    author = {Hebart, Martin N and Contier, Oliver and Teichmann, Lina and Rockter, Adam H and Zheng, Charles Y and Kidder, Alexis and Corriveau, Anna and Vaziri-Pashkam, Maryam and Baker, Chris I},\n    title = {THINGS-data, a multimodal collection of large-scale datasets for investigating object representations in human brain and behavior},\n    article_type = {journal},\n}"
      },
      "source": "https://raw.githubusercontent.com/ViCCo-Group/THINGS-data/main/README.md",
      "technique": "regular_expression"
    }
  ],
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/ViCCo-Group/THINGS-data"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2022-11-07T13:12:52Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2024-09-19T05:46:44Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "THINGS-data: A multimodal collection of large-scale datasets for investigating object representations in brain and behavior"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 0.9991667917320722,
      "result": {
        "original_header": "THINGS-data",
        "type": "Text_excerpt",
        "value": "[THINGS-data](https://elifesciences.org/articles/82580) is a collection of large-scale datasets for the study of natural object representations in brain and behavior. It includes functional magnetic resonance imaging (fMRI) data, magnetoencephalographic (MEG) recordings, and 4.70 million similarity judgments in response to thousands of images from the [THINGS object concept and image database](https://doi.org/10.1371/journal.pone.0223792).\n \n"
      },
      "source": "https://raw.githubusercontent.com/ViCCo-Group/THINGS-data/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9845155895889652,
      "result": {
        "original_header": "Code Repositories",
        "type": "Text_excerpt",
        "value": "This repository the scripts and notebooks for reproducing the neuroimaging analyses presented in the [THINGS-data paper](https://elifesciences.org/articles/82580). It is structured into two sub-folders reflecting the two neuroimaging data modalities: \n- [MRI](MRI)\n- [MEG](MEG) \n"
      },
      "source": "https://raw.githubusercontent.com/ViCCo-Group/THINGS-data/main/README.md",
      "technique": "supervised_classification"
    }
  ],
  "download": [
    {
      "confidence": 1,
      "result": {
        "original_header": "figshare",
        "parent_header": [
          "Download"
        ],
        "type": "Text_excerpt",
        "value": "THINGS-data is hosted as a collection of data objects on figshare. \n\n> \ud83d\udd17 THINGS-data on FigShare\n> \n> [https://doi.org/10.25452/figshare.plus.c.6161151](https://doi.org/10.25452/figshare.plus.c.6161151)\n\nBesides the raw data, this collection includes a data derivatives such as preprocessed versions of both the fMRI and MEG data. Additional derivatives for the fMRI data include single trial response estimates, cortical surface maps, noise ceiling estimates, and regions of interest.\n\nYou can browse the collection and download individual parts which are relevant for your research.\n\nFor smaller files, you can simply click the `Download` button!\n![](assets/download_button.png)\n\nIf you plan to download larger data objects, it might make sense to start this process in the command line. Simply right-click on the `Download`` button and copy the link address. Executing the following code in the command line to begin the download process for that file. \n```\n# This link downloads the fMRI single trial responses\nwget -O betas_csv.zip https://plus.figshare.com/ndownloader/files/36789690\n```\nSince downloading larger data object may take some time, it can make sense to run this process in the background with tools such as `screen` or `tmux`.\n\n"
      },
      "source": "https://raw.githubusercontent.com/ViCCo-Group/THINGS-data/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "OpenNeuro",
        "parent_header": [
          "Download"
        ],
        "type": "Text_excerpt",
        "value": "The raw fMRI and MEG datasets are available on [OpenNeuro](https://openneuro.org). \n\n> \ud83d\udd17 THINGS-data on OpenNeuro\n> \n> - MRI: [https://openneuro.org/datasets/ds004192](https://openneuro.org/datasets/ds004192)\n> - MEG: [https://openneuro.org/datasets/ds004212](https://openneuro.org/datasets/ds004212)\n\nThe official [documentation](https://docs.openneuro.org/user-guide) gives helpful explanations on how to download data from OpenNeuro.\n\n"
      },
      "source": "https://raw.githubusercontent.com/ViCCo-Group/THINGS-data/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "OSF",
        "parent_header": [
          "Download"
        ],
        "type": "Text_excerpt",
        "value": "The behavioral dataset containing 4.7 million human similarity judgements is available on OSF and can be downloaded directly via your web browser.\n\n> \ud83d\udd17 THINGS-data on OSF\n> \n> [osf.io/f5rn6/](https://osf.io/f5rn6/)\n\n"
      },
      "source": "https://raw.githubusercontent.com/ViCCo-Group/THINGS-data/main/README.md",
      "technique": "header_analysis"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/ViCCo-Group/THINGS-data/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "executable_example": [
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/ViCCo-Group/THINGS-data/main/MRI/notebooks/working_with_rois.ipynb"
      },
      "source": "https://raw.githubusercontent.com/ViCCo-Group/THINGS-data/main/MRI/notebooks/working_with_rois.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/ViCCo-Group/THINGS-data/main/MRI/notebooks/fmri_usage.ipynb"
      },
      "source": "https://raw.githubusercontent.com/ViCCo-Group/THINGS-data/main/MRI/notebooks/fmri_usage.ipynb",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "jupyter_notebook",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/ViCCo-Group/THINGS-data/main/MRI/notebooks/animacy_size.ipynb"
      },
      "source": "https://raw.githubusercontent.com/ViCCo-Group/THINGS-data/main/MRI/notebooks/animacy_size.ipynb",
      "technique": "file_exploration"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 6
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/ViCCo-Group/THINGS-data/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "ViCCo-Group/THINGS-data"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "THINGS-data"
      },
      "source": "https://raw.githubusercontent.com/ViCCo-Group/THINGS-data/main/README.md",
      "technique": "regular_expression"
    }
  ],
  "has_script_file": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/ViCCo-Group/THINGS-data/main/MEG/swarm50_imagewisedecoding.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/ViCCo-Group/THINGS-data/main/MEG/swarm100_categorywise_decoding.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/ViCCo-Group/THINGS-data/main/MRI/scripts/run_fmriprep.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/ViCCo-Group/THINGS-data/main/MRI/scripts/reconall.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/ViCCo-Group/THINGS-data/main/MRI/scripts/neurodocker.sh"
      },
      "technique": "file_exploration"
    }
  ],
  "images": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/ViCCo-Group/THINGS-data/main/assets/download_button.png"
      },
      "source": "https://raw.githubusercontent.com/ViCCo-Group/THINGS-data/main/README.md",
      "technique": "regular_expression"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/ViCCo-Group/THINGS-data/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ""
      },
      "technique": "GitHub_API"
    }
  ],
  "license": [
    {
      "confidence": 1,
      "result": {
        "name": "Creative Commons Zero v1.0 Universal",
        "spdx_id": "CC0-1.0",
        "type": "License",
        "url": "https://api.github.com/licenses/cc0-1.0",
        "value": "https://api.github.com/licenses/cc0-1.0"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "type": "File_dump",
        "value": "Creative Commons Legal Code\n\nCC0 1.0 Universal\n\n    CREATIVE COMMONS CORPORATION IS NOT A LAW FIRM AND DOES NOT PROVIDE\n    LEGAL SERVICES. DISTRIBUTION OF THIS DOCUMENT DOES NOT CREATE AN\n    ATTORNEY-CLIENT RELATIONSHIP. CREATIVE COMMONS PROVIDES THIS\n    INFORMATION ON AN \"AS-IS\" BASIS. CREATIVE COMMONS MAKES NO WARRANTIES\n    REGARDING THE USE OF THIS DOCUMENT OR THE INFORMATION OR WORKS\n    PROVIDED HEREUNDER, AND DISCLAIMS LIABILITY FOR DAMAGES RESULTING FROM\n    THE USE OF THIS DOCUMENT OR THE INFORMATION OR WORKS PROVIDED\n    HEREUNDER.\n\nStatement of Purpose\n\nThe laws of most jurisdictions throughout the world automatically confer\nexclusive Copyright and Related Rights (defined below) upon the creator\nand subsequent owner(s) (each and all, an \"owner\") of an original work of\nauthorship and/or a database (each, a \"Work\").\n\nCertain owners wish to permanently relinquish those rights to a Work for\nthe purpose of contributing to a commons of creative, cultural and\nscientific works (\"Commons\") that the public can reliably and without fear\nof later claims of infringement build upon, modify, incorporate in other\nworks, reuse and redistribute as freely as possible in any form whatsoever\nand for any purposes, including without limitation commercial purposes.\nThese owners may contribute to the Commons to promote the ideal of a free\nculture and the further production of creative, cultural and scientific\nworks, or to gain reputation or greater distribution for their Work in\npart through the use and efforts of others.\n\nFor these and/or other purposes and motivations, and without any\nexpectation of additional consideration or compensation, the person\nassociating CC0 with a Work (the \"Affirmer\"), to the extent that he or she\nis an owner of Copyright and Related Rights in the Work, voluntarily\nelects to apply CC0 to the Work and publicly distribute the Work under its\nterms, with knowledge of his or her Copyright and Related Rights in the\nWork and the meaning and intended legal effect of CC0 on those rights.\n\n1. Copyright and Related Rights. A Work made available under CC0 may be\nprotected by copyright and related or neighboring rights (\"Copyright and\nRelated Rights\"). Copyright and Related Rights include, but are not\nlimited to, the following:\n\n  i. the right to reproduce, adapt, distribute, perform, display,\n     communicate, and translate a Work;\n ii. moral rights retained by the original author(s) and/or performer(s);\niii. publicity and privacy rights pertaining to a person's image or\n     likeness depicted in a Work;\n iv. rights protecting against unfair competition in regards to a Work,\n     subject to the limitations in paragraph 4(a), below;\n  v. rights protecting the extraction, dissemination, use and reuse of data\n     in a Work;\n vi. database rights (such as those arising under Directive 96/9/EC of the\n     European Parliament and of the Council of 11 March 1996 on the legal\n     protection of databases, and under any national implementation\n     thereof, including any amended or successor version of such\n     directive); and\nvii. other similar, equivalent or corresponding rights throughout the\n     world based on applicable law or treaty, and any national\n     implementations thereof.\n\n2. Waiver. To the greatest extent permitted by, but not in contravention\nof, applicable law, Affirmer hereby overtly, fully, permanently,\nirrevocably and unconditionally waives, abandons, and surrenders all of\nAffirmer's Copyright and Related Rights and associated claims and causes\nof action, whether now known or unknown (including existing as well as\nfuture claims and causes of action), in the Work (i) in all territories\nworldwide, (ii) for the maximum duration provided by applicable law or\ntreaty (including future time extensions), (iii) in any current or future\nmedium and for any number of copies, and (iv) for any purpose whatsoever,\nincluding without limitation commercial, advertising or promotional\npurposes (the \"Waiver\"). Affirmer makes the Waiver for the benefit of each\nmember of the public at large and to the detriment of Affirmer's heirs and\nsuccessors, fully intending that such Waiver shall not be subject to\nrevocation, rescission, cancellation, termination, or any other legal or\nequitable action to disrupt the quiet enjoyment of the Work by the public\nas contemplated by Affirmer's express Statement of Purpose.\n\n3. Public License Fallback. Should any part of the Waiver for any reason\nbe judged legally invalid or ineffective under applicable law, then the\nWaiver shall be preserved to the maximum extent permitted taking into\naccount Affirmer's express Statement of Purpose. In addition, to the\nextent the Waiver is so judged Affirmer hereby grants to each affected\nperson a royalty-free, non transferable, non sublicensable, non exclusive,\nirrevocable and unconditional license to exercise Affirmer's Copyright and\nRelated Rights in the Work (i) in all territories worldwide, (ii) for the\nmaximum duration provided by applicable law or treaty (including future\ntime extensions), (iii) in any current or future medium and for any number\nof copies, and (iv) for any purpose whatsoever, including without\nlimitation commercial, advertising or promotional purposes (the\n\"License\"). The License shall be deemed effective as of the date CC0 was\napplied by Affirmer to the Work. Should any part of the License for any\nreason be judged legally invalid or ineffective under applicable law, such\npartial invalidity or ineffectiveness shall not invalidate the remainder\nof the License, and in such case Affirmer hereby affirms that he or she\nwill not (i) exercise any of his or her remaining Copyright and Related\nRights in the Work or (ii) assert any associated claims and causes of\naction with respect to the Work, in either case contrary to Affirmer's\nexpress Statement of Purpose.\n\n4. Limitations and Disclaimers.\n\n a. No trademark or patent rights held by Affirmer are waived, abandoned,\n    surrendered, licensed or otherwise affected by this document.\n b. Affirmer offers the Work as-is and makes no representations or\n    warranties of any kind concerning the Work, express, implied,\n    statutory or otherwise, including without limitation warranties of\n    title, merchantability, fitness for a particular purpose, non\n    infringement, or the absence of latent or other defects, accuracy, or\n    the present or absence of errors, whether or not discoverable, all to\n    the greatest extent permissible under applicable law.\n c. Affirmer disclaims responsibility for clearing rights of other persons\n    that may apply to the Work or any use thereof, including without\n    limitation any person's Copyright and Related Rights in the Work.\n    Further, Affirmer disclaims responsibility for obtaining any necessary\n    consents, permissions or other rights required for any use of the\n    Work.\n d. Affirmer understands and acknowledges that Creative Commons is not a\n    party to this document and has no duty or obligation with respect to\n    this CC0 or use of the Work.\n"
      },
      "source": "https://raw.githubusercontent.com/ViCCo-Group/THINGS-data/main/LICENSE",
      "technique": "file_exploration"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "THINGS-data"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "Organization",
        "value": "ViCCo-Group"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Jupyter Notebook",
        "size": 1182788,
        "type": "Programming_language",
        "value": "Jupyter Notebook"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 236602,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Shell",
        "size": 139501,
        "type": "Programming_language",
        "value": "Shell"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "MATLAB",
        "size": 40601,
        "type": "Programming_language",
        "value": "MATLAB"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/ViCCo-Group/THINGS-data/main/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "somef_missing_categories": [
    "installation",
    "acknowledgement",
    "run",
    "requirements",
    "contact",
    "contributors",
    "documentation",
    "usage",
    "faq",
    "support",
    "identifier",
    "has_build_file"
  ],
  "somef_provenance": {
    "date": "2024-10-04 09:49:09",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 39
      },
      "technique": "GitHub_API"
    }
  ],
  "type": [
    {
      "confidence": 0.82,
      "result": {
        "type": "String",
        "value": "commandline-application"
      },
      "technique": "software_type_heuristics"
    }
  ]
}