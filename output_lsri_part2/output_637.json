{
  "acknowledgement": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Acknowledgement",
        "parent_header": [
          "NDNet"
        ],
        "type": "Text_excerpt",
        "value": "HRNet-Semantic-Segmentation <https://github.com/HRNet/HRNet-Semantic-Segmentation>\n"
      },
      "source": "https://raw.githubusercontent.com/LiShuTJ/NDNet/main/README.md",
      "technique": "header_analysis"
    }
  ],
  "application_domain": [
    {
      "confidence": 69.23,
      "result": {
        "type": "String",
        "value": "Computer Vision"
      },
      "technique": "supervised_classification"
    }
  ],
  "citation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Citation",
        "parent_header": [
          "NDNet"
        ],
        "type": "Text_excerpt",
        "value": "If you find our work useful, please consider citing our paper:\n\n```\n@ARTICLE{li2022ndnet,\n  author={Li, Shu and Yan, Qingqing and Zhou, Xun and Wang, Deming and Liu, Chengju and Chen, Qijun},\n  journal={IEEE Transactions on Neural Networks and Learning Systems}, \n  title={NDNet: Spacewise Multiscale Representation Learning via Neighbor Decoupling for Real-Time Driving Scene Parsing}, \n  year={2022}\n  doi={10.1109/TNNLS.2022.3221745}}\n```\n"
      },
      "source": "https://raw.githubusercontent.com/LiShuTJ/NDNet/main/README.md",
      "technique": "header_analysis"
    }
  ],
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/LiShuTJ/NDNet"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2022-08-25T12:26:07Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2024-03-06T06:15:19Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 0.9956282956584247,
      "result": {
        "original_header": "NDNet",
        "type": "Text_excerpt",
        "value": "> This is the  official implementation of \"NDNet: Space-wise Multiscale Representation Learning via Neighbor Decoupling for Real-time Driving Scene Parsing\" (PyTorch)\n> IEEE Transactions on Neural Networks and Learning Systems\n \n"
      },
      "source": "https://raw.githubusercontent.com/LiShuTJ/NDNet/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.950023970995786,
      "result": {
        "original_header": "NOTICE: This repo is still under construction",
        "type": "Text_excerpt",
        "value": "- [x] Implementation of paper models\n- [x] Training code\n- [x] Speed measurement \n- [x] Pretrained weights on ImageNet and Cityscapes\n    - [x] Pretrained weights on ImageNet\n    - [x] Pretrained weights on Cityscapes\n- [x] TensorRT implementation\n- [x] Prediction code\n \n"
      },
      "source": "https://raw.githubusercontent.com/LiShuTJ/NDNet/main/README.md",
      "technique": "supervised_classification"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/LiShuTJ/NDNet/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 0
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/LiShuTJ/NDNet/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "LiShuTJ/NDNet"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "NDNet"
      },
      "source": "https://raw.githubusercontent.com/LiShuTJ/NDNet/main/README.md",
      "technique": "regular_expression"
    }
  ],
  "installation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Install",
        "parent_header": [
          "NDNet"
        ],
        "type": "Text_excerpt",
        "value": "You can install all dependencies (without TensorRT) by:\n```\npip install -r requirement.txt\n```\n\nFor TensorRT installation, please refer to [official installation guide](https://docs.nvidia.com/deeplearning/tensorrt/install-guide/index.html).\n"
      },
      "source": "https://raw.githubusercontent.com/LiShuTJ/NDNet/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 0.822618910441788,
      "result": {
        "original_header": "Speed Measurement (Pytorch not TRT)",
        "type": "Text_excerpt",
        "value": "Run the following commond and you'll see the model statistics and the inference speed on your mechine:\n```\npython tools/speedMeasure.py --cfg experiments/cityscapes/ndnet_res18.yaml\n```\n \n"
      },
      "source": "https://raw.githubusercontent.com/LiShuTJ/NDNet/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9972570118458172,
      "result": {
        "original_header": "Validation/Testing",
        "type": "Text_excerpt",
        "value": "2. Using the `test.py` script (check the DATASET.TEST_SET path and TEST.MODEL_FILE path carefully):\n   ```\n   python tools/test.py --cfg experiments/cityscapes/ndnet_df1_test.yaml\n   ```\n \n"
      },
      "source": "https://raw.githubusercontent.com/LiShuTJ/NDNet/main/README.md",
      "technique": "supervised_classification"
    }
  ],
  "invocation": [
    {
      "confidence": 0.8693767246531405,
      "result": {
        "original_header": "Training",
        "type": "Text_excerpt",
        "value": "1. Download the pretrained weights, and put it under `pretrained_models` (or modify the `MODEL.PRETRAINED` path in the cfg file).\n   \n   | Model | Top 1 Acc. | Link |\n   | :----: | :----:  | :----: |\n   | NDNet-DF1   | 70.86 | [model (code: l27o)](https://pan.baidu.com/s/1vvjtUmz5QcS61onunO8gqw) |\n   | NDNet-DF2   | 75.56 | [model (code: nl59)](https://pan.baidu.com/s/1hbDVb2leNrNc7W5Jtl2edQ) |\n   | NDNet-Res18 | 72.16 | [model (code: uel1)](https://pan.baidu.com/s/1DbPaxKED_S_0QnwYEec2ZA) |\n   | NDNet-Res34 | 76.97 | [model (code: 0pss)](https://pan.baidu.com/s/1h44wjl9-_oJ-9ZzHnUdMnQ ) | \n\n2. For multi-GPU training, taking NDNet-DF1 as an example, type:\n   ```\n   python -m torch.distributed.launch --nproc_per_node=4 tools/train.py --cfg experiments/cityscapes/ndnet_df1.yaml\n   ```\n \n"
      },
      "source": "https://raw.githubusercontent.com/LiShuTJ/NDNet/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9181710318642393,
      "result": {
        "original_header": "Validation/Testing",
        "type": "Text_excerpt",
        "value": "1. Train the model, or download the Cityscapes pretrained weights.\n   | Model | Test MIoU | Link |\n   | :----: | :----:  | :----: |\n   | NDNet-DF1   | 75.5 | [model (code: h8nx)](https://pan.baidu.com/s/1ihWD4l9FOXzKzrVn3DFiyg) |\n   | NDNet-DF2   | 77.0 | [model (code: 002a)](https://pan.baidu.com/s/1hOQecVXspbSvZIXO273SKw) |\n   | NDNet-Res18 | 76.5 | [model (code: f9je)](https://pan.baidu.com/s/1O-7wWbQ_4O1ZROdrULeR2A) |\n   | NDNet-Res34 | 78.8 | [model (code: 1tsc)](https://pan.baidu.com/s/1D34hLWqJlYwemRQOfqmm6Q) | \n2. Using the `test.py` script (check the DATASET.TEST_SET path and TEST.MODEL_FILE path carefully):\n   ```\n   python tools/test.py --cfg experiments/cityscapes/ndnet_df1_test.yaml\n   ```\n \n"
      },
      "source": "https://raw.githubusercontent.com/LiShuTJ/NDNet/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.88068794414464,
      "result": {
        "original_header": "Predict an Image",
        "type": "Text_excerpt",
        "value": "1. Download the Cityscapes pretrained weights. \n2. Using the `tools/predict.py` script (check the TEST.MODEL_FILE path carefully):\n   ```\n   python tools/predict.py --cfg experiments/cityscapes/ndnet_df1_test.yaml \\\n                           --img_path images/1.png \\\n                           --save_path predict.png \\\n                           TEST.MODEL_FILE pretrained_models/NDNet_DF1_Cityscapes.pth\n   ```\n \n"
      },
      "source": "https://raw.githubusercontent.com/LiShuTJ/NDNet/main/README.md",
      "technique": "supervised_classification"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/LiShuTJ/NDNet/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ""
      },
      "technique": "GitHub_API"
    }
  ],
  "license": [
    {
      "confidence": 1,
      "result": {
        "name": "Other",
        "spdx_id": "NOASSERTION",
        "type": "License",
        "url": null,
        "value": null
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "type": "File_dump",
        "value": "MIT License\n\nCopyright (c) [2019] [Microsoft]\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n\n=======================================================================================\n3-clause BSD licenses\n=======================================================================================\n1. syncbn - For details, see lib/models/syncbn/LICENSE\n         Copyright (c) 2017 mapillary\n"
      },
      "source": "https://raw.githubusercontent.com/LiShuTJ/NDNet/main/LICENSE",
      "technique": "file_exploration"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "NDNet"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "User",
        "value": "LiShuTJ"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 121197,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Cuda",
        "size": 9966,
        "type": "Programming_language",
        "value": "Cuda"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "C++",
        "size": 9883,
        "type": "Programming_language",
        "value": "C++"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/LiShuTJ/NDNet/main/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "somef_missing_categories": [
    "run",
    "download",
    "requirements",
    "contact",
    "contributors",
    "documentation",
    "usage",
    "faq",
    "identifier",
    "has_build_file",
    "executable_example"
  ],
  "somef_provenance": {
    "date": "2024-10-04 11:26:59",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 4
      },
      "technique": "GitHub_API"
    }
  ],
  "support": [
    {
      "confidence": 1,
      "result": {
        "original_header": "TensorRT Support",
        "parent_header": [
          "NDNet"
        ],
        "type": "Text_excerpt",
        "value": "There are two ways to convert a trained model into trt engine.\n\n1. Export to ONNX, and run `trtexec`:\n   ```\n   1. python tools/exportONNX.py --cfg experiments/cityscapes/ndnet_res18.yaml\n   2. trtexec --onnx=NDNet_Res18.onnx --saveEngine=NDNet_Res18.engine\n   ```\n   > Tips: Running the above may reproduce the speed result in out paper. If you want faster speed (lower precision), you may enable the `--fp16`, `--int8` or `--best` flag in the `trtexec` command.\n2. Using [PyTorch-TensorRT](https://www.runoob.com) \n   ```\n   # TODO\n   ```\n"
      },
      "source": "https://raw.githubusercontent.com/LiShuTJ/NDNet/main/README.md",
      "technique": "header_analysis"
    }
  ]
}