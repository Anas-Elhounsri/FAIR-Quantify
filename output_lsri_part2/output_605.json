{
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/harmancilab/XCVATR"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2020-11-12T04:40:29Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2022-12-28T22:04:39Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 0.9986510953525267,
      "result": {
        "original_header": "XCVATR:",
        "type": "Text_excerpt",
        "value": "This repository contains the source code and documentation for XCVATR -- Detection of variant clumps in embeddings.\n \n"
      },
      "source": "https://raw.githubusercontent.com/harmancilab/XCVATR/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9748923111248986,
      "result": {
        "original_header": "Read mapping and filtering",
        "type": "Text_excerpt",
        "value": "In order to provide a complete processing pipeline, XCVATR includes \"scripts/map_filter_dedup_reads.sh\" can be used to map bulk RNA sequences. By default, XCVATR uses hisat2 for read mapping. This script can be used to remove reads that overlap with repeats, and for deduplication using samtools.\n \n"
      },
      "source": "https://raw.githubusercontent.com/harmancilab/XCVATR/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.867367507748627,
      "result": {
        "original_header": "Embedding based on Gene Expression Matrix",
        "type": "Text_excerpt",
        "value": "XCVATR can be used to generate embeddings for bulk and single cell RNA-seq datasets. It should be noted that the embedding coordinates or distance matrices can be supplied externally by the user. These are implemented as R scripts that can be found under \"scripts/Dimensionality_Reduction\". There are two scripts that can be used to generate tSNE-based embeddings.\n \n"
      },
      "source": "https://raw.githubusercontent.com/harmancilab/XCVATR/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.952301864463247,
      "result": {
        "original_header": "COSMIC Level Analysis and Visualization of Variants",
        "type": "Text_excerpt",
        "value": "XCVATR can be used to pool the detected variants in COSMIC catalogue and visualize the collective effect of these variants. \nTo perform COSMIC-level pooling analysis, we first get the variants that overlap with COSMIC variants and generate an expressed variant fraction for each cell:\n```\n./XCVATR_SC_SNV_Indel_Pipeline.sh -get_cosmic_variants\n./XCVATR_SC_SNV_Indel_Pipeline.sh -pool_COSMIC_variants_per_var_count cosmic_selected_snvs.txt ANNOTATED 5 0.2\n``` \n"
      },
      "source": "https://raw.githubusercontent.com/harmancilab/XCVATR/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/harmancilab/XCVATR/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 0
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/harmancilab/XCVATR/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "harmancilab/XCVATR"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "XCVATR:"
      },
      "source": "https://raw.githubusercontent.com/harmancilab/XCVATR/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "has_script_file": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/harmancilab/XCVATR/master/scripts/XCVATR_CNV_Pipeline.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/harmancilab/XCVATR/master/scripts/map_filter_dedup_reads.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/harmancilab/XCVATR/master/scripts/XCVATR_SC_SNV_Indel_Pipeline.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/harmancilab/XCVATR/master/scripts/XCVATR_Bulk_SNV_Indel_Pipeline.sh"
      },
      "technique": "file_exploration"
    }
  ],
  "installation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Setting up Files and Datasets",
        "parent_header": [
          "XCVATR:"
        ],
        "type": "Text_excerpt",
        "value": "XCVATR makes use of numerous data sources. There is nothing needed to be done after downloading the directory.\n\n\"-init_files\" option of XCVATR scripts checks for existing of the data files, downloads some files and writes important scripts. This option needs to be run when the directory structure is changed.\n"
      },
      "source": "https://raw.githubusercontent.com/harmancilab/XCVATR/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Setup the data_config.params file",
        "parent_header": [
          "XCVATR:"
        ],
        "type": "Text_excerpt",
        "value": "XCVATR depends on setting up the input files in a file named \"data_config.params\", where the data options are. There are examples of the configuration file under example folder.\n"
      },
      "source": "https://raw.githubusercontent.com/harmancilab/XCVATR/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 0.9999588209029057,
      "result": {
        "original_header": "Build",
        "type": "Text_excerpt",
        "value": "Run following commands to build XCVATR:\n```\nmake clean\nmake\n``` \nXCVATR makes use of \"samtools\" for processing bam files. It is necessary to install samtools:\n```\nwget https://sourceforge.net/projects/samtools/files/latest/download?source=files\ntar -xvjf \"download?source=files\"\nsamtools_dir=`find . -name 'samtools-*' | xargs -Ifiles basename files`\ncd ${samtools_dir}\n./configure --without-curses --disable-lzma\nmake clean\nmake\nmake install\n```\n \n"
      },
      "source": "https://raw.githubusercontent.com/harmancilab/XCVATR/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9999075816616524,
      "result": {
        "original_header": "COSMIC Level Analysis and Visualization of Variants",
        "type": "Text_excerpt",
        "value": "Finally, these can be visualized using R scripts:\n```\n# Integrate the visualization scripts.\ngzip SMOOTHED_AFs/*.txt\n\nsource data_config.params\nfor cur_smoothed_AF in SMOOTHED_AFs/scale_*_smoothed_AF_counts.txt.gz\ndo\n        ./visualize_smoothed_AFs_CLI.R $TSNE_COORDS_FP ${cur_smoothed_AF}\n        mv smoothed_AFs.pdf ${cur_smoothed_AF}.pdf\ndone\n``` \n"
      },
      "source": "https://raw.githubusercontent.com/harmancilab/XCVATR/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 1.0,
      "result": {
        "original_header": "Visualization",
        "type": "Text_excerpt",
        "value": "Visualization makes use of the R scripts that are located under \"Visualization_CLI/\" directory. Note that it is necessary to have \"Rscript\" to be installed in the path of the user. Also, there are several packages that are necessary for visualizing datasets. These popular packages can be installed using:\n```\ninstall.packages(ggplot2);\ninstall.packages('gridExtra');\ninstall.packages('ggforce')\ninstall.packages(stringr);\ninstall.packages(RColorBrewer);\n```\nAfter installing packages, we decompress the counts file and\n```\n./visualize_expressed_SNV_Indel_embeddings_CLI.R EMBEDDING/GBM_TSNE.csv.tsv_fixed_sample_ids.tsv_BT_S2_SRR_ID_remapped.tsv filtered_summarized_vars.txt ALLELIC_COUNT/final_counts.txt.gz NONE\n```\nAfter the script executes successfully, the visualizations are stored in a pdf file named \"embedding_SNV_Indel_AFs.pdf\".\n \n"
      },
      "source": "https://raw.githubusercontent.com/harmancilab/XCVATR/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/harmancilab/XCVATR/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ""
      },
      "technique": "GitHub_API"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "XCVATR"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "User",
        "value": "harmancilab"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "C++",
        "size": 1725765,
        "type": "Programming_language",
        "value": "C++"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Shell",
        "size": 102907,
        "type": "Programming_language",
        "value": "Shell"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "R",
        "size": 48459,
        "type": "Programming_language",
        "value": "R"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "C",
        "size": 6521,
        "type": "Programming_language",
        "value": "C"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Makefile",
        "size": 1136,
        "type": "Programming_language",
        "value": "Makefile"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/harmancilab/XCVATR/master/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "somef_missing_categories": [
    "citation",
    "acknowledgement",
    "run",
    "download",
    "requirements",
    "contact",
    "contributors",
    "documentation",
    "license",
    "faq",
    "identifier",
    "has_build_file",
    "executable_example"
  ],
  "somef_provenance": {
    "date": "2024-10-04 11:20:12",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 1
      },
      "technique": "GitHub_API"
    }
  ],
  "support": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Pileup Generation and Indel Supporting Read Extraction",
        "parent_header": [
          "XCVATR:",
          "Example: Darmanis et al. 2016"
        ],
        "type": "Text_excerpt",
        "value": "Next step is generation of the stranded pileups for detecting SNVs and indels.\n```\nmin_mapq=20\nmin_phred=0\n\n./XCVATR_SC_SNV_Indel_Pipeline.sh -generate_pileups $min_mapq $min_phred\n```\nThis command uses the reads with mapping quality greater than 20 to build strand specific pileups.\n\nAfter building the pileups, we identify the indel supporting reads with quality cutoffs using the same mapping quality for the reads:\n```\nmin_mapq=20\n./XCVATR_SC_SNV_Indel_Pipeline.sh -parse_indel_blocks $min_mapq\n```\n"
      },
      "source": "https://raw.githubusercontent.com/harmancilab/XCVATR/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "usage": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Example: Darmanis et al. 2016",
        "parent_header": [
          "XCVATR:"
        ],
        "type": "Text_excerpt",
        "value": "We generated an example file from chromosome 17 of the Darmanis et al. 2016 study. The example data can be downloaded from [here](https://drive.google.com/file/d/17dqwz0rPVl2swJbn-Cd6SzMXbG2p0dKk/view?usp=sharing). \n\nThis file contains the bam file that is used to identify variants and score clumps. The complete workflow is implemented under the script named RUN_EXAMPLE.sh. We also provide an example \"data_config.params\" file that needs to be set before running XCVATR.\n\nWe go over the commands to perform the clump analysis and visualization. For this analysis, we use the \"XCVATR_SC_SNV_Indel_Pipeline.sh\" script under \"scripts/\" directory.\n"
      },
      "source": "https://raw.githubusercontent.com/harmancilab/XCVATR/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Data Initialization",
        "parent_header": [
          "XCVATR:",
          "Example: Darmanis et al. 2016"
        ],
        "type": "Text_excerpt",
        "value": "For initializing the data files and checking existence of files:\n\n```\n./XCVATR_SC_SNV_Indel_Pipeline.sh -init_files\n```\n"
      },
      "source": "https://raw.githubusercontent.com/harmancilab/XCVATR/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "SNV/Indel Detection",
        "parent_header": [
          "XCVATR:",
          "Example: Darmanis et al. 2016"
        ],
        "type": "Text_excerpt",
        "value": "Next step is detection of SNVs and Indels\n```\nmax_strand_discordance=1.5\n\nmin_covg=10\nmin_alt_covg=4\nmin_alt_freq=0.2\nmax_strand_imbalance=${max_strand_discordance}\n\n./XCVATR_SC_SNV_Indel_Pipeline.sh -call_snvs ${min_covg} ${min_alt_covg} ${min_alt_freq} ${max_strand_imbalance}\n```\nThis command identifies SNVs that show at least 10 reads coverage, and 4 reads of alternate alleles and an alternate read allele frequency of 0.2. Also, XCVATR enforces a maximum strand balance between the forward/reverse strand reads at a fraction of 1.5. Note that for stranded RNA-seq reads, this value should be set to a high value.\n\nNext step is scanning the indels:\n```\t\nmax_strand_discordance=1.5\n\nmin_covg=10\nmin_alt_covg=4\nmin_alt_freq=0.2\nmax_strand_imbalance=${max_strand_discordance}\n\n./XCVATR_SC_SNV_Indel_Pipeline.sh -scan_indels ${min_covg} ${min_alt_covg} ${min_alt_freq} ${max_strand_imbalance}\n```\n"
      },
      "source": "https://raw.githubusercontent.com/harmancilab/XCVATR/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Per Cell Allele Count Matrix",
        "parent_header": [
          "XCVATR:",
          "Example: Darmanis et al. 2016"
        ],
        "type": "Text_excerpt",
        "value": "Following step is counting the reads for each cell on each variant:\n```\n./XCVATR_SC_SNV_Indel_Pipeline.sh -count_allelic_reads_per_variant ${min_mapq}\t\n```\nThis command generates the read count matrix. The commands are separated for each chromosome independently so that they can be run in parallel. For submitting the jobs in parallel, simply run the script named \"./q_count_submission_script.csh\". This script is automatically written by XCVATR. This script can also be used to run the commands on a cluster such as PBS/Torque or slurm-based clusters.\n"
      },
      "source": "https://raw.githubusercontent.com/harmancilab/XCVATR/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Variant Annotation",
        "parent_header": [
          "XCVATR:",
          "Example: Darmanis et al. 2016"
        ],
        "type": "Text_excerpt",
        "value": "XCVATR annotates the allele count matrices directly. For this we run following:\n```\n./XCVATR_SC_SNV_Indel_Pipeline.sh -annotate_variants\n```\nThis command writes the per-chromosome scripts for variant annotation. \n"
      },
      "source": "https://raw.githubusercontent.com/harmancilab/XCVATR/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "dbSNP frequency-based variant filtering",
        "parent_header": [
          "XCVATR:",
          "Example: Darmanis et al. 2016"
        ],
        "type": "Text_excerpt",
        "value": "The next steps are the filtering of the variants. dbSNP-based filtering can provide information for the most impactful mutations. It is not necessary to perform these steps if variant-based analysis is performed.\n```\nmin_MAF=0.05\n./XCVATR_SC_SNV_Indel_Pipeline.sh -filter_variants_per_dbSNP_freq $min_MAF\n```\n"
      },
      "source": "https://raw.githubusercontent.com/harmancilab/XCVATR/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Impact-based variant filtering",
        "parent_header": [
          "XCVATR:",
          "Example: Darmanis et al. 2016"
        ],
        "type": "Text_excerpt",
        "value": "Next, we filter the variants based on their impact. The list of impacts that are stored in the file \"DAMAGING_EFFECTS_LIST_FP\" in data_config.params file is used to filter the variants with impact.\n```\n./XCVATR_SC_SNV_Indel_Pipeline.sh -filter_variants_per_impact\n```\nThe variant impact list file can be changed to select specific set of mutations with specific impact, such as splice-altering mutations.\n"
      },
      "source": "https://raw.githubusercontent.com/harmancilab/XCVATR/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Gene Level Summarization and Pooling of allele count matrices",
        "parent_header": [
          "XCVATR:",
          "Example: Darmanis et al. 2016"
        ],
        "type": "Text_excerpt",
        "value": "Upto this point, XCVATR uses per chromosome variants. Depending on the application, the variants can be summarized on the genes (gene-level analysis) or variant level analysis. For this, we run following:\n```\n./XCVATR_SC_SNV_Indel_Pipeline.sh -gene_level_summarize_variants 5\n```\nThis command summarizes the variants on genes and generates a pooled allele count matrix.\n\nIn order to perform variant-level analysis (without summarizing on genes), we run following command: \n```\n./XCVATR_SC_SNV_Indel_Pipeline.sh -variant_level_pool_variants\n```\n"
      },
      "source": "https://raw.githubusercontent.com/harmancilab/XCVATR/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Scale Selection",
        "parent_header": [
          "XCVATR:",
          "Example: Darmanis et al. 2016"
        ],
        "type": "Text_excerpt",
        "value": "Next, we select the scales for detection of the clumps on the embedding. By default, we use at least 10 cells, with 1% percent of cells and maximum of 10% of cells to identify the minimum and maximum scales:\n```\n./XCVATR_SC_SNV_Indel_Pipeline.sh -get_scales 10 0.01 0.1\n```\nThis command writes a file named \"inv_scales.txt\". This file should not be moved or renamed.\n"
      },
      "source": "https://raw.githubusercontent.com/harmancilab/XCVATR/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Clump Identification and Filtering",
        "parent_header": [
          "XCVATR:",
          "Example: Darmanis et al. 2016"
        ],
        "type": "Text_excerpt",
        "value": "We finally, run XCVATR for clump identification and filtering.\n```\n./XCVATR_SC_SNV_Indel_Pipeline.sh -analyze_allelic_spatial_patterns 5 1000 0.001 1000\n./XCVATR_SC_SNV_Indel_Pipeline.sh -summarize_results 0.0 0.05 5\n```\n\nThis command write scripts for running XCVATR on each scale separately. These can be submitted in parallel or run on a single process. Finally, we summarize and filter out the low quality clumps:\n```\n./XCVATR_SC_SNV_Indel_Pipeline.sh -summarize_results 0.0 0.05 5\n```\n\nNote that the results can be further filtered using the reported set of columns in the file named \"filtered_summarized_vars.txt\". Above command filters out the clumps minimum weighted AF of 0.05 and z-score threshold of 5\n"
      },
      "source": "https://raw.githubusercontent.com/harmancilab/XCVATR/master/README.md",
      "technique": "header_analysis"
    }
  ]
}