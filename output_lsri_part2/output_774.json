{
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/TomMaullin/BLMM"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2019-11-14T12:40:06Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2024-02-08T21:53:29Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "This repository contains all code for the BLMM toolbox."
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 0.991031209319891,
      "result": {
        "original_header": "Pyblmm",
        "type": "Text_excerpt",
        "value": "This repository contains the code for Big Linear Mixed Models for Neuroimaging cluster and local usage.\n \n"
      },
      "source": "https://raw.githubusercontent.com/TomMaullin/BLMM/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8524382589624975,
      "result": {
        "original_header": "Testing",
        "type": "Text_excerpt",
        "value": "Currently, only unit tests are available for `BLMM`. These can be accessed by in the `tests/Unit` folder and must be run from the top of the directory.\n \n"
      },
      "source": "https://raw.githubusercontent.com/TomMaullin/BLMM/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.944492085658327,
      "result": {
        "original_header": "Notation",
        "type": "Text_excerpt",
        "value": "Throughout the code, the following notation is universal. \n - `Y`: The response vector at each voxel.\n - `X`: The fixed effects design matrix.\n - `Z`: The random effects design matrix.\n - `sigma2`: (An estimate of) The fixed effects variance.\n - `beta`: (An estimate of) The fixed effects parameter vector.\n - `D`: (An estimate of) The random effects covariance matrix (in full).\n - `Ddict`: A dictionary containing the unique blocks of `D`. For example, `Ddict[k]` is the block of `D` representing within-factor covariance for the kth random factor. \n - `XtX, XtY, XtZ, YtX, YtY, YtZ, ZtX, ZtY, ZtZ`: These are the product matrices (i.e. X transposed multiplied by X, X transposed multiplied by Y, etc...).\n - `n`: Number of observations/input images.\n - `r`: Number of Random Factors in the design.\n - `q`: Total number of Random Effects (duplicates included), i.e. the second dimension of, Z, the random effects design matrix.\n - `qu`: Total number of unique Random effects (`vech(D_1),...vech(D_r)`).\n - `p`: Number of Fixed Effects parameters in the design.\n - `nraneffs`: A vector containing the number of random effects for each factor, e.g. `nraneffs=[2,1]` would mean the first factor has 2 random effects and the second factor has 1 random effect.\n - `nlevels`: A vector containing the number of levels for each factor, e.g. `nlevels=[3,4]` would mean the first factor has 3 levels and the second factor has 4 levels.\n - `inputs`: A dictionary containing all the inputs from the `blmm_config.yml`.\n - `e`: The residual vector (i.e. `e=Y-X @ beta`)\n - `V`: The matrix `I+ZDZ'` where `I` is the identity matrix.\n - `DinvIplusZtZD`: The matrix `D(I+Z'ZD)^(-1)`. \n - `_sv`: Spatially varying. `a_sv` means we have a value of `a` for every voxel we are considering, or rather, `a` \"varies\" across space.\n - `_i`: \"Inner\" voxels. This refers to the set of voxels which do not have missingness caused by mask variability in their designs. Typically, these make up the vast majority of the brain and tend not to lie near the edge of the brain, hence \"inner\".\n - `_r`: \"Ring\" voxels. This refers to the set of voxels which have missingness caused by mask variability in their designs. Special care must be taken with these voxels as `X` and `Z` are not the same across this set. Typically, these make up a small minority of the brain and tend to lie near the edge of the brain; they look like a \"ring\" around the edge of the brain.\n - `2D`: A function or file with this suffix will contain code designed to work analysis only on one voxel. As `X`,`Y` and `Z` are all 2 dimensional, all arrays considered for one voxel are 2D, hence the suffix.\n - `3D`: A function or file with this suffix will contain code designed to work analysis on multiple voxels. As `X`,`Y` and `Z` are all 3 dimensional (an extra dimension has been added for \"voxel number\"), all arrays considered are 3D, hence the suffix. \nWhen the user has specified 1 random factor and 1 random effect only, the matrices `DinvIplusZtZD` and `ZtZ` become diagonal. As a result of this, in this setting, instead of saving these variable as matrices of dimension `(v,q,q)` (one `(q,q)` matrix for every voxel), we only record the diagonal elements of these matrices. As a result, in this setting `DinvIplusZtZD` and `ZtZ` have dimension `(v,q)` throughout the code. This results in significant performance gains.\n \n"
      },
      "source": "https://raw.githubusercontent.com/TomMaullin/BLMM/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9704831333494345,
      "result": {
        "original_header": "Structure of the repository",
        "type": "Text_excerpt",
        "value": "The repository contains 4 main folders, plus 3 files at the head of the repository. These are:\n- `README.md`: This file.\n- `blmm_config.yml`: A file template for the user to enter their design into.\n- `blmm`: The BLMM package\n  - `blmm_cluster.py`: The python script used to run blmm.\n  - `blmm_compare.sh`: The shell script used to run blmm likelihood ratio tests (see previous).\n  - `src`: Helper functions:\n    - `npMatrix2d.py`: Helper functions for 2d numpy array operations.\n    - `npMatrix3d.py`: Helper functions for 3d numpy array operations.\n    - `cvxMatrix2d.py`: Helper functions for 2d cvxopt matrix operations (used only by `PeLS`).\n    - `PeLS.py`: Code for the PeLS method (only for benchmarking, currently unavailable in BLMM).\n    - `fileio.py`: Miscellaneous functions for handling files.\n    - `est2d.py`: Parameter estimation methods for inference on one voxel.\n    - `est3d.py`: Parameter estimation methods for inference on multiple voxels.\n  - `lib`: The main stages of the blmm pipeline:\n    - `blmm_setup`: Formats inputs and works out the number of batches needed.\n    - `blmm_batch`: Calculates the product matrices for individual batches of images.\n    - `blmm_concat`: Sums the product matrices across batches, to obtain the product matrices for the overall model. \n    - `blmm_results`: Separate voxels into \"Inner\" and \"Ring\" and then calls to `blmm_estimate` and `blmm_inference`.\n    - `blmm_estimate`: Estimates the parameters beta, sigma^2 and D.\n    - `blmm_inference`: Performs statistical inference on parameters and outputs results.\n    - `blmm_cleanup`: Removes any leftover files from the analysis.\n    - `blmm_compare`: Performs likelihood ratio tests comparing the results of multiple analyses.\n  - `scripts`: Bash scripts which run each individual stage of the BLMM pipeline.\n- `test`: Test functions:\n  - `Unit`: Unit tests for individual parts of the code:\n    - `genTestDat.py`: Functions to generate test datasets and product matrices.\n    - `npMatrix2d_tests.py`: Unit tests for all functions in `npMatrix2d.py`.\n    - `npMatrix3d_tests.py`: Unit tests for all functions in `npMatrix3d.py`.\n    - `cvxMatrix2d_tests.py`: Unit tests for all functions in `cvxMatrix2d.py`.\n    - `est2d_tests.py`: A function for comparing results of all methods in `est2d.py`, as well as `PeLS.py`.\n    - `est3d_tests.py`: Functions for comparing results of all methods in `est3d.py`. \n"
      },
      "source": "https://raw.githubusercontent.com/TomMaullin/BLMM/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "documentation": [
    {
      "confidence": 1,
      "result": {
        "format": "wiki",
        "type": "Url",
        "value": "https://github.com/TomMaullin/BLMM/wiki"
      },
      "source": "https://raw.githubusercontent.com/TomMaullin/BLMM/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/TomMaullin/BLMM/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 5
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/TomMaullin/BLMM/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "TomMaullin/BLMM"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "Pyblmm"
      },
      "source": "https://raw.githubusercontent.com/TomMaullin/BLMM/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "has_script_file": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/TomMaullin/BLMM/master/blmm/blmm_compare.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/TomMaullin/BLMM/master/blmm/scripts/cluster_blmm_cleanup.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/TomMaullin/BLMM/master/blmm/scripts/cluster_blmm_results.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/TomMaullin/BLMM/master/blmm/scripts/cluster_blmm_batch.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/TomMaullin/BLMM/master/blmm/scripts/cluster_blmm_setup.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/TomMaullin/BLMM/master/blmm/scripts/parse_yaml.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/TomMaullin/BLMM/master/blmm/scripts/cluster_blmm_concat.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/TomMaullin/BLMM/master/blmm/scripts/cluster_blmm_compare.sh"
      },
      "technique": "file_exploration"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/TomMaullin/BLMM/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ""
      },
      "technique": "GitHub_API"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "BLMM"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "User",
        "value": "TomMaullin"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 859931,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Shell",
        "size": 3169,
        "type": "Programming_language",
        "value": "Shell"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/TomMaullin/BLMM/master/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "requirements": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Requirements",
        "parent_header": [
          "Pyblmm"
        ],
        "type": "Text_excerpt",
        "value": "To use the pyblmm code, please pip install like so:\n\n```\npip install pyblmm\n```\n\nFinally, you must set up your `dask-jobqueue` configuration file, which is likely located at `~/.config/dask/jobqueue.yaml`. This will require you to provide some details about your HPC system. See [here](https://jobqueue.dask.org/en/latest/configuration-setup.html#managing-configuration-files) for further detail. For instance, if you are using rescomp your `jobqueue.yaml` file may look something like this:\n\n```\njobqueue:\n  slurm:\n    name: dask-worker\n\n    # Dask worker options\n    cores: 1                 # Total number of cores per job\n    memory: \"100GB\"                # Total amount of memory per job\n    processes: 1                # Number of Python processes per job\n\n    interface: ib0             # Network interface to use like eth0 or ib0\n    death-timeout: 60           # Number of seconds to wait if a worker can not find a scheduler\n    local-directory: \"/path/of/your/choosing/\"       # Location of fast local storage like /scratch or $TMPDIR\n    log-directory: \"/path/of/your/choosing/\"\n    silence_logs: True\n\n    # SLURM resource manager options\n    shebang: \"#!/usr/bin/bash\"\n    queue: short\n    project: null\n    walltime: '01:00:00'\n    job-cpu: null\n    job-mem: null\n    log-directory: null\n\n    # Scheduler options\n    scheduler-options: {'dashboard_address': ':46405'}\n```\n\n\nIf running the `BLMM` tests on a cluster, `fsl_sub` must also be configured correctly.\n"
      },
      "source": "https://raw.githubusercontent.com/TomMaullin/BLMM/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "run": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Running the Analysis",
        "parent_header": [
          "Pyblmm",
          "Usage"
        ],
        "type": "Text_excerpt",
        "value": "\nBLMM can be run from the terminal as follows:\n\n```\nblmm <name_of_your_yaml_file>.yml\n```\n\nYou can watch your analysis progress either by using `qstat` or `squeue` (depending on your system), or by using the interactive dask console. To do so, in a seperate terminal, tunnel into your HPC as follows:\n\n```\nssh -L <local port>:localhost:<remote port> username@hpc_address\n```\n\nwhere the local port is the port you want to view on your local machine and the remote port is the dask dashboard adress (for instance, if you are on rescomp and you used the above `jobqueue.yaml`, `<remote port>` is `46405`). On your local machine, in a browser you can now go to `http://localhost:<local port>/` to watch the analysis run.\n"
      },
      "source": "https://raw.githubusercontent.com/TomMaullin/BLMM/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "somef_missing_categories": [
    "installation",
    "citation",
    "acknowledgement",
    "download",
    "contact",
    "contributors",
    "license",
    "faq",
    "support",
    "identifier",
    "has_build_file",
    "executable_example"
  ],
  "somef_provenance": {
    "date": "2024-10-04 11:57:59",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 19
      },
      "technique": "GitHub_API"
    }
  ],
  "usage": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Usage",
        "parent_header": [
          "Pyblmm"
        ],
        "type": "Text_excerpt",
        "value": "To run `BLMM-py` first specify your design using `blmm_config.yml` and then run your analysis by following the below guidelines.\n"
      },
      "source": "https://raw.githubusercontent.com/TomMaullin/BLMM/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Specifying your model",
        "parent_header": [
          "Pyblmm",
          "Usage"
        ],
        "type": "Text_excerpt",
        "value": "The regression model for BLMM must be specified in `blmm_config.yml`. Below is a complete list of possible inputs to this file.\n"
      },
      "source": "https://raw.githubusercontent.com/TomMaullin/BLMM/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Mandatory fields",
        "parent_header": [
          "Pyblmm",
          "Usage",
          "Specifying your model"
        ],
        "type": "Text_excerpt",
        "value": "The following fields are mandatory:\n\n - `Y_files`: Text file containing a list of response variable images.\n - `analysis_mask`: A mask to be applied during analysis.\n - `X`: CSV file of the design matrix (no column header, no ID row).\n - `Z`: Random factors in the design. They should be listed as `f1,f2,...` etc and each random factor should contain the fields:\n   - `name`: Name of the random factor.\n   - `factor`: CSV file containing a vector of indices representing which level of the factor each image belongs to. e.g. if the first factor is `subject` and the second image belonged to subject 5, the second entry in this file should be 5.\n   - `design`: CSV file containing the design matrix for this random factor.\n - `outdir`: Path to the output directory.\n - `contrasts`: Contrast vectors to be tested. They should be listed as `c1,c2,...` etc and each contrast should contain the fields:\n   - `name`: A name for the contrast. i.e. `AwesomelyNamedContrast1`.\n   - `vector`: A vector for the contrast. This contrast must be one dimensional for a T test and two dimensional for an F test. For example; `[1, 0, 0]` (T contrast) or `[[1, 0, 0],[0,1,0]]` (F contrast).\n   \n   At least one contrast must be given, see `Examples` for an example of how to specify contrasts.\n "
      },
      "source": "https://raw.githubusercontent.com/TomMaullin/BLMM/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Optional fields",
        "parent_header": [
          "Pyblmm",
          "Usage",
          "Specifying your model"
        ],
        "type": "Text_excerpt",
        "value": "The following fields are optional:\n\n - `MAXMEM`: This is the maximum amount of memory (in bits) that the BLMM code is allowed to work with. How this should be set depends on your machine capabilities; the default value however matches the SPM default of 2^32 (note this must be in python notation i.e. `2**32`).\n - `data_mask_files`: A text file containing a list of masks to be applied to the `Y_files`. \n   - The number of masks must be equal to the number of `Y_files` as each mask is applied to the corresponding entry `Y_files`. E.g. The first mask listed for `data_mask_files` will be applied to the first image in `Y_files`, the second mask in `data_mask_files` will be applied to the second image in `Y_files` and so on. \n - `Missingness`: This field allows the user to mask the image based on how many studies had recorded values for each voxel. This can be specified in 3 ways.\n   - `MinPercent`: The percentage of studies present at a voxel necessary for that voxel to be included in the final analysis mask. For example, if this is set to `0.1` then any voxel with recorded values for at least 10% of studies will be kept in the analysis.\n   - `MinN`: The number of studies present at a voxel necessary for that voxel to be included in the final analysis mask. For example, if this is set to `20` then any voxel with recorded values for at least 20 studies will be kept in the analysis.\n - `OutputCovB`: If set to `True` this will output between beta covariance maps. For studies with a large number of paramters this may not be desirable as, for example, 30 analysis paramters will create 30x30=900 between beta covariance maps. By default this is set to `True`.\n - `data_mask_thresh`: Any voxel with value below this threshold will be treated as missing data. (By default, no such thresholding  is done, i.e. `data_mask_thresh` is essentially -infinity). \n - `minlog`: Any `-inf` values in the `-log10(p)` maps will be converted to the value of `minlog`. Currently, a default value of `-323.3062153431158` is used as this is the most negative value which was seen during testing before `-inf` was encountered (see [this thread](https://github.com/TomMaullin/BLMM/issues/76) for more details).\n - `method`: (Beta option). Which method to use for parameter estimation. Options are: `pSFS` (pseudo Simplified Fisher Scoring), `SFS` (Simplified Fisher Scoring), `pFS` (pseudo Fisher Scoring) and `FS` (Fisher Scoring). The (recommended) default is `pSFS`.\n - `tol`: Tolerance for convergence for the parameter estimation. Estimates will be output once the log-likelihood changes by less than `tol` from iteration to iteration. The default value is `1e-6`. \n - `voxelBatching`: (Recommended for large designs). If set to `1`, the parameter estimation and inference steps of the analysis will be performed on seperate groups (batches) of voxels concurrently/in parallel. By default this is set to `0`. This setting is purely for computation speed purposes.\n - `maxnvb`: (Only used when `voxelBatching` is set to `1`). The maximum number of voxel batches/concurrent jobs allowed for estimation and inference. By default this is set to `60`. For large designs, this prevents the code from trying to submit thousands of jobs, should it decide this would be the quickest way to perform computation. This setting is purely for computation speed purposes.\n - `maxnit`: The maximum number of iterations each voxel is allowed for parameter estimation. By default this is set to `10000` iterations. If the iteration limit is reached a warning is thrown in the log files.\n - `resms`: If set to `1`, the `blmm_vox_resms` volume is output, if set to `0`, the `blmm_vox_resms` volume is not output.\n - `safeMode`: If set to `1`, voxels with more random effects than observations will be dropped from the analysis. By default this is set to `1`. It is not recommended to change this setting without good reason.\n\n "
      },
      "source": "https://raw.githubusercontent.com/TomMaullin/BLMM/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Examples",
        "parent_header": [
          "Pyblmm",
          "Usage",
          "Specifying your model"
        ],
        "type": "Text_excerpt",
        "value": "Below are some example `blmm_config.yml` files.\n\nExample 1: A minimal configuration.\n\n```\nY_files: /path/to/data/Y.txt\nX: /path/to/data/X.csv\nZ:\n  - f1: \n      name: factorName\n      factor: /path/to/data/Z1factorVector.csv\n      design: /path/to/data/Z1DesignMatrix.csv\noutdir: /path/to/output/directory/\ncontrasts:\n  - c1:\n      name: Tcontrast1\n      vector: [1, 0, 1, 0, 1]\n```\n\nExample 2: A configuration with multiple optional fields.\n\n```\nMAXMEM: 2**32\nY_files: /path/to/data/Y.txt\ndata_mask_files: /path/to/data/M_.txt\ndata_mask_thresh: 0.1\nX: /path/to/data/X.csv\nZ:\n  - f1: \n      name: factorName\n      factor: /path/to/data/Z1factorVector.csv\n      design: /path/to/data/Z1DesignMatrix.csv\n  - f2: \n      name: factorName2\n      factor: /path/to/data/Z2factorVector.csv\n      design: /path/to/data/Z2DesignMatrix.csv\noutdir: /path/to/output/directory/\ncontrasts:\n  - c1:\n      name: Tcontrast1\n      vector: [1, 0, 0]\n  - c2:\n      name: Tcontrast2\n      vector: [0, 1, 0]\n  - c3:\n      name: Tcontrast3\n      vector: [0, 0, 1]\n  - c4:\n      name: Fcontrast1\n      vector: [[1, 0, 0], [0, 1, 0], [0, 0, 1]]\nMissingness:\n  MinPercent: 0.10\n  MinN: 15\nanalysis_mask: /path/to/data/MNI152_T1_2mm_brain_mask.nii.gz\n```\n"
      },
      "source": "https://raw.githubusercontent.com/TomMaullin/BLMM/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Analysis Output",
        "parent_header": [
          "Pyblmm",
          "Usage"
        ],
        "type": "Text_excerpt",
        "value": "Below is a full list of image files output after a BLMM analysis.\n\n| Filename  | Description  |\n|---|---|\n| `blmm_vox_mask` | This is the analysis mask. |\n| `blmm_vox_n` | This is a map of the number of input images which contributed to each voxel in the final analysis. |\n| `blmm_vox_edf` | This is the spatially varying niave degrees of freedom\\*. |\n| `blmm_vox_beta`  | These are the beta (fixed effects parameter) estimates.  |\n| `blmm_vox_sigma2`  | These are the sigma2 (fixed effects variance) estimates.  |\n| `blmm_vox_D`  | These are the D (random effects variance) estimates\\*\\*. |\n| `blmm_vox_llh` | These are the log likelihood values. |\n| `blmm_vox_con`  | These are the contrasts multiplied by the estimate of beta (this is the same as `COPE` in FSL).  |\n| `blmm_vox_cov`  | These are the between-beta covariance estimates.  |\n| `blmm_vox_conSE` | These are the standard error of the contrasts multiplied by beta (only available for T contrasts). |\n| `blmm_vox_conR2` | These are the partial R^2 maps for the contrasts (only available for F contrasts). |\n| `blmm_vox_resms` | This is the residual mean squares map for the analysis\\*\\*\\*. |\n| `blmm_vox_conT` | These are the T statistics for the contrasts (only available for T contrasts). |\n| `blmm_vox_conF` | These are the F statistics for the contrasts (only available for F contrasts). |\n| `blmm_vox_conTlp` | These are the maps of -log10 of the uncorrected P values for the contrasts (T contrast). |\n| `blmm_vox_conT_swedf` | These are the maps of Sattherthwaithe degrees of freedom estimates for the contrasts (T contrast). |\n| `blmm_vox_conFlp` | These are the maps of -log10 of the uncorrected P values for the contrasts (F contrast). |\n| `blmm_vox_conF_swedf` | These are the maps of Sattherthwaithe degrees of freedom estimates for the contrasts (F contrast). |\n\nThe maps are given the same ordering as the inputs. For example, in `blmm_vox_con`, the `0`th volume corresponds to the `1`st contrast, the `1`st volume corresponds to the `2`nd contrast and so on. For covariances, the ordering is of a similar form with covariance between beta 1 and  beta 1 (variance of beta 1) being the `0`th volume, covariance between beta 1 and  beta 2 being the `1`st volume and so on. In addition, a copy of the design is saved in the output directory as `inputs.yml`. It is recommended that this be kept for data provenance purposes.\n\n\\* These degrees of freedom are not used in inference and are only given as reference. The degrees of freedom used in inference are the Sattherthwaite approximations given in `blmm_vox_conT_swedf`  and `blmm_vox_conF_swedf` .\n\\*\\* The `D` estimates are ordered as `vech(D1)`,...,`vech(Dr)` where `Dk` is the Random effects covariance matrix for the `k`th random factor, `r` is the total number of random factors in the design and `vech` represents [\"half-vectorisation\"](https://en.wikipedia.org/wiki/Vectorization_(mathematics)#Half-vectorization).\n\\*\\*\\* This is optional and may differ from the estimate of `sigma2`, which accounts for the random effects variance.\n"
      },
      "source": "https://raw.githubusercontent.com/TomMaullin/BLMM/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Model Comparison",
        "parent_header": [
          "Pyblmm",
          "Usage"
        ],
        "type": "Text_excerpt",
        "value": "**Note:** The code described in this section is currently not supported. Please contact Tom Maullin for further information.\n\n`BLMM-py` also offers model comparison for nested single-factor models via Likelihood Ratio Tests under a `50:50` chi^2 mixture distribtuion assumption (c.f. Linear Mixed Models for Longitudinal Data. 2000. Verbeke, G. & Molenberghs, G. Chapter 6 Section 3.). To compare the output of two single-factor models in `BLMM-py` (or the output of a single-factor model from `BLMM-py` with the output of a corresponding linear model run using [`BLM-py`](https://github.com/TomMaullin/BLM)) run the following command:\n\n```\nbash ./blmm_compare.sh /path/to/the/results/of/the/smaller/model/ /path/to/the/results/of/the/larger/model/ /path/to/output/directory/\n```\n\nBelow is a full list of image files output after a BLMM likelihood ratio comparison test.\n\n| Filename  | Description  |\n|---|---|\n| `blmm_vox_mask` | This is the analysis mask (this will be the intersection of the masks from each analysis). |\n| `blmm_vox_Chi2` | This is the map of the Likelihood Ratio Statistic. |\n| `blmm_vox_Chi2lp` | This is the map of -log10 of the uncorrected P values for the likelihood ratio test. |\n\n"
      },
      "source": "https://raw.githubusercontent.com/TomMaullin/BLMM/master/README.md",
      "technique": "header_analysis"
    }
  ]
}