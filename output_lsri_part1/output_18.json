{
  "application_domain": [
    {
      "confidence": 14.05,
      "result": {
        "type": "String",
        "value": "Computer Vision"
      },
      "technique": "supervised_classification"
    }
  ],
  "citation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Reference",
        "parent_header": [
          "ArCH - (Ar)tifact Filtering (C)lonal (H)ematapoiesis Variant Calling Pipeline",
          "Usage"
        ],
        "type": "Text_excerpt",
        "value": "| Variable | Type | Definition |\n| --- | --- | --- |\n|reference|File|Reference|\n|reference_fai|File|Reference FAI|\n|reference_dict|File|Reference Dictionary|\n|reference_amb|File|Reference AMB|\n|reference_ann|File|Reference ANN|\n|reference_bwt|File|Reference BWT|\n|reference_pac|File|Reference PAC|\n|reference_sa|File|Reference SA|\n"
      },
      "source": "https://raw.githubusercontent.com/kbolton-lab/ArCH/main/README.md",
      "technique": "header_analysis"
    }
  ],
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/kbolton-lab/ArCH"
      },
      "technique": "GitHub_API"
    }
  ],
  "contact": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Contact Information",
        "parent_header": [
          "ArCH - (Ar)tifact Filtering (C)lonal (H)ematapoiesis Variant Calling Pipeline"
        ],
        "type": "Text_excerpt",
        "value": "Created by: Irenaeus Chan <br />\nEmail: chani@wustl.edu <br />\n"
      },
      "source": "https://raw.githubusercontent.com/kbolton-lab/ArCH/main/README.md",
      "technique": "header_analysis"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2022-03-09T20:42:34Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2024-10-02T21:04:25Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 0.9799659220670955,
      "result": {
        "original_header": "ArCH - (Ar)tifact Filtering (C)lonal (H)ematapoiesis Variant Calling Pipeline",
        "type": "Text_excerpt",
        "value": "ArCH is a somatic variant calling pipeline designed to detect low variant allele fraction (VAF) clonal hematopoiesjsonsis (CH) variants. Starting from either unaligned FASTQ/BAM/CRAM files or aligned BAM/CRAM files, ArCH utilizes four variant callers (Mutect2, VarDictJava, LoFreq2, and Pindel) to detect somatic variants. These variants are then filtered using a variety of false positive filters and detection methods (false positive filters, panel of normal, etc.). The pipeline also generates VEP style annotations for all called variants as well as additional putative driver annotations generated from various database sources (TOPMed, MSK-IMPACT, COSMIC, OncoKB, etc.). \nIf you end up using this tool in your publication, please cite this paper:\n```\nIrenaeus C C Chan, Alex Panchot, Evelyn Schmidt, et al. ArCH: improving the performance of clonal hematopoiesis variant calling and interpretation, Bioinformatics, Volume 40, Issue 4, April 2024, btae121, https://doi.org/10.1093/bioinformatics/btae121\n```\n \n"
      },
      "source": "https://raw.githubusercontent.com/kbolton-lab/ArCH/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.911084371113148,
      "result": {
        "original_header": "Post Pipeline Steps",
        "type": "Text_excerpt",
        "value": "After the pipeline has finished running there should be several files that are generated. The final output file would be `${sample_name}.final.annotated.tsv`. All of these files generated for all the samples should be combined together into a final file using the following command\n```sh\n# Grab the header from one of the output files\ncat ${sample_name}.final.annotated.tsv | head -n1 > final.combined.tsv\n\n# Merge all output files together\nfor dir in $(ls -d */); do\n  zcat $dir/${sample_name}.final.annotated.tsv | tail -n+2 >> final.combined.tsv;\ndone\n\n# If the resulting file is too large, we can pre-filter the results prior to running our post filtering script\n# Find the relative index position for the \"all_fp_pass\" filter\nhead -n1 final.combined.tsv | awk -F'\\t' -vs='all_fp_pass' '{for (i=1;i<=NF;i++)if($i~\"^\"s\"$\"){print i;exit;}}'\n\n# For all of the output files, only keep the variants that had passed all our applied filters via checking the \"all_fp_pass\" column\n# In this case, our column is index position 170\nfor dir in $(ls -d */); do \n  zcat $dir/${sample_name}.final.annotated.tsv | tail -n+2 | awk -F'\\t' '{if($170==\"TRUE\")print $0}' >> final.combined.FPpass.tsv; \ndone\n\n# Now the resulting final.combined.FPpass.tsv can be used as an input into our ArCHPostPipeline.R which can be run from this docker: kboltonlab/r_docker_ichan:latest\nLC_ALL=C.UTF-8 Rscript --vanilla ArCHPostPipeline.R --tsv final.combined.FPpass.tsv --bolton_bick_vars AnnotatePD_Files/bick.bolton.vars3.txt --gene_list AnnotatePD_Files/oncoKB_CGC_pd_table_disparity_KB_BW.csv --cosmic AnnotatePD_Files/COSMIC.heme.myeloid.hotspot.w_truncating_counts.tsv --pd_table AnnotatePD_Files/pd_table_kbreview_bick_trunc4_oncoKB_SAFE.filtered_genes_oncoKB_CGC.tsv\n```\nThe output from ArCHPostPipeline.R will produce three output files:\n|File|Description|\n|---|---|\n| final.all.csv | All variants that passed all post pipeline filters with additional annotations |\n| final.pass.csv | Variants that passed all post pipeline filters and have been identified as potential CH variants that are putative drivers |\n| final.review.csv | Variants that passed all post pipeline filters and could potentially be CH variants that are putative drivers, but need to be manually reviewed by an expert |\n \n"
      },
      "source": "https://raw.githubusercontent.com/kbolton-lab/ArCH/main/README.md",
      "technique": "supervised_classification"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/kbolton-lab/ArCH/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 1
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/kbolton-lab/ArCH/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "kbolton-lab/ArCH"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "ArCH - (Ar)tifact Filtering (C)lonal (H)ematapoiesis Variant Calling Pipeline"
      },
      "source": "https://raw.githubusercontent.com/kbolton-lab/ArCH/main/README.md",
      "technique": "regular_expression"
    }
  ],
  "has_build_file": [
    {
      "confidence": 1,
      "result": {
        "format": "dockerfile",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/kbolton-lab/ArCH/main/R_Docker/Dockerfile"
      },
      "source": "https://raw.githubusercontent.com/kbolton-lab/ArCH/main/R_Docker/Dockerfile",
      "technique": "file_exploration"
    }
  ],
  "installation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Installation",
        "parent_header": [
          "ArCH - (Ar)tifact Filtering (C)lonal (H)ematapoiesis Variant Calling Pipeline"
        ],
        "type": "Text_excerpt",
        "value": "This pipeline requires several files to be downloaded and configured prior to running. The following files are required for the pipeline to run:\n1. Reference Genome\n2. Gene Panel Interval List\n3. Panel of Normals\n4. gnomAD VCF\n5. VEP Cache & Plugins\n6. Somalier VCF\n7. COSMIC VCF\n\nStep-by-step instructions to prepare each file will be provided below.\n"
      },
      "source": "https://raw.githubusercontent.com/kbolton-lab/ArCH/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Panel of Normals",
        "parent_header": [
          "ArCH - (Ar)tifact Filtering (C)lonal (H)ematapoiesis Variant Calling Pipeline",
          "Installation"
        ],
        "type": "Text_excerpt",
        "value": "One of the most important pieces of this pipeline is the Panel of Normals (PoN). The PoN is a collection of BAM files from young individuals that are used to filter out false positives from the tumor samples by representing a base threshold of noise. Typically, 10 to 20 samples yields the best performance for the PoN.\n\nTwo separate filters are generated from the PoN:\n1. Threshold of Noise: This is a Bonferroni corrected Fisher's Exact Test that is used to determine the threshold of noise for the PoN. This is used to filter out any variants that are found in the tumor samples at a lower frequency than the threshold of noise.\n2. Potential Germline Variants: These are non-hotspot variants that are found in 2 or more of the PoN samples at a 2% VAF or higher. These variants are then used to filter out any variants found in the tumor samples as possible germline variants.\n\nTo generate the PoN, the following steps are required:\n1. Run the [ArCH Alignment WDL Workflow](https://github.com/kbolton-lab/ArCH/blob/main/WDL/ArCH_Alignment.wdl) - This will create UMI consensus aligned BAM files for all the PoN samples.\n2. Check the PoN Files for potential CH hotspots and remove them from the PoN samples.\n```sh\n# Using this Docker: duct/getbasecount:latest\ndocker run -v /path/to/PoN:/mnt duct/getbasecount:latest /opt/GetBaseCountsMultiSample/GetBaseCountsMultiSample --fasta $REF --bam ${sample_name}:/mnt/PoN.bam --vcf AnnotatePD_Files/bick_kelly_HGVSp5_pileup.vcf --output ${sample_name}.pileup.vcf --maq 5 --baq 5\nbgzip ${sample_name}.pileup.vcf && tabix ${sample_name}.pileup.vcf.gz\n\n# Check the resulting pileup files for potential CH hotspots\nbcftools view -i 'FORMAT/VF>0.02' ${sample_name}.pileup.vcf.gz\n```\nNOTE: For the variant: `chr20:32434638:A:AG`. Only remove the PoN Sample if this variant is found above 5% VAF in the PoN sample.\n\n3. Run the UMI Consensus Aligned BAM files through the [pon2_creation.wdl](https://github.com/kbolton-lab/ArCH/blob/main/WDL/pon2_creation.wdl)\n\nThis pipeline will generate 3 files:\n- mutect.2N.maxVAF.vcf.gz\n- lofreq.2N.maxVAF.vcf.gz\n- vardict.2N.maxVAF.vcf.gz\n"
      },
      "source": "https://raw.githubusercontent.com/kbolton-lab/ArCH/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "gnomAD Resource",
        "parent_header": [
          "ArCH - (Ar)tifact Filtering (C)lonal (H)ematapoiesis Variant Calling Pipeline",
          "Installation"
        ],
        "type": "Text_excerpt",
        "value": "Due to the size of gnomAD. The database is split into individual chromosomes. They will all have to be downloaded individually before merging them into a singular VCF file\nPlease go to the [official gnomAD download repository](https://gnomad.broadinstitute.org/downloads#summary) to download the latest version of gnomAD (v4.1.0 - as of 05/30/2024)\n```sh\nfor chr in {1..22} X Y; do\n  bcftools view -f PASS -i 'INFO/AF>=0.005' -Ou gnomad.exomes.v4.1.sites.chr${chr}.vcf.bgz | bcftools annotate -x ^INFO/AC,INFO/AF -Ou - | bcftools norm --multiallelics -any -Oz -o gnomad.exomes.v4.1.sites.chr${chr}.AF_only.exclude_0.005.normalized.vcf.gz -  \ndone\nbcftools concat -Oz -o gnomad.exomes.v4.1.AF_only.exclude_0.005.normalized.vcf.gz gnomad.exomes.v4.1.sites.chr*.AF_only.exclude_0.005.normalized.vcf.gz\n```\n"
      },
      "source": "https://raw.githubusercontent.com/kbolton-lab/ArCH/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "VEP Cache",
        "parent_header": [
          "ArCH - (Ar)tifact Filtering (C)lonal (H)ematapoiesis Variant Calling Pipeline",
          "Installation"
        ],
        "type": "Text_excerpt",
        "value": "This Pipeline's annotation step has been configured to use VEP cache files, which can be downloaded from the [Ensembl FTP - Homo sapiens v109](ftp://ftp.ensembl.org/pub/release-109/variation/indexed_vep_cache/homo_sapiens_merged_vep_109_GRCh38.tar.gz). The cache files should be downloaded along with all necessary plugin files and zipped into a single file for the pipeline to use.\n\nCreate the VepData which will contain the VEP v109 Cache\n```sh\nmkdir VEP_cache && mkdir VEP_cache/VepData;\ncd VEP_cache;\ncurl -O ftp://ftp.ensembl.org/pub/release-109/variation/indexed_vep_cache/homo_sapiens_merged_vep_109_GRCh38.tar.gz\ntar xzf homo_sapiens_merged_vep_109_GRCh38.tar.gz -C VepData\nrm homo_sapiens_merged_vep_109_GRCh38.tar.gz\n```\n\nCreate the plugin directory that will contain all the VEP plugins used in this pipeline\n```sh\nmkdir plugin\ncurl -o plugin/CADD.pm https://github.com/Ensembl/VEP_plugins/blob/431b1516431fcb4ee6431120c749769e6516a23e/CADD.pm\ncurl -o plugin/REVEL.pm https://github.com/Ensembl/VEP_plugins/blob/431b1516431fcb4ee6431120c749769e6516a23e/REVEL.pm\ncurl -o plugin/SpliceAI.pm https://github.com/Ensembl/VEP_plugins/blob/431b1516431fcb4ee6431120c749769e6516a23e/SpliceAI.pm\ncurl -o plugin/pLI.pm https://github.com/Ensembl/VEP_plugins/blob/431b1516431fcb4ee6431120c749769e6516a23e/pLI.pm\ncurl -o plugin/Frameshift.pm https://raw.githubusercontent.com/griffithlab/pVACtools/v2.0.0/tools/pvacseq/VEP_plugins/Frameshift.pm\ncurl -o plugin/Wildtype.pm https://raw.githubusercontent.com/griffithlab/pVACtools/v2.0.0/tools/pvacseq/VEP_plugins/Wildtype.pm\n```\n\nCreate the individual raw resources for each of the VEP Plugins\n```sh\n# Synonyms File\nmkdir Synonyms\ncurl -o Synonyms/chromAlias.txt https://hgdownload.soe.ucsc.edu/hubs/GCF/000/001/405/GCF_000001405.39/GCF_000001405.39.chromAlias.txt\n\n# CADD\nmkdir CADD\ncurl -o CADD/whole_genome_SNVs.tsv.gz https://krishna.gs.washington.edu/download/CADD/v1.7/GRCh38/whole_genome_SNVs.tsv.gz\ncurl -o CADD/gnomad.genomes.r4.0.indel.tsv.gz https://krishna.gs.washington.edu/download/CADD/v1.7/GRCh38/gnomad.genomes.r4.0.indel.tsv.gz\n\n# Clinvar\nmkdir Clinvar\ncurl -o Clinvar/clinvar.vcf.gz https://ftp.ncbi.nlm.nih.gov/pub/clinvar/vcf_GRCh38/clinvar.vcf.gz\ntabix Clinvar/clinvar.vcf.gz\n\n# pLI\nmkdir pLI\ncurl -o pLI/fordist_cleaned_exac_r03_march16_z_pli_rec_null_data.txt https://ftp.broadinstitute.org/pub/ExAC_release/release0.3/functional_gene_constraint/fordist_cleaned_exac_r03_march16_z_pli_rec_null_data.txt\nawk '{print $2, $20}' pLI/fordist_cleaned_exac_r03_march16_z_pli_rec_null_data.txt > pLI/pLI_gene.txt\n\n# REVEL\nmkdir REVEL\ncurl -o REVEL/revel-v1.3_all_chromosomes.zip https://rothsj06.dmz.hpc.mssm.edu/revel-v1.3_all_chromosomes.zip\ncd REVEL/\nunzip revel-v1.3_all_chromosomes.zip\ncat revel_with_transcript_ids | tr \",\" \"\\t\" > tabbed_revel.tsv\nsed '1s/.*/#&/' tabbed_revel.tsv > new_tabbed_revel.tsv\nbgzip new_tabbed_revel.tsv\n\nzcat new_tabbed_revel.tsv.gz | head -n1 > h\nzgrep -h -v ^#chr new_tabbed_revel.tsv.gz | awk '$3 != \".\" ' | sort -k1,1 -k3,3n - | cat h - | bgzip -c > new_tabbed_revel_grch38.tsv.gz\ntabix -f -s 1 -b 3 -e 3 new_tabbed_revel_grch38.tsv.gz\n\n# SpliceAI\nmkdir spliceAI\n# Files for spliceAI can be downloaded from Illumina basespace: https://basespace.illumina.com/analyses/194103939/files \n# You will need:\n# - spliceai_scores.raw.indel.hg38.vcf.gz\n# - spliceai_scores.raw.indel.hg38.vcf.gz.tbi\n# - spliceai_scores.raw.snv.hg38.vcf.gz\n# - spliceai_scores.raw.snv.hg38.vcf.gz.tbi\n```\n\nZIP all the files into a single file for the pipeline to use\n```sh\nzip -r VEP_cache.zip VEP_cache\n```\n"
      },
      "source": "https://raw.githubusercontent.com/kbolton-lab/ArCH/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Somalier",
        "parent_header": [
          "ArCH - (Ar)tifact Filtering (C)lonal (H)ematapoiesis Variant Calling Pipeline",
          "Installation"
        ],
        "type": "Text_excerpt",
        "value": "[Somalier (v0.2.15) written by Brentp](https://github.com/brentp/somalier/releases/tag/v0.2.15) is run as a part of this pipeline to ensure that the samples are correctly identified. \n\nThe VCF file containing all the sites used for this step can be prepared as follows\n```sh\ncurl -O https://github.com/brentp/somalier/files/3412456/sites.hg38.vcf.gz\n```\n"
      },
      "source": "https://raw.githubusercontent.com/kbolton-lab/ArCH/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "COSMIC Counts Files",
        "parent_header": [
          "ArCH - (Ar)tifact Filtering (C)lonal (H)ematapoiesis Variant Calling Pipeline",
          "Installation"
        ],
        "type": "Text_excerpt",
        "value": "To generate the necessary file inputs for these files requires a lot of work and we have not optimized a pipeline to automatically perform this task. Please download the necessary zip file which has been configured for [COSMIC v94](https://arch-example-files.s3.us-east-2.amazonaws.com/cosmic_zip.zip)\n"
      },
      "source": "https://raw.githubusercontent.com/kbolton-lab/ArCH/main/README.md",
      "technique": "header_analysis"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/kbolton-lab/ArCH/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ""
      },
      "technique": "GitHub_API"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "ArCH"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "Organization",
        "value": "kbolton-lab"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "WDL",
        "size": 181910,
        "type": "Programming_language",
        "value": "WDL"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "R",
        "size": 144180,
        "type": "Programming_language",
        "value": "R"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Julia",
        "size": 85777,
        "type": "Programming_language",
        "value": "Julia"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Dockerfile",
        "size": 1794,
        "type": "Programming_language",
        "value": "Dockerfile"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/kbolton-lab/ArCH/main/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "releases": [
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "IrenaeusChan",
          "type": "User"
        },
        "date_created": "2024-06-21T20:01:29Z",
        "date_published": "2024-06-21T20:16:04Z",
        "description": "Major Changes:\r\n- ArCH utilizes various R scripts that have now been added under R_docker for clarity \r\n- Installation instructions for ArCH have now been documented and tested in README\r\n\r\nMinor Changes:\r\n- Fixed issue with oncoKB API Key being publically posted in Github\r\n- Added archer_adapter_sequence to allow different adapter sequences for ArcherDX sequencing",
        "html_url": "https://github.com/kbolton-lab/ArCH/releases/tag/v2.1.1",
        "name": "ArCH v2.1.1",
        "release_id": 161736052,
        "tag": "v2.1.1",
        "tarball_url": "https://api.github.com/repos/kbolton-lab/ArCH/tarball/v2.1.1",
        "type": "Release",
        "url": "https://api.github.com/repos/kbolton-lab/ArCH/releases/161736052",
        "value": "https://api.github.com/repos/kbolton-lab/ArCH/releases/161736052",
        "zipball_url": "https://api.github.com/repos/kbolton-lab/ArCH/zipball/v2.1.1"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "IrenaeusChan",
          "type": "User"
        },
        "date_created": "2024-03-22T16:29:03Z",
        "date_published": "2024-03-22T16:52:01Z",
        "description": "ArCH.wdl has not been changed from v2.0.0 aside from various renaming from ArCCH to ArCH.\r\nHowever, due to https://github.com/kbolton-lab/ch-toolkit/releases/tag/v2.6.1 major overhauls on ArCH_WGS.wdl workflow logic.\r\n\r\n### **Major Changes:**\r\n\r\nArCH_WGS.wdl\r\n- `mutect_vcf` and `vardict_vcf` are now individual inputs to allow for easier parallel processing of both variant caller VCFs\r\n- Added `create_sample_blocks` as an intermediate step to combine VCFs into 1 Gb blocks to reduce how many VCFs are being processed at once for `variants` and `sample_vcfs` step\r\n- Removed scattering of VCFs in favour of running a larger VM to process all VCFs in parallel\r\n- Merging of VCFs was done Mutect --> Vardict, but is now handled in parallel\r\n- Due to improvements in ch-toolkit v2.6.1 allowing us to read from the database simultaneously, more workflows can be run in parallel\r\n- Due to multi-threading options in ch-toolkit v2.6.1 certain tasks are now expected to be parallel e.g. merge_batch_vcfs\r\n- Due to changes in parallelization and multi-threading various memory increases within ArCH_WGS.wdl\r\n\r\n### **Minor Changes:**\r\nArCH.wdl: Accounted for the possibility of tumor_only being FALSE and correct vardict.vcf.gz output was not accounted for.\r\nArCH_Alignment.wdl: UMI Consensus and Alignment from main ArCH.wdl.\r\nvariant_calling.wdl: Added ability account for CRAM and BAM inputs.\r\npon2_creation.wdl: Removed chromosome splitting due to being too resource intensive, runtime is longer but less costly.\r\n\r\n**Full Changelog**: https://github.com/kbolton-lab/ArCH/compare/v2.1.0...v2.1.0",
        "html_url": "https://github.com/kbolton-lab/ArCH/releases/tag/v2.1.0",
        "name": "v2.1.0",
        "release_id": 147950196,
        "tag": "v2.1.0",
        "tarball_url": "https://api.github.com/repos/kbolton-lab/ArCH/tarball/v2.1.0",
        "type": "Release",
        "url": "https://api.github.com/repos/kbolton-lab/ArCH/releases/147950196",
        "value": "https://api.github.com/repos/kbolton-lab/ArCH/releases/147950196",
        "zipball_url": "https://api.github.com/repos/kbolton-lab/ArCH/zipball/v2.1.0"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "IrenaeusChan",
          "type": "User"
        },
        "date_created": "2023-10-13T19:39:41Z",
        "date_published": "2023-10-13T19:50:48Z",
        "description": "ArCH v1.0.1 --> ArCH v2.0.0\r\n\r\n- Overhaul in memory optimizations, reducing overall memory usage for tools that do not require multiple cores and threads\r\n- Cost decreased through the usage of HDD over SSD for tools not requiring constant File I/O\r\n- Overhauled pipeline logic, simplified code to allow heavy decision making at task level rather than workflow level e.g. Inputs are simplified without the need for BAM input, CRAM input, FASTQ input. Now only a single Input variable is needed. Task will detect what input and handle accordingly\r\n- Due to HDD changes, Scattering of large BAMs causes a lot of runtime to be used for localization of files. Where possible, changed Scattering to run asynchronously in the background of a single VM (more time is invested in the actual tool rather than localization of all necessary BAM files)\r\n- Tools affected by this change: Vardict, Pindel, and fpFilter\r\n- XGBoost Julia Machine Learning is no longer default option. Due to the results not providing strong enough evidence for continued support. The XGBoost Machine Learning has been removed for now\r\n- Removal of Complex Script: Previous Script needs further testing and development\r\n\r\nVersion Upgrades\r\n- Upgrading of GetBaseCounts Docker, recompiled without output_fragment_count and optimized for better memory usage @duct317 \r\n- Upgraded fgbio from v1.3.0 to v2.0.2 - No longer backwards compatible with several algorithm changes: https://twitter.com/fulcrumgenomics/status/1511114220422631426\r\n- Upgraded VEP to v1.09.3 - Needs new cache\r\n\r\nCost\r\n- Previous Pipeline cost ($3.78, $3.60, $4.74)\r\n- New Pipeline costs ($1.14, $1.07, $1.17)\r\n\r\nRuntime\r\n- Previous Pipeline Runtime (7 hrs, 8.5 hrs, 8 hrs)\r\n- New Pipeline Runtime (9 hrs, 11 hrs, 11 hrs)\r\n\r\nComparison\r\n![image (9)](https://github.com/kbolton-lab/ArCH/assets/10765692/51ff2dd4-04fa-40cb-902d-d5f3dbe30379)\r\n",
        "html_url": "https://github.com/kbolton-lab/ArCH/releases/tag/v2.0.0",
        "name": "ArCH v2.0.0",
        "release_id": 125047039,
        "tag": "v2.0.0",
        "tarball_url": "https://api.github.com/repos/kbolton-lab/ArCH/tarball/v2.0.0",
        "type": "Release",
        "url": "https://api.github.com/repos/kbolton-lab/ArCH/releases/125047039",
        "value": "https://api.github.com/repos/kbolton-lab/ArCH/releases/125047039",
        "zipball_url": "https://api.github.com/repos/kbolton-lab/ArCH/zipball/v2.0.0"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "IrenaeusChan",
          "type": "User"
        },
        "date_created": "2023-08-23T19:36:04Z",
        "date_published": "2023-08-23T19:39:54Z",
        "description": "- Optimizations towards the PoN Pileup Script (for TERRABio)\r\n- Bug Fix with the AWK script during the LoFreq Reformat Step\r\n- Bug Fix with the PoN2 BCFTools Step missing the VCF input",
        "html_url": "https://github.com/kbolton-lab/ArCH/releases/tag/v1.0.1",
        "name": "ArCH v1.0.1",
        "release_id": 118457911,
        "tag": "v1.0.1",
        "tarball_url": "https://api.github.com/repos/kbolton-lab/ArCH/tarball/v1.0.1",
        "type": "Release",
        "url": "https://api.github.com/repos/kbolton-lab/ArCH/releases/118457911",
        "value": "https://api.github.com/repos/kbolton-lab/ArCH/releases/118457911",
        "zipball_url": "https://api.github.com/repos/kbolton-lab/ArCH/zipball/v1.0.1"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "IrenaeusChan",
          "type": "User"
        },
        "date_created": "2023-08-08T17:56:20Z",
        "date_published": "2023-08-08T23:21:50Z",
        "description": "The original ArCH Pipeline \r\n\r\nThis version is stable and works perfectly fine for the somatic calling step. There are issues with the WGS workflow (still in development at this point).\r\n\r\nUnfortunately, this version is not fully optimized for large scale cloud based infrastructure. New releases following provide greater optimization, decreasing overall cost and speeding up runtime.",
        "html_url": "https://github.com/kbolton-lab/ArCH/releases/tag/v1.0.0",
        "name": "ArCH v1.0.0",
        "release_id": 115684741,
        "tag": "v1.0.0",
        "tarball_url": "https://api.github.com/repos/kbolton-lab/ArCH/tarball/v1.0.0",
        "type": "Release",
        "url": "https://api.github.com/repos/kbolton-lab/ArCH/releases/115684741",
        "value": "https://api.github.com/repos/kbolton-lab/ArCH/releases/115684741",
        "zipball_url": "https://api.github.com/repos/kbolton-lab/ArCH/zipball/v1.0.0"
      },
      "technique": "GitHub_API"
    }
  ],
  "somef_missing_categories": [
    "acknowledgement",
    "run",
    "download",
    "requirements",
    "contributors",
    "documentation",
    "license",
    "faq",
    "support",
    "identifier",
    "executable_example"
  ],
  "somef_provenance": {
    "date": "2024-10-03 22:58:23",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 8
      },
      "technique": "GitHub_API"
    }
  ],
  "usage": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Usage",
        "parent_header": [
          "ArCH - (Ar)tifact Filtering (C)lonal (H)ematapoiesis Variant Calling Pipeline"
        ],
        "type": "Text_excerpt",
        "value": "For ease of use, a [WDL pipeline](https://github.com/kbolton-lab/ArCH/blob/main/WDL/ArCH.wdl) is available to run the entire ArCH pipeline from either unaligned FASTQ/BAM/CRAM or aligned BAM/CRAM files.\n\nAn example sample has been provided which can be accessed through the following links:\n```\nhttps://arch-example-files.s3.us-east-2.amazonaws.com/ArCH_S1_R1.fastq.gz\nhttps://arch-example-files.s3.us-east-2.amazonaws.com/ArCH_S1_R2.fastq.gz\n```\n\nThis Pipeline has been tested and configured to run using Cromwell-70 as well as on TERRAbio.\n"
      },
      "source": "https://raw.githubusercontent.com/kbolton-lab/ArCH/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Inputs",
        "parent_header": [
          "ArCH - (Ar)tifact Filtering (C)lonal (H)ematapoiesis Variant Calling Pipeline",
          "Usage"
        ],
        "type": "Text_excerpt",
        "value": "For basic usage, please use the following [JSON](https://github.com/kbolton-lab/ArCH/tree/main/Example/ArCH_pipeline.json) as a base template for your input file.\n\n| Variable | Type | Definition |\n| --- | --- | --- |\n|input_file|File|This will be the first input file. It can be a R1 FASTQ, BAM, or CRAM|\n|input_file_two|File|This will be the second input file. It can be R2 FASTQ, BAI, or CRAI|\n|tumor_sample_name|String|Name of the tumor sample|\n|normal_bam|File?|Optional matched normal sample BAM for variant calling, leave blank if not used.|\n|normal_bai|File?|Optional matched normal sample BAM index for variant calling, leave blank if not used.|\n|normal_sample_name|String?|Optional name of the normal sample, leave blank if not used.|\n|input_type|String|Three options: \"BAM\", \"CRAM\", or \"FASTQ\" (Default: \"FASTQ\")|\n|aligned|Boolean|Set TRUE if UMI consensus sequencing building ArCH_Alignment.wdl was done prior to pipeline, FALSE if unaligned|\n|target_intervals|File|Interval list for the sequencing panel|\n"
      },
      "source": "https://raw.githubusercontent.com/kbolton-lab/ArCH/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Sequence and UMI Information",
        "parent_header": [
          "ArCH - (Ar)tifact Filtering (C)lonal (H)ematapoiesis Variant Calling Pipeline",
          "Usage"
        ],
        "type": "Text_excerpt",
        "value": "| Variable | Type | Definition |\n| --- | --- | --- |\n|platform|String|PL Tag for BAM Metadata e.g. NovaSeq6000, NovaSeqX, etc...|\n|platform_unit|String|PU Tag for BAM Metadata e.g. the specific sequencing machine used e.g. FlowCellID_LaneX|\n|library|String|LB Tag for BAM Metadata e.g. ArcherDX VariantPlex, MGI, IlluminaWES|\n|has_umi|Boolean|Set TRUE if the sequencing data has UMIs, FALSE if it does not|\n|umi_paired|Boolean?|Set TRUE if the sequencing data has paired UMIs, FALSE if it does not|\n|where_is_umi|String|Three options: Use \"N = If the UMI is already in the sequence name\", \"R = If the UMI is contained within the read\", or \"T = If the UMI has already been tagged\"|\n|read_structure|Array[String]|https://github.com/fulcrumgenomics/fgbio/wiki/Read-Structures|\n|min_reads|Array[Int]|Minimum number of reads that constitutes a \"read family\" (Default: 1)|\n"
      },
      "source": "https://raw.githubusercontent.com/kbolton-lab/ArCH/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Consensus Building",
        "parent_header": [
          "ArCH - (Ar)tifact Filtering (C)lonal (H)ematapoiesis Variant Calling Pipeline",
          "Usage"
        ],
        "type": "Text_excerpt",
        "value": "| Variable | Type | Definition |\n| --- | --- | --- |\n|min_base_quality|Integer|During consensus building, any base with a QUAL less than this value is masked with an N (Default: 1)|\n|max_base_error_rate|Float?|During consensus building, if this percent of the bases within a \"read family\" do not match, the base is masked with an N (Default: 0.1)|\n|max_read_error_rate|Float?|During consensus building, if this percent of the reads within a \"read family\" do not match, the entire family is removed (Default: 0.05)|\n|max_no_call_fraction|Float|During consensus building, the maximum fraction of no-calls (N) within the read after filtering allowed (Default: 0.5)|\n"
      },
      "source": "https://raw.githubusercontent.com/kbolton-lab/ArCH/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Quality Control",
        "parent_header": [
          "ArCH - (Ar)tifact Filtering (C)lonal (H)ematapoiesis Variant Calling Pipeline",
          "Usage"
        ],
        "type": "Text_excerpt",
        "value": "|Variable|Type|Definition|\n|---|---|---|\n|apply_bqsr|Boolean|Set TRUE if Base Quality Score Recalibration should be applied, FALSE if it should not (Default: False)|\n|bqsr_known_sites|Array[File]|A series of VCF denoted sites in which have known variation to avoid confusing real variation with errors. Can be downloaded from: https://console.cloud.google.com/storage/browser/genomics-public-data/resources/broad/hg38/v0/|\n|bqsr_known_sites_tbi|Array[File]|The index for the VCFs within bqsr_known_sites|\n|af_only_snp_only_vcf|File|A VCF file that contains specific SNPs sites of interest, used for Somalier. Can be from https://github.com/brentp/somalier/releases/tag/v0.2.15|\n"
      },
      "source": "https://raw.githubusercontent.com/kbolton-lab/ArCH/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Variant Callers",
        "parent_header": [
          "ArCH - (Ar)tifact Filtering (C)lonal (H)ematapoiesis Variant Calling Pipeline",
          "Usage"
        ],
        "type": "Text_excerpt",
        "value": "|Variable|Type|Definition|\n|---|---|---|\n|tumor_only|Boolean|Set TRUE if the analysis will be done using only Tumor samples without matched normals, FALSE if there is a matched normals are available|\n|af_threshold|Float?|Optional minimum VAF cut-off (Default: 0.0001)|\n|bcbio_filter_string|String|https://github.com/bcbio/bcbio-nextgen/blob/master/bcbio/variation/vardict.py#L251|\n"
      },
      "source": "https://raw.githubusercontent.com/kbolton-lab/ArCH/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Filtering Parameters",
        "parent_header": [
          "ArCH - (Ar)tifact Filtering (C)lonal (H)ematapoiesis Variant Calling Pipeline",
          "Usage"
        ],
        "type": "Text_excerpt",
        "value": "|Variable|Type|Definition|\n|---|---|---|\n|pon_bams|Array[Pair[File, File]]|The Panel of Normal Aligned BAMs generated in the Panel of Normals step and their associated index files|\n|pon_pvalue|Float|Minimum Bonferroni corrected p-value for Fisher's Exact Test of the Panel of Normals (Default: 2.114164905e-6)|\n|normalized_gnomad_exclude|File|Filtered gnomAD VCF with VAFs higher than 0.5%\n|normalized_gnomad_exclude_tbi|File|Filtered gnomAD VCF index|\n|mutect_pon2_file|File|Mutect2 called variants from PoN BAMs that are found in two or more samples above 2% VAF|\n|mutect_pon2_file_tbi|File|Mutect2 called variants from PoN BAMs index|\n|lofreq_pon2_file|File|Lofreq2 called variants from PoN BAMs that are found in two or more samples above 2% VAF|\n|lofreq_pon2_file_tbi|File|Lofreq2 called variants from PoN BAMs index|\n|vardict_pon2_file|File|VarDictJava called variants from PoN BAMs that are found in two or more samples above 2% VAF|\n|vardict_pon2_file_tbi|File|VarDictJava called variants from PoN BAMs index|\n"
      },
      "source": "https://raw.githubusercontent.com/kbolton-lab/ArCH/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "VEP Annotation Parameters",
        "parent_header": [
          "ArCH - (Ar)tifact Filtering (C)lonal (H)ematapoiesis Variant Calling Pipeline",
          "Usage"
        ],
        "type": "Text_excerpt",
        "value": "|Variable|Type|Definition|\n|---|---|---|\n|vep_cache_dir_zip|File|The VEP cache directory in ZIP format|\n|vep_plugins|Array[String]|List of plugins to be used in VEP (Default: \"Frameshift\", \"Wildtype\")|\n|synonyms_file|File?|Optional file of chromosome synonyms, leave blank if not used.|\n|annotate_coding_only|Boolean?|Set TRUE if VEP should return consequences that fall within the coding only regions of the transcript, FALSE if all consequences should be returned|\n|clinvar_vcf|File|Clinvar VCF file|\n|clinvar_vcf_tbi|File|Clinvar VCF index|\n"
      },
      "source": "https://raw.githubusercontent.com/kbolton-lab/ArCH/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Putative Driver Annotation Parameters",
        "parent_header": [
          "ArCH - (Ar)tifact Filtering (C)lonal (H)ematapoiesis Variant Calling Pipeline",
          "Usage"
        ],
        "type": "Text_excerpt",
        "value": "|Variable|Type|Definition|\n|---|---|---|\n|bolton_bick_vars|File|Pathogenic CH Variants found in Bolton et al. (2020) Nature Genetics and Bick et al. (2020) Nature|\n|mut2_bick|File|Subset of bolton_bick_vars containing VEP type annotations from Bick et al. (2020) Nature|\n|mut2_kelly|File|Subset of bolton_bick_vars containing VEP type annotations from Bolton et al. (2020) Nature Genetics|\n|matches2|File|Intersection of mut2_bick and mut2_kelly variants containing VEP type annotations|\n|truncating|File|Subset of bolton_bick_vars containing all truncating mutations|\n|gene_list|File|List of genes that are considered putative drivers|\n|oncokb_genes|File|List of genes that are considered putative drivers from OncoKB|\n|oncokb_api_key|String|API Key for OncoKB: https://www.oncokb.org/account/settings|\n|cosmic_dir_zip|File|COSMIC Counts Files in ZIP format|\n"
      },
      "source": "https://raw.githubusercontent.com/kbolton-lab/ArCH/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "BCBio Filter Parameters",
        "parent_header": [
          "ArCH - (Ar)tifact Filtering (C)lonal (H)ematapoiesis Variant Calling Pipeline",
          "Usage"
        ],
        "type": "Text_excerpt",
        "value": "According to BCBIO, VarDict has multiple false positive calls at regions of low depth and allelic fractions. These are the [default](https://github.com/bcbio/bcbio-nextgen/blob/master/bcbio/variation/vardict.py#L251) parameters recommended by BCBIO. However, we have found that these parameters are too stringent for our purposes and have modified them to the following:\n```\n- Low mapping quality and multiple mismatches in a read (NM)\n  For bwa only: MQ < 55.0 and NM > 1.0 or MQ < 60.0 and NM > 3.0\n- Low depth (DP < n) where n is calculated as 0.25 of the average read depth e.g. If the average read depth is 20,000 bp, then the n is 5000\n- Low QUAL (QUAL < 27)\n```\n"
      },
      "source": "https://raw.githubusercontent.com/kbolton-lab/ArCH/main/README.md",
      "technique": "header_analysis"
    }
  ],
  "workflows": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/kbolton-lab/ArCH/main/WDL/ArCH.wdl"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/kbolton-lab/ArCH/main/WDL/ArCH_Alignment.wdl"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/kbolton-lab/ArCH/main/WDL/pon2_creation.wdl"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/kbolton-lab/ArCH/main/WDL/WGS/ArCH_WGS.wdl"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/kbolton-lab/ArCH/main/WDL/WGS/Subworkflows/variant_calling.wdl"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/kbolton-lab/ArCH/main/WDL/WGS/Subworkflows/PoN.wdl"
      },
      "technique": "file_exploration"
    }
  ]
}