{
  "application_domain": [
    {
      "confidence": 5.52,
      "result": {
        "type": "String",
        "value": "Audio"
      },
      "technique": "supervised_classification"
    }
  ],
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/GBLille/MassiveFold"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2023-03-22T11:27:53Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2024-10-01T14:38:58Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 0.9689681682242446,
      "result": {
        "original_header": "Table of contents",
        "type": "Text_excerpt",
        "value": "MassiveFold is a tool that allows to massively expand the sampling of structure predictions by improving the computing \nof [AlphaFold](https://github.com/google-deepmind/alphafold) based predictions. \nIt optimizes the parallelization of the structure inference by splitting the computing on CPU for alignments, running \nautomatically batches of structure predictions on GPU, and gathering the results in one global output directory, with a \nglobal ranking and a variety of plots. \nMassiveFold uses [AFmassive](https://github.com/GBLille/AFmassive) or [ColabFold](https://github.com/sokrypton/ColabFold). as inference engine; AFmassive is an updated version of Bj\u00f6rn \nWallner's [AFsample](https://github.com/bjornwallner/alphafoldv2.2.0/) that offers additional diversity parameters for \nmassive sampling. \nIt has been submitted for publication and a preprint is available here: \n[https://doi.org/10.21203/rs.3.rs-4319486/v1](https://doi.org/10.21203/rs.3.rs-4319486/v1).\n \n"
      },
      "source": "https://raw.githubusercontent.com/GBLille/MassiveFold/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.923374265165465,
      "result": {
        "original_header": "MassiveFold: parallelize protein structure prediction",
        "type": "Text_excerpt",
        "value": "MassiveFold's design (see schematic below) is optimized for GPU cluster usage. It allows fast computing for massive \nsampling by automatically splitting a large run of numerous predictions into several jobs. Each of these individual \njobs are computed on a single GPU node and their results are then gathered as a single output with each prediction \nranked on a global level instead of the level of each individual job.   \nThis automatic splitting is also convenient for massive sampling on a single GPU server to manage jobs priorities.   \nMassiveFold is only available with the **SLURM** workload manager (Simple Linux Utility for Resource Management) as \nit relies heavily on its features (job array, job dependency, etc...). \nA run is composed of three steps:  \n1. **alignment**: on CPU, sequence alignments is the first step (can be skipped if alignments are already computed) \n2. **structure prediction**: on GPU, structure predictions follow the massive sampling principle. The total number \nof predictions is divided into smaller batches and each of them is distributed on a single GPU. These jobs wait for the \nalignment job to be over, if the alignments are not provided by the user. \n"
      },
      "source": "https://raw.githubusercontent.com/GBLille/MassiveFold/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9597905018769389,
      "result": {
        "original_header": "Required arguments",
        "type": "Text_excerpt",
        "value": "- **--input_path**: it designates MassiveFold output dir and the directory to store the plots except if you want them \nin a separate directory (use `--output_path` for this purpose) \n- **--chosen_plots**: plots you want to get. You can give a list of plot names separated by a coma \n(*e.g.*: `--chosen_plots`=coverage,DM_plddt_PAE,CF_PAEs). \nHere is the list of available plots:\n  * DM_plddt_PAE: Deepmind's plots for predicted lddt per residue and predicted aligned error matrix\n  ![header](imgs/plot_illustrations/plddt_PAES.png)\n  * CF_plddts: ColabFold's plot for predicted lddt per residue\n  ![header](imgs/plot_illustrations/plddts.png)\n  * CF_PAEs: ColabFold's plot for predicted aligned error of the n best predictions set with *--top_n_predictions*\n  ![header](imgs/plot_illustrations/PAEs.png)\n  * coverage: ColabFold's plot for sequence alignment coverage\n  ![header](imgs/plot_illustrations/coverage.png)\n  * score_distribution: performs 3 plots that summarize the score's distribution at three levels: \n    - an histogram of all scores indiscriminately  \n    ![header](imgs/plot_illustrations/score_distribution.png)\n    - a density plot for each neural network model version  \n    ![header](imgs/plot_illustrations/versions_density.png)\n    - a boxplot for each neural network model  \n    ![header](imgs/plot_illustrations/models_scores.png)\n  * distribution_comparison: ranking confidence distribution comparison between various MassiveFold outputs, typically \n  useful for runs with different sets of parameters on the same input sequence(s).\n  ![header](imgs/plot_illustrations/distribution_comparison.png)\n  * recycles: ranking confidence during the recycle process (only for multimers and ColabFold monomers)\n  ![header](imgs/plot_illustrations/recycles.png)\n \n"
      },
      "source": "https://raw.githubusercontent.com/GBLille/MassiveFold/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9905668367788584,
      "result": {
        "original_header": "Facultative arguments",
        "type": "Text_excerpt",
        "value": "- `--top_n_predictions`: (default 10), number of best predictions to take into account for plotting\n- `--runs_to_compare`: names of the runs you want to compare on their distribution, this argument is coupled with \n**--chosen_plots=distribution_comparison** \n"
      },
      "source": "https://raw.githubusercontent.com/GBLille/MassiveFold/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9379763322807345,
      "result": {
        "original_header": "Authors",
        "type": "Text_excerpt",
        "value": "This work was carried out as part of Work Package 4 of the [MUDIS4LS project](https://www.france-bioinformatique.fr/actualites/mudis4ls-le-projet-despaces-numeriques-mutualises-pour-les-sciences-du-vivant/) \nled by the French Bioinformatics Institute ([IFB](https://www.france-bioinformatique.fr/)). It was initiated at the \n[IDRIS Open Hackathon](http://www.idris.fr/annonces/idris-gpu-hackathon-2023.html), part of the Open Hackathons program. \nThe authors would like to acknowledge OpenACC-Standard.org for their support.\n \n"
      },
      "source": "https://raw.githubusercontent.com/GBLille/MassiveFold/main/README.md",
      "technique": "supervised_classification"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/GBLille/MassiveFold/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 5
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/GBLille/MassiveFold/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "GBLille/MassiveFold"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "MassiveFold"
      },
      "source": "https://raw.githubusercontent.com/GBLille/MassiveFold/main/README.md",
      "technique": "regular_expression"
    }
  ],
  "has_script_file": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/GBLille/MassiveFold/main/install.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/GBLille/MassiveFold/main/massivefold/run_massivefold.sh"
      },
      "technique": "file_exploration"
    }
  ],
  "identifier": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://doi.org/10.5281/zenodo.13870060"
      },
      "source": "https://raw.githubusercontent.com/GBLille/MassiveFold/main/README.md",
      "technique": "regular_expression"
    }
  ],
  "images": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/GBLille/MassiveFold/main/imgs/header.png"
      },
      "source": "https://raw.githubusercontent.com/GBLille/MassiveFold/main/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/GBLille/MassiveFold/main/imgs/massivefold_diagram.svg"
      },
      "source": "https://raw.githubusercontent.com/GBLille/MassiveFold/main/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/GBLille/MassiveFold/main/imgs/plot_illustrations/plddt_PAES.png"
      },
      "source": "https://raw.githubusercontent.com/GBLille/MassiveFold/main/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/GBLille/MassiveFold/main/imgs/plot_illustrations/plddts.png"
      },
      "source": "https://raw.githubusercontent.com/GBLille/MassiveFold/main/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/GBLille/MassiveFold/main/imgs/plot_illustrations/PAEs.png"
      },
      "source": "https://raw.githubusercontent.com/GBLille/MassiveFold/main/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/GBLille/MassiveFold/main/imgs/plot_illustrations/coverage.png"
      },
      "source": "https://raw.githubusercontent.com/GBLille/MassiveFold/main/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/GBLille/MassiveFold/main/imgs/plot_illustrations/score_distribution.png"
      },
      "source": "https://raw.githubusercontent.com/GBLille/MassiveFold/main/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/GBLille/MassiveFold/main/imgs/plot_illustrations/versions_density.png"
      },
      "source": "https://raw.githubusercontent.com/GBLille/MassiveFold/main/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/GBLille/MassiveFold/main/imgs/plot_illustrations/models_scores.png"
      },
      "source": "https://raw.githubusercontent.com/GBLille/MassiveFold/main/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/GBLille/MassiveFold/main/imgs/plot_illustrations/distribution_comparison.png"
      },
      "source": "https://raw.githubusercontent.com/GBLille/MassiveFold/main/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/GBLille/MassiveFold/main/imgs/plot_illustrations/recycles.png"
      },
      "source": "https://raw.githubusercontent.com/GBLille/MassiveFold/main/README.md",
      "technique": "regular_expression"
    }
  ],
  "installation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Installation",
        "parent_header": [
          "MassiveFold"
        ],
        "type": "Text_excerpt",
        "value": "MassiveFold was developed to run massive sampling with [AFmassive](https://github.com/GBLille/AFmassive) and \n[ColabFold](https://github.com/sokrypton/ColabFold) and relies on them for its installation.\n"
      },
      "source": "https://raw.githubusercontent.com/GBLille/MassiveFold/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Steps",
        "parent_header": [
          "MassiveFold",
          "Installation"
        ],
        "type": "Text_excerpt",
        "value": "1. **Retrieve MassiveFold**\n\n```bash\n# clone MassiveFold's repository\ngit clone https://github.com/GBLille/MassiveFold.git\n```\n\nFor AFmassive runs, two additional installation steps are required to use MassiveFold for AFmassive runs:\n- Download [sequence databases](https://github.com/GBLille/AFmassive?tab=readme-ov-file#sequence-databases)\n- Retrieve the [neural network (NN) models parameters](https://github.com/GBLille/AFmassive?tab=readme-ov-file#alphafold-neural-network-model-parameters)\n\nFor ColabFold runs, two additional installation steps are required to use MassiveFold for AFmassive runs:\n- Download [sequence databases](https://github.com/sokrypton/ColabFold?tab=readme-ov-file#generating-msas-for-large-scale-structurecomplex-predictions)\n- Retrieve the neural network (NN) models parameters](https://github.com/GBLille/AFmassive?tab=readme-ov-file#alphafold-neural-network-model-parameters)\nand move them to a 'params' folder in the sequence databases folder\n\n2. **Install MassiveFold**\n\nWe use an installation based on conda. The **install.sh** script we provide installs the conda environments using the \n`environment.yml` and `mf-colabfold.yml` files. One is created for MassiveFold and AFmassive, and another one is created \nfor ColabFold. It also creates the files architecture and set paths according to this architecture in the \n`AFmassive_params.json` and/or `ColabFold_params.json` parameters file.  \n\nHelp with:\n```bash\ncd MassiveFold\n./install.sh -h\n```\n\nInstallation with:\n```bash\n./install.sh [--only-envs] || --alphafold-db <AF_DB_PATH> --colabfold-db <CF_DB_PATH> [--no-env]\n\nOptions:\n  --alphafold-db <AF_DB_PATH>: path to AlphaFold database\n  --colabfold-db <CF_DB_PATH>: path to ColabFold database\n  --no-env: do not install the environments, only sets up the files and parameters.\n    At least one of --alphafold-db or colabfold-db is required with this option.\n  --only-envs: only install the environments (other arguments are not used)\n```\n\nThis file tree displays the files' architecture after running `./install.sh`.\n\n<a id=\"tree\"></a> \n```txt\nMassiveFold\n\u251c\u2500\u2500 install.sh\n\u251c\u2500\u2500 ...\n\u251c\u2500\u2500 examples\n\u251c\u2500\u2500 massivefold\n\u2514\u2500\u2500 massivefold_runs\n    \u251c\u2500\u2500 AFmassive_params.json\n    \u251c\u2500\u2500 ColabFold_params.json\n    \u251c\u2500\u2500 headers/\n        \u251c\u2500\u2500 example_header_alignment_jeanzay.slurm\n        \u251c\u2500\u2500 example_header_jobarray_jeanzay.slurm\n        \u2514\u2500\u2500 example_header_post_treatment_jeanzay.slurm\n    \u251c\u2500\u2500 input/\n    \u251c\u2500\u2500 log/\n    \u251c\u2500\u2500 output/\n    \u2514\u2500\u2500 run_massivefold.sh\n```\nThe directory `massivefold_runs` is created, which contains:\n- `AFmassive_params.json` to set the run parameters for AFmassive,\n- `ColabFold_params.json` to set the run parameters for ColabFold,\n- `headers`' directory, containing the headers that must be created to use MassiveFold. Examples are given for the Jean \nZay national CNRS French cluster (ready to use, see the [installation on Jean Zay](#install-on-jean-zay) to run \nMassiveFold directly on Jean Zay),\n- `input` which contains the FASTA sequences,\n- `log` with the logs of the MassiveFold runs (debug purposes), \n- `output` which contains the predictions, \n- `run_massivefold.sh` being the script to run [MassiveFold](#usage)\n\n**On a GPU cluster:**  \n- the **administrator** only needs to install the environments: \n```bash\ncd MassiveFold\n./install.sh --only-envs\n```\n- the **user** only needs to install the remaining files:\n```bash\ncd MassiveFold\n./install.sh --no-env --alphafold-db <AF_DB_PATH> --colabfold-db <CF_DB_PATH>\n```\n\n3. **Create header files**  \n\nRefer to [Jobfile's header](#jobfiles-header) for this installation step.\n\nTo run MassiveFold in parallel on your cluster/server, it is **required** to build custom jobfile headers for each step. \nThey are three and should be named as follows: `{step}.slurm` (`alignment.slurm`, `jobarray.slurm` and \n`post_treatment.slurm`). The headers contain the parameters to give to SLURM for the jobs running (#SBATCH parameters). \nThey have to be added in `MassiveFold/massivefold_runs/headers/` directory. Depending on your installation it can be \nanother path, this path has to be set in the `AFmassive_params.json` and/or `ColabFold_params.json` as \n`jobfile_headers_dir` parameter.\n\nHeaders for Jean Zay cluster are provided as examples to follow (named `example_header_<step>_jeanzay.slurm`), to use \nthem, rename each one following the previously mentioned naming convention.  \n\n4. **Set custom parameters**\n\nEach cluster has its own specifications in parameterizing job files. For flexibility needs, you can add your custom \nparameters in your headers, and then in the `AFmassive_params.json` and/or `ColabFold_params.json` file so that you can \ndynamically change their values in the json file.  \n\nTo illustrate these \"special needs\", here is an example of parameters that can be used on the French national Jean Zay \ncluster to specify GPU type, time limits or the project on which the hours are used:\n\nGo to `AFmassive_params.json` and/or `ColabFold_params.json` location:\n```bash\ncd MassiveFold/massivefold_runs\n```\nModify `AFmassive_params.json` and/or `ColabFold_params.json`:\n```json\n\"custom_params\":\n{\n    \"jeanzay_gpu\": \"v100\",\n    \"jeanzay_project\": \"<project>\",\n    \"jeanzay_account\": \"<project>@v100\",\n    \"jeanzay_gpu_with_memory\": \"v100-32g\",\n    \"jeanzay_alignment_time\": \"05:00:00\",\n    \"jeanzay_jobarray_time\": \"15:00:00\"\n}\n```\nAnd specify them in the jobfile headers (such as here for `MassiveFold/headers/jobarray.slurm`) \n```\n#SBATCH --account=$jeanzay_account\n#SBATCH -C $jeanzay_gpu_with_memory\n#SBATCH --time=$jeanzay_jobarray_time\n```"
      },
      "source": "https://raw.githubusercontent.com/GBLille/MassiveFold/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Building",
        "parent_header": [
          "MassiveFold",
          "Installation",
          "Jobfile's header"
        ],
        "type": "Text_excerpt",
        "value": "The jobfiles for each step are built by combining the jobfile header that you have to create in \n**MassiveFold/massivefold_runs/headers/** with the jobfile body in **massivefold/parallelization/templates/**.\n\nOnly the headers have to be adapted in function of your computing infrastructure. They contain the parameters to give to \nSLURM for the job running (#SBATCH parameters).\nEach of the three headers (`alignment`, `jobarray` and `post treatment`) must be located in the **headers** directory \n(see [File architecture](#installation) section).\n\nTheir names should be identical to:\n* **alignment.slurm**\n* **jobarray.slurm**\n* **post_treatment.slurm**\n\nThe templates work with the parameters provided in `AFmassive_params.json` and/or `ColabFold_params.json` file, given \nas a parameter to the **run_massivefold.sh** script.  \nThese parameters are substituted in the template job files thanks to the python library [string.Template](https://docs.python.org/3.8/library/string.html#template-strings).  \nRefer to [How to add a parameter](#how-to-add-a-parameter) for parameters substitution.\n\n- **Requirement:** In the jobarray's jobfile header (*massivefold_runs/headers/jobarray.slurm*) should be stated that \nit is a job array and the number of tasks in it has to be given. The task number argument is substituted with the \n*$substitute_batch_number* parameter.  \nIt should be expressed as:\n```\n#SBATCH --array=0-$substitute_batch_number\n```\nFor example, if there are 45 batches, with 1 batch per task of the job array, the substituted expression will be:\n```\n#SBATCH --array=0-44\n```\n- Add these lines too in the headers, it is necessary to store MassiveFold's log:\n\nIn **alignment.slurm**:\n```\n#SBATCH --error=${logs_dir}/${sequence_name}/${run_name}/alignment.log\n#SBATCH --output=${logs_dir}/${sequence_name}/${run_name}/alignment.log\n```\nIn **jobarray.slurm**:\n\n```\n#SBATCH --error=${logs_dir}/${sequence_name}/${run_name}/jobarray_%a.log\n#SBATCH --output=${logs_dir}/${sequence_name}/${run_name}/jobarray_%a.log\n```\nIn **post_treatment.slurm**:\n```\n#SBATCH --output=${logs_dir}/${sequence_name}/${run_name}/post_treatment.log\n#SBATCH --error=${logs_dir}/${sequence_name}/${run_name}/post_treatment.log\n```\nWe provide headers for the Jean Zay French CNRS national GPU cluster ([IDRIS](http://www.idris.fr/),) \nthat can also be used as examples for your own infrastructure.\n"
      },
      "source": "https://raw.githubusercontent.com/GBLille/MassiveFold/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "How to add a parameter",
        "parent_header": [
          "MassiveFold",
          "Installation",
          "Jobfile's header"
        ],
        "type": "Text_excerpt",
        "value": "- Add **\\$new_parameter** or **\\$\\{new_parameter\\}** in the template's header where you want its value to be set and \nin the \"custom_params\" section of `AFmassive_params.json` and/or `ColabFold_params.json` where its value can be \nspecified and modified conveniently for each run.\n\n**Example** in the json parameters file for Jean Zay headers:\n```json\n\"custom_params\":\n{\n    \"jeanzay_account\": \"project@v100\",\n    \"jeanzay_gpu_with_memory\": \"v100-32g\",\n    \"jeanzay_jobarray_time\": \"10:00:00\"\n}\n```\nWhere \"project\" is your 3 letter project with allocated hours on Jean Zay.\n\n- These parameters will be substituted in the header where the parameter keys are located:\n\n```\n#SBATCH --account=$jeanzay_account\n\n#SBATCH --error=${logs_dir}/${sequence_name}/${run_name}/jobarray_%a.log\n#SBATCH --output=${logs_dir}/${sequence_name}/${run_name}/jobarray_%a.log\n\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=1\n#SBATCH --cpus-per-task=8\n#SBATCH --hint=nomultithread\n#SBATCH --gpus-per-node=1\n#SBATCH --array=0-$substitute_batch_number\n#SBATCH --time=$jeanzay_jobarray_time\n##SBATCH --qos=qos_gpu-t4               # Uncomment for job requiring more than 20h (max 16 GPUs)\n#SBATCH -C $jeanzay_gpu_with_memory     # GPU type+memory\n```\n- Never use single \\$ symbol for other uses than parameter/value substitution from the json file.\\\nTo use $ inside the template files (bash variables or other uses), use instead $$ as an escape following \n[string.Template](https://docs.python.org/3.8/library/string.html#template-strings) documentation.\n"
      },
      "source": "https://raw.githubusercontent.com/GBLille/MassiveFold/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Installation on Jean Zay",
        "parent_header": [
          "MassiveFold",
          "Installation"
        ],
        "type": "Text_excerpt",
        "value": "To use it on Jean Zay, the only installation steps are:\n```bash\ngit clone https://github.com/GBLille/MassiveFold.git\n./install.sh\n```\nThe same [file architecture](#tree) is built, follow the [usage](#usage) section to use MassiveFold.\n"
      },
      "source": "https://raw.githubusercontent.com/GBLille/MassiveFold/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Hardware recommendations",
        "parent_header": [
          "MassiveFold",
          "Installation"
        ],
        "type": "Text_excerpt",
        "value": "We recommend a 4 TB fast storage to host the sequence databases for AFmassive and ColabFold. The requirements in RAM \ndepend on the length of the sequence(s) but 128GB should work for the majority of cases, both for AFmassive and \nColabFold. A GPU with at least 16 GB RAM is also recommended, knowing that more memory allows to model larger systems. \n"
      },
      "source": "https://raw.githubusercontent.com/GBLille/MassiveFold/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 0.9954321440134921,
      "result": {
        "original_header": "MassiveFold: parallelize protein structure prediction",
        "type": "Text_excerpt",
        "value": "A run is composed of three steps:  \n1. **alignment**: on CPU, sequence alignments is the first step (can be skipped if alignments are already computed) \n"
      },
      "source": "https://raw.githubusercontent.com/GBLille/MassiveFold/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9988168689725586,
      "result": {
        "original_header": "massivefold_plots: output representation",
        "type": "Text_excerpt",
        "value": "Here is an example of a basic command you can run:\n```bash\nconda activate massivefold\nmassivefold_plots.py --input_path=<path_to_MF_output> --chosen_plots=DM_plddt_PAE\n```\n \n"
      },
      "source": "https://raw.githubusercontent.com/GBLille/MassiveFold/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9262305834840044,
      "result": {
        "original_header": "Required arguments",
        "type": "Text_excerpt",
        "value": "- **--input_path**: it designates MassiveFold output dir and the directory to store the plots except if you want them \nin a separate directory (use `--output_path` for this purpose) \n"
      },
      "source": "https://raw.githubusercontent.com/GBLille/MassiveFold/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9997546175601373,
      "result": {
        "original_header": "Facultative arguments",
        "type": "Text_excerpt",
        "value": "More help with\n```bash\nconda activate massivefold\nmassivefold_plots.py --help\n```\n \n"
      },
      "source": "https://raw.githubusercontent.com/GBLille/MassiveFold/main/README.md",
      "technique": "supervised_classification"
    }
  ],
  "invocation": [
    {
      "confidence": 0.8750859636237599,
      "result": {
        "original_header": "massivefold_plots: output representation",
        "type": "Text_excerpt",
        "value": "Here is an example of a basic command you can run:\n```bash\nconda activate massivefold\nmassivefold_plots.py --input_path=<path_to_MF_output> --chosen_plots=DM_plddt_PAE\n```\n \n"
      },
      "source": "https://raw.githubusercontent.com/GBLille/MassiveFold/main/README.md",
      "technique": "supervised_classification"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/GBLille/MassiveFold/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ""
      },
      "technique": "GitHub_API"
    }
  ],
  "license": [
    {
      "confidence": 1,
      "result": {
        "name": "Other",
        "spdx_id": "NOASSERTION",
        "type": "License",
        "url": null,
        "value": null
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "type": "File_dump",
        "value": "\n  CeCILL FREE SOFTWARE LICENSE AGREEMENT\n\nVersion 2.1 dated 2013-06-21\n\n\n    Notice\n\nThis Agreement is a Free Software license agreement that is the result\nof discussions between its authors in order to ensure compliance with\nthe two main principles guiding its drafting:\n\n  * firstly, compliance with the principles governing the distribution\n    of Free Software: access to source code, broad rights granted to users,\n  * secondly, the election of a governing law, French law, with which it\n    is conformant, both as regards the law of torts and intellectual\n    property law, and the protection that it offers to both authors and\n    holders of the economic rights over software.\n\nThe authors of the CeCILL (for Ce[a] C[nrs] I[nria] L[ogiciel] L[ibre]) \nlicense are: \n\nCommissariat \u00e0 l'\u00e9nergie atomique et aux \u00e9nergies alternatives - CEA, a\npublic scientific, technical and industrial research establishment,\nhaving its principal place of business at 25 rue Leblanc, immeuble Le\nPonant D, 75015 Paris, France.\n\nCentre National de la Recherche Scientifique - CNRS, a public scientific\nand technological establishment, having its principal place of business\nat 3 rue Michel-Ange, 75794 Paris cedex 16, France.\n\nInstitut National de Recherche en Informatique et en Automatique -\nInria, a public scientific and technological establishment, having its\nprincipal place of business at Domaine de Voluceau, Rocquencourt, BP\n105, 78153 Le Chesnay cedex, France.\n\n\n    Preamble\n\nThe purpose of this Free Software license agreement is to grant users\nthe right to modify and redistribute the software governed by this\nlicense within the framework of an open source distribution model.\n\nThe exercising of this right is conditional upon certain obligations for\nusers so as to preserve this status for all subsequent redistributions.\n\nIn consideration of access to the source code and the rights to copy,\nmodify and redistribute granted by the license, users are provided only\nwith a limited warranty and the software's author, the holder of the\neconomic rights, and the successive licensors only have limited liability.\n\nIn this respect, the risks associated with loading, using, modifying\nand/or developing or reproducing the software by the user are brought to\nthe user's attention, given its Free Software status, which may make it\ncomplicated to use, with the result that its use is reserved for\ndevelopers and experienced professionals having in-depth computer\nknowledge. Users are therefore encouraged to load and test the\nsuitability of the software as regards their requirements in conditions\nenabling the security of their systems and/or data to be ensured and,\nmore generally, to use and operate it in the same conditions of\nsecurity. This Agreement may be freely reproduced and published,\nprovided it is not altered, and that no provisions are either added or\nremoved herefrom.\n\nThis Agreement may apply to any or all software for which the holder of\nthe economic rights decides to submit the use thereof to its provisions.\n\nFrequently asked questions can be found on the official website of the\nCeCILL licenses family (http://www.cecill.info/index.en.html) for any \nnecessary clarification.\n\n\n    Article 1 - DEFINITIONS\n\nFor the purpose of this Agreement, when the following expressions\ncommence with a capital letter, they shall have the following meaning:\n\nAgreement: means this license agreement, and its possible subsequent\nversions and annexes.\n\nSoftware: means the software in its Object Code and/or Source Code form\nand, where applicable, its documentation, \"as is\" when the Licensee\naccepts the Agreement.\n\nInitial Software: means the Software in its Source Code and possibly its\nObject Code form and, where applicable, its documentation, \"as is\" when\nit is first distributed under the terms and conditions of the Agreement.\n\nModified Software: means the Software modified by at least one\nContribution.\n\nSource Code: means all the Software's instructions and program lines to\nwhich access is required so as to modify the Software.\n\nObject Code: means the binary files originating from the compilation of\nthe Source Code.\n\nHolder: means the holder(s) of the economic rights over the Initial\nSoftware.\n\nLicensee: means the Software user(s) having accepted the Agreement.\n\nContributor: means a Licensee having made at least one Contribution.\n\nLicensor: means the Holder, or any other individual or legal entity, who\ndistributes the Software under the Agreement.\n\nContribution: means any or all modifications, corrections, translations,\nadaptations and/or new functions integrated into the Software by any or\nall Contributors, as well as any or all Internal Modules.\n\nModule: means a set of sources files including their documentation that\nenables supplementary functions or services in addition to those offered\nby the Software.\n\nExternal Module: means any or all Modules, not derived from the\nSoftware, so that this Module and the Software run in separate address\nspaces, with one calling the other when they are run.\n\nInternal Module: means any or all Module, connected to the Software so\nthat they both execute in the same address space.\n\nGNU GPL: means the GNU General Public License version 2 or any\nsubsequent version, as published by the Free Software Foundation Inc.\n\nGNU Affero GPL: means the GNU Affero General Public License version 3 or\nany subsequent version, as published by the Free Software Foundation Inc.\n\nEUPL: means the European Union Public License version 1.1 or any\nsubsequent version, as published by the European Commission.\n\nParties: mean both the Licensee and the Licensor.\n\nThese expressions may be used both in singular and plural form.\n\n\n    Article 2 - PURPOSE\n\nThe purpose of the Agreement is the grant by the Licensor to the\nLicensee of a non-exclusive, transferable and worldwide license for the\nSoftware as set forth in Article 5 <#scope> hereinafter for the whole\nterm of the protection granted by the rights over said Software.\n\n\n    Article 3 - ACCEPTANCE\n\n3.1 The Licensee shall be deemed as having accepted the terms and\nconditions of this Agreement upon the occurrence of the first of the\nfollowing events:\n\n  * (i) loading the Software by any or all means, notably, by\n    downloading from a remote server, or by loading from a physical medium;\n  * (ii) the first time the Licensee exercises any of the rights granted\n    hereunder.\n\n3.2 One copy of the Agreement, containing a notice relating to the\ncharacteristics of the Software, to the limited warranty, and to the\nfact that its use is restricted to experienced users has been provided\nto the Licensee prior to its acceptance as set forth in Article 3.1\n<#accepting> hereinabove, and the Licensee hereby acknowledges that it\nhas read and understood it.\n\n\n    Article 4 - EFFECTIVE DATE AND TERM\n\n\n      4.1 EFFECTIVE DATE\n\nThe Agreement shall become effective on the date when it is accepted by\nthe Licensee as set forth in Article 3.1 <#accepting>.\n\n\n      4.2 TERM\n\nThe Agreement shall remain in force for the entire legal term of\nprotection of the economic rights over the Software.\n\n\n    Article 5 - SCOPE OF RIGHTS GRANTED\n\nThe Licensor hereby grants to the Licensee, who accepts, the following\nrights over the Software for any or all use, and for the term of the\nAgreement, on the basis of the terms and conditions set forth hereinafter.\n\nBesides, if the Licensor owns or comes to own one or more patents\nprotecting all or part of the functions of the Software or of its\ncomponents, the Licensor undertakes not to enforce the rights granted by\nthese patents against successive Licensees using, exploiting or\nmodifying the Software. If these patents are transferred, the Licensor\nundertakes to have the transferees subscribe to the obligations set\nforth in this paragraph.\n\n\n      5.1 RIGHT OF USE\n\nThe Licensee is authorized to use the Software, without any limitation\nas to its fields of application, with it being hereinafter specified\nthat this comprises:\n\n 1. permanent or temporary reproduction of all or part of the Software\n    by any or all means and in any or all form.\n\n 2. loading, displaying, running, or storing the Software on any or all\n    medium.\n\n 3. entitlement to observe, study or test its operation so as to\n    determine the ideas and principles behind any or all constituent\n    elements of said Software. This shall apply when the Licensee\n    carries out any or all loading, displaying, running, transmission or\n    storage operation as regards the Software, that it is entitled to\n    carry out hereunder.\n\n\n      5.2 ENTITLEMENT TO MAKE CONTRIBUTIONS\n\nThe right to make Contributions includes the right to translate, adapt,\narrange, or make any or all modifications to the Software, and the right\nto reproduce the resulting software.\n\nThe Licensee is authorized to make any or all Contributions to the\nSoftware provided that it includes an explicit notice that it is the\nauthor of said Contribution and indicates the date of the creation thereof.\n\n\n      5.3 RIGHT OF DISTRIBUTION\n\nIn particular, the right of distribution includes the right to publish,\ntransmit and communicate the Software to the general public on any or\nall medium, and by any or all means, and the right to market, either in\nconsideration of a fee, or free of charge, one or more copies of the\nSoftware by any means.\n\nThe Licensee is further authorized to distribute copies of the modified\nor unmodified Software to third parties according to the terms and\nconditions set forth hereinafter.\n\n\n        5.3.1 DISTRIBUTION OF SOFTWARE WITHOUT MODIFICATION\n\nThe Licensee is authorized to distribute true copies of the Software in\nSource Code or Object Code form, provided that said distribution\ncomplies with all the provisions of the Agreement and is accompanied by:\n\n 1. a copy of the Agreement,\n\n 2. a notice relating to the limitation of both the Licensor's warranty\n    and liability as set forth in Articles 8 and 9,\n\nand that, in the event that only the Object Code of the Software is\nredistributed, the Licensee allows effective access to the full Source\nCode of the Software for a period of at least three years from the\ndistribution of the Software, it being understood that the additional\nacquisition cost of the Source Code shall not exceed the cost of the\ndata transfer.\n\n\n        5.3.2 DISTRIBUTION OF MODIFIED SOFTWARE\n\nWhen the Licensee makes a Contribution to the Software, the terms and\nconditions for the distribution of the resulting Modified Software\nbecome subject to all the provisions of this Agreement.\n\nThe Licensee is authorized to distribute the Modified Software, in\nsource code or object code form, provided that said distribution\ncomplies with all the provisions of the Agreement and is accompanied by:\n\n 1. a copy of the Agreement,\n\n 2. a notice relating to the limitation of both the Licensor's warranty\n    and liability as set forth in Articles 8 and 9,\n\nand, in the event that only the object code of the Modified Software is\nredistributed,\n\n 3. a note stating the conditions of effective access to the full source\n    code of the Modified Software for a period of at least three years\n    from the distribution of the Modified Software, it being understood\n    that the additional acquisition cost of the source code shall not\n    exceed the cost of the data transfer.\n\n\n        5.3.3 DISTRIBUTION OF EXTERNAL MODULES\n\nWhen the Licensee has developed an External Module, the terms and\nconditions of this Agreement do not apply to said External Module, that\nmay be distributed under a separate license agreement.\n\n\n        5.3.4 COMPATIBILITY WITH OTHER LICENSES\n\nThe Licensee can include a code that is subject to the provisions of one\nof the versions of the GNU GPL, GNU Affero GPL and/or EUPL in the\nModified or unmodified Software, and distribute that entire code under\nthe terms of the same version of the GNU GPL, GNU Affero GPL and/or EUPL.\n\nThe Licensee can include the Modified or unmodified Software in a code\nthat is subject to the provisions of one of the versions of the GNU GPL,\nGNU Affero GPL and/or EUPL and distribute that entire code under the\nterms of the same version of the GNU GPL, GNU Affero GPL and/or EUPL.\n\n\n    Article 6 - INTELLECTUAL PROPERTY\n\n\n      6.1 OVER THE INITIAL SOFTWARE\n\nThe Holder owns the economic rights over the Initial Software. Any or\nall use of the Initial Software is subject to compliance with the terms\nand conditions under which the Holder has elected to distribute its work\nand no one shall be entitled to modify the terms and conditions for the\ndistribution of said Initial Software.\n\nThe Holder undertakes that the Initial Software will remain ruled at\nleast by this Agreement, for the duration set forth in Article 4.2 <#term>.\n\n\n      6.2 OVER THE CONTRIBUTIONS\n\nThe Licensee who develops a Contribution is the owner of the\nintellectual property rights over this Contribution as defined by\napplicable law.\n\n\n      6.3 OVER THE EXTERNAL MODULES\n\nThe Licensee who develops an External Module is the owner of the\nintellectual property rights over this External Module as defined by\napplicable law and is free to choose the type of agreement that shall\ngovern its distribution.\n\n\n      6.4 JOINT PROVISIONS\n\nThe Licensee expressly undertakes:\n\n 1. not to remove, or modify, in any manner, the intellectual property\n    notices attached to the Software;\n\n 2. to reproduce said notices, in an identical manner, in the copies of\n    the Software modified or not.\n\nThe Licensee undertakes not to directly or indirectly infringe the\nintellectual property rights on the Software of the Holder and/or\nContributors, and to take, where applicable, vis-\u00e0-vis its staff, any\nand all measures required to ensure respect of said intellectual\nproperty rights of the Holder and/or Contributors.\n\n\n    Article 7 - RELATED SERVICES\n\n7.1 Under no circumstances shall the Agreement oblige the Licensor to\nprovide technical assistance or maintenance services for the Software.\n\nHowever, the Licensor is entitled to offer this type of services. The\nterms and conditions of such technical assistance, and/or such\nmaintenance, shall be set forth in a separate instrument. Only the\nLicensor offering said maintenance and/or technical assistance services\nshall incur liability therefor.\n\n7.2 Similarly, any Licensor is entitled to offer to its licensees, under\nits sole responsibility, a warranty, that shall only be binding upon\nitself, for the redistribution of the Software and/or the Modified\nSoftware, under terms and conditions that it is free to decide. Said\nwarranty, and the financial terms and conditions of its application,\nshall be subject of a separate instrument executed between the Licensor\nand the Licensee.\n\n\n    Article 8 - LIABILITY\n\n8.1 Subject to the provisions of Article 8.2, the Licensee shall be\nentitled to claim compensation for any direct loss it may have suffered\nfrom the Software as a result of a fault on the part of the relevant\nLicensor, subject to providing evidence thereof.\n\n8.2 The Licensor's liability is limited to the commitments made under\nthis Agreement and shall not be incurred as a result of in particular:\n(i) loss due the Licensee's total or partial failure to fulfill its\nobligations, (ii) direct or consequential loss that is suffered by the\nLicensee due to the use or performance of the Software, and (iii) more\ngenerally, any consequential loss. In particular the Parties expressly\nagree that any or all pecuniary or business loss (i.e. loss of data,\nloss of profits, operating loss, loss of customers or orders,\nopportunity cost, any disturbance to business activities) or any or all\nlegal proceedings instituted against the Licensee by a third party,\nshall constitute consequential loss and shall not provide entitlement to\nany or all compensation from the Licensor.\n\n\n    Article 9 - WARRANTY\n\n9.1 The Licensee acknowledges that the scientific and technical\nstate-of-the-art when the Software was distributed did not enable all\npossible uses to be tested and verified, nor for the presence of\npossible defects to be detected. In this respect, the Licensee's\nattention has been drawn to the risks associated with loading, using,\nmodifying and/or developing and reproducing the Software which are\nreserved for experienced users.\n\nThe Licensee shall be responsible for verifying, by any or all means,\nthe suitability of the product for its requirements, its good working\norder, and for ensuring that it shall not cause damage to either persons\nor properties.\n\n9.2 The Licensor hereby represents, in good faith, that it is entitled\nto grant all the rights over the Software (including in particular the\nrights set forth in Article 5 <#scope>).\n\n9.3 The Licensee acknowledges that the Software is supplied \"as is\" by\nthe Licensor without any other express or tacit warranty, other than\nthat provided for in Article 9.2 <#good-faith> and, in particular,\nwithout any warranty as to its commercial value, its secured, safe,\ninnovative or relevant nature.\n\nSpecifically, the Licensor does not warrant that the Software is free\nfrom any error, that it will operate without interruption, that it will\nbe compatible with the Licensee's own equipment and software\nconfiguration, nor that it will meet the Licensee's requirements.\n\n9.4 The Licensor does not either expressly or tacitly warrant that the\nSoftware does not infringe any third party intellectual property right\nrelating to a patent, software or any other property right. Therefore,\nthe Licensor disclaims any and all liability towards the Licensee\narising out of any or all proceedings for infringement that may be\ninstituted in respect of the use, modification and redistribution of the\nSoftware. Nevertheless, should such proceedings be instituted against\nthe Licensee, the Licensor shall provide it with technical and legal\nexpertise for its defense. Such technical and legal expertise shall be\ndecided on a case-by-case basis between the relevant Licensor and the\nLicensee pursuant to a memorandum of understanding. The Licensor\ndisclaims any and all liability as regards the Licensee's use of the\nname of the Software. No warranty is given as regards the existence of\nprior rights over the name of the Software or as regards the existence\nof a trademark.\n\n\n    Article 10 - TERMINATION\n\n10.1 In the event of a breach by the Licensee of its obligations\nhereunder, the Licensor may automatically terminate this Agreement\nthirty (30) days after notice has been sent to the Licensee and has\nremained ineffective.\n\n10.2 A Licensee whose Agreement is terminated shall no longer be\nauthorized to use, modify or distribute the Software. However, any\nlicenses that it may have granted prior to termination of the Agreement\nshall remain valid subject to their having been granted in compliance\nwith the terms and conditions hereof.\n\n\n    Article 11 - MISCELLANEOUS\n\n\n      11.1 EXCUSABLE EVENTS\n\nNeither Party shall be liable for any or all delay, or failure to\nperform the Agreement, that may be attributable to an event of force\nmajeure, an act of God or an outside cause, such as defective\nfunctioning or interruptions of the electricity or telecommunications\nnetworks, network paralysis following a virus attack, intervention by\ngovernment authorities, natural disasters, water damage, earthquakes,\nfire, explosions, strikes and labor unrest, war, etc.\n\n11.2 Any failure by either Party, on one or more occasions, to invoke\none or more of the provisions hereof, shall under no circumstances be\ninterpreted as being a waiver by the interested Party of its right to\ninvoke said provision(s) subsequently.\n\n11.3 The Agreement cancels and replaces any or all previous agreements,\nwhether written or oral, between the Parties and having the same\npurpose, and constitutes the entirety of the agreement between said\nParties concerning said purpose. No supplement or modification to the\nterms and conditions hereof shall be effective as between the Parties\nunless it is made in writing and signed by their duly authorized\nrepresentatives.\n\n11.4 In the event that one or more of the provisions hereof were to\nconflict with a current or future applicable act or legislative text,\nsaid act or legislative text shall prevail, and the Parties shall make\nthe necessary amendments so as to comply with said act or legislative\ntext. All other provisions shall remain effective. Similarly, invalidity\nof a provision of the Agreement, for any reason whatsoever, shall not\ncause the Agreement as a whole to be invalid.\n\n\n      11.5 LANGUAGE\n\nThe Agreement is drafted in both French and English and both versions\nare deemed authentic.\n\n\n    Article 12 - NEW VERSIONS OF THE AGREEMENT\n\n12.1 Any person is authorized to duplicate and distribute copies of this\nAgreement.\n\n12.2 So as to ensure coherence, the wording of this Agreement is\nprotected and may only be modified by the authors of the License, who\nreserve the right to periodically publish updates or new versions of the\nAgreement, each with a separate number. These subsequent versions may\naddress new issues encountered by Free Software.\n\n12.3 Any Software distributed under a given version of the Agreement may\nonly be subsequently distributed under the same version of the Agreement\nor a subsequent version, subject to the provisions of Article 5.3.4\n<#compatibility>.\n\n\n    Article 13 - GOVERNING LAW AND JURISDICTION\n\n13.1 The Agreement is governed by French law. The Parties agree to\nendeavor to seek an amicable solution to any disagreements or disputes\nthat may arise during the performance of the Agreement.\n\n13.2 Failing an amicable solution within two (2) months as from their\noccurrence, and unless emergency proceedings are necessary, the\ndisagreements or disputes shall be referred to the Paris Courts having\njurisdiction, by the more diligent Party.\n\n"
      },
      "source": "https://raw.githubusercontent.com/GBLille/MassiveFold/main/LICENSE",
      "technique": "file_exploration"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "MassiveFold"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "User",
        "value": "GBLille"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 73518,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Shell",
        "size": 19121,
        "type": "Programming_language",
        "value": "Shell"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/GBLille/MassiveFold/main/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "releases": [
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "GBLille",
          "type": "User"
        },
        "date_created": "2024-10-01T14:17:53Z",
        "date_published": "2024-10-01T14:22:18Z",
        "description": "- massivefold_plots.py: modified for script calling from another python program putting plot in axes; legacy logs recycling parsing added\r\n- extract_scores.py: added support for monomeric runs",
        "html_url": "https://github.com/GBLille/MassiveFold/releases/tag/v1.2.5",
        "name": "v1.2.5",
        "release_id": 177817117,
        "tag": "v1.2.5",
        "tarball_url": "https://api.github.com/repos/GBLille/MassiveFold/tarball/v1.2.5",
        "type": "Release",
        "url": "https://api.github.com/repos/GBLille/MassiveFold/releases/177817117",
        "value": "https://api.github.com/repos/GBLille/MassiveFold/releases/177817117",
        "zipball_url": "https://api.github.com/repos/GBLille/MassiveFold/zipball/v1.2.5"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "GBLille",
          "type": "User"
        },
        "date_created": "2024-09-12T11:21:43Z",
        "date_published": "2024-09-12T11:32:11Z",
        "description": "- chain IDs are reassigned automatically\r\n- `--max_template_date` parameter added to AFmassive's json\r\n- `-j`parameter added to `run_massivefold.sh` to wait for an alignment to finish when running multiple runs\r\n- `gather_runs.py`: bug fix and rank parameter added\r\n- `extract_scores.py` added\r\n- recycle plots: bug fix\r\n-  bug fix on fasta file names for ColabFold",
        "html_url": "https://github.com/GBLille/MassiveFold/releases/tag/v1.2.4",
        "name": "v1.2.4",
        "release_id": 174739160,
        "tag": "v1.2.4",
        "tarball_url": "https://api.github.com/repos/GBLille/MassiveFold/tarball/v1.2.4",
        "type": "Release",
        "url": "https://api.github.com/repos/GBLille/MassiveFold/releases/174739160",
        "value": "https://api.github.com/repos/GBLille/MassiveFold/releases/174739160",
        "zipball_url": "https://api.github.com/repos/GBLille/MassiveFold/zipball/v1.2.4"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "GBLille",
          "type": "User"
        },
        "date_created": "2024-05-17T15:21:14Z",
        "date_published": "2024-05-17T15:29:11Z",
        "description": "- relaxation is now supported by colabfold_relax script and doesn't appear anymore in AFmassive parameters\r\n- in massivefold_plots.py, recycling plots are now also supported for ColabFold multimers and ColabFold monomers\r\n- new ranking for monomer predictions by ptm: ranking_ptm.json\r\n- gather_runs.py:\r\n  - now creates a global ranking.csv file\r\n  - --include_pickles option allows to include them either from the \\<output\\> folder directly (full pickles) or from the `light_pkl` folder (light pickles)",
        "html_url": "https://github.com/GBLille/MassiveFold/releases/tag/v1.2.3",
        "name": "v1.2.3",
        "release_id": 156293410,
        "tag": "v1.2.3",
        "tarball_url": "https://api.github.com/repos/GBLille/MassiveFold/tarball/v1.2.3",
        "type": "Release",
        "url": "https://api.github.com/repos/GBLille/MassiveFold/releases/156293410",
        "value": "https://api.github.com/repos/GBLille/MassiveFold/releases/156293410",
        "zipball_url": "https://api.github.com/repos/GBLille/MassiveFold/zipball/v1.2.3"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "GBLille",
          "type": "User"
        },
        "date_created": "2024-04-17T14:55:00Z",
        "date_published": "2024-04-17T14:56:58Z",
        "description": "- Environment fixed for jax version (set to 0.4.23)\r\n- Install.sh: check on the conda environment existence removed\r\n- Massivefold_plots.py now also takes pickles in \"light_pkl\" dir as arguments for PAEs\r\n- Fix for CF alignment plot when using AFmassive\r\n",
        "html_url": "https://github.com/GBLille/MassiveFold/releases/tag/v1.2.2",
        "name": "v1.2.2",
        "release_id": 151579528,
        "tag": "v1.2.2",
        "tarball_url": "https://api.github.com/repos/GBLille/MassiveFold/tarball/v1.2.2",
        "type": "Release",
        "url": "https://api.github.com/repos/GBLille/MassiveFold/releases/151579528",
        "value": "https://api.github.com/repos/GBLille/MassiveFold/releases/151579528",
        "zipball_url": "https://api.github.com/repos/GBLille/MassiveFold/zipball/v1.2.2"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "GBLille",
          "type": "User"
        },
        "date_created": "2024-04-12T19:04:17Z",
        "date_published": "2024-04-12T19:09:09Z",
        "description": "- Bug fixed for pkl in JSON file, path for massivefold_plots.py and plots for ColabFold\r\n- Recycling plots protected in case of misretrieval in logs",
        "html_url": "https://github.com/GBLille/MassiveFold/releases/tag/v1.2.1",
        "name": "v1.2.1",
        "release_id": 150979502,
        "tag": "v1.2.1",
        "tarball_url": "https://api.github.com/repos/GBLille/MassiveFold/tarball/v1.2.1",
        "type": "Release",
        "url": "https://api.github.com/repos/GBLille/MassiveFold/releases/150979502",
        "value": "https://api.github.com/repos/GBLille/MassiveFold/releases/150979502",
        "zipball_url": "https://api.github.com/repos/GBLille/MassiveFold/zipball/v1.2.1"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "GBLille",
          "type": "User"
        },
        "date_created": "2024-04-12T16:18:10Z",
        "date_published": "2024-04-12T16:25:04Z",
        "description": "- ColabFold added as an inference engine\r\n- 'gather_runs.py' allows to gather the predictions from several runs in a common 'all_runs' folder and rerank them all\r\n- 'pkl_format' parameter added to JSON files to reduce the size of the pkl files (full=default, light=reduced pkl, none=pkl removed)\r\n- 'lighten_pkl.py' script to reduce pkl files size",
        "html_url": "https://github.com/GBLille/MassiveFold/releases/tag/v1.2.0",
        "name": "v1.2.0",
        "release_id": 150959003,
        "tag": "v1.2.0",
        "tarball_url": "https://api.github.com/repos/GBLille/MassiveFold/tarball/v1.2.0",
        "type": "Release",
        "url": "https://api.github.com/repos/GBLille/MassiveFold/releases/150959003",
        "value": "https://api.github.com/repos/GBLille/MassiveFold/releases/150959003",
        "zipball_url": "https://api.github.com/repos/GBLille/MassiveFold/zipball/v1.2.0"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "GBLille",
          "type": "User"
        },
        "date_created": "2024-03-01T16:36:34Z",
        "date_published": "2024-03-01T16:37:36Z",
        "description": "- Bug fix: job template file fixed for monomers\r\n- Plots quality enhanced",
        "html_url": "https://github.com/GBLille/MassiveFold/releases/tag/v1.1.1",
        "release_id": 144399186,
        "tag": "v1.1.1",
        "tarball_url": "https://api.github.com/repos/GBLille/MassiveFold/tarball/v1.1.1",
        "type": "Release",
        "url": "https://api.github.com/repos/GBLille/MassiveFold/releases/144399186",
        "value": "https://api.github.com/repos/GBLille/MassiveFold/releases/144399186",
        "zipball_url": "https://api.github.com/repos/GBLille/MassiveFold/zipball/v1.1.1"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "GBLille",
          "type": "User"
        },
        "date_created": "2024-02-06T14:16:00Z",
        "date_published": "2024-02-06T14:20:17Z",
        "description": "- MassiveFold repository split into [MassiveFold](https://github.com/GBLille/MassiveFold) for parallellization and [AFmassive](https://github.com/GBLille/AFmassive) for structure prediction core\r\n- `environnement.yml` and `install.sh` files added for installation\r\n- `run_massivefold.sh` to create a run that splits automatically into 1 job on CPU for alignments, batches of jobs on GPU for structure predictions and 1 job on CPU for post treatment\r\n- plots added",
        "html_url": "https://github.com/GBLille/MassiveFold/releases/tag/v1.1.0",
        "name": "v1.1.0",
        "release_id": 140101363,
        "tag": "v1.1.0",
        "tarball_url": "https://api.github.com/repos/GBLille/MassiveFold/tarball/v1.1.0",
        "type": "Release",
        "url": "https://api.github.com/repos/GBLille/MassiveFold/releases/140101363",
        "value": "https://api.github.com/repos/GBLille/MassiveFold/releases/140101363",
        "zipball_url": "https://api.github.com/repos/GBLille/MassiveFold/zipball/v1.1.0"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "GBLille",
          "type": "User"
        },
        "date_created": "2023-07-21T10:21:21Z",
        "date_published": "2024-02-06T12:43:46Z",
        "description": "MassiveFold initial release",
        "html_url": "https://github.com/GBLille/MassiveFold/releases/tag/v1.0.0",
        "name": "v1.0.0",
        "release_id": 140082487,
        "tag": "v1.0.0",
        "tarball_url": "https://api.github.com/repos/GBLille/MassiveFold/tarball/v1.0.0",
        "type": "Release",
        "url": "https://api.github.com/repos/GBLille/MassiveFold/releases/140082487",
        "value": "https://api.github.com/repos/GBLille/MassiveFold/releases/140082487",
        "zipball_url": "https://api.github.com/repos/GBLille/MassiveFold/zipball/v1.0.0"
      },
      "technique": "GitHub_API"
    }
  ],
  "run": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Multiple runs gathering",
        "parent_header": [
          "MassiveFold",
          "Usage"
        ],
        "type": "Text_excerpt",
        "value": "We provide a `gather_runs.py` script in the `massivefold` folder that allows to collate the results of several runs. It \ngathers all the results and ranks them all.\n\nWe also provide an `extract_scores.py` script that allows to extract the scores from pickle files and create rankings\n(notably useful for interrupted runs).\n"
      },
      "source": "https://raw.githubusercontent.com/GBLille/MassiveFold/main/README.md",
      "technique": "header_analysis"
    }
  ],
  "somef_missing_categories": [
    "citation",
    "acknowledgement",
    "download",
    "requirements",
    "contact",
    "contributors",
    "documentation",
    "faq",
    "support",
    "has_build_file",
    "executable_example"
  ],
  "somef_provenance": {
    "date": "2024-10-03 23:37:37",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 21
      },
      "technique": "GitHub_API"
    }
  ],
  "type": [
    {
      "confidence": 0.82,
      "result": {
        "type": "String",
        "value": "commandline-application"
      },
      "technique": "software_type_heuristics"
    }
  ],
  "usage": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Usage",
        "parent_header": [
          "MassiveFold"
        ],
        "type": "Text_excerpt",
        "value": "Edit the `AFmassive_params.json` or `ColabFold_params.json` parameters file (see [file architecture](#tree)).  \nSet first the [parameters of your run](https://github.com/GBLille/AFmassive?tab=readme-ov-file#running-afmassive) in the \n**AFM_run** section of the `AFmassive_params.json`, for instance:\n```json\n\"AFM_run\":\n{\n    \"model_preset\": \"multimer\",\n    \"max_recycles\": \"20\",\n    \"templates\": \"true\",\n    \"dropout\": \"false\",\n    \"dropout_structure_module\": \"false\",\n    \"dropout_rates_filename\": \"\",\n    \"stop_recycling_below\": \"0\",\n    \"max_template_date\": \"2024-08-31\",\n    \"min_score\": \"0\",\n    \"max_score\": \"1\",\n    \"db_preset\": \"full_dbs\",\n    \"early_stop_tolerance\": \"0.5\",\n    \"bfd_max_hits\": \"100000\",\n    \"mgnify_max_hits\": \"501\",\n    \"uniprot_max_hits\": \"50000\",\n    \"uniref_max_hits\": \"10000\"\n}\n```\nor in the `ColabFold_params.json` file, for instance:\n```json\n\"CF_run\":\n{\n    \"model_preset\": \"multimer\",\n    \"pair_strategy\": \"greedy\",\n    \"use_dropout\": \"false\",\n    \"num_recycle\": \"20\",\n    \"recycle_early_stop_tolerance\": \"0.5\",\n    \"stop_at_score\": \"100\",\n    \"disable_cluster_profile\": \"false\"\n}\n```\n\nThen you can set the parameters of the **custom_params** section if necessary and the \n[plots section](#massivefold_plots-output-representation).\n\nActivate the conda environment, then launch MassiveFold.\n```bash\nconda activate massivefold\n./run_massivefold.sh -s <SEQUENCE_PATH> -r <RUN_NAME> -p <NUMBER_OF_PREDICTIONS_PER_MODEL> -f <JSON_PARAMETERS_FILE> \n```\n**N.B.**: on the Jean Zay cluster, load the massivefold module instead of activating the conda environment\n\nExample for AFmassive:\n```bash\n./run_massivefold.sh -s input/H1140.fasta -r afm_default_run -p 5 -f AFmassive_params.json\n```\nExample for ColabFold:\n```bash\n./run_massivefold.sh -s input/H1140.fasta -r cf_default_run -p 5 -f ColabFold_params.json -t ColabFold\n```\nIf the multiple sequence alignments have already been run and are present in the output folder, they won't be computed, \nbut you can force their recomputation with:\n```bash\n./run_massivefold.sh -s input/H1140.fasta -r afm_default_run -p 5 -f AFmassive_params.json -a\n```\nExample to only run the alignments with AFmassive (JackHMMer and HHblits):\n```bash\n./run_massivefold.sh -s input/H1140.fasta -r afm_default_run -p 1 -f AFmassive_params.json -o\n```\nor with ColabFold(MMseqs2):\n```bash\n./run_massivefold.sh -s input/H1140.fasta -r cf_default_run -p 1 -f ColabFold_params.json -t ColabFold -o\n```\n\nFor more help and list of required and facultative parameters, run:\n```bash\n./run_massivefold.sh -h\n```\nHere is the help message given by this command:\n```txt\nUsage: ./run_massivefold.sh -s str -r str -p int -f str [-t str] [ -b int | [[-C str | -c] [-w int]] ] [-m str] [-n str] [-a] [-o]\n./run_massivefold.sh -h for more details \n  Required arguments:\n    -s| --sequence: path of the sequence(s) to infer, should be a 'fasta' file \n    -r| --run: name chosen for the run to organize in outputs.\n    -p| --predictions_per_model: number of predictions computed for each neural network model.\n    -f| --parameters: json file's path containing the parameters used for this run.\n\n  Facultative arguments:\n    -b| --batch_size: (default: 25) number of predictions per batch, should not be higher than -p.\n    -C| --calibration_from: path of a previous run to calibrate the batch size from (see --calibrate).\n    -w| --wall_time: (default: 20) total time available for calibration computations, unit is hours.\n    -m| --msas_precomputed: path to directory that contains computed msas.\n    -n| --top_n_models: uses the n neural network models with best ranking confidence from this run's path.\n    -j| --jobid: jobid of an alignment job to wait for inference, skips the alignments.\n\n  Facultative options:\n    -t| --tool_to_use: (default: 'AFmassive') Use either AFmassive or ColabFold in structure prediction for MassiveFold\n    -o| --only_msas: only compute alignments, the first step of MassiveFold\n    -c| --calibrate: calibrate --batch_size value. Searches from the previous runs for the same 'fasta' path given\n        in --sequence and uses the longest prediction time found to compute the maximal number of predictions per batch.\n        This maximal number depends on the total time given by --wall_time.\n    -a| --recompute_msas: purges previous alignment step and recomputes msas.\n```"
      },
      "source": "https://raw.githubusercontent.com/GBLille/MassiveFold/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Inference workflow",
        "parent_header": [
          "MassiveFold",
          "Usage"
        ],
        "type": "Text_excerpt",
        "value": "It launches MassiveFold with the same parameters introduced above but instead of running AFmassive or ColabFold a single \ntime, it divides it into multiple batches.\n\nFor the following examples, we assume that **--model_preset=multimer** as it is the majority of cases to run MassiveFold\nin parallel.\n\nHowever, **--model_preset=monomer_ptm** works too and needs to be adapted accordingly, at least the models to use (if \nparameter not set as default).\n\nYou can decide how the run will be divided by assigning `run_massivefold.sh` parameters *e.g.*:\n\n```bash\n./run_massivefold.sh -s ./input/H1140.fasta -r 1005_preds -p 67 -b 25 -f AFmassive_params.json\n```\n\nThe predictions are computed individually for each neural network (NN) model,  **-p** or **--predictions_per_model** \nallows to specify the number of predictions desired for each chosen model.  \nThese **--predictions_per_model** are then divided into batches with a fixed **-b** or **--batch_size** to optimize the \nrun in parallel as each batch can be computed on a different GPU, if available.  \nThe last batch of each NN model is generally smaller than the others to match the number of predictions fixed by \n**--predictions_per_model**.\n\n***N.B.***: an interest to use `run_massivefold.sh` on a single server with a single GPU is to be able to run massive \nsampling for a structure in low priority, allowing other jobs with higher priority to be run in between.\n\nFor example, with **-b 25** and **-p 67** the predictions are divided into the following batches (separated runs), which \nare repeated for each NN model:\n\n  1.  First batch: **--start_prediction=0** and **--end_prediction=24**\n  2.  Second batch: **--start_prediction=25** and **--end_prediction=49**\n  3.  Third batch: **--start_prediction=50** and **--end_prediction=67** \n\nBy default (if **--models_to_use** is not assigned), all NN models are used: with **--model_preset=multimer**, \n15 models in total = 5 neural network models $\\times$ 3 AlphaFold2 versions; with **--model_preset=monomer_ptm**, 5 \nneural network models are used.\n\nThe prediction number per model can be adjusted, here with 67 per model and 15 models, it amounts to **1005 predictions \nin total divided into 45 batches**, these batches can therefore be run in parallel on a GPU cluster infrastructure.\n\nThe batch size can also be auto calibrated with the `-c` or `-C` parameters if at least one basic run has already been \nperformed. The `-c` parameter will automatically search in the output folder that corresponds to the input sequence for \nthe longest prediction duration. These options have to be coupled with the `-w` walltime parameter (it is advised to \nadapt this walltime value to the one of the job). For instance:\n\n```bash\n./run_massivefold.sh -s ./input/H1140.fasta -r 1005_preds -p 67 -f AFmassive_params.json -c -w 10\n```\n"
      },
      "source": "https://raw.githubusercontent.com/GBLille/MassiveFold/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Parameters in run_massivefold.sh",
        "parent_header": [
          "MassiveFold",
          "Usage",
          "Parameters"
        ],
        "type": "Text_excerpt",
        "value": "In addition to the parameters displayed with **-h** option, the json parameters file set with **-f** or **--parameters** \nshould be organized like the `AFmassive_params.json` or `ColabFold_params.json` file.\n"
      },
      "source": "https://raw.githubusercontent.com/GBLille/MassiveFold/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Parameters in the json file",
        "parent_header": [
          "MassiveFold",
          "Usage",
          "Parameters"
        ],
        "type": "Text_excerpt",
        "value": "Each section of `AFmassive_params.json` or `ColabFold_params.json` is used for a different purpose.\n\nThe **massivefold** section designates the whole run parameters.  \n\n```json\n\"massivefold\": \n{\n    \"run_massivefold\": \"run_AFmassive.py\",\n    \"run_massivefold_plots\": \"../massivefold/massivefold_plots.py\",\n    \"data_dir\": \"/gpfsdswork/dataset/Alphafold-2024-04\",\n    \"jobfile_headers_dir\": \"./headers\",\n    \"jobfile_templates_dir\": \"../massivefold/parallelization/templates\",\n    \"output_dir\": \"./output\",\n    \"logs_dir\": \"./log\",\n    \"input_dir\": \"./input\",\n    \"scripts_dir\": \"../massivefold/parallelization\",\n    \"models_to_use\": \"\",\n    \"pkl_format\": \"full\"\n}\n```\nThe paths in the section are filled by `install.sh` but can be changed here if necessary. \nHeaders (**jobfile_headers_dir**) are specified to setup the run, in order to give the parameters that are required to \nrun the jobs on your cluster/server. \nBuild your own according to the [Jobfile's header building](#jobfiles-header-building) section.   \n**models_to_use** is the list of NN models to use. To select which NN models are used, separate them with a comma *e.g.*:\n\"model_3_multimer_v1,model_3_multimer_v3\", by default all are used  \n**pkl_format**: how to manage pickle files  \n    - \u2018full\u2019 to keep the pickle files generated by the inference engine,  \n    - \u2018light\u2019 to reduce its size by selecting main components, which are: number of recycles, PAE values, max PAE, \nplddt scores, ptm scores, iptm scores and ranking confidence values (stored in ./light_pkl directory)  \n    - \u2018none\u2019 to remove them  \n\n- The **custom_params** section is relative to the personalized parameters that you want to add for your own cluster. \nFor instance, for the Jean Zay GPU cluster:\n```json\n\"custom_params\": \n{\n    \"jeanzay_project\": \"<project>\",\n    \"jeanzay_account\": \"<project>@v100\",\n    \"jeanzay_gpu_with_memory\": \"v100-32g\",\n    \"jeanzay_alignment_time\": \"10:00:00\",\n    \"jeanzay_jobarray_time\": \"10:00:00\"\n}\n\n```\nAs explained in [How to add a parameter](#how-to-add-a-parameter), these variables are substituted by their value when \nthe jobfiles are created.\n\n- For AFmassive, the **AFM_run** section gathers all the parameters used by MassiveFold for the run \n(see [AFmassive parameters](https://github.com/GBLille/AFmassive?tab=readme-ov-file#running-afmassive) \nsection). All parameters except *--keep_pkl*, *--models_to_relax*, *--use_precomputed_msas*, *--alignment_only*, \n*--start_prediction*, *--end_prediction*, *--fasta_path* and *--output_dir* are exposed in this section.  \nYou can adapt the parameter values in function of your needs.  \nThe non exposed parameters mentioned before are set internally by the Massivefold's pipeline or in the **massivefold** \nsection (**models_to_use** and **pkl_format**).  \n\n```json\n\"AFM_run\":\n{\n    \"model_preset\": \"multimer\",\n    \"max_recycles\": \"20\",\n    \"templates\": \"true\",\n    \"dropout\": \"false\",\n    \"dropout_structure_module\": \"false\",\n    \"dropout_rates_filename\": \"\",\n    \"stop_recycling_below\": \"0\",\n    \"max_template_date\": \"2024-08-31\",\n    \"min_score\": \"0\",\n    \"max_score\": \"1\",\n    \"db_preset\": \"full_dbs\",\n    \"early_stop_tolerance\": \"0.5\",\n    \"bfd_max_hits\": \"100000\",\n    \"mgnify_max_hits\": \"501\",\n    \"uniprot_max_hits\": \"50000\",\n    \"uniref_max_hits\": \"10000\"\n}\n```\nLastly, the **plots** section is used for the MassiveFold plotting module.\n\n```json\n\"plots\":\n{\n    \"MF_plots_top_n_predictions\": \"10\",\n    \"MF_plots_chosen_plots\": \"coverage,DM_plddt_PAE,CF_PAEs,score_distribution,recycles\"\n}\n```\n"
      },
      "source": "https://raw.githubusercontent.com/GBLille/MassiveFold/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Relaxation",
        "parent_header": [
          "MassiveFold",
          "Usage"
        ],
        "type": "Text_excerpt",
        "value": "Because the relaxation takes time and resources to compute and that the MassiveFold process splits the predictions in \nmany batches, the \u201cuse_gpu_relax\u201d and \u201cmodels_to_relax\u201d parameters are set to \u201cfalse\u201d and \u201cnone\u201d respectively. Indeed, \nif the relaxation is activated during the process, it will be run per batches, before the final ranking, resulting in \nrelaxed structures that wouldn't necessarily be the best predictions. Instead, we recommend to use the `colabfold_relax` \nprogram provided in the MassiveFold conda environment and developed by the ColabFold team, once all the predicted \nstructures are produced and ranked. It allows to relax only selected PDB structures.  \nFor help, type:  \n```bash\ncolabfold_relax -h\n```\n"
      },
      "source": "https://raw.githubusercontent.com/GBLille/MassiveFold/main/README.md",
      "technique": "header_analysis"
    }
  ]
}