{
  "application_domain": [
    {
      "confidence": 44.81,
      "result": {
        "type": "String",
        "value": "Computer Vision"
      },
      "technique": "supervised_classification"
    }
  ],
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/CobiontID/MarkerScan"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2021-01-22T16:43:44Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2023-06-28T14:59:45Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "This repository contains a Snakemake pipeline which determines the species composition of the sample by SSU presence and separates them accordingly."
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 0.9881954679488564,
      "result": {
        "original_header": "MarkerScan Pipeline",
        "type": "Text_excerpt",
        "value": "Pipeline to determine the species composition of your sample, and separate and assemble every component. \n"
      },
      "source": "https://raw.githubusercontent.com/CobiontID/MarkerScan/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9343788305043309,
      "result": {
        "original_header": "Workflow steps",
        "type": "Text_excerpt",
        "value": "1. Run nhmmer with SSU_Prok_Euk_Microsporidia.hmm across the assembly and coordinates of matches can be found in {shortname}.SSU.readsinfo\n2. The SSU loci are extracted and collapsed with 99% nucleotide identity and stored in {shortname}.SSU.reduced.fa\n3. Classify SSU regions using SILVA. Taxonomy per sequence is found in {shortname}.SSU.reduced.SILVA.tax\n4. Determine the species composition of sample and for which families the procedure continues, output in {workingdirectory}/genera\n5. Download genomes for the closest relatives of the target species available. Next, this fasta file is split and masked using duskmasker. Outputfile: relatives/kraken.relatives.masked.ffn.\n6. Download all available genomes (refseq if bacterial, all if eukaryotic) for the detected families and store in {datadir}/genera (re-run, when older than 180 days).\n7. All fasta files of the detected cobiont families are combined in kraken.tax.masked.ffn.\n8. A custom kraken database consisting out of kraken.tax.masked.ffn and relatives/kraken.relatives.masked.ffn is created: krakendb/\n9. Kraken2 is run. Outputfiles are kraken.output and kraken.report\n10. All reads are mapped to the draft assembly: AllReadsGenome.paf \n\nThe following part of the pipeline will be done for every detected family based on the composition of the sample. \n1. Reads are extracted per bin. {family}/kraken.fa\n2. Kraken reads are mapped to draft assembly. Fully aligned contigs {family}/{family}.ctgs\n3. Run Busco on these contigs: {family}/busco/\n4. Based on the downloaded genomes of this family, homology search using nucmer is performed on these contigs:{family}/{family}\\_vs_contigs.overview.txt\n5. Combine these results and define certain set of reads which are deemed to belong to this {family}. {family}/{family}.final_reads.fa --> concatenated across families in final_reads_removal.fa and corresponding assembled sequence in final_assembly.fa. \nMoreover, also a re-assembly is done.\n1. Reads of draft contigs which are not fully aligned are added to the kraken reads: {family}/{family}.reads2assemble.fa\n2. Assembly is done using hifiasm: {family}/hifiasm/\n3. Busco is run twice, both on the reads as on the novel assembly: {family}/buscoReads and {family}/buscoAssembly\n4. Nucmer against re-assembled contigs: {family}/{family}\\_vs_hifiasm.overview.txt\n5. Map reads to re-assembled contigs: {family}/{family}.re-assembly_reads.fa --> concatenated across families in re-assembly_reads.fa \n"
      },
      "source": "https://raw.githubusercontent.com/CobiontID/MarkerScan/main/README.md",
      "technique": "supervised_classification"
    }
  ],
  "download": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Download steps",
        "parent_header": [
          "MarkerScan Pipeline",
          "Workflow details"
        ],
        "type": "Text_excerpt",
        "value": "1. Download SILVA DB (https://ftp.arb-silva.de/current/ARB_files/) into {datadir}/silva (re-run, when new version)\n2. Download all refseq organellar sequences from https://ftp.ncbi.nlm.nih.gov/refseq/release/mitochondrion/ and https://ftp.ncbi.nlm.nih.gov/refseq/release/plastid/ and store in {datadir}/organelles (re-run, when older than 180 days)\n3. Download all genbank organellar sequences for apicomplexans (common contaminant, but sequence information is rare) via e-utils and store in {datadir}/apicomplexa (re-run, when older than 180 days)\n4. Download NCBI taxonomy (both names.dmp / nodes.dmp and nucl_wgs.accession2taxid/nucl_gb.accession2taxid) (re-run, when older than 180 days)\n"
      },
      "source": "https://raw.githubusercontent.com/CobiontID/MarkerScan/main/README.md",
      "technique": "header_analysis"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/CobiontID/MarkerScan/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 2
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/CobiontID/MarkerScan/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "CobiontID/MarkerScan"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "MarkerScan Pipeline"
      },
      "source": "https://raw.githubusercontent.com/CobiontID/MarkerScan/main/README.md",
      "technique": "regular_expression"
    }
  ],
  "has_build_file": [
    {
      "confidence": 1,
      "result": {
        "format": "dockerfile",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/CobiontID/MarkerScan/main/src/docker/Dockerfile"
      },
      "source": "https://raw.githubusercontent.com/CobiontID/MarkerScan/main/src/docker/Dockerfile",
      "technique": "file_exploration"
    }
  ],
  "has_script_file": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/CobiontID/MarkerScan/main/run_snakemake.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/CobiontID/MarkerScan/main/submit_snakemake.sh"
      },
      "technique": "file_exploration"
    }
  ],
  "installation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Singularity installation",
        "parent_header": [
          "MarkerScan Pipeline",
          "Installation"
        ],
        "type": "Text_excerpt",
        "value": "The prefered way of installation is via the provided singularity container as this will ensure there are no software incompatibilities. \nAfter installation of singularity, you can pull a docker image of the latest version of the code and convert it into a singularity container:\n\n```\nsingularity pull docker://emvcaest/markerscan:latest\n```\n\nNext you need to bind all required directories of your local machine (see [Config file](#config-file)) to the image\n\n```\nexport SINGULARITY_BIND=\"$DIR\"\n```\n\nThe image can now be run as follows:\n\n```\nsingularity run markerscan_latest.sif snakemake --cores $threads --use-conda --conda-prefix /opt/conda/ -s /MarkerScanPipeline/Snakefile --configfile $configfile\n```\n"
      },
      "source": "https://raw.githubusercontent.com/CobiontID/MarkerScan/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "From source",
        "parent_header": [
          "MarkerScan Pipeline",
          "Installation"
        ],
        "type": "Text_excerpt",
        "value": "Please clone this directory to your location of choice.\n\n```\ngit clone https://github.com/CobiontID/MarkerScan.git\n```\nDownload snakemake, e.g. via conda\n```\nconda install -c bioconda snakemake\n```\n\n```\n# activate the Conda environment\nconda activate snakemake\nsnakemake --configfile $configfile --cores $threads --use-conda --conda-prefix $condaprefix -s $pipelinedir/Snakefile\n```\n\n"
      },
      "source": "https://raw.githubusercontent.com/CobiontID/MarkerScan/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 0.9914799217059237,
      "result": {
        "original_header": "Visual overview of MarkerScan pipeline",
        "type": "Text_excerpt",
        "value": "```mermaid\nflowchart\n\nA[Genome] --> B(Scan for SSU)\nB --> C(Extract SSU)\nC --> D(Classify SSU)\nD --> E(Get families)\nE --> F(Download public genomes families)\nF --> H(Classify reads - kraken)\nG[Reads] --> H\nH --> I(Extract reads)\nE --> I\nI -->J(Map reads)\nI -->K(Independent assembly)\nA-->J\nJ-->L(Busco)\nF-->M\nJ-->M(Whole genome alignment)\nK-->O(Busco)\nF-->P\nK-->P(Whole genome alignment)\nM-->N(Report)\nL-->N(Report)\nO-->N(Report)\nP-->N(Report)\n```\n \n"
      },
      "source": "https://raw.githubusercontent.com/CobiontID/MarkerScan/main/README.md",
      "technique": "supervised_classification"
    }
  ],
  "invocation": [
    {
      "confidence": 0.8642074035670616,
      "result": {
        "original_header": "Config file",
        "type": "Text_excerpt",
        "value": "To run the pipeline a yaml file containing all external parameters needs to be created, an example is shown below.\n```\nreads: zipped fasta read file\ngenome: unzipped fasta file\nshortname: e.g. ilBlaLact1, this will be used in output file names\nsci_name: e.g. Blastobasis lacticolella, this full scientific name name needs to be present in NCBI taxonomy with exact spelling \nworkingdirectory: folder to store all output files\ndatadir: central folder to store output which can be re-used across multiple pipeline runs\nfull: 0|1 (run only the SSU detection steps, or complete the full pipeline)\n```\n \n"
      },
      "source": "https://raw.githubusercontent.com/CobiontID/MarkerScan/main/README.md",
      "technique": "supervised_classification"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/CobiontID/MarkerScan/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ""
      },
      "technique": "GitHub_API"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "MarkerScan"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "Organization",
        "value": "CobiontID"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 141368,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Dockerfile",
        "size": 830,
        "type": "Programming_language",
        "value": "Dockerfile"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Shell",
        "size": 752,
        "type": "Programming_language",
        "value": "Shell"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/CobiontID/MarkerScan/main/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "somef_missing_categories": [
    "citation",
    "acknowledgement",
    "run",
    "requirements",
    "contact",
    "contributors",
    "documentation",
    "license",
    "usage",
    "faq",
    "support",
    "identifier",
    "executable_example"
  ],
  "somef_provenance": {
    "date": "2024-10-03 23:14:17",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 4
      },
      "technique": "GitHub_API"
    }
  ],
  "workflows": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/CobiontID/MarkerScan/main/Snakefile"
      },
      "technique": "file_exploration"
    }
  ]
}