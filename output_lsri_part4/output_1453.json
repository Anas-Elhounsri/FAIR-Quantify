{
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/HIITMetagenomics/dsm-framework"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2013-08-21T13:05:11Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2021-10-22T17:18:53Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "Distributed String Mining Framework"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 0.9408769883125603,
      "result": {
        "original_header": "Distributed String Mining Framework",
        "type": "Text_excerpt",
        "value": "This software package implements the algorithm published in [1]. It also includes\nthe extensions  proposed in [2]. \n- [1] Niko V\u00e4lim\u00e4ki and Simon J. Puglisi: **Distributed String Mining for\nHigh-Throughput Sequencing Data**. In _Proc. 12th Workshop on Algorithms\nin Bioinformatics (WABI'12)_, Springer-Verlag, LNCS 7534, pages\n441-452, Ljubljana, Slovenia, September 9-14, 2012.\n- [2] Sohan Seth, Niko V\u00e4lim\u00e4ki, Samuel Kaski and Antti Honkela: **Exploration \nand retrieval of whole-metagenome sequencing samples**. \n_Bioinformatics_, Vol. 30, No. 17, pages 2471-2479.\ndoi: 10.1093/bioinformatics/btu340,\nMay 19, 2014.  \n"
      },
      "source": "https://raw.githubusercontent.com/HIITMetagenomics/dsm-framework/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9219705752927112,
      "result": {
        "original_header": "PREPROCESSING THE DATA",
        "type": "Text_excerpt",
        "value": "The input data for the dsm-framework must be in FASTA format. It is\nrecommended that you first trim the FASTQ short-read data according\nto sequencing quality and output the trimmed short-reads as a FASTA file. \nThen the FASTA input files must be preprocessed with:\n```\n    ./builder -v input.fasta\n```\nIt will output the resulting _index_ under the filename `input.fasta.fmi`.\nYou should run `builder` independendly over each of your input datasets.\nThe preprocessing can be parallelized by building multiple indexes\nsimultaneously, however, these processes might require\nconsiderable amount of main-memory (depending on the input size). \n"
      },
      "source": "https://raw.githubusercontent.com/HIITMetagenomics/dsm-framework/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8060833889129996,
      "result": {
        "original_header": "INITIALIZING THE SERVER",
        "type": "Text_excerpt",
        "value": "The server must be set up before running the clients. It expects a\nlist of dataset names as input. This list must match the dataset names\nthat the clients use when they connect to the server.\n```\nusage: ./metaserver [options] < names.txt\n\n  names.txt         A list of expected library names (read from stdin).\n\nMandatory option:\n -E,--emax <double> Maximum entropy to output.\n\nOther options:\n -p,--port <p>      Listen to port number p.\n -P,--pmin <int>    p_min value (min. number of samples to have occ's in),\n                    default 2.\n --pmax <int>       p_max value (max. number of samples to have occ's in),\n                    default no-limit. Set p_min=p_max=1 to restrict the \n                    output to sample-specific substrings.\n -e,--emin <double> Minimum entropy to output (default 0.0)\n -F,--topfreq <p>   Print the top-p output frequencies.\n -T,--toptimes <p>  Print the top-p latencies.\n -v,--verbose       Print progress information.\n --debug            More verbose but still safe.\n -A,--outputall     Even more verbose (not safe).\n```\nHere follows an example using the SLURM scripts. First, you need to construct\na text file that contains a list of dataset names. In this example, you can use:\nBASH2*\nThus, the resulting file `sample-names.txt` should look like\nBASH3*\nThen you can initialize the server-side processes using the attached script \nBASH4*\nThe script will store temporary configuration files under\nthe directory `tmp_dsmframework_config/`. These files are used\ntrack the hostname of each server process so that the client-side\nprocesses know which hosts to connect to. The files also store the\nTCP port number and the (unique) hash associated with each server.\n \n"
      },
      "source": "https://raw.githubusercontent.com/HIITMetagenomics/dsm-framework/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9796942819937114,
      "result": {
        "original_header": "POST-PROCESSING THE MINED SUBSTRINGS",
        "type": "Text_excerpt",
        "value": "The experiments in paper [2] use the script given in `wrapper-distance-matrix/smtxt2entropy.c`. \nYou can compile and run it to directly post-process the output from `metaserver` in your scripts:\n```\ncd /path/to/dsm-framework/wrapper-distance-matrix\ngcc -Wall -O2 -o smtxt2entropy smtxt2entropy.c -lm\n../metaserver [server-side-parameters] | ./smtxt2entropy -v -s <nsamples> -e <estep> -N <normf> -F <outputfile>\n```\nwhere `<nsamples>` is the number of samples, `<estep>` is the stepping to consider all values (0;estep;1),\n`<normf>` is the file storing a list of normalization factors (if needed), and `<outputfile>` is the \noutput filename prefix.\n \n"
      },
      "source": "https://raw.githubusercontent.com/HIITMetagenomics/dsm-framework/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "documentation": [
    {
      "confidence": 1,
      "result": {
        "format": "wiki",
        "type": "Url",
        "value": "https://github.com/HIITMetagenomics/dsm-framework/wiki"
      },
      "source": "https://raw.githubusercontent.com/HIITMetagenomics/dsm-framework/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/HIITMetagenomics/dsm-framework/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 5
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/HIITMetagenomics/dsm-framework/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "HIITMetagenomics/dsm-framework"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "Distributed String Mining Framework"
      },
      "source": "https://raw.githubusercontent.com/HIITMetagenomics/dsm-framework/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "has_script_file": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/HIITMetagenomics/dsm-framework/master/wrapper-SLURM/client-wrapper.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/HIITMetagenomics/dsm-framework/master/wrapper-SLURM/example-builder.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/HIITMetagenomics/dsm-framework/master/wrapper-SLURM/server-wrapper.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/HIITMetagenomics/dsm-framework/master/wrapper-SLURM/example-client.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/HIITMetagenomics/dsm-framework/master/wrapper-SLURM/example-server.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/HIITMetagenomics/dsm-framework/master/wrapper-simple/distribute.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/HIITMetagenomics/dsm-framework/master/wrapper-simple/distributebuild.sh"
      },
      "technique": "file_exploration"
    }
  ],
  "installation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "INSTALLATION AND GETTING STARTED",
        "parent_header": [
          "Distributed String Mining Framework"
        ],
        "type": "Text_excerpt",
        "value": "The current installation is, in short, to write suitable wrapper-scripts \naround the main C/C++ program. We provide example wrapper-scripts for the \n_SLURM batch job system_. The main computation is divided over\n\n1. preprocessing of each dataset (`builder`),\n2. 64-256 _CPU intensive_ processes (`metaserver`), \n3. _memory intensive_ processes which use very little CPU (`metaenumerate`), and\n4. post-processing of the mined substrings (see e.g. `wrapper-distance-matrix/smtxt2entropy.c`).\n\nThe preprocessing step (1) is ran separately from (2) and (3). \nSteps (2) and (3) are run in parallel so that (2) is started first. The \nprocesses in Step (1) and (3) use memory that depends on the dataset sizes.\nProcesses from Step (2) require only a small amount of memory.\n\nTo get started, please download the following example data (~25 MB). The rest of\nour example commands use these data files.\n```\nmkdir example\ncd example\nwget http://www.cs.helsinki.fi/u/nvalimak/dsm-framework/toydata-1.fasta.gz\nwget http://www.cs.helsinki.fi/u/nvalimak/dsm-framework/toydata-2.fasta.gz\nwget http://www.cs.helsinki.fi/u/nvalimak/dsm-framework/toydata-3.fasta.gz\nwget http://www.cs.helsinki.fi/u/nvalimak/dsm-framework/toydata-4.fasta.gz\nwget http://www.cs.helsinki.fi/u/nvalimak/dsm-framework/toydata-5.fasta.gz\ngunzip toydata-?.fasta.gz\n```\n\n"
      },
      "source": "https://raw.githubusercontent.com/HIITMetagenomics/dsm-framework/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 0.9999999636759198,
      "result": {
        "original_header": "PREPROCESSING THE DATA",
        "type": "Text_excerpt",
        "value": "If you have access to a cluster environment with SLURM batch job system,\nyou can use the following commands to build indexes for the example data.\nNotice that you might need to give the input filename with full directory \npath according to your own cluster environment.\n```\nexport DSM_FRAMEWORK_PATH=/path/to/dsm-framework/\nsbatch $DSM_FRAMEWORK_PATH/wrapper-SLURM/example-builder.sh toydata-1.fasta\nsbatch $DSM_FRAMEWORK_PATH/wrapper-SLURM/example-builder.sh toydata-2.fasta\nsbatch $DSM_FRAMEWORK_PATH/wrapper-SLURM/example-builder.sh toydata-3.fasta\nsbatch $DSM_FRAMEWORK_PATH/wrapper-SLURM/example-builder.sh toydata-4.fasta\nsbatch $DSM_FRAMEWORK_PATH/wrapper-SLURM/example-builder.sh toydata-5.fasta\n```\nSee the specific scripts above for details and SLURM settings.  \nRemark: If your cluster does not have SLURM, modify e.g. the script \n`wrapper-simple/distributebuild.sh` to build multiple indexes at once. \nThe script expects a list of cluster node names as standard\ninput. Please see the actual script to setup the correct paths to your\nfasta files etc. You will need to modify it to suite your own cluster environment. \n"
      },
      "source": "https://raw.githubusercontent.com/HIITMetagenomics/dsm-framework/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "invocation": [
    {
      "confidence": 0.8107087159528982,
      "result": {
        "original_header": "PREPROCESSING THE DATA",
        "type": "Text_excerpt",
        "value": "If you have access to a cluster environment with SLURM batch job system,\nyou can use the following commands to build indexes for the example data.\nNotice that you might need to give the input filename with full directory \npath according to your own cluster environment.\n```\nexport DSM_FRAMEWORK_PATH=/path/to/dsm-framework/\nsbatch $DSM_FRAMEWORK_PATH/wrapper-SLURM/example-builder.sh toydata-1.fasta\nsbatch $DSM_FRAMEWORK_PATH/wrapper-SLURM/example-builder.sh toydata-2.fasta\nsbatch $DSM_FRAMEWORK_PATH/wrapper-SLURM/example-builder.sh toydata-3.fasta\nsbatch $DSM_FRAMEWORK_PATH/wrapper-SLURM/example-builder.sh toydata-4.fasta\nsbatch $DSM_FRAMEWORK_PATH/wrapper-SLURM/example-builder.sh toydata-5.fasta\n```\nSee the specific scripts above for details and SLURM settings.  \n"
      },
      "source": "https://raw.githubusercontent.com/HIITMetagenomics/dsm-framework/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/HIITMetagenomics/dsm-framework/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ""
      },
      "technique": "GitHub_API"
    }
  ],
  "license": [
    {
      "confidence": 1,
      "result": {
        "name": "Other",
        "spdx_id": "NOASSERTION",
        "type": "License",
        "url": null,
        "value": null
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "type": "File_dump",
        "value": "Copyright (c) 2013 Niko V\u00e4lim\u00e4ki\n\nThis program is free software; you can redistribute it and/or modify\nit under the terms of the GNU General Public License as published by\nthe Free Software Foundation; either version 2 of the License, or\n(at your option) any later version.\n\nThis program is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\nGNU General Public License for more details.\n\nYou should have received a copy of the GNU General Public License along\nwith this program; if not, write to the Free Software Foundation, Inc.,\n51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA.\n"
      },
      "source": "https://raw.githubusercontent.com/HIITMetagenomics/dsm-framework/master/LICENSE",
      "technique": "file_exploration"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "dsm-framework"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "Organization",
        "value": "HIITMetagenomics"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "C++",
        "size": 824594,
        "type": "Programming_language",
        "value": "C++"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "C",
        "size": 31547,
        "type": "Programming_language",
        "value": "C"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Makefile",
        "size": 23606,
        "type": "Programming_language",
        "value": "Makefile"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Shell",
        "size": 9553,
        "type": "Programming_language",
        "value": "Shell"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 1143,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/HIITMetagenomics/dsm-framework/master/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "releases": [
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "nvalimak",
          "type": "User"
        },
        "date_created": "2016-04-12T18:06:16Z",
        "date_published": "2016-04-12T18:17:41Z",
        "html_url": "https://github.com/HIITMetagenomics/dsm-framework/releases/tag/bioinformatics2014",
        "name": "Bioinformatics 2014 version of the DSM framework",
        "release_id": 3004558,
        "tag": "bioinformatics2014",
        "tarball_url": "https://api.github.com/repos/HIITMetagenomics/dsm-framework/tarball/bioinformatics2014",
        "type": "Release",
        "url": "https://api.github.com/repos/HIITMetagenomics/dsm-framework/releases/3004558",
        "value": "https://api.github.com/repos/HIITMetagenomics/dsm-framework/releases/3004558",
        "zipball_url": "https://api.github.com/repos/HIITMetagenomics/dsm-framework/zipball/bioinformatics2014"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "nvalimak",
          "type": "User"
        },
        "date_created": "2013-08-22T10:47:30Z",
        "date_published": "2013-08-22T11:00:11Z",
        "html_url": "https://github.com/HIITMetagenomics/dsm-framework/releases/tag/wabi12",
        "name": "WABI'12 version of the DSM framework",
        "release_id": 31004,
        "tag": "wabi12",
        "tarball_url": "https://api.github.com/repos/HIITMetagenomics/dsm-framework/tarball/wabi12",
        "type": "Release",
        "url": "https://api.github.com/repos/HIITMetagenomics/dsm-framework/releases/31004",
        "value": "https://api.github.com/repos/HIITMetagenomics/dsm-framework/releases/31004",
        "zipball_url": "https://api.github.com/repos/HIITMetagenomics/dsm-framework/zipball/wabi12"
      },
      "technique": "GitHub_API"
    }
  ],
  "requirements": [
    {
      "confidence": 1,
      "result": {
        "original_header": "REQUIREMENTS AND COMPILING",
        "parent_header": [
          "Distributed String Mining Framework"
        ],
        "type": "Text_excerpt",
        "value": "Run `make clean` and `make` to compile. The requirements are\n\n- GNU GCC (g++ 4.3) environment including the OpenMP library.\n- TCP connectivity between the cluster nodes (some range of vacant TCP port numbers).\n- some synchronization when initializing the server-side and \nclient-side programs (i.e. wrapper-scripts).\n\nThe first requirement should be fullfilled in typical linux installations. \nThe second requirement depends on the cluster environment (see technical \ndetails on this below). The third requirement is crucial and it will \nrequire some scripting to be able to run the framework on specific cluster \nenvironments; to help you get started, we provide example wrapper-scripts \nfor the _SLURM batch job system_.\n\n"
      },
      "source": "https://raw.githubusercontent.com/HIITMetagenomics/dsm-framework/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "run": [
    {
      "confidence": 1,
      "result": {
        "original_header": "RUNNING THE CLIENTS",
        "parent_header": [
          "Distributed String Mining Framework"
        ],
        "type": "Text_excerpt",
        "value": "The clients are run using `metaenumerate`. The dataset name assigned\nto each client is determined from the index filename. Currently, the\nname is truncated from the index filename by finding the last `/`\nsymbol and the first `.` symbol. Thus, starting the client for the\nindex file `/path/index01.fmi` will use `index01` as the client's\ndataset name. The server will compare the dataset name against its own\nlist (see above).\n\n```\nusage: ./metaenumerate [options] <index>  < hostinfo.txt\n\n <index>        Index file.\n hostinfo.txt   A list of server details, say \n                   <hostname> <TCP port n:o> <hash>\n                to connect to (read from stdin).\n\nOptions:\n --check        Check integrity of index and quit.\n --port <p>     Connect to port <p>.\n --verbose      Print progress information.\nDebug options:\n --debug        Print more progress information.\n```\nHere follows an example on how to initialize the client side processes.\nFirst, you need to make sure that all the server-side processes are \nup and running - you might want to set up SLURM job dependencies\nto ensure that the server-side processes are started first. Once you \ninitialize the client processes, they will\nconnect to the server processes, load the index and start the computation.\nHere, each client is associated with one index (i.e. one dataset).\n```\nexport DSM_FRAMEWORK_PATH=/path/to/dsm-framework/\n$DSM_FRAMEWORK_PATH/wrapper-SLURM/example-client.sh sample-names.txt tmp_dsmframework_config\n```\nThe resulting output is found under the files server-output*.txt.gz.\nSee the above example scripts and papers [1] and [2] for details. \nMore information and related Matlab packages are available at\nhttps://github.com/HIITMetagenomics\n\nRemark: If your cluster does not have SLURM, the script \n`wrapper-simple/distribute.sh` gives an example how to distribute the client\nprocesses. You will need to modify it to suite your own\ncluster environment.\n\n"
      },
      "source": "https://raw.githubusercontent.com/HIITMetagenomics/dsm-framework/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "somef_missing_categories": [
    "citation",
    "acknowledgement",
    "download",
    "contact",
    "contributors",
    "faq",
    "support",
    "identifier",
    "has_build_file",
    "executable_example"
  ],
  "somef_provenance": {
    "date": "2024-11-04 07:12:14",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 5
      },
      "technique": "GitHub_API"
    }
  ],
  "usage": [
    {
      "confidence": 1,
      "result": {
        "original_header": "INSTALLATION AND GETTING STARTED",
        "parent_header": [
          "Distributed String Mining Framework"
        ],
        "type": "Text_excerpt",
        "value": "The current installation is, in short, to write suitable wrapper-scripts \naround the main C/C++ program. We provide example wrapper-scripts for the \n_SLURM batch job system_. The main computation is divided over\n\n1. preprocessing of each dataset (`builder`),\n2. 64-256 _CPU intensive_ processes (`metaserver`), \n3. _memory intensive_ processes which use very little CPU (`metaenumerate`), and\n4. post-processing of the mined substrings (see e.g. `wrapper-distance-matrix/smtxt2entropy.c`).\n\nThe preprocessing step (1) is ran separately from (2) and (3). \nSteps (2) and (3) are run in parallel so that (2) is started first. The \nprocesses in Step (1) and (3) use memory that depends on the dataset sizes.\nProcesses from Step (2) require only a small amount of memory.\n\nTo get started, please download the following example data (~25 MB). The rest of\nour example commands use these data files.\n```\nmkdir example\ncd example\nwget http://www.cs.helsinki.fi/u/nvalimak/dsm-framework/toydata-1.fasta.gz\nwget http://www.cs.helsinki.fi/u/nvalimak/dsm-framework/toydata-2.fasta.gz\nwget http://www.cs.helsinki.fi/u/nvalimak/dsm-framework/toydata-3.fasta.gz\nwget http://www.cs.helsinki.fi/u/nvalimak/dsm-framework/toydata-4.fasta.gz\nwget http://www.cs.helsinki.fi/u/nvalimak/dsm-framework/toydata-5.fasta.gz\ngunzip toydata-?.fasta.gz\n```\n\n"
      },
      "source": "https://raw.githubusercontent.com/HIITMetagenomics/dsm-framework/master/README.md",
      "technique": "header_analysis"
    }
  ]
}