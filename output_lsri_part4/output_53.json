{
  "application_domain": [
    {
      "confidence": 83.71,
      "result": {
        "type": "String",
        "value": "Computer Vision"
      },
      "technique": "supervised_classification"
    }
  ],
  "citation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Citation",
        "parent_header": [
          "STRA-Net"
        ],
        "type": "Text_excerpt",
        "value": "If you use our code in your research work, please consider citing the following papers:\n\n    @ARTICLE{lai2019video,\n      title={Video Saliency Prediction using Spatiotemporal Residual Attentive Networks},\n      author={Qiuxia Lai and Wenguan Wang and Hanqiu Sun and Jianbing Shen},\n      journal={IEEE Trans. on Image Processing},\n      year={2019}\n    }\n\n    @InProceedings{Wang_2018_CVPR,\n    author = {Wang, Wenguan and Shen, Jianbing and Guo, Fang and Cheng, Ming-Ming and Borji, Ali},\n    title = {Revisiting Video Saliency: A Large-Scale Benchmark and a New Model},\n    booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition},\n    year = {2018}\n    }\n\n    @ARTICLE{Wang_2019_revisitingVS, \n    author={W. {Wang} and J. {Shen} and J. {Xie} and M. {Cheng} and H. {Ling} and A. {Borji}}, \n    journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, \n    title={Revisiting Video Saliency Prediction in the Deep Learning Era}, \n    year={2019}, \n    }\n"
      },
      "source": "https://raw.githubusercontent.com/ashleylqx/STRA-Net/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "author": "Qiuxia Lai and Wenguan Wang and Hanqiu Sun and Jianbing Shen",
        "format": "bibtex",
        "title": "Video Saliency Prediction using Spatiotemporal Residual Attentive Networks",
        "type": "Text_excerpt",
        "value": "@article{lai2019video,\n    year = {2019},\n    journal = {IEEE Trans. on Image Processing},\n    author = {Qiuxia Lai and Wenguan Wang and Hanqiu Sun and Jianbing Shen},\n    title = {Video Saliency Prediction using Spatiotemporal Residual Attentive Networks},\n}"
      },
      "source": "https://raw.githubusercontent.com/ashleylqx/STRA-Net/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "author": "Wang, Wenguan and Shen, Jianbing and Guo, Fang and Cheng, Ming-Ming and Borji, Ali",
        "format": "bibtex",
        "title": "Revisiting Video Saliency: A Large-Scale Benchmark and a New Model",
        "type": "Text_excerpt",
        "value": "@inproceedings{Wang_2018_CVPR,\n    year = {2018},\n    booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition},\n    title = {Revisiting Video Saliency: A Large-Scale Benchmark and a New Model},\n    author = {Wang, Wenguan and Shen, Jianbing and Guo, Fang and Cheng, Ming-Ming and Borji, Ali},\n}"
      },
      "source": "https://raw.githubusercontent.com/ashleylqx/STRA-Net/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "author": "W. {Wang} and J. {Shen} and J. {Xie} and M. {Cheng} and H. {Ling} and A. {Borji}",
        "format": "bibtex",
        "title": "Revisiting Video Saliency Prediction in the Deep Learning Era",
        "type": "Text_excerpt",
        "value": "@article{Wang_2019_revisitingVS,\n    year = {2019},\n    title = {Revisiting Video Saliency Prediction in the Deep Learning Era},\n    journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},\n    author = {W. {Wang} and J. {Shen} and J. {Xie} and M. {Cheng} and H. {Ling} and A. {Borji}},\n}"
      },
      "source": "https://raw.githubusercontent.com/ashleylqx/STRA-Net/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/ashleylqx/STRA-Net"
      },
      "technique": "GitHub_API"
    }
  ],
  "contact": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Contact",
        "parent_header": [
          "STRA-Net"
        ],
        "type": "Text_excerpt",
        "value": "Qiuxia Lai: <ashleylqx@gmail.com>\n\n\n\n\n\n"
      },
      "source": "https://raw.githubusercontent.com/ashleylqx/STRA-Net/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2019-08-07T13:44:17Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2024-09-26T16:56:12Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "STRAL-Net"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 0.9892052457649364,
      "result": {
        "original_header": "STRA-Net",
        "type": "Text_excerpt",
        "value": "This repository is the implementation of **'Video Saliency Prediction using Spatiotemporal Residual Attentive Networks (TIP2019)'**. \n"
      },
      "source": "https://raw.githubusercontent.com/ashleylqx/STRA-Net/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9294872841707793,
      "result": {
        "original_header": "Testing",
        "type": "Text_excerpt",
        "value": "2.To get other testing results, prepare the datasets with optical flows, and modify the dataset settings in `config.py`. Run `demo_test.py`. \nYou may also run `demo.py` after editing the `config.py` with `model_no = 0 or 1` and `phase = 'vis'`\uff0c where `0` is for the feature net, and `1` is for the whole model. \n"
      },
      "source": "https://raw.githubusercontent.com/ashleylqx/STRA-Net/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8523353777435059,
      "result": {
        "original_header": "Training",
        "type": "Text_excerpt",
        "value": "Our model is trained in tendem. To train the feature net, we initialize it with the weight of resnet-50 pretrained on the ImageNet. Then, we initialize the feature net with the weight in the first step, randomly initialize the remaining part, and train the whole network. \nIn case that you do not want to train from the feature net, you may directly use the provided weight `U\\_td3\\_res_ds.h5`, and begin from step 2. \n2)Modify the initilization weight of the feature net in `demo.py` to the one you obtained in step 1, or leave it as the default one that you've downloaded. \n"
      },
      "source": "https://raw.githubusercontent.com/ashleylqx/STRA-Net/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "download": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Results Download",
        "parent_header": [
          "STRA-Net"
        ],
        "type": "Text_excerpt",
        "value": "Prediction results on **DHF1K**, **Hollywood-2**, **UCF sports**, and **DIEM** can be downloaded from:\n\nGoogle Drive: <https://drive.google.com/file/d/1VmXVJ5H8y3-uihDrr1yTVPZBNIE0eoOW/view?usp=sharing>\n\nBaidu Disk: <https://pan.baidu.com/s/1wvTtHuL5ra7umsG9_dICig>  password:dizw\n"
      },
      "source": "https://raw.githubusercontent.com/ashleylqx/STRA-Net/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Download weights for testing or initialization of training",
        "parent_header": [
          "STRA-Net",
          "Preparation"
        ],
        "type": "Text_excerpt",
        "value": "Google Drive: <https://drive.google.com/file/d/14EgtXJboEnrM19aL5i9gGPNKbus8790_/view?usp=sharing>\n\nBaidu Disk: <https://pan.baidu.com/s/1jmRNufO_IXxJX4D0LKxTaQ>  password:pqil\n\nThe testing weights `U_td3_res_ds.h5` and `UHD_dcross_res_matt_res.h5` are put into '**/vap_model**' by default. The initialization weights `A_resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5` and `M_resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5` are put into '**/weights**' by default.\n"
      },
      "source": "https://raw.githubusercontent.com/ashleylqx/STRA-Net/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/ashleylqx/STRA-Net/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 8
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/ashleylqx/STRA-Net/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "ashleylqx/STRA-Net"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "STRA-Net"
      },
      "source": "https://raw.githubusercontent.com/ashleylqx/STRA-Net/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "installation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Generate optical flows",
        "parent_header": [
          "STRA-Net",
          "Preparation"
        ],
        "type": "Text_excerpt",
        "value": "The optical flows are generated using [flownet-2.0](https://github.com/lmb-freiburg/flownet2 \"flownet2\"). The '**.flo**' files in the '**/flow**' folders under the video directory. Please be noted that the optical flow files may take up a considerable amout of storage space. The dataset directory is as follows: \n    \n        DataSets\n        |----DHF1K\n             |---train\n                 |--0001\n                    |----images\n                    |----flow\n                    |----fixation\n                    |----maps\n                 |--0002\n                    |----...\n                 |--...\n             |---test\n                 |--...\n        |----Hollowood-2\n             |---train\n             |---test\n        |----UCF sports\n             |---train\n             |---test\n\nFor **Holloyood-2**, we further seperate the video sequences into shots according to the ground-truth shot boundaries, and discard the ones that contains less than 10 frames. \n\nFor more information about **DHF1K**, click [here](https://github.com/wenguanwang/DHF1K \"dhf1k\"). See **DHF1K leaderboard** [here](https://mmcheng.net/videosal/ \"dhf1k_lb\")\n"
      },
      "source": "https://raw.githubusercontent.com/ashleylqx/STRA-Net/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Modify corresponding directories",
        "parent_header": [
          "STRA-Net",
          "Preparation"
        ],
        "type": "Text_excerpt",
        "value": "Please modify the `config.py` accordingly.\n\n"
      },
      "source": "https://raw.githubusercontent.com/ashleylqx/STRA-Net/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 0.9989201333615668,
      "result": {
        "original_header": "Environment",
        "type": "Text_excerpt",
        "value": "- CentOS-7\n- Python 3.5.2\n- Tensorflow 1.11.0\n- Keras 2.2.4\n- CUDA 9.0\n- CUDNN 7.5.0\n \n"
      },
      "source": "https://raw.githubusercontent.com/ashleylqx/STRA-Net/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8925372435389388,
      "result": {
        "original_header": "Training",
        "type": "Text_excerpt",
        "value": "In case that you do not want to train from the feature net, you may directly use the provided weight `U\\_td3\\_res_ds.h5`, and begin from step 2. \n1)In `config.py`, set `model_no = 0` and `phase = 'train'` \n1)In `config.py`, set `model_no = 1` and `phase = 'train'` \n"
      },
      "source": "https://raw.githubusercontent.com/ashleylqx/STRA-Net/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "invocation": [
    {
      "confidence": 0.8712397007604084,
      "result": {
        "original_header": "Training",
        "type": "Text_excerpt",
        "value": "1)In `config.py`, set `model_no = 0` and `phase = 'train'` \n2)Run `demo.py` \n1)In `config.py`, set `model_no = 1` and `phase = 'train'` \n3)Run `demo.py` \n"
      },
      "source": "https://raw.githubusercontent.com/ashleylqx/STRA-Net/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/ashleylqx/STRA-Net/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "saliency-prediction, visual-attention"
      },
      "technique": "GitHub_API"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "STRA-Net"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "User",
        "value": "ashleylqx"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 109410,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/ashleylqx/STRA-Net/master/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "somef_missing_categories": [
    "acknowledgement",
    "run",
    "requirements",
    "contributors",
    "documentation",
    "license",
    "usage",
    "faq",
    "support",
    "identifier",
    "has_build_file",
    "executable_example"
  ],
  "somef_provenance": {
    "date": "2024-11-04 01:39:31",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 23
      },
      "technique": "GitHub_API"
    }
  ]
}