{
  "application_domain": [
    {
      "confidence": 13.56,
      "result": {
        "type": "String",
        "value": "Computer Vision"
      },
      "technique": "supervised_classification"
    }
  ],
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/grocsvs/grocsvs"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2016-09-08T17:16:48Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2024-10-28T07:06:32Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "Genome-wide reconstruction of complex structural variants"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 0.9448713025402785,
      "result": {
        "original_header": "GROC-SVs",
        "type": "Text_excerpt",
        "value": "Genome-wide Reconstruction of Complex Structural Variants, or GROC-SVs, is a software pipeline for identifying large-scale structural variants, performing sequence assembly at the breakpoints, and reconstructing the complex structural variants using the long-fragment information from the 10x Genomics platform. \n"
      },
      "source": "https://raw.githubusercontent.com/grocsvs/grocsvs/master/README.rst",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9938498586589188,
      "result": {
        "original_header": "Comparison to Long Ranger Pipeline",
        "type": "Text_excerpt",
        "value": "Briefly, GROC-SVs was designed to detect and characterize complex structural variants such as those frequently found in cancer or in orphan diseases. The Long Ranger software available from 10x Genomics can also perform SV detection using inferred long-fragment sequence information, but is more well-suited to analysis of individual germline genomes - eg, Long Ranger includes a module to detect modest-sized deletions common in the germline. Note that both GROC-SVs and Long Ranger are being actively developed, and so some features may migrate between packages. \n* performs sequence assembly of structural variants\n* reconstructs large-scale complex structural variants\n* is designed for multi-sample analyses (tumor/normal, or trios) - this is important when identifying somatic or de novo germline events, as analyzing multiple samples separately can result in false negative calls in the control or parent samples \n"
      },
      "source": "https://raw.githubusercontent.com/grocsvs/grocsvs/master/README.rst",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8726732055690385,
      "result": {
        "original_header": "Troubleshooting",
        "type": "Text_excerpt",
        "value": "**ShortSequence: Sequence is too long.** If you get this error during assembly, please make sure you are using `the grocsvs fork of idba_ud <https://github.com/grocsvs/idba/releases/tag/1.1.3g1>`_. \n"
      },
      "source": "https://raw.githubusercontent.com/grocsvs/grocsvs/master/README.rst",
      "technique": "supervised_classification"
    }
  ],
  "documentation": [
    {
      "confidence": 1,
      "result": {
        "format": "readthedocs",
        "type": "Url",
        "value": "http://bedtools.readthedocs.io/"
      },
      "source": "https://raw.githubusercontent.com/grocsvs/grocsvs/master/README.rst",
      "technique": "regular_expression"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/grocsvs/grocsvs/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 9
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/grocsvs/grocsvs/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "grocsvs/grocsvs"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ""
      },
      "source": "https://raw.githubusercontent.com/grocsvs/grocsvs/master/README.rst",
      "technique": "regular_expression"
    }
  ],
  "has_build_file": [
    {
      "confidence": 1,
      "result": {
        "format": "dockerfile",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/grocsvs/grocsvs/master/Dockerfile"
      },
      "source": "https://raw.githubusercontent.com/grocsvs/grocsvs/master/Dockerfile",
      "technique": "file_exploration"
    }
  ],
  "installation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Installation",
        "type": "Text_excerpt",
        "value": "Prerequisites: the following programs must be installed prior to running GROC-SVs:\n\n* python -- GROC-SVs has been tested on python 2.7 on Mac and Linux; it is not compatible with python 3.x\n* `idba_ud <https://github.com/grocsvs/idba/releases/tag/1.1.3g1>`_ -- please use this version, as the version distributed by the original author does not support paired reads longer than 128 bp\n* `samtools and htslib <http://www.htslib.org/download/>`_ -- version 1.0 or later of the ``samtools``, ``bgzip``, and ``tabix`` programs must all be in your ``$PATH``\n* `bwa-mem <https://github.com/lh3/bwa/releases>`_\n* `graphviz <http://www.graphviz.org/Download..php>`_ (required for pygraphviz visualization; see `here <https://github.com/grocsvs/grocsvs/issues/7>`_ if you have trouble installing)\n* (optional): `rpy2 <https://rpy2.bitbucket.io>`_ which is required for generation of the visualizations; this stage will be skipped if rpy2 can't be found. (Note that you may re-start the pipeline after installing rpy2 in order to complete this step, picking up where it left off.)\n\nWe recommend setting up a `virtualenv <http://docs.python-guide.org/en/latest/dev/virtualenvs/>`_ prior to installing GROC-SVs (or using `virtualenvwrapper <http://www.simononsoftware.com/virtualenv-tutorial-part-2/>`_):\n\n.. code-block:: bash\n\n    sudo pip install virtualenv\n    virtualenv grocsvs_env\n\nThe virtualenv can be activated by running the following command:\n\n.. code-block:: bash\n\n    source grocsvs_env/bin/activate\n\nThen, to install grocsvs:\n\n.. code-block:: bash\n\n    cd /path/to/grocsvs\n    pip install .\n\nTo test that GROC-SVs is installed correctly, you can simply run ``grocsvs`` from the commandline, which should show help text without any error messages.\n\n"
      },
      "source": "https://raw.githubusercontent.com/grocsvs/grocsvs/master/README.rst",
      "technique": "header_analysis"
    },
    {
      "confidence": 0.972507029064932,
      "result": {
        "original_header": "Troubleshooting",
        "type": "Text_excerpt",
        "value": "The ``grocsvs /path/to/experiment/configuration.json`` command may be run multiple times to resume the pipeline. \nIf you are having trouble installing or running grocsvs, the docker file (see above) may help you diagnose the issue. \nIf an error arises, the output from ``grocsvs`` or the log files may be informative. \n**ShortSequence: Sequence is too long.** If you get this error during assembly, please make sure you are using `the grocsvs fork of idba_ud <https://github.com/grocsvs/idba/releases/tag/1.1.3g1>`_. \n\nPlease submit issues on the `github page for grocsvs <https://github.com/grocsvs/grocsvs/issues>`_. \n"
      },
      "source": "https://raw.githubusercontent.com/grocsvs/grocsvs/master/README.rst",
      "technique": "supervised_classification"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/grocsvs/grocsvs/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ""
      },
      "technique": "GitHub_API"
    }
  ],
  "license": [
    {
      "confidence": 1,
      "result": {
        "name": "MIT License",
        "spdx_id": "MIT",
        "type": "License",
        "url": "https://api.github.com/licenses/mit",
        "value": "https://api.github.com/licenses/mit"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "type": "File_dump",
        "value": "The MIT License (MIT)\n\nCopyright (c) 2016 Noah Spies\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
      },
      "source": "https://raw.githubusercontent.com/grocsvs/grocsvs/master/LICENSE",
      "technique": "file_exploration"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "grocsvs"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "Organization",
        "value": "grocsvs"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 347931,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Dockerfile",
        "size": 1158,
        "type": "Programming_language",
        "value": "Dockerfile"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/grocsvs/grocsvs/master/README.rst"
      },
      "technique": "file_exploration"
    }
  ],
  "releases": [
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "nspies",
          "type": "User"
        },
        "date_created": "2017-06-06T20:01:25Z",
        "date_published": "2017-06-06T20:03:21Z",
        "description": "fixes numerous bugs and adds automated visualization output (if rpy2 is installed)",
        "html_url": "https://github.com/grocsvs/grocsvs/releases/tag/v0.2.5",
        "release_id": 6623599,
        "tag": "v0.2.5",
        "tarball_url": "https://api.github.com/repos/grocsvs/grocsvs/tarball/v0.2.5",
        "type": "Release",
        "url": "https://api.github.com/repos/grocsvs/grocsvs/releases/6623599",
        "value": "https://api.github.com/repos/grocsvs/grocsvs/releases/6623599",
        "zipball_url": "https://api.github.com/repos/grocsvs/grocsvs/zipball/v0.2.5"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "nspies",
          "type": "User"
        },
        "date_created": "2017-04-17T15:46:47Z",
        "date_published": "2017-04-17T15:48:34Z",
        "description": "Adding new preflight step to check that dependencies are installed correctly and worker nodes have enough physical memory installed",
        "html_url": "https://github.com/grocsvs/grocsvs/releases/tag/v0.2.4",
        "name": "v0.2.4",
        "release_id": 6098497,
        "tag": "v0.2.4",
        "tarball_url": "https://api.github.com/repos/grocsvs/grocsvs/tarball/v0.2.4",
        "type": "Release",
        "url": "https://api.github.com/repos/grocsvs/grocsvs/releases/6098497",
        "value": "https://api.github.com/repos/grocsvs/grocsvs/releases/6098497",
        "zipball_url": "https://api.github.com/repos/grocsvs/grocsvs/zipball/v0.2.4"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "nspies",
          "type": "User"
        },
        "date_created": "2017-03-30T16:53:46Z",
        "date_published": "2017-03-30T16:54:10Z",
        "html_url": "https://github.com/grocsvs/grocsvs/releases/tag/v0.2.3",
        "release_id": 5925782,
        "tag": "v0.2.3",
        "tarball_url": "https://api.github.com/repos/grocsvs/grocsvs/tarball/v0.2.3",
        "type": "Release",
        "url": "https://api.github.com/repos/grocsvs/grocsvs/releases/5925782",
        "value": "https://api.github.com/repos/grocsvs/grocsvs/releases/5925782",
        "zipball_url": "https://api.github.com/repos/grocsvs/grocsvs/zipball/v0.2.3"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "nspies",
          "type": "User"
        },
        "date_created": "2017-03-30T16:46:55Z",
        "date_published": "2017-03-30T16:48:15Z",
        "html_url": "https://github.com/grocsvs/grocsvs/releases/tag/v0.2.2",
        "name": "grocsvs version 0.2.2",
        "release_id": 5925719,
        "tag": "v0.2.2",
        "tarball_url": "https://api.github.com/repos/grocsvs/grocsvs/tarball/v0.2.2",
        "type": "Release",
        "url": "https://api.github.com/repos/grocsvs/grocsvs/releases/5925719",
        "value": "https://api.github.com/repos/grocsvs/grocsvs/releases/5925719",
        "zipball_url": "https://api.github.com/repos/grocsvs/grocsvs/zipball/v0.2.2"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "nspies",
          "type": "User"
        },
        "date_created": "2017-03-29T23:46:43Z",
        "date_published": "2017-03-29T23:47:34Z",
        "html_url": "https://github.com/grocsvs/grocsvs/releases/tag/v0.2.1",
        "name": "grocsvs version 0.2.1",
        "release_id": 5916312,
        "tag": "v0.2.1",
        "tarball_url": "https://api.github.com/repos/grocsvs/grocsvs/tarball/v0.2.1",
        "type": "Release",
        "url": "https://api.github.com/repos/grocsvs/grocsvs/releases/5916312",
        "value": "https://api.github.com/repos/grocsvs/grocsvs/releases/5916312",
        "zipball_url": "https://api.github.com/repos/grocsvs/grocsvs/zipball/v0.2.1"
      },
      "technique": "GitHub_API"
    }
  ],
  "run": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Running GROC-SVs",
        "type": "Text_excerpt",
        "value": "Overview:\n\n1. extract barcodes and align your 10x sequencing data to the reference genome\n2. setup a ``configuration.json`` file describing your samples and your compute (eg cluster) setup\n3. run grocsvs\n\n\n1. Extract barcodes and align reads\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n\nThere are two options to align 10x Genomics data to the reference genome for downstream use by GROC-SVs. The simplest option is to use the accompanying `simple_demux_map`_ script followed by read alignment using ``bwa mem``. Note that this will extract the 10x droplet barcodes for use by GROC-SVs (optionally demultiplexing pooled samples) but does not perform `barcode-aware read alignment <http://genome.cshlp.org/content/25/10/1570>`_.\n\n.. _simple_demux_map: simple_demux_map/\n\nThe second option is to use the 10x Genomics `longranger align <http://support.10xgenomics.com/genome-exome/software>`_ pipeline, which can optionally perform barcode-aware alignment. While not necessary, the full 10x longranger pipeline may be run, which adds phasing information that GROC-SVs can include in its analysis.\n\n\n2. Setup a configuration file\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n\nBecause GROC-SVs can analyze multiple samples jointly, and each sample can involve multiple input files, GROC-SVs uses a configuration file to specify inputs and settings for each run. See the examples directory for an example ``configuration.json`` file.\n\nThe configuration file is in the `JSON <http://www.json.org>`_ format, and contains the following three parts:\n\n1. reference genome paths\n2. sample information\n3. compute cluster settings\n\n**Reference genome** The following paths must be defined:\n\n* ``ref_fasta``: path to the reference genome FASTA file (hg19.fa, GRCh38.fa, etc)\n* ``bwa_index``: path to the genome index used by bwa-mem\n\nIn addition, the following optional paths may be specified:\n\n* ``blacklists``: a list of paths of blacklist regions, either `bed <https://genome.ucsc.edu/FAQ/FAQformat.html>`_ or `bedpe <http://bedtools.readthedocs.io/en/latest/content/general-usage.html#bedpe-format>`_ format\n* ``binaries``: a hash containing paths for any of the following binaries: ``idba_ud``, ``bwa``, ``samtools``, ``bgzip``, ``tabix``. If these are in your ``$PATH``, there is no need to specify them in the configuration file.\n\n**Sample information** Samples is a hash with key specifying sample name, and the value is a list of datasets. Each sample must have one 10x dataset specified, and may optionally specify a separate standard Illumina short-frag library or a mate-pair library (these are used for validation and comparison only).\n\nEach dataset is defined as a hash. 10x datasets must define the following items:\n\n* ``bam``: the path of the bam file produced by longranger. From the root longranger output directory, this is typically the file ``$ROOT/outs/possorted_bam.bam``.\n* ``id``: this is a name used to identify the dataset; typically, it would be something like \"``sample_name_10x``\"\n* ``type``: this should be the string \"``TenXDataset``\"\n\n**Tumor/normal, trio and other multi-sample analyses** GROC-SVs performs variant calling jointly on all samples specified in the configuration.json file, and no additional arguments are required to indicate the biological meaning of the sample. See the Output section below for descriptions of the \"genotypes.tsv\" and \"classes.txt\" files, which can be filtered in order to obtain events that are somatic (ie private to the tumor, and not present in the germline sample) or de novo in the child (ie private to the child and not present in either parent).\n\n**Compute cluster settings** This has defines the compute environment being used to perform the analysis. A standard cluster setup looks like this:\n\n.. code-block:: json\n\n    \"cluster_settings\": {\n        \"cluster_type\": \"IPCluster\",\n        \"processes\": 128,\n        \"cluster_options\": {\n            \"scheduler\": \"slurm\",\n            \"queue\": \"normal\",\n            \"start_wait\": 120,\n            \"extra_params\": {\"mem\":16}\n        }\n    }\n\nWhere ``processes`` specifies the maximum number of separate jobs (1 processor per job) to allow. ``scheduler`` may be any of the clusters supported by `ipython-cluster-helper <https://github.com/roryk/ipython-cluster-helper>`_. Currently, these are Platform LSF (\"lsf\"), Sun Grid Engine (\"sge\"), Torque (\"torque\"), and SLURM (\"slurm\").\n\nNote that the optional ``start_wait`` parameter determines how long grocsvs will wait for jobs to start running after they have been submitted to the scheduler. If you expect particularly long queueing times, you can set this to a much higher value - the default is 16 minutes (rather short for most cluster setups!) and as shown in the example above, it's been set to 120 minutes.\n\nTo run in parallel on a single machine, use ``cluster_type\":\"multiprocessing\"`` and specify the desired number of ``processes``.\n\nTo override the cluster options in the configuration.json file, use ``--local`` to specify single-core mode or ``--multiprocessing`` to specify running in parallel using all cores on a single machine.\n\n3. Run GROC-SVs\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n\nTo run GROC-SVs, use the ``grocsvs /path/to/experiment/configuration.json`` command. If you are using a virtualenv, remember to run ``source grocsvs_env/bin/activate`` to activate the virtualenv prior to running ``grocsvs``. \n\nThe output will be placed in the directory containing configuration (in this case, in ``/path/to/experiment/``), so make sure this filesystem has enough space for the analysis (~40GB per sample). GROC-SVs typically requires about 12-16 GB of memory in order to run, though this depends on your samples. If you have less than 16 GB of memory available on your machine, a warning will be output but the pipeline will continue to run as best as it can.\n\nNote that the ``grocsvs`` command will continue running until all steps have completed. The ``grocsvs`` command itself is lightweight, and so can be run from a head node on your cluster.\n\nLogging output for each step will be put in ``/path/to/experiment/logs``. The final results will be put in ``/path/to/experiment/results``.\n\n\nOutput\n\"\"\"\"\"\"\n\nFinal results of interest might be:\n\n* ``results/MergeGenotypesStep/genotypes.tsv``: the structural variant calls, including coordinates, information on which samples are positive for each event, which events together form complex events, and some filtering information (eg blacklist annotations provided above, genome gaps, etc) to remove potential false-positives\n* ``results/QCStep/qc_report.tsv``: some basic quality control statistics, including fragment lengths and number of barcodes per sample\n* ``results/AssemblyStep/assembly.i``: the sequence assemblies for event ``i``; in this directory, ``contigs.sorted.bam`` contain the contigs aligned back to the reference genome (this file may be viewed with `IGV <https://www.broadinstitute.org/igv/>`_)\n* ``results/FinalClusterSVsStep/edges.tsv``: full information relating breakpoints in complex structural variants\n* ``results/PostprocessingStep/classes.txt``: this file includes a simple presence/absence call for each structural variant for each sample, denoted as a 0 for absence and a 1 for presence. For example, if your tumor sample were the first sample, and the matched normal sample were the second sample, a \"10\" would indicate a somatic event and a \"11\" would indicate a germline event. These classes are determined using a simple allele-frequency cutoff which in our experience has been quite robust. More statistically motivated filters can be established by filtering on the p-values for each sample, which are indicated in this file as \"sarcoma_p_resampling\" if your sample name were \"sarcoma\" (note that missing p-values should be treated as 1).\n\n"
      },
      "source": "https://raw.githubusercontent.com/grocsvs/grocsvs/master/README.rst",
      "technique": "header_analysis"
    }
  ],
  "somef_missing_categories": [
    "citation",
    "acknowledgement",
    "download",
    "requirements",
    "contact",
    "contributors",
    "faq",
    "support",
    "identifier",
    "executable_example"
  ],
  "somef_provenance": {
    "date": "2024-11-04 06:24:47",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 39
      },
      "technique": "GitHub_API"
    }
  ],
  "type": [
    {
      "confidence": 0.82,
      "result": {
        "type": "String",
        "value": "commandline-application"
      },
      "technique": "software_type_heuristics"
    }
  ],
  "usage": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Docker (and example dataset)",
        "type": "Text_excerpt",
        "value": "A docker image is available for grocsvs. If you wish to download and run grocsvs on an example dataset (~1.3GB required), you can run the following commands:\n\n.. code-block:: bash\n    \n    # use 'curl -O' if you're on a mac without wget\n    wget http://mendel.stanford.edu/public/noah/grocsvs_example.tar.gz \n    tar -xzf grocsvs_example.tar.gz\n\nAssuming `docker <https://docs.docker.com/engine/installation/>`_ is installed, the following command can be used to analyze the example data from within docker (make sure you are in the same directory where you downloaded and extracted grocsvs_example.tar.gz):\n\n.. code-block:: bash\n\n    docker run -v `pwd`:/data -w /data/grocsvs_example/ grocsvs/grocsvs-docker grocsvs configuration.json --local\n\nThis requires ~16GB of memory to run and will take ~1 hour to complete. If you are running docker for Mac, please make sure that your virtual machine has access to at least 16GB of memory.\n\nThe output can be found in ``grocsvs_example/results``.\n"
      },
      "source": "https://raw.githubusercontent.com/grocsvs/grocsvs/master/README.rst",
      "technique": "header_analysis"
    }
  ]
}