{
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/mstrazar/iONMF"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2015-08-03T07:37:05Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2024-08-20T07:24:31Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "Integrative orthogonal non-negative matrix factorization"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 0.9931217920285276,
      "result": {
        "original_header": "iONMF",
        "type": "Text_excerpt",
        "value": "An integrative approach to model and predict multiple data sources based on orthogonal matrix factorization. \nFor details of the model, please refer to \nStra\u017ear M., \u017ditnik M., Zupan B., Ule. J, Curk. T: Orthogonal matrix factorization enables integrative analysis of multiple RNA binding proteins\n(to appear).\n \n"
      },
      "source": "https://raw.githubusercontent.com/mstrazar/ionmf/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "documentation": [
    {
      "confidence": 1,
      "result": {
        "format": "wiki",
        "type": "Url",
        "value": "https://github.com/mstrazar/ionmf/wiki"
      },
      "source": "https://raw.githubusercontent.com/mstrazar/ionmf/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/mstrazar/ionmf/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 15
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/mstrazar/iONMF/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "mstrazar/iONMF"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "iONMF"
      },
      "source": "https://raw.githubusercontent.com/mstrazar/ionmf/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "images": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/mstrazar/iONMF/master/img/yeast_rpr.png"
      },
      "source": "https://raw.githubusercontent.com/mstrazar/ionmf/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/mstrazar/iONMF/master/img/clip.png"
      },
      "source": "https://raw.githubusercontent.com/mstrazar/ionmf/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "installation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Installation",
        "parent_header": [
          "iONMF"
        ],
        "type": "Text_excerpt",
        "value": "iONMF can be installed using the pip package manager (may require root privileges):\n```\n    pip install ionmf\n```\n\niONMF can then be used within Python scripts. To factorize a NumPy array, type:\n```\n    import numpy as np\n    from ionmf.factorization.onmf import onmf\n    X = np.random.rand(10, 10)\n    W, H = onmf(X, k=5, alpha=1.0)\n```\n\n"
      },
      "source": "https://raw.githubusercontent.com/mstrazar/ionmf/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Dataset preparation",
        "parent_header": [
          "iONMF",
          "Basic usage"
        ],
        "type": "Text_excerpt",
        "value": "The data is assumed to be stored in one or more Numpy arrays (`numpy.ndarray`) and contain only non-negative values.\nThe dataset is then stored as a dictionary:\n\n```\ndataset = {\n  \"data_source_1\": X1,\n  \"data_source_2\": X2,\n  \"data_source_3\": X3,\n  # etc.\n}\n```\n\nwhere the keys are data source names and `X1, X2, X3` represent matrices (Numpy arrays having the same number of rows.) \n"
      },
      "source": "https://raw.githubusercontent.com/mstrazar/ionmf/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/mstrazar/iONMF/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ""
      },
      "technique": "GitHub_API"
    }
  ],
  "license": [
    {
      "confidence": 1,
      "result": {
        "name": "Other",
        "spdx_id": "NOASSERTION",
        "type": "License",
        "url": null,
        "value": null
      },
      "technique": "GitHub_API"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "iONMF"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "User",
        "value": "mstrazar"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 6923,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/mstrazar/ionmf/master/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "run": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Running the matrix factorization model",
        "parent_header": [
          "iONMF",
          "Basic usage"
        ],
        "type": "Text_excerpt",
        "value": "The model is initizalized as a class as follows\n```\nfrom ionmf.factorization.model import iONMF\nmodel = iONMF(rank=5, max_iter=100, alpha=1.0)\n```\n\nwhere `rank` is the maximum rank of the low-rank approximation, `max_iter` the number of iterations during optimization and `alpha` the orthogonality regularization. Higher alpha yields more distinct (orthogonal) basis vectors.\n\nHaving prepared the dataset, the model is trained as follows:\n```\nmodel.fit(dataset)\n```\n\nTHe low-rank approximations can be accessed e.g.\n```\nmodel.basis_[\"data_source_1\"]  # Get the basis (H) matrix for data_source_1\nmodel.coef_                    # Get the coefficient (W) matrix\n```\n\nNext, suppose we have a another set of samples, where one or more data sources are missing.\n```\ntestset = {\n  \"data_source_1\": Y1,\n  \"data_source_3\": Y3,\n}\n```\nIn this example, the `data_source_2` is missing. Again, `Y1, Y3` must share the same number of rows. Having trained a model on the previous (training) dataset, \nthe missing data sources can be filled in.\n```\nresults = model.predict(testset)\n```\nThe result is a dictionary results that contains approximations to all data sources that were missing from `testset`, in this case, `data_source_2`.\n```\nY2 = results[\"data_source_2\"]\n```\n"
      },
      "source": "https://raw.githubusercontent.com/mstrazar/ionmf/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "somef_missing_categories": [
    "citation",
    "acknowledgement",
    "download",
    "requirements",
    "contact",
    "contributors",
    "faq",
    "support",
    "identifier",
    "has_build_file",
    "executable_example"
  ],
  "somef_provenance": {
    "date": "2024-11-04 08:54:05",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 32
      },
      "technique": "GitHub_API"
    }
  ],
  "usage": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Basic usage",
        "parent_header": [
          "iONMF"
        ],
        "type": "Text_excerpt",
        "value": "The framework is simple to use within Python scripts.  Assume the data is represented as matrices `X1, X2, ..., XN` - data sources, where rows represent <i>samples</i> and columns represent <i>features</i>. There can be multiple feature matrices as long as they share the same number of rows. \n\nAn iONMF model approximates each matrix `Xi` with a matrix product `W Hi`, such that\n```\nX_1 ~ W H1\nX_2 ~ W H2\n...\nX_N ~ W HN\n```\nwhere `W`, and `H1, H2, ..., HN` are non-negative matrices of lower ranks and their matrix product approximates the data sources `X1, X2, ... XN`.\n\nThe coefficient matrix `W` is common to all data sources and represents clustering of rows, while each basis matrices `H1, H2, ..., HN` represent clustering of columns. Due to non-negativity constraints, the rows of `H` can be interpreted as commonly occuring combinations of features. \n\nSuch model can be used to provide and interpetation of the dataset (unsupervised learning; clustering of rows and most commonly occuring features) or prediction (supervised learning), where one or more datasource is missing for a set of test samples, provided at least one `Xi` is available. \n\n"
      },
      "source": "https://raw.githubusercontent.com/mstrazar/ionmf/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Pre-prepared examples",
        "parent_header": [
          "iONMF"
        ],
        "type": "Text_excerpt",
        "value": "Prepared practical examples for usage of the model are available.\n"
      },
      "source": "https://raw.githubusercontent.com/mstrazar/ionmf/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Yeast RPR dataset",
        "parent_header": [
          "iONMF",
          "Pre-prepared examples"
        ],
        "type": "Text_excerpt",
        "value": "See ionmf.example.yeast_rpr.py \nA simple example of running iONMF on a differential gene expression dataset. The dataset contains 186 samples and 79 genes, divided into 3 classes. \n\nSome values in the matrix `X` contain negative values. The following trick is used. The number of columns is doubled to form the matrices `Xp`, `Xn` each of size (186 rows, 79 columns). All positive values are stored in `Xp`, while absolute values of negative cells are stored in `Xn`.\n\nAdditional three 186 x 1 matrices are stored to represent the three classes (value 1 if the sample i belongs to the class).\n\nIn this demonstrative example, the model is trained on the whole dataset. In the test phase, the datasources representing classes are removed from the model. After prediction, each sample is assigne to class 0, 1, or 2 depending on maximum value in approximated columns `class_0, class_1, class_2`. The training accuracy is measured as the fraction of correctly classified examples.\n\nEach matrix `X` is plotted along with the approximation `W H`. Increasing the maximum model rank would yield more accurate approximations.\n\n![yeast_rpr](https://raw.githubusercontent.com/mstrazar/iONMF/master/img/yeast_rpr.png)\n\nThe details of each step is explained in the comments.\n\n"
      },
      "source": "https://raw.githubusercontent.com/mstrazar/ionmf/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "RNA-binding proteins dataset (CLIP)",
        "parent_header": [
          "iONMF",
          "Pre-prepared examples"
        ],
        "type": "Text_excerpt",
        "value": "An application is presented on modeling protein-RNA interaction data as presented in the article above. Currently, 31 CLIP datasets are available corresponding to the numbering adopted in the article.  Each training and test set contains 20% positive (cross-linked positions) and additional data sources: RNA k-mers, RNA structure (as predicted with RNAfold), Region types (genomic annotation), GeneOntology terms and Co-bining (CLIP experiments on other proteins that are not technical or biological replicates).\n\nThe `master` branch include only one training/test sample of positions of size 5000 per protein.\nLarger datasets with 30000 positions as well as more training/test splits are available at\nbranch `master_full`. For more details on the format of data, see [/datasets/clip/README.html](/datasets/clip/README.html).\nCharacteristic data-source featue values, presented in the article Suplementary Section 7 are\n available within branch `master_full` at [/features](/features)\n\n\nAn example is run as follows\n```\ncd ionmf/examples/\nexport PYTHONPATH=\"../..\"\npython clip.py  27_ICLIP_TDP43_hg19\n```\n\nwhere the argument is one of the datasets within the collection:\n```\ndatasets/\n  clip/\n    1_PARCLIP_AGO1234_hg19\n    2_PARCLIP_AGO2MNASE_hg19\n    3_HITSCLIP_Ago2_binding_clusters\n    4_HITSCLIP_Ago2_binding_clusters_2\n    5_CLIPSEQ_AGO2_hg19\n    6_CLIP-seq-eIF4AIII_1\n    7_CLIP-seq-eIF4AIII_2\n    8_PARCLIP_ELAVL1_hg19\n    9_PARCLIP_ELAVL1MNASE_hg19\n    10_PARCLIP_ELAVL1A_hg19\n    11_CLIPSEQ_ELAVL1_hg19\n    12_PARCLIP_EWSR1_hg19\n    13_PARCLIP_FUS_hg19\n    14_PARCLIP_FUS_mut_hg19\n    15_PARCLIP_IGF2BP123_hg19\n    16_ICLIP_hnRNPC_Hela_iCLIP_all_clusters\n    17_ICLIP_HNRNPC_hg19\n    18_ICLIP_hnRNPL_Hela_group_3975_all-hnRNPL-Hela-hg19_sum_G_hg19--ensembl59_from_2337-2339-741_bedGraph-cDNA-hits-in-genome\n    19_ICLIP_hnRNPL_U266_group_3986_all-hnRNPL-U266-hg19_sum_G_hg19--ensembl59_from_2485_bedGraph-cDNA-hits-in-genome\n    20_ICLIP_hnRNPlike_U266_group_4000_all-hnRNPLlike-U266-hg19_sum_G_hg19--ensembl59_from_2342-2486_bedGraph-cDNA-hits-in-genome\n    21_PARCLIP_MOV10_Sievers_hg19\n    22_ICLIP_NSUN2_293_group_4007_all-NSUN2-293-hg19_sum_G_hg19--ensembl59_from_3137-3202_bedGraph-cDNA-hits-in-genome\n    23_PARCLIP_PUM2_hg19\n    24_PARCLIP_QKI_hg19\n    25_CLIPSEQ_SFRS1_hg19\n    26_PARCLIP_TAF15_hg19\n    27_ICLIP_TDP43_hg19\n    28_ICLIP_TIA1_hg19\n    29_ICLIP_TIAL1_hg19\n    30_ICLIP_U2AF65_Hela_iCLIP_ctrl_all_clusters\n    31_ICLIP_U2AF65_Hela_iCLIP_ctrl+kd_all_clusters\n```\n\nA desired subset of data sources is seleted via the method\n\n```\ndef load_data(path,\n    kmer    = True,   # RNA k-mers\n    rg      = True,   # Region Type\n    clip    = True,   # Experiments (cobinding)\n    rna     = True,   # RNAfold structure prediction\n    go      = True,   # Gene Ontology terms\n    )\n```\n\nA run including all data sources required 12 GB of RAM and completes in\n21 minutes on a 2GHz CPU. Support for sparse matrices is under construction.\n\n\nA single training / prediction run is perfomed.\nThe positions in the test samples are sampled from genes that do not overlap with training genes. The exact location of the positions can be examined in the corresponding .bedGraph text file, e.g.: `datasets/clip/27_ICLIP_TDP43_hg19/2000/training_sample_0/positions.bedGraph.gz`\n    \n    \nExamples of low-dimensional modules for the data sources RNA structure and region types, along with an estimate of each module belongin to either positive/negative examples is shown: \n\n![clip](https://raw.githubusercontent.com/mstrazar/iONMF/master/img/clip.png)\n\n  The details of each step is explained in the comments within the script.\n"
      },
      "source": "https://raw.githubusercontent.com/mstrazar/ionmf/master/README.md",
      "technique": "header_analysis"
    }
  ]
}