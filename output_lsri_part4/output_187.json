{
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/MedChaabane/deepRAM"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2019-01-27T01:08:56Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2023-12-23T00:56:24Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "End-to-end deep learning toolkit for predicting protein binding sites and motifs. "
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 0.9806719305818066,
      "result": {
        "original_header": "deepRAM",
        "type": "Text_excerpt",
        "value": "deepRAM is an end-to-end deep learning toolkit for predicting protein binding sites and motifs. It helps users run experiments using many state-of-the-art deep learning methods and addresses the challenge of selecting model parameters in deep learning models using a fully automatic model selection strategy. This helps avoid hand-tuning and thus removes any bias in running experiments, making it user friendly without losing its flexibility. While it was designed with ChIP-seq and CLIP-seq data in mind, it can be used for any DNA/RNA sequence binary classification problem. \ndeepRAM allows users the flexibility to choose a deep learning model by selecting its different components:  input sequence representation (one-hot or k-mer embedding), whether to use a CNN and how many layers, and whether to use an RNN, and the number of layers and their type. For CNNs, the user can choose to use dilated convolution as well.\n <br><br> \n"
      },
      "source": "https://raw.githubusercontent.com/MedChaabane/deepRAM/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.969606968873474,
      "result": {
        "original_header": "Motifs identification and visualization",
        "type": "Text_excerpt",
        "value": "You need to install <a href=http://weblogo.berkeley.edu/> WebLogo </a> and TOMTOM in <a href=http://meme-suite.org> MEME Suite </a> to match identifyed motifs with known motifs of Transcription Factors and RBPs. Read documentations about installation and usage.\n \n"
      },
      "source": "https://raw.githubusercontent.com/MedChaabane/deepRAM/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9590044685445144,
      "result": {
        "original_header": "Datasets",
        "type": "Text_excerpt",
        "value": "We have provided two preprocessing scripts to change the format of the used datasets to a format compatible with deepRAM input data format (deepRAM input data format: sequence label. See [Example input data](https://github.com/MedChaabane/deepRAM/blob/master/datasets/example-input-data.gz)): \n- [preprocess_1.py](https://github.com/MedChaabane/deepRAM/blob/master/preprocess_1.py) can be used for [DeepBind](https://www.nature.com/articles/nbt.3300)-ENCODE-ChIP-seq-data-like format and, \n- [preprocess_2.py](https://github.com/MedChaabane/deepRAM/blob/master/preprocess_2.py) can be used for [iONMF](https://www.ncbi.nlm.nih.gov/pubmed/26787667)-CLIP-seq-data-like format. \n"
      },
      "source": "https://raw.githubusercontent.com/MedChaabane/deepRAM/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/MedChaabane/deepRAM/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 13
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/MedChaabane/deepRAM/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "MedChaabane/deepRAM"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "deepRAM"
      },
      "source": "https://raw.githubusercontent.com/MedChaabane/deepRAM/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "images": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/MedChaabane/deepRAM/master/CSU-Ram.jpg"
      },
      "source": "https://raw.githubusercontent.com/MedChaabane/deepRAM/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "installation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Installation",
        "parent_header": [
          "deepRAM"
        ],
        "type": "Text_excerpt",
        "value": "1) Download deepRAM\n```bash\ngit clone https://github.com/MedChaabane/deepRAM.git\n\ncd deepRAM\n```\n\n2) Install required packages \n```bash\npip3 install -r Prerequisites\n```\n3) Install deepRAM\n```bash\npython setup.py install\n```"
      },
      "source": "https://raw.githubusercontent.com/MedChaabane/deepRAM/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 0.9976763168047946,
      "result": {
        "original_header": "Motifs identification and visualization",
        "type": "Text_excerpt",
        "value": "You need to install <a href=http://weblogo.berkeley.edu/> WebLogo </a> and TOMTOM in <a href=http://meme-suite.org> MEME Suite </a> to match identifyed motifs with known motifs of Transcription Factors and RBPs. Read documentations about installation and usage.\n \n"
      },
      "source": "https://raw.githubusercontent.com/MedChaabane/deepRAM/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9946277787533429,
      "result": {
        "original_header": "Datasets",
        "type": "Text_excerpt",
        "value": "1. ChIP-seq datasets can be downloaded from:\nhttp://tools.genes.toronto.edu/deepbind/nbtcode \n2) CLIP-seq datasets can be downloaded from: https://github.com/xypan1232/iDeepS/tree/master/datasets/clip \n"
      },
      "source": "https://raw.githubusercontent.com/MedChaabane/deepRAM/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/MedChaabane/deepRAM/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ""
      },
      "technique": "GitHub_API"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "deepRAM"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "User",
        "value": "MedChaabane"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 60868,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/MedChaabane/deepRAM/master/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "requirements": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Dependency <br>",
        "parent_header": [
          "deepRAM"
        ],
        "type": "Text_excerpt",
        "value": "We recommend to use [Anaconda 3](https://www.anaconda.com/download/) platform. \n-  <a href=https://www.python.org/downloads/source/>Python 3.6 </a> <br>\n-  <a href=https://pytorch.org/>PyTorch 1.0 library </a> (Deep learning library) <br>\n-  <a href=https://github.com/scikit-learn/scikit-learn>sklearn</a> (Machine learning library)<br>\n-  <a href=https://anaconda.org/anaconda/gensim>gensim</a> (library used to train word2vec algorithm) <br>\n-  <a href=https://anaconda.org/anaconda/numpy>numpy</a> <br>\n"
      },
      "source": "https://raw.githubusercontent.com/MedChaabane/deepRAM/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "somef_missing_categories": [
    "citation",
    "acknowledgement",
    "run",
    "download",
    "contact",
    "contributors",
    "documentation",
    "license",
    "faq",
    "support",
    "identifier",
    "has_build_file",
    "executable_example"
  ],
  "somef_provenance": {
    "date": "2024-11-04 02:25:38",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 44
      },
      "technique": "GitHub_API"
    }
  ],
  "usage": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Usage",
        "parent_header": [
          "deepRAM"
        ],
        "type": "Text_excerpt",
        "value": "```bash \nusage: deepRAM.py [-h] [--train_data TRAIN_DATA] [--test_data TEST_DATA]\n                  [--data_type DATA_TYPE] [--train TRAIN]\n                  [--predict_only PREDICT_ONLY]\n                  [--evaluate_performance EVALUATE_PERFORMANCE]\n                  [--models_dir MODELS_DIR] [--model_path MODEL_PATH]\n                  [--motif MOTIF] [--motif_dir MOTIF_DIR]\n                  [--tomtom_dir TOMTOM_DIR] [--out_file OUT_FILE]\n                  [--Embedding EMBEDDING] [--Conv CONV] [--RNN RNN]\n                  [--RNN_type RNN_TYPE] [--kmer_len KMER_LEN]\n                  [--stride STRIDE] [--word2vec_train WORD2VEC_TRAIN]\n                  [--word2vec_model WORD2VEC_MODEL]\n                  [--conv_layers CONV_LAYERS] [--dilation DILATION]\n                  [--RNN_layers RNN_LAYERS]\n\nsequence specificities prediction using deep learning approach\n\noptional arguments:\n  -h, --help            show this help message and exit\n  --train_data TRAIN_DATA\n                        path for training data with format: sequence label\n  --test_data TEST_DATA\n                        path for test data containing test sequences with or\n                        without label\n  --data_type DATA_TYPE\n                        type of data: DNA or RNA. default: DNA\n  --train TRAIN         use this option for automatic calibration, training\n                        model using train_data and predict labels for\n                        test_data. default: True\n  --predict_only PREDICT_ONLY\n                        use this option to load pretrained model (found in\n                        model_path) and use it to predict test sequences\n                        (train will be set to False). default: False\n  --evaluate_performance EVALUATE_PERFORMANCE\n                        use this option to calculate AUC on test_data. If\n                        True, test_data should be format: sequence label.\n                        default: False\n  --models_dir MODELS_DIR\n                        The directory to save the trained models for future\n                        prediction including best hyperparameters and\n                        embedding model. default: models/\n  --model_path MODEL_PATH\n                        If train is set to True, This path will be used to\n                        save your best model. If train is set to False, this\n                        path should have the model that you want to use for\n                        prediction. default: BestModel.pkl\n  --motif MOTIF         use this option to generate motif logos. default:\n                        False\n  --motif_dir MOTIF_DIR\n                        directory to save motifs logos. default: motifs\n  --tomtom_dir TOMTOM_DIR\n                        directory of TOMTOM, i.e:meme-5.0.3/src/tomtom\n  --out_file OUT_FILE   The output file used to store the prediction\n                        probability of testing data\n  --Embedding EMBEDDING\n                        Use embedding layer: True or False. default: False\n  --Conv CONV           Use conv layer: True or False. default: True\n  --RNN RNN             Use RNN layer: True or False. default: False\n  --RNN_type RNN_TYPE   RNN type: LSTM or GRU or BiLSTM or BiGRU. default:\n                        BiLSTM\n  --kmer_len KMER_LEN   length of kmer used for embedding layer, default= 3\n  --stride STRIDE       stride used for embedding layer, default= 1\n  --word2vec_train WORD2VEC_TRAIN\n                        set it to False if you have already trained word2vec\n                        model. If you set it to False, you need to specify the\n                        path for word2vec model in word2vec_model argument.\n                        default: True\n  --word2vec_model WORD2VEC_MODEL\n                        If word2vec_train is set to True, This path will be\n                        used to save your word2vec model. If word2vec_train is\n                        set to False, this path should have the word2vec model\n                        that you want to use for embedding layer. default:\n                        word2vec\n  --conv_layers CONV_LAYERS\n                        number of convolutional modules. default= 1\n  --dilation DILATION   the spacing between kernel elements for convolutional\n                        modules (except the first convolutional module).\n                        default= 1\n  --RNN_layers RNN_LAYERS\n                        number of RNN layers. default= 1\n```\n"
      },
      "source": "https://raw.githubusercontent.com/MedChaabane/deepRAM/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "preprocess CLIP-seq files (train and test) to match deepRAM data format: sequence label",
        "parent_header": [
          "deepRAM",
          "Example with CLIP-seq"
        ],
        "type": "Text_excerpt",
        "value": "```bash\npython preprocess_2.py --CLIP_data datasets/CLIP-seq/1_PARCLIP_AGO1234_hg19/30000/training_sample_0/sequences.fa.gz --output CLIP_train.gz\n```\n```bash\npython preprocess_2.py --CLIP_data datasets/CLIP-seq/1_PARCLIP_AGO1234_hg19/30000/test_sample_0/sequences.fa.gz --output CLIP_test.gz\n```"
      },
      "source": "https://raw.githubusercontent.com/MedChaabane/deepRAM/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "train DeepBind architecture with CLIP_train.gz and evaluate performance on CLIP_test.gz",
        "parent_header": [
          "deepRAM",
          "Example with CLIP-seq"
        ],
        "type": "Text_excerpt",
        "value": "```\npython deepRAM.py --train_data CLIP_train.gz --test_data CLIP_test.gz --data_type RNA --train True --evaluate_performance True --model_path DeepBind.pkl --out_file prediction.txt --Embedding False --Conv True --RNN False --conv_layers 1 \n```"
      },
      "source": "https://raw.githubusercontent.com/MedChaabane/deepRAM/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "visualizating motifs and matching them with known motifs",
        "parent_header": [
          "deepRAM",
          "Example with CLIP-seq"
        ],
        "type": "Text_excerpt",
        "value": "```\npython deepRAM.py --test_data CLIP_test.gz --data_type RNA --predict_only True --model_path DeepBind.pkl --motif True --motif_dir motifs --tomtom_dir meme-5.0.3/src/tomtom --out_file prediction.txt --Embedding False --Conv True --RNN False --conv_layers 1\n```\nmake sure to specify the directory of TOMTOM in --tomtom_dir argument\n"
      },
      "source": "https://raw.githubusercontent.com/MedChaabane/deepRAM/master/README.md",
      "technique": "header_analysis"
    }
  ]
}