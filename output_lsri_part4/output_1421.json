{
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/dzerbino/oases"
      },
      "technique": "GitHub_API"
    }
  ],
  "contributing_guidelines": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Oases does not give an expression level. How can I get that?",
        "parent_header": [
          "Running Oases",
          "FAQ and Practical considerations"
        ],
        "type": "Text_excerpt",
        "value": "In general you need to align reads to the transcripts with your favorite\naligner, one that allows for multi mappings !! Although few results\nexist about the difficulties and problems of quantitation of *de novo*\ntranscripts\u2019 expression levels, here are a few pointers to specialized\ntools:\n\n1.  eXpress - <http://bio.math.berkeley.edu/eXpress/> (command line,\n    Windows support)\n\n2.  RSEM - <http://deweylab.biostat.wisc.edu/rsem/> (command line)\n\n"
      },
      "source": "https://raw.githubusercontent.com/dzerbino/oases/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2010-01-29T16:35:48Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2024-09-09T22:01:03Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "De novo transcriptome assembler for short reads"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 0.8733886779791291,
      "result": {
        "original_header": "Compilation options",
        "type": "Text_excerpt",
        "value": "| Option | Default | Description \n| ------ | ------- | ------------\n| CATEGORIES | 2 | Maxium number of different DNA libraries\n| MAXKMERLENGTH | 64 | Maximum k-mer value supported\n| OPENMP | 0 | Enable OpenMP multithreading support\n| BIGASSEMBLY | 0 | FIXME\n| VBIGASSEMBLY | 0 | FIXME\n| LONGSEQUENCES | 0 | FIXME\n| SINGLE_COV_CAT | 0 | FIXME\n| BUNDLEDZLIB | 0 | Use the bundled zlib 1.2.3 instead of system one \nYou can apply them as in this example which changes three options: \n"
      },
      "source": "https://raw.githubusercontent.com/dzerbino/oases/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "documentation": [
    {
      "confidence": 1,
      "result": {
        "format": "wiki",
        "type": "Url",
        "value": "https://github.com/dzerbino/oases/wiki"
      },
      "source": "https://raw.githubusercontent.com/dzerbino/oases/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/dzerbino/oases/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "faq": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Avoid overlapping reads",
        "parent_header": [
          "Running Oases",
          "FAQ and Practical considerations",
          "I am running out of memory. What should I do?"
        ],
        "type": "Text_excerpt",
        "value": "In our experience, if insert lengths are so short that paired reads\noverlap on their 3\u2019 ends, i.e., if the insert length is less than\ntwice the length, this prevents the early filtering of low coverage reads. \nThis means that even small datasets may require huge amounts of memory. A way\nto avoid the problem is to join paired-end reads that overlap.\nOne tool to do this is\n[PEAR](http://sco.h-its.org/exelixis/web/software/pear/doc.html).\n"
      },
      "source": "https://raw.githubusercontent.com/dzerbino/oases/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Avoid bad quality reads",
        "parent_header": [
          "Running Oases",
          "FAQ and Practical considerations",
          "I am running out of memory. What should I do?"
        ],
        "type": "Text_excerpt",
        "value": "Reads with many errors create new nodes in the de Bruijn graph, all of\nwhich are later discarded by the error removal steps. Removing the\nerrors in the reads *a priori* is a good way to decrease the memory\nconsumption. A very common approach is to remove bad quality bases from\nthe ends of read sequences or remove entire read sequences, numerous\npackages exist to do that but differ in functionality and definition of\nbad quality.\nOne tool to do this is\n[Trimmomatic](http://www.usadellab.org/cms/?page=trimmomatic)\n\nNote that when you use paired-end sequences and reads are discarded from\nthe file you need to make sure that the fasta/fastq file that you give\nto velveth contains the paired-end reads in correct pairing. Also if the\nread clipper retains single end reads from a pair, it is advisable to\ngive them as a second dataset of type ```-short``` to avoid data loss.\n"
      },
      "source": "https://raw.githubusercontent.com/dzerbino/oases/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Trim sequencing adapters",
        "parent_header": [
          "Running Oases",
          "FAQ and Practical considerations",
          "I am running out of memory. What should I do?"
        ],
        "type": "Text_excerpt",
        "value": "Depending on your sequencing experiment, some of the reads may have\nadapters that were used, e.g, during library preparation. These adapters\nshould be trimmed. Tools like\n[Trimmomatic](http://www.usadellab.org/cms/?page=trimmomatic)\ncan also do this.\n"
      },
      "source": "https://raw.githubusercontent.com/dzerbino/oases/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Remove duplicate reads",
        "parent_header": [
          "Running Oases",
          "FAQ and Practical considerations",
          "I am running out of memory. What should I do?"
        ],
        "type": "Text_excerpt",
        "value": "Especially for paired-end datasets it happens that the exact same read\nsequence is found a large number of times. One tool to do this is using\n[Picard](http://broadinstitute.github.io/picard/).\n\n"
      },
      "source": "https://raw.githubusercontent.com/dzerbino/oases/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "I want to predict coding regions. How can I do that?",
        "parent_header": [
          "Running Oases",
          "FAQ and Practical considerations"
        ],
        "type": "Text_excerpt",
        "value": "All the transcripts reported in a locus should have the same\ndirectionality, but that is only true if there is no contamination.\nStandard approaches are to use blastp and tools alike. Alternatively use\ngene prediction tools like GlimmerHMM, SNAP or AUGUSTUS.\n\n\n"
      },
      "source": "https://raw.githubusercontent.com/dzerbino/oases/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 9
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/dzerbino/oases/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "dzerbino/oases"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "Oases"
      },
      "source": "https://raw.githubusercontent.com/dzerbino/oases/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "installation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Installing Oases",
        "parent_header": [
          "Oases"
        ],
        "type": "Text_excerpt",
        "value": "    > git clone --recursive https://github.com/dzerbino/oases\n    > cd oases\n    > make\n    > ./oases --version\n    0.2.09\n"
      },
      "source": "https://raw.githubusercontent.com/dzerbino/oases/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 0.8835102503131397,
      "result": {
        "original_header": "Compilation options",
        "type": "Text_excerpt",
        "value": "    make OPENMP=1 CATEGORIES=4 MAXKMERLENGTH=192 \n"
      },
      "source": "https://raw.githubusercontent.com/dzerbino/oases/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/dzerbino/oases/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ""
      },
      "technique": "GitHub_API"
    }
  ],
  "license": [
    {
      "confidence": 1,
      "result": {
        "name": "GNU General Public License v3.0",
        "spdx_id": "GPL-3.0",
        "type": "License",
        "url": "https://api.github.com/licenses/gpl-3.0",
        "value": "https://api.github.com/licenses/gpl-3.0"
      },
      "technique": "GitHub_API"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "oases"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "User",
        "value": "dzerbino"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "C",
        "size": 248264,
        "type": "Programming_language",
        "value": "C"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "C++",
        "size": 9246,
        "type": "Programming_language",
        "value": "C++"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 5681,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Makefile",
        "size": 3121,
        "type": "Programming_language",
        "value": "Makefile"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/dzerbino/oases/master/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "releases": [
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "tseemann",
          "type": "User"
        },
        "date_created": "2015-03-22T21:36:39Z",
        "date_published": "2015-03-22T21:41:34Z",
        "description": "First official tagged github release. No algorithmic changes, just\n- new Makefile\n- new Markdown manual\n- new option --version \n- new option --citation.\n",
        "html_url": "https://github.com/dzerbino/oases/releases/tag/0.2.09",
        "name": "Not just one oasis.",
        "release_id": 1078138,
        "tag": "0.2.09",
        "tarball_url": "https://api.github.com/repos/dzerbino/oases/tarball/0.2.09",
        "type": "Release",
        "url": "https://api.github.com/repos/dzerbino/oases/releases/1078138",
        "value": "https://api.github.com/repos/dzerbino/oases/releases/1078138",
        "zipball_url": "https://api.github.com/repos/dzerbino/oases/zipball/0.2.09"
      },
      "technique": "GitHub_API"
    }
  ],
  "requirements": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Requirements",
        "parent_header": [
          "Oases"
        ],
        "type": "Text_excerpt",
        "value": "Oases should function on any standard 64 bit Unix environment with a C compiler.\nA good amount of physical memory (12GB to start with, more is no luxury) is recommended.\n"
      },
      "source": "https://raw.githubusercontent.com/dzerbino/oases/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "run": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Running Oases",
        "type": "Text_excerpt",
        "value": "If you are not familiar with using Velvet, read Velvet\u2019s manual first,\nas many references below will point to that document.\n"
      },
      "source": "https://raw.githubusercontent.com/dzerbino/oases/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "For impatient people",
        "parent_header": [
          "Running Oases"
        ],
        "type": "Text_excerpt",
        "value": "    # hash reads for k=31 and k=23\n    > velveth directory 31,23 data/test_reads.fa\n\n    # assemble the k=31 reads\n    > velvetg directory_31 -read_trkg yes\n    > oases directory_31\n\n    # assemble the k=23 reads\n    > velvetg directory_23 -read_trkg yes\n    > oases directory_23\n\n    # merge the above assemblies with a nominal k=23\n    > velveth mergedAssembly 23 -long directory*/transcripts.fa\n    > velvetg mergedAssembly -read_trkg yes -conserveLong yes\n    > oases mergedAssembly -merge yes\n\nOr use the python script ```oases_pipeline.py```:\n\n    > python scripts/oases_pipeline.py -m 21 -M 23 -d 'data/test_reads.fa'\n"
      },
      "source": "https://raw.githubusercontent.com/dzerbino/oases/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "For patient people",
        "parent_header": [
          "Running Oases"
        ],
        "type": "Text_excerpt",
        "value": "To run Oases it is recommended to run an array of single-_k_ assemblies,\nfor different values of _k_ (i.e. the hash length). These assemblies are\nthen merged into a final assembly.\n"
      },
      "source": "https://raw.githubusercontent.com/dzerbino/oases/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Single-*k* assemblies",
        "parent_header": [
          "Running Oases",
          "For patient people"
        ],
        "type": "Text_excerpt",
        "value": "Each single-_k_ assembly consists of a simple Velvet run, followed by an\nOases run. As in Velvet, the hash length _k_ is an odd integer. Velveth\nis run normally and velvetg is run with only one option:\n\n    > velveth directory_k k reads.fa\n    > velvetg directory_k -read_trkg yes\n\nIf you have strand specific reads then you have to type:\n\n    > velveth directory_k k -strand_specific reads.fa\n\nAnd if they are also FASTQ files compressed with GZIP you use the regular\nVelvet options to change the format\n\n    > velveth directory_k k -strand_specific -short -fastq.gz reads.fastq.gz\n\nOases is then run on that directory:\n\n    > oases directory_k\n\n\n"
      },
      "source": "https://raw.githubusercontent.com/dzerbino/oases/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Insert length",
        "parent_header": [
          "Running Oases",
          "Oases options"
        ],
        "type": "Text_excerpt",
        "value": "If using paired-end reads, Oases needs to know the expected insert\nlength (it cannot be estimated reliably automatically). The syntax to\nprovide insert lengths is identical to that used in Velvet:\n\n    oases directory -ins_length 500\n\nDon't forget to also ensure the reads were hashed into a _paired_ category\nat the earlier ```velveth``` stage!\n\n    > velveth directory_k k -shortPaired -fastq.gz -separate R1.fq.gz R2.fq.gz\n\n"
      },
      "source": "https://raw.githubusercontent.com/dzerbino/oases/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Coverage cutoff",
        "parent_header": [
          "Running Oases",
          "Oases options"
        ],
        "type": "Text_excerpt",
        "value": "Just like Velvet, low coverage contigs are removed from the assembly.\nBecause genes span all the spectrum of expression levels and therefore\ncoverage depths, setting the coverage cutoff does not depend on an\nexpected or median coverage. Instead, the coverage cutoff is set to\nremove all the contigs whose coverage is so low that *de novo* assembly\nwould be impossible anyways (by default it is set at 3x). If you wish\nto set it to another value, simply use the Velvet-like option:\n\n    oases directory -cov_cutoff 5\n"
      },
      "source": "https://raw.githubusercontent.com/dzerbino/oases/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Edge fraction cutoff",
        "parent_header": [
          "Running Oases",
          "Oases options"
        ],
        "type": "Text_excerpt",
        "value": "To allow more efficient error removal at high coverage, Oases integrates\na dynamic correction method: if at a given node, an edge\u2019s coverage\nrepresents less than a given percentage of the sum of coverages of edges\ncoming out of that node, it is removed.\n\nBy default this percentage is 10% (0.1) but you can set it manually:\n\n    oases directory -edgeFractionCutoff 0.01\n"
      },
      "source": "https://raw.githubusercontent.com/dzerbino/oases/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Scaffold filtering",
        "parent_header": [
          "Running Oases",
          "Oases options"
        ],
        "type": "Text_excerpt",
        "value": "By default the distance estimate between two long contigs is discarded\nas unreliable if it is supported by less than a given number (by default\n4) or read-pairs or bridging reads. If you wish to change this cutoff:\n\n    oases directory -min_pair_count 5\n"
      },
      "source": "https://raw.githubusercontent.com/dzerbino/oases/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Filtering the output",
        "parent_header": [
          "Running Oases",
          "Oases options"
        ],
        "type": "Text_excerpt",
        "value": "By setting the minimum transfrag length (by default 100bp), the user can\ncontrol what is being output in the results files:\n\n    > oases directory -min_trans_lgth 200\n"
      },
      "source": "https://raw.githubusercontent.com/dzerbino/oases/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Assembly merging",
        "parent_header": [
          "Running Oases",
          "Oases options"
        ],
        "type": "Text_excerpt",
        "value": "After running the previous process for different values of _k_ it is\nnecessary to merge the results of all these assemblies (contained in\n```transcripts.fa``` files) into a single, non redundant assembly. To\nrealize this merge, it is necessary to choose a value of K.\nExperiments have shown that K=27 works nicely for most organisms.\nHigher values for K should be used if problems with missassemblies are\nobserved. \n\nAssume we want to create a merged assembly in a folder called ```MergedAssembly```:\n\n    > velveth MergedAssembly/ K -long directory*/transcripts.fa\n    > velvetg MergedAssembly/ -read_trkg yes -conserveLong yes\n    > oases MergedAssembly/ -merge yes\n\nNote\u00a0that the ```transcripts.fa``` files need to be given as ```-long``` category.\n"
      },
      "source": "https://raw.githubusercontent.com/dzerbino/oases/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Using the supplied python script",
        "parent_header": [
          "Running Oases",
          "Oases options"
        ],
        "type": "Text_excerpt",
        "value": "With version 0.2 of Oases comes a new python script that runs the\nindividual single-_k_ assemblies and the new merge module. We highly\nrecommend to use the script for the analyses, but please read the\nprevious section for the Oases options that you\nneed to supply to the script. However, as the script also runs velvet\nplease consult the velvet manual for more insight. First notice the\noptions for the script below:\n\n    python scripts/oases_pipeline.py\n    Options:\n      -h, --help            show this help message and exit\n      -d FILES, --data=FILES\n                            Velveth file descriptors\n      -p OPTIONS, --options=OPTIONS\n                            Oases options that are passed to the command line,\n                            e.g., -cov_cutoff 5 -ins_length 300\n      -m KMIN, --kmin=KMIN  Minimum k\n      -M KMAX, --kmax=KMAX  Maximum k\n      -s KSTEP, --kstep=KSTEP\n                            Steps in k\n      -g KMERGE, --merge=KMERGE\n                            Merge k\n      -o NAME, --output=NAME\n                            Output directory prefix\n      -r, --mergeOnly       Only do the merge\n      -c, --clean           Clean temp files\n\nNote\u00a0that the script checks if Oases version at least 0.2.01 and Velvet at\nleast 1.1.7 are installed on your path. Otherwise it will not work.\n\nWe will illustrate the usage of the script with the two most common\nscenarios single-end and paired-end reads.\n\nFirst assume we \u00a0want to compute a merged assembly from 21 to 35 with\nOases on a single-end data set that is strand specific and retain\ntranscripts of minimum length 100. We want to save the assemblies in\nfolders that start with singleEnd :\n\n    python scripts/oases_pipeline.py -m 21 -M 35 -o singleEnd \n    -d ' data/test_reads.fa -strand_specific '\n    -p ' -min_trans_lgth 100 ' \n\nThe script creates a folder named singleEnd_k for each single-k\nassembly and one folder named singleEndMerged that contains the merged\ntranscripts for all single-_k_ assemblies in the ```transcripts.fa``` file.\n\nNow assume we have paired-end reads with insert length 300 and we want\nto compute a merged assembly from 17 to 40. We want to save the\nassemblies in the folders that start with pairedEnd\n\n    python scripts/oases_pipeline.py \n      -m 17 -M 40 -o pairedEnd \n      -d ' -shortPaired  data/test_reads.fa '\n      -p ' -ins_length 300 '\n\nNow say we found that using k=17 was a bit too low and we want to look\nat a different merged assembly range. Instead of redoing all the time\nconsuming assemblies we can re-run the merged module on a different\nrange from 21 to 40 like this:\n\n    python scripts/oases_pipeline.py -m 21 -M 40 -r -o pairedEnd  \n\nNote\u00a0that it is essential when you re-run the merged assembly for the\nscript to function properly to give the exact same output prefix with\nthe ```-o``` parameter.\n"
      },
      "source": "https://raw.githubusercontent.com/dzerbino/oases/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Output files",
        "parent_header": [
          "Running Oases"
        ],
        "type": "Text_excerpt",
        "value": "Oases produces two output files. The predicted transcript sequences can\nbe found in ```transcripts.fa``` and the file ```contig-ordering.txt``` explains\nthe composition of these transcripts, see below.\n\n* ```transcripts.fa``` is a FASTA file containing the\n  transcripts imputed directly from trivial clusters of contigs (loci\n  with less than two transcripts and Confidence Values = 1) and the\n  highly expressed transcripts imputed by dynamic programming (loci\n  with more than 2 transcripts and Confidence Values $<$1).\n\n* ```contig-ordering.txt``` is a hybrid file which describes\n  the contigs contained in each locus in FASTA format, interlaced with\n  one line summaries of the transcripts generated by dynamic programming. \n  Each line is a string of atoms defined as:\n\n    contig_id:cumulative_length-(distance_to_next_contig)->nextitem\n\n  Here the cumulative length is the total length of the transcript\n  assembly from its 5\u2019 end to the 3\u2019 end of that contig. This allows\n  you to locate the contig sequence within the transcript sequence.\n\n\n"
      },
      "source": "https://raw.githubusercontent.com/dzerbino/oases/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "I am running out of memory. What should I do?",
        "parent_header": [
          "Running Oases",
          "FAQ and Practical considerations"
        ],
        "type": "Text_excerpt",
        "value": "Depending on the complexity of the dataset it may happen that Velvet and\nOases start to use a large amount of memory. In general, the assembly\ngraphs for transcriptome data are smaller as compared to genome data.\nHowever, because the coverage is not even roughly uniform it depends on\nthe sample being sequenced how much memory is used. Below we give\nexamples of pre-processing steps that lead to a decrease in memory\nconsumption, sorted in order of importance.\n"
      },
      "source": "https://raw.githubusercontent.com/dzerbino/oases/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Avoid overlapping reads",
        "parent_header": [
          "Running Oases",
          "FAQ and Practical considerations",
          "I am running out of memory. What should I do?"
        ],
        "type": "Text_excerpt",
        "value": "In our experience, if insert lengths are so short that paired reads\noverlap on their 3\u2019 ends, i.e., if the insert length is less than\ntwice the length, this prevents the early filtering of low coverage reads. \nThis means that even small datasets may require huge amounts of memory. A way\nto avoid the problem is to join paired-end reads that overlap.\nOne tool to do this is\n[PEAR](http://sco.h-its.org/exelixis/web/software/pear/doc.html).\n"
      },
      "source": "https://raw.githubusercontent.com/dzerbino/oases/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Avoid bad quality reads",
        "parent_header": [
          "Running Oases",
          "FAQ and Practical considerations",
          "I am running out of memory. What should I do?"
        ],
        "type": "Text_excerpt",
        "value": "Reads with many errors create new nodes in the de Bruijn graph, all of\nwhich are later discarded by the error removal steps. Removing the\nerrors in the reads *a priori* is a good way to decrease the memory\nconsumption. A very common approach is to remove bad quality bases from\nthe ends of read sequences or remove entire read sequences, numerous\npackages exist to do that but differ in functionality and definition of\nbad quality.\nOne tool to do this is\n[Trimmomatic](http://www.usadellab.org/cms/?page=trimmomatic)\n\nNote that when you use paired-end sequences and reads are discarded from\nthe file you need to make sure that the fasta/fastq file that you give\nto velveth contains the paired-end reads in correct pairing. Also if the\nread clipper retains single end reads from a pair, it is advisable to\ngive them as a second dataset of type ```-short``` to avoid data loss.\n"
      },
      "source": "https://raw.githubusercontent.com/dzerbino/oases/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Trim sequencing adapters",
        "parent_header": [
          "Running Oases",
          "FAQ and Practical considerations",
          "I am running out of memory. What should I do?"
        ],
        "type": "Text_excerpt",
        "value": "Depending on your sequencing experiment, some of the reads may have\nadapters that were used, e.g, during library preparation. These adapters\nshould be trimmed. Tools like\n[Trimmomatic](http://www.usadellab.org/cms/?page=trimmomatic)\ncan also do this.\n"
      },
      "source": "https://raw.githubusercontent.com/dzerbino/oases/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Remove duplicate reads",
        "parent_header": [
          "Running Oases",
          "FAQ and Practical considerations",
          "I am running out of memory. What should I do?"
        ],
        "type": "Text_excerpt",
        "value": "Especially for paired-end datasets it happens that the exact same read\nsequence is found a large number of times. One tool to do this is using\n[Picard](http://broadinstitute.github.io/picard/).\n\n"
      },
      "source": "https://raw.githubusercontent.com/dzerbino/oases/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "I want to predict coding regions. How can I do that?",
        "parent_header": [
          "Running Oases",
          "FAQ and Practical considerations"
        ],
        "type": "Text_excerpt",
        "value": "All the transcripts reported in a locus should have the same\ndirectionality, but that is only true if there is no contamination.\nStandard approaches are to use blastp and tools alike. Alternatively use\ngene prediction tools like GlimmerHMM, SNAP or AUGUSTUS.\n\n\n"
      },
      "source": "https://raw.githubusercontent.com/dzerbino/oases/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Mailing list:",
        "parent_header": [
          "Running Oases"
        ],
        "type": "Text_excerpt",
        "value": "For questions/requests/etc. you can subscribe to the users\u2019 mailing list\nat the [oases-users listserver](http://listserver.ebi.ac.uk/mailman/listinfo/oases-users).\n"
      },
      "source": "https://raw.githubusercontent.com/dzerbino/oases/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Paper",
        "parent_header": [
          "Running Oases"
        ],
        "type": "Text_excerpt",
        "value": "Schulz MH, Zerbino DR, Vingron M, Birney E. \n_Oases: robust de novo RNA-seq assembly across the dynamic range of expression levels._\n__Bioinformatics__ 2012 Apr 15;28(8):1086-92. \n[PubMed](http://www.ncbi.nlm.nih.gov/pubmed/22368243)\n"
      },
      "source": "https://raw.githubusercontent.com/dzerbino/oases/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Authors",
        "parent_header": [
          "Running Oases"
        ],
        "type": "Text_excerpt",
        "value": "* Daniel Zerbino <dzerbino@soe.ucsc.edu>\n* Marcel Schulz <marcel.schulz@molgen.mpg.de>\n\n"
      },
      "source": "https://raw.githubusercontent.com/dzerbino/oases/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "somef_missing_categories": [
    "citation",
    "acknowledgement",
    "download",
    "contact",
    "contributors",
    "identifier",
    "has_build_file",
    "executable_example"
  ],
  "somef_provenance": {
    "date": "2024-11-04 07:05:48",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 62
      },
      "technique": "GitHub_API"
    }
  ],
  "support": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Oases help",
        "parent_header": [
          "Running Oases",
          "Oases options"
        ],
        "type": "Text_excerpt",
        "value": "In case of doubt, you can always print a help message by typing\n(interchangeably):\n\n    > oases\n    > oases --help\n"
      },
      "source": "https://raw.githubusercontent.com/dzerbino/oases/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "type": [
    {
      "confidence": 0.82,
      "result": {
        "type": "String",
        "value": "commandline-application"
      },
      "technique": "software_type_heuristics"
    }
  ],
  "usage": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Oases does not give an expression level. How can I get that?",
        "parent_header": [
          "Running Oases",
          "FAQ and Practical considerations"
        ],
        "type": "Text_excerpt",
        "value": "In general you need to align reads to the transcripts with your favorite\naligner, one that allows for multi mappings !! Although few results\nexist about the difficulties and problems of quantitation of *de novo*\ntranscripts\u2019 expression levels, here are a few pointers to specialized\ntools:\n\n1.  eXpress - <http://bio.math.berkeley.edu/eXpress/> (command line,\n    Windows support)\n\n2.  RSEM - <http://deweylab.biostat.wisc.edu/rsem/> (command line)\n\n"
      },
      "source": "https://raw.githubusercontent.com/dzerbino/oases/master/README.md",
      "technique": "header_analysis"
    }
  ]
}