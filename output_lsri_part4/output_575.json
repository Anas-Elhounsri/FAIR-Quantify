{
  "citation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Step 3: Correct frame and prepare coding and AA sequences of reference",
        "parent_header": [
          "TUTORIAL",
          "DATA PREPARATION"
        ],
        "type": "Text_excerpt",
        "value": "First, we need to correct frame and prepare coding and AA sequences of reference in fasta format:\n\n  \t$ predict_frames.pl \\\n  \t--baits Oreochromis_niloticus.fas \\\n  \t--cds Oreochromis_niloticus.onehitCDSmarkers.column1.txt \\\n  \t--ref_prot Oreochromis_niloticus.pep.fas\n\nInvolved options:\n\n*\t--baits: Frame-uncorrected sequences of reference\n*\t--cds: OnehitCDSmarker generated from Evolmarker. Only info in first columns will be used,so just input file with only first column is fine\n*\t--ref_prot: Reference protein sequences mined from ENSMBL\n\nOutput:\n* Oreochromis_niloticus.dna.fas: Coding DNA sequences of reference\n* Oreochromis_niloticus.aa.fas: Amino acid sequences of reference\n* frame_result.txt: Frame prediction result for each locus\n"
      },
      "source": "https://raw.githubusercontent.com/yhadevol/Assexon/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Step 2: Check the existence of reference sequences in given genome:",
        "parent_header": [
          "TUTORIAL",
          "ASSEMBLE",
          "Run whole pipeline"
        ],
        "type": "Text_excerpt",
        "value": "Determination of orthology between reference and enriched sequence is based on whether they can be aligned to same position on the genome of reference species. Thus, existence of reference in genome must be verified first to avoid false negative detection resulting from missing targeted loci:\n\n\t$ assemble.pl \\\n\t--check_query \\\n\t--queryn Oreochromis_niloticus.dna.fas \\\n\t--db Oreochromis_niloticus.genome.fas \\\n\t--dbtype nucleo\n\nInvolved options:\n\n*\t--check_query: Check whether reference sequences existing in given database, and return list of missing loci, then exit\n*\t--queryn: DNA sequences of reference in fasta format\n*\t--db: Path to DNA or AA database, either in Fasta or UDB format\n*\t--dbtype: Database type either 'nucleo' for DNA or 'prot' for AA database\n\nIf input genome is in Fasta format, a corresponding UDB database will be generated. If input database is in udb format, then no file will be generated. You will see the following text in STDOUT in both case:\n\n\tStart constructing ublast database in parallel\n\tSomething generated by usearch...\n\tUblast database has been constructed\n\tSomething generated by usearch...\n\t#### All genes are found in provided database ####\n\nIf some genes do not exist in given genome, STDOUT will be:\n\n\t#### 2 genes below are not found in provided database  ####\n\tDanio_rerio.1.46410167.46410317\n\tDanio_rerio.14.21871634.21871111\n"
      },
      "source": "https://raw.githubusercontent.com/yhadevol/Assexon/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/yhadevol/Assexon"
      },
      "technique": "GitHub_API"
    }
  ],
  "contributing_guidelines": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Step 2: Check the existence of reference sequences in given genome:",
        "parent_header": [
          "TUTORIAL",
          "ASSEMBLE",
          "Run whole pipeline"
        ],
        "type": "Text_excerpt",
        "value": "Determination of orthology between reference and enriched sequence is based on whether they can be aligned to same position on the genome of reference species. Thus, existence of reference in genome must be verified first to avoid false negative detection resulting from missing targeted loci:\n\n\t$ assemble.pl \\\n\t--check_query \\\n\t--queryn Oreochromis_niloticus.dna.fas \\\n\t--db Oreochromis_niloticus.genome.fas \\\n\t--dbtype nucleo\n\nInvolved options:\n\n*\t--check_query: Check whether reference sequences existing in given database, and return list of missing loci, then exit\n*\t--queryn: DNA sequences of reference in fasta format\n*\t--db: Path to DNA or AA database, either in Fasta or UDB format\n*\t--dbtype: Database type either 'nucleo' for DNA or 'prot' for AA database\n\nIf input genome is in Fasta format, a corresponding UDB database will be generated. If input database is in udb format, then no file will be generated. You will see the following text in STDOUT in both case:\n\n\tStart constructing ublast database in parallel\n\tSomething generated by usearch...\n\tUblast database has been constructed\n\tSomething generated by usearch...\n\t#### All genes are found in provided database ####\n\nIf some genes do not exist in given genome, STDOUT will be:\n\n\t#### 2 genes below are not found in provided database  ####\n\tDanio_rerio.1.46410167.46410317\n\tDanio_rerio.14.21871634.21871111\n"
      },
      "source": "https://raw.githubusercontent.com/yhadevol/Assexon/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2019-05-27T13:35:56Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2024-02-14T18:21:30Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "Assexon: Assembling Exon Using Gene Capture Data"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "INTRODUCTION",
        "parent_header": [
          "Assexon"
        ],
        "type": "Text_excerpt",
        "value": "This pipeline is to recover targeted exons and their flanking sequences from exon capture data\n\nPipeline can be divided into 3 steps:\n\n(1) Data preparation\n\n(2) Assembling\n\n(3) Further processing\n\nThis documentation includes a step-by-step tutorial using a small test dataset. It will\nhelp you to familiarize with this pipeline.\n"
      },
      "source": "https://raw.githubusercontent.com/yhadevol/Assexon/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Summary statistics",
        "parent_header": [
          "TUTORIAL",
          "FURTHER PROCESSING"
        ],
        "type": "Text_excerpt",
        "value": "Finally, let's summary statistics of filter alignment.\n\nDependencies:\n* Bio::AlignIO (included in Bioperl)\n* Bio::Align::DNAStatistics (included in Bioperl)\n* Parallel::ForkManager\n\nSummarized statistics for coding region of each locus including:\n* Number of enriched samples\n* Alignment length\n* GC content\n* Percentage of Missing data\n* Average pairwise distance among sequences\n\nSummarized statistics for flanking region of each locus including:\n* Alignment length of left flanking region\n* Alignment length of right flanking region\n* Average pairwise distance in left flanking region (only calculated for flanking region >= 20 bp)\n* Average pairwise distance in right flanking region (only calculated for flanking region >= 20 bp)\n\nSummarized statistcis for each sample including:\n* Number of enriched loci\n* GC content\n* Average length of flanking region (left + right)\n\nCommand:\n\n\t$ statistics.pl \\\n\t--coding_aligned merged_nf_filtered \\\n\t--flanking_aligned f_aligned\n\nOutput:\n* coding_summary.txt: Tab delimited table of summarized statistics for coding region of each locus\n* flanking_summary.txt: Tab delimited table of summarized statistics for flanking region of each locus\n* sample_summary.txt: Tab delimited table of summarized statistics for each sample\n\nInvolved options:\n* --coding_aligned: Folder comprising aligned coding sequences\n* --flanking_aligned: Folder comprising aligned coding sequences with flanking region\n"
      },
      "source": "https://raw.githubusercontent.com/yhadevol/Assexon/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 0.8350379111332931,
      "result": {
        "original_header": "Assexon",
        "type": "Text_excerpt",
        "value": "Assexon: Assembling Exon Using Gene Capture Data\n \n"
      },
      "source": "https://raw.githubusercontent.com/yhadevol/Assexon/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "documentation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "DOCUMENTATION",
        "type": "Text_excerpt",
        "value": "A manual page containing a description of all options can be accessed by option `-h` or\n`--help`. For example, full options of `assemble.pl` can be accessed by:\n\n\t$ assemble.pl -h\n\nor\n\n\t$ assemble.pl --help\n"
      },
      "source": "https://raw.githubusercontent.com/yhadevol/Assexon/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "SCRIPTS FOR EACH STEP",
        "parent_header": [
          "DOCUMENTATION"
        ],
        "type": "Text_excerpt",
        "value": "(1) Data preparation (pipeline_scripts/data_preparation):\n\n*\tgunzip_Files.pl (Expand gunzipped raw data)\n*\ttrim_adaptor.pl (Trim low quality bases and adaptors)\n*\tpredict_frames.pl (predict frame for reference, then generate coding and AA sequences of reference)\n\n(2) Assembling (pipeline_scripts/assemble):\n\nMain script:\n\n* assemble.pl (Wrapper around several scripts to recover orthologous exons and their flanking sequences from target enrichment data)\n\nCalled scripts:\n\n*\trmdup.pl (Remove PCR duplication)\n*\tubxandp.pl (Parse reads to homologous loci)\n*\tsga_assemble.pl (De novo assemble parsed reads)\n*\texonerate_best.pl (Filter unqualified assemblies and find assemblies can be further assembled)\n*\tmerge.pl (Assemble contigs further and retrieve best contigs for each locus)\n*\treblast.pl (Remove potential paralogs)\n\n(3) Further processing (pipeline_scripts/postprocess):\n\nManipulate dataset:\n*\tpick_taxa.pl (Pick out needed taxa or discard unneeded taxa)\n*\tmerge_loci.pl (Merge sequences under several directories from the same loci)\n*\tget_orthologues.pl (Find sequences orthology to reference from existing genomes)\n\nAlign:\n*\tmafft_aln.pl (Align nucleotide sequences in codon or normally)\n\nFilter:\n*\tfilter.pl (Remove badly aligned sequences)\n*\tflank_filter.pl (Discard too variable flanking regions)\n*\tclocklikeness_test.pl (Pick out loci which follows molecular clock hypothesis)\n*\tmonophyly_test.pl (Pick out loci which topology is not congurence with provided monophyly group)\n\nStatistics:\n*\tstatistics.pl (Summary statistics for each locus and sample)\n*\tmap_statistics.pl (Summary statistics for each sample from duplication-marked bam file)\n*\tcount_reads_bases.pl (Count number of base pairs and reads for fastq file)\n\nSNP-based analysis\n*\tconsensus.pl (Make majority consensus sequences)\n*\tgatk.sh (Wrapper to call SNPs by GATK)\n*\tvcftosnps.pl (Convert output from GATK into other format)\n\nPhylogenetic analysis\n*\tconcat_loci.pl (Concatenate all loci into a master gene)\n*\tconstruct_tree.pl (Construct constrained or not constrained ML trees in batch)\n\nOthers:\n*\tunixlb_unwarp.pl (Substitute line breaks and unwrap sequences of fasta file)\n\n**NOTE:** Only part of scripts will be demonstrated in following tutorial. Please use \"-h\" or \"--help\" to\nsee the detailed usage and options for each script\n"
      },
      "source": "https://raw.githubusercontent.com/yhadevol/Assexon/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/yhadevol/Assexon/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 1
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/yhadevol/Assexon/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "yhadevol/Assexon"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "Assexon"
      },
      "source": "https://raw.githubusercontent.com/yhadevol/Assexon/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "has_script_file": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/yhadevol/Assexon/master/pipeline_scripts/postprocess/gatk.sh"
      },
      "technique": "file_exploration"
    }
  ],
  "installation": [
    {
      "confidence": 1,
      "result": {
        "original_header": "INSTALLATION",
        "type": "Text_excerpt",
        "value": "Clone the Assexon repostory from GitHub:\n\n\t$ git clone https://github.com/yhadevol/Assexon.git\n\nChange directory to Assexon\n\n\t$ cd Assexon\n\nScripts are placed under \"pipeline_scripts\", and it has three subfolders:\n\n\tpipeline_scripts\n\t\t\u2514\u2500\u2500 data_preparation\n\t\t\u2514\u2500\u2500 assemble\n\t\t\u2514\u2500\u2500 postprocess\n\nOpen `~/.bashrc` then add paths to those folders to `$PATH`, so that all scripts can be easily called:\n\n\texport PATH=$PATH:/path/to/pipeline_scripts/data_preparation:/path/to/pipeline_scripts/assemble:/path/to/pipeline_scripts/postprocess\n\nWe have successfully installed Assexon and all dependencies on Linux (CentOS 6).\n"
      },
      "source": "https://raw.githubusercontent.com/yhadevol/Assexon/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Step 1: Gunzip data",
        "parent_header": [
          "TUTORIAL",
          "DATA PREPARATION"
        ],
        "type": "Text_excerpt",
        "value": "First, let's expand gzipped reads under `raw_reads`:\n\n\t$ gunzip_Files.pl \\\n\t--gzip raw_reads \\\n\t--gunzipped gunzipped_raw_reads\n\nInvolved options:\n\n* --gzip: Directory containing gzipped raw data\n* --gunzipped: Directory containing expanded raw data\n\nOutput:\n* gunzipped_raw_reads: Directory containing expanded raw data\n"
      },
      "source": "https://raw.githubusercontent.com/yhadevol/Assexon/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Step 2: Trim adaptor and low quality bases",
        "parent_header": [
          "TUTORIAL",
          "DATA PREPARATION"
        ],
        "type": "Text_excerpt",
        "value": "Then, trim illumina adaptor and low quality bases.\n\n\t$ trim_adaptor.pl \\\n\t--raw_reads gunzipped_raw_reads \\\n\t--trimmed trimmed\n\nOutput:\n* trimmed: Directory containing reads without adaptor and low quality bases\n* trimmed_reads_bases_count.txt: file summarized number of reads and bases in raw and trimmed reads\n* trimming_report: Directory containg trimming report for each sample\n\nInvolved options:\n\n* --raw_reads: Directory containing raw data\n* --trimmed: Output directory containing reads without adaptor and low quality bases\n"
      },
      "source": "https://raw.githubusercontent.com/yhadevol/Assexon/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Step 3: Correct frame and prepare coding and AA sequences of reference",
        "parent_header": [
          "TUTORIAL",
          "DATA PREPARATION"
        ],
        "type": "Text_excerpt",
        "value": "First, we need to correct frame and prepare coding and AA sequences of reference in fasta format:\n\n  \t$ predict_frames.pl \\\n  \t--baits Oreochromis_niloticus.fas \\\n  \t--cds Oreochromis_niloticus.onehitCDSmarkers.column1.txt \\\n  \t--ref_prot Oreochromis_niloticus.pep.fas\n\nInvolved options:\n\n*\t--baits: Frame-uncorrected sequences of reference\n*\t--cds: OnehitCDSmarker generated from Evolmarker. Only info in first columns will be used,so just input file with only first column is fine\n*\t--ref_prot: Reference protein sequences mined from ENSMBL\n\nOutput:\n* Oreochromis_niloticus.dna.fas: Coding DNA sequences of reference\n* Oreochromis_niloticus.aa.fas: Amino acid sequences of reference\n* frame_result.txt: Frame prediction result for each locus\n"
      },
      "source": "https://raw.githubusercontent.com/yhadevol/Assexon/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/yhadevol/Assexon/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ""
      },
      "technique": "GitHub_API"
    }
  ],
  "license": [
    {
      "confidence": 1,
      "result": {
        "name": "GNU General Public License v3.0",
        "spdx_id": "GPL-3.0",
        "type": "License",
        "url": "https://api.github.com/licenses/gpl-3.0",
        "value": "https://api.github.com/licenses/gpl-3.0"
      },
      "technique": "GitHub_API"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "Assexon"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "User",
        "value": "yhadevol"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Perl",
        "size": 454597,
        "type": "Programming_language",
        "value": "Perl"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Shell",
        "size": 4888,
        "type": "Programming_language",
        "value": "Shell"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/yhadevol/Assexon/master/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "requirements": [
    {
      "confidence": 1,
      "result": {
        "original_header": "SYSTEM REQUIREMENTS",
        "parent_header": [
          "Assexon"
        ],
        "type": "Text_excerpt",
        "value": "(1) Data preparation and assembling:\n\nSoftwares: (Please put them under `$PATH`)\n\n* Perl v5.18 or higher\n* trim_galore v0.4.1 or higher\n* cutadapt v1.2.1 or higher\n* USEARCH 10.0.240 or higher\n* SGA v0.10.15 or higher\n* Exonerate v2.2.0 or higher\n\nPerl module:\n\n* Bio::Seq (Included in Bioperl)\n* Parallel::Forkmanager\n* Sys::Info\n\n(2) Further processing:\n\nThis step is optional, so system requirements for this step are not listed here. Please check\nrequirements for these scripts by `-h` or `--help` options\n\n**NOTE:** All softwares need to be installed and can be found in `$PATH`.\n"
      },
      "source": "https://raw.githubusercontent.com/yhadevol/Assexon/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Step 1: Check requirements of assembling",
        "parent_header": [
          "TUTORIAL",
          "ASSEMBLE",
          "Run whole pipeline"
        ],
        "type": "Text_excerpt",
        "value": "Before running the script, we need to check requirements which can be checked by `--check_depends`.\n\n\t$ assemble.pl --check_depends\n\nInvolved options:\n\n*\t--check_depends: Check all dependencies for assemble.pl\n\nIf all dependencies are properly installed, you will see the following text in STDOUT:\n\n\tCurrently used interpreter is \"/XXX/perl\"\n\n\tVersion of your perl interpreter (/XXX/perl) is v5.xx\n\n\tAll modules are properly installed\n\n\tAll softwares are properly installed\n\n\tAll scripts are found under $PATH\n"
      },
      "source": "https://raw.githubusercontent.com/yhadevol/Assexon/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "run": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Run whole pipeline",
        "parent_header": [
          "TUTORIAL",
          "ASSEMBLE"
        ],
        "type": "Text_excerpt",
        "value": "Normally, we run the whole assembling pipeline (input cleaned reads, output orthologous assemblies), which includes 3 steps:\n"
      },
      "source": "https://raw.githubusercontent.com/yhadevol/Assexon/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Step 3: Assemble:",
        "parent_header": [
          "TUTORIAL",
          "ASSEMBLE",
          "Run whole pipeline"
        ],
        "type": "Text_excerpt",
        "value": "Requirements and existence of target loci in given genome have been checked. Let's start assemble:\n\n\t$ assemble.pl \\\n\t--trimmed trimmed \\\n\t--queryp Oreochromis_niloticus.aa.fas \\\n\t--queryn Oreochromis_niloticus.dna.fas \\\n\t--db Oreochromis_niloticus.genome.fas \\\n\t--dbtype nucleo \\\n\t--ref_name Oreochromis_niloticus \\\n\t--outdir assemble_result\n\nInvolved options:\n\n*\t--trimmed: Directory containing reads without adaptor and low quality bases\n*\t--queryp: Amino acid sequences of target loci in fasta format\n*\t--queryn: Nucleotide sequences of target loci in fasta format\n*\t--db: Path to DNA or amino acid database, either in fasta or udb format\n*\t--dbtype: Database type either 'nucleo' for DNA or 'prot' for amino acid database\n*\t--ref_name: Substitute name of target loci as --ref_name in the output of last step (reblast.pl), disabled in default\n*\t--outdir: Directory to pipeline output\n\nSeveral folders and files will be generated during the execution:\n* run_dir: All intermediate outputs will be generated under this folder.\n* samplelist.txt: A list includes name of all samples\n* rmdup_reads_bases_count.txt: A table records number of reads and bases before and after removing PCR duplicates\n* enriched_loci.txt: A table records number of total loci, number of enriched loci and percentage of enriched loci for each sample\n* Oreochromis_niloticus.genome.fas.udb: UDB of `Oreochromis_niloticus.genome.fas`. This can be used as input database.\n\nOutput will be placed under `assemble_result` including 3 folders:\n* nf: folder containing coding nucleotide sequences\n* f: folder containing coding sequences with flanking regions\n* p: folder containing AA sequences\n"
      },
      "source": "https://raw.githubusercontent.com/yhadevol/Assexon/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Run partial pipeline",
        "parent_header": [
          "TUTORIAL",
          "ASSEMBLE"
        ],
        "type": "Text_excerpt",
        "value": "If something goes wrong at the intermediate step, don't worry, assemble.pl is able to restart from intermediate step. It can also stop at the step you want.\n\nTo restart from intermediate step, 4 things are essentially needed:\n* Intermediate output from previous one step\n* Essential options for the following step\n* Options for restart or stop\n* sample list\n\n1) Intermediate output from each step:\n*\tStep 1: rmdup.pl: `./run_dir/rmdup`\n*\tStep 2: ubxandp.pl: `./run_dir/parsed`\n*\tStep 3: sga_assemble.pl: `./run_dir/assembled`\n*\tStep 4: exonerate_best.pl: `./run_dir/filtered`\n*\tStep 5: merge.pl: `./run_dir/merged`\n*\tStep 6: reblast.pl: `./run_dir/reblastout`\n\n2) Essential options for each step:\n*\tStep 1: rmdup.pl: `--trimmed`\n*\tStep 2: ubxandp.pl: `--queryp`\n*\tStep 3: sga_assemble.pl: nothing\n*\tStep 4: exonerate_best.pl: `--queryp`\n*\tStep 5: merge.pl: `--queryp` and `--queryn`\n*\tStep 6: reblast.pl: `--db`, `--dbtype`, `--ref_name` and `--outdir`\n\n3) Option for restart or stop at a step\n* To restart from a step: `--restart_from_xxx`\n* To stop at a step: `--stop_after_xxx`\n\nFor example, I want restart from step 4 (`exonerate_best.pl`). The option is:\n\n`--restart_from_exonerate_best`\n\nI want stop at step 5 (`merge.pl`). The option is:\n\n`\t--stop_after_merge`\n\nI want restart from step 4 and stop at step 5, then specify 2 options:\n\n`--restart_from_exonerate_best` and `--stop_after_merge`\n\n4) Sample list\nSample list is named as `samplelist.txt` in default. It contains the list of sample names, one sample name per line. It is automatically generated from first step. It looks like:\n\n\ttest1\n\ttest2\n\nHere are 3 examples of running partial pipeline:\n\n**EXAMPLE 1**: From an intermediate step to the end (exonerate_best.pl -> end):\n* Output from previous one step `sga_assemble.pl` (`./run_dir/assembled`)\n* Essential inputs of `exonerate_best.pl` (`--queryp`), `merge.pl` (`--queryn`, `--queryp`) and\n`reblast.pl` (`--db`, `--dbtype`, `--ref_name`, `--outdir`)\n* samplelist.txt\n* option `--restart_from_exonerate_best`\n\nSo the command is:\n\n\t$ assemble.pl \\\n\t--queryp Oreochromis_niloticus.aa.fas \\\n\t--queryn Oreochromis_niloticus.dna.fas \\\n\t--db Oreochromis_niloticus.genome.fas \\\n\t--dbtype nucleo \\\n\t--outdir assemble_result \\\n\t--ref_name Oreochromis_niloticus \\\n\t--samplelist samplelist.txt \\\n\t--restart_from_exonerate_best\n\n**EXAMPLE 2**: Restart from an intermediate step to another intermediate step (sga_assemble.pl -> merge.pl):\n\n* output from previous one step `ubxandp.pl` (`./run_dir/parsed`)\n* Essential inputs of `sga_assemble.pl` (nothing), exonerate_best.pl (`--queryp`) and `merge.pl`\n(`--queryn`, `--queryp`)\n* samplelist.txt\n* 2 options `--restart_from_sga_assemble` as well as `--stop_after_merge`\n\nCommand:\n\n\t$ assemble.pl \\\n\t--queryp Oreochromis_niloticus.aa.fas \\\n\t--queryn Oreochromis_niloticus.dna.fas \\\n\t--samplelist samplelist.txt \\\n\t--restart_from_sga_assemble \\\n\t--stop_after_merge\n\n**EXAMPLE 3**: Stop at an intermediate step (start -> sga_assemble.pl)\n\nWe start from the first step, so there's no input from previous one step. We just need:\n\n* Essential inputs of `rmdup.pl` (`--trimmed`), `ubxandp.pl` (`--queryp`), `sga_assemble.pl` (nothing)\n* samplelist.txt\n* option `--stop_after_sga_assemble`\n\nCommand:\n\n\t$ assemble.pl \\\n\t--trimmed trimmed \\\n\t--queryp Oreochromis_niloticus.aa.fas \\\n\t--samplelist samplelist.txt \\\n\t--stop_after_sga_assemble\n"
      },
      "source": "https://raw.githubusercontent.com/yhadevol/Assexon/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "somef_missing_categories": [
    "acknowledgement",
    "download",
    "contact",
    "contributors",
    "faq",
    "support",
    "identifier",
    "has_build_file",
    "executable_example"
  ],
  "somef_provenance": {
    "date": "2024-11-04 04:01:49",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 5
      },
      "technique": "GitHub_API"
    }
  ],
  "type": [
    {
      "confidence": 0.82,
      "result": {
        "type": "String",
        "value": "commandline-application"
      },
      "technique": "software_type_heuristics"
    }
  ],
  "usage": [
    {
      "confidence": 1,
      "result": {
        "original_header": "TUTORIAL",
        "type": "Text_excerpt",
        "value": "The purpose of this tutorial is to help familiarize you with the format of the input you need and output you should expect from running this pipeline. The tutorial uses a test dataset in `test_data` that is a subset of real Illumina data from an enriched library.\n\nThis tutorial assumes that you have some experience executing programs from the command line on a UNIX-like system. If you would like to learn more about the command line, or need a refresher, you can find a command line tutorial in `introToCmdLine.pdf`.\n\n"
      },
      "source": "https://raw.githubusercontent.com/yhadevol/Assexon/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "TEST DATA",
        "parent_header": [
          "TUTORIAL"
        ],
        "type": "Text_excerpt",
        "value": "Change directory to test data:\n\n\t$ cd test_data\n\nUnder `test_data` there are:\n* raw_reads: A folder containing 2 gzipped raw reads. Structure of folder looks like:\n\n\t\traw_reads\n\t\t    \u2514\u2500\u2500 test1\n\t\t    |     \u251c\u2500\u2500 test1_R1.fq.gz\n\t\t    |     \u2514\u2500\u2500 test1_R2.fq.gz\n\t\t    \u2514\u2500\u2500 test2\n\t\t          \u251c\u2500\u2500 test2_R1.fq.gz\n\t\t          \u2514\u2500\u2500 test2_R2.fq.gz\t\t\n\n* Oreochromis_niloticus.fas: DNA sequences of reference in fasta format.\n\n* Oreochromis_niloticus.pep.fas: Reference protein sequences mined from Ensembl\n\n* Oreochromis_niloticus.onehitCDSmarkers.column1.txt: First coloumn of OnehitCDSmarker\ngenerated from Evolmarker, which should be generated during baits designing\n\n* Oreochromis_niloticus.genome.fas: Soft-masked genomic DNA sequences in fasta format.\n(It's not a real genome, but we treat it as a genome in this tutorial for convenience.\nIn real case, well soft-masked genomic sequences can be downloaded from Ensembl).\n\n* species1.genome.fas and species2.genome.fas: genome sequences of other species\n"
      },
      "source": "https://raw.githubusercontent.com/yhadevol/Assexon/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Step 1: Gunzip data",
        "parent_header": [
          "TUTORIAL",
          "DATA PREPARATION"
        ],
        "type": "Text_excerpt",
        "value": "First, let's expand gzipped reads under `raw_reads`:\n\n\t$ gunzip_Files.pl \\\n\t--gzip raw_reads \\\n\t--gunzipped gunzipped_raw_reads\n\nInvolved options:\n\n* --gzip: Directory containing gzipped raw data\n* --gunzipped: Directory containing expanded raw data\n\nOutput:\n* gunzipped_raw_reads: Directory containing expanded raw data\n"
      },
      "source": "https://raw.githubusercontent.com/yhadevol/Assexon/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Step 2: Trim adaptor and low quality bases",
        "parent_header": [
          "TUTORIAL",
          "DATA PREPARATION"
        ],
        "type": "Text_excerpt",
        "value": "Then, trim illumina adaptor and low quality bases.\n\n\t$ trim_adaptor.pl \\\n\t--raw_reads gunzipped_raw_reads \\\n\t--trimmed trimmed\n\nOutput:\n* trimmed: Directory containing reads without adaptor and low quality bases\n* trimmed_reads_bases_count.txt: file summarized number of reads and bases in raw and trimmed reads\n* trimming_report: Directory containg trimming report for each sample\n\nInvolved options:\n\n* --raw_reads: Directory containing raw data\n* --trimmed: Output directory containing reads without adaptor and low quality bases\n"
      },
      "source": "https://raw.githubusercontent.com/yhadevol/Assexon/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "ASSEMBLE",
        "parent_header": [
          "TUTORIAL"
        ],
        "type": "Text_excerpt",
        "value": "All inputs for assembly has been prepared. Let's start assembling now. The main script\nis assemble.pl. This script calls another 6 scripts to recover assemblies.\n\n6 scripts represent 6 steps of assembly. They are called by main script in following procedure:\n* rmdup.pl: Remove PCR duplicates\n* ubxandp.pl: Parse reads to targeted loci\n* sga_assemble.pl: Assemble reads for each locus\n* exonerate_best.pl: Filter unqualified contigs and find contigs which might be furtherly assembled  \n* merge.pl: Assemble contigs further and retrieve best contigs for each locus\n* reblast.pl: Remove potential paralogs\n"
      },
      "source": "https://raw.githubusercontent.com/yhadevol/Assexon/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Step 3: Assemble:",
        "parent_header": [
          "TUTORIAL",
          "ASSEMBLE",
          "Run whole pipeline"
        ],
        "type": "Text_excerpt",
        "value": "Requirements and existence of target loci in given genome have been checked. Let's start assemble:\n\n\t$ assemble.pl \\\n\t--trimmed trimmed \\\n\t--queryp Oreochromis_niloticus.aa.fas \\\n\t--queryn Oreochromis_niloticus.dna.fas \\\n\t--db Oreochromis_niloticus.genome.fas \\\n\t--dbtype nucleo \\\n\t--ref_name Oreochromis_niloticus \\\n\t--outdir assemble_result\n\nInvolved options:\n\n*\t--trimmed: Directory containing reads without adaptor and low quality bases\n*\t--queryp: Amino acid sequences of target loci in fasta format\n*\t--queryn: Nucleotide sequences of target loci in fasta format\n*\t--db: Path to DNA or amino acid database, either in fasta or udb format\n*\t--dbtype: Database type either 'nucleo' for DNA or 'prot' for amino acid database\n*\t--ref_name: Substitute name of target loci as --ref_name in the output of last step (reblast.pl), disabled in default\n*\t--outdir: Directory to pipeline output\n\nSeveral folders and files will be generated during the execution:\n* run_dir: All intermediate outputs will be generated under this folder.\n* samplelist.txt: A list includes name of all samples\n* rmdup_reads_bases_count.txt: A table records number of reads and bases before and after removing PCR duplicates\n* enriched_loci.txt: A table records number of total loci, number of enriched loci and percentage of enriched loci for each sample\n* Oreochromis_niloticus.genome.fas.udb: UDB of `Oreochromis_niloticus.genome.fas`. This can be used as input database.\n\nOutput will be placed under `assemble_result` including 3 folders:\n* nf: folder containing coding nucleotide sequences\n* f: folder containing coding sequences with flanking regions\n* p: folder containing AA sequences\n"
      },
      "source": "https://raw.githubusercontent.com/yhadevol/Assexon/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Clean intermediate output",
        "parent_header": [
          "TUTORIAL",
          "ASSEMBLE"
        ],
        "type": "Text_excerpt",
        "value": "Intermediate output under \"run_dir\" would occupy lot of memory. Remove \"run_dir\" and all files under it by:\n\n\t$ assemble.pl --clean\n\n"
      },
      "source": "https://raw.githubusercontent.com/yhadevol/Assexon/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Only assemble part of samples",
        "parent_header": [
          "TUTORIAL",
          "ASSEMBLE"
        ],
        "type": "Text_excerpt",
        "value": "Samples exist in `samplelist.txt` will be assembled. You can only write name of samples which need to be assembled. For example, I want to assemble test1 only, then the list is:\n\n\ttest1\n\nThen, specify the option `--samplelist` to input your list:\n\n\t$ assemble.pl \\\n\t--trimmed trimmed \\\n\t--queryp Oreochromis_niloticus.aa.fas \\\n\t--queryn Oreochromis_niloticus.dna.fas \\\n\t--db Oreochromis_niloticus.genome.fas \\\n\t--dbtype nucleo \\\n\t--outdir assemble_result \\\n\t--ref_name Oreochromis_niloticus \\\n\t--samplelist samplelist.txt\n"
      },
      "source": "https://raw.githubusercontent.com/yhadevol/Assexon/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "FURTHER PROCESSING",
        "parent_header": [
          "TUTORIAL"
        ],
        "type": "Text_excerpt",
        "value": "Before downstream analysis, datasets probably need to be modified. Sequences are required to be aligned, and poorly aligned sequences should be discarded. We also need to access statistics of filtered alignments. So further processing mainly includes:\n* Manipulate dataset\n* Aligning\n* Filtering\n* Summary statistics\n"
      },
      "source": "https://raw.githubusercontent.com/yhadevol/Assexon/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Manipulate dataset (optional):",
        "parent_header": [
          "TUTORIAL",
          "FURTHER PROCESSING"
        ],
        "type": "Text_excerpt",
        "value": "Before aligning and filtering, Some users may want to add orthologue sequences from existing\ngenomes or delete poorly enriched sequences. Before introducing how to do it, we emphasize\nonce again that:\n\n`SEQUENCES MUST BE ADDED OR DELETED BEFORE ALIGNING!!!`\n"
      },
      "source": "https://raw.githubusercontent.com/yhadevol/Assexon/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Add orthologous sequences",
        "parent_header": [
          "TUTORIAL",
          "FURTHER PROCESSING"
        ],
        "type": "Text_excerpt",
        "value": "Dependencies:\n* USEARCH v10.0.240 or higher\n* BioPerl v1.007001 or higher\n"
      },
      "source": "https://raw.githubusercontent.com/yhadevol/Assexon/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Step 1: Extract orthologous sequences from existing genomes",
        "parent_header": [
          "TUTORIAL",
          "FURTHER PROCESSING",
          "Add orthologous sequences"
        ],
        "type": "Text_excerpt",
        "value": "First, we extract sequences orthology to loci in `Oreochromis_niloticus.dna.fas` from `species1.genome.fas` and `species2.genome.fas`\n\n\t$ get_orthologues.pl \\\n\t--query Oreochromis_niloticus.dna.fas \\\n\t--querydb Oreochromis_niloticus.genome.fas \\\n\t--subdb \"species1.genome.fas|species2.genome.fas\" \\\n\t--subname \"species1 species2\" \\\n\t--outdir orthologs \\\n\t--cpu 12\n\nOutput:\n* orthologs: Directory includes sequences orthology to reference\n* Oreochromis_niloticus.genome.fas.udb: udb of `Oreochromis_niloticus.genome.fas`.\n* species1.genome.fas.udb: udb of `species1.genome.fas`\n* species2.genome.fas.udb: udb of `species2.genome.fas`\n\nInvolved options:\n\n*\t--query: Coding DNA sequences of reference\n*\t--querydb: Space delimited list of one or more DNA databases of reference species in either in FASTA or UDB format\n*\t--subdb: List of DNA databases of subjects in FASTA or UDB format ONLY, but database format of the same subject need to consistent. Input database list of different subjects are delimited by '|', and database belonging to the same subject are delimited by space. e.g. \\\"sp1.genome.1.fas sp1.genome.2.fas|sp2.genome.1.udb sp2.genome.2.udb\\\"\n*\t--subname: Space delimited list of subject name in output, which is one-to-one match to the list of subject databases.\n*\t--outdir: Name of output directory, which has 2 subfolders including 'nf' for coding sequences and 'p' for AA sequences.\n*\t--cpu: Limit the number of CPUs, 1 in default\n"
      },
      "source": "https://raw.githubusercontent.com/yhadevol/Assexon/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Step 2: Add them into datasets",
        "parent_header": [
          "TUTORIAL",
          "FURTHER PROCESSING",
          "Add orthologous sequences"
        ],
        "type": "Text_excerpt",
        "value": "Then, we add coding sequences from `species1.genome.fas` and `species2.genome.fas` to enriched datasets. Each locus should have at least 3 sequences:\n\n\t$ merge_loci.pl \\\n\t--indir \"assemble_result/nf orthologs/nf\" \\\n\t--outdir merged_nf \\\n\t--min_seq 3\n\nOutput:\n* merged_nf: Dir containing merged loci files\n\nInvolved options:\n\n* --indir: List of dir containing sequences\n* --outdir: Dir containing merged loci files\n*\t--min_seq: Minimum sequences required in merged file, 2 in default\n"
      },
      "source": "https://raw.githubusercontent.com/yhadevol/Assexon/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Delete unneeded sequences",
        "parent_header": [
          "TUTORIAL",
          "FURTHER PROCESSING"
        ],
        "type": "Text_excerpt",
        "value": "Dependencies:\n* Nothing\n\nDiscard taxa `species2` by \"--deselected_taxa\":\n\n\t$ pick_taxa.pl \\\n\t--indir merged_nf \\\n\t--outdir merged_nf_deselected \\\n\t--deselected_taxa \"species2\"\n\nOutput:\n* merged_nf_deselected: Dir containing sequences of without discarded taxon\n\nInvolved options:\n\n* --indir: Dir containing unaligned sequences\n* --outdir: Dir containing sequences of selected taxon\n*\t--deselected_taxa: List of taxa want to be discarded, each taxon is delimited by space\n"
      },
      "source": "https://raw.githubusercontent.com/yhadevol/Assexon/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Aligning",
        "parent_header": [
          "TUTORIAL",
          "FURTHER PROCESSING"
        ],
        "type": "Text_excerpt",
        "value": "Then, let's align each loci.\n\nDependencies:\n* BioPerl v1.007001 or higher\n* Mafft v7.294b or higher (rename it as `mafft` and put it under `$PATH`)\n* Parallel::ForkManager;\n\n1) If input sequences are full-coding sequence:\n\n\t$ mafft_aln.pl \\\n\t--dna_unaligned merged_nf \\\n\t--dna_aligned merged_nf_aligned \\\n\t--cpu 12\n\nOutput:\n* merged_nf_aligned: Dir containing nucleotide sequences aligned in codon\n\n2) If input sequences are not coding sequence or coding sequences with flanks:\n\n\t$ mafft_aln.pl \\\n\t--dna_unaligned assemble_result/f \\\n\t--dna_aligned f_aligned \\\n\t--non_codon_aln \\\n\t--cpu 12\n\nOutput:\n* f_aligned: Dir containing aligned nucleotide sequences\n\nInvolved options:\n\n*\t--dna_unaligned: Dir containing unaligned DNA sequences\n*\t--dna_aligned: Dir containing aligned DNA sequences, named as \"xx_aligned\" if this option is not specified\n*\t--non_codon_aln: Do not align DNA sequences in codon. This option is turned off by default\n*\t--cpu: Limit the number of CPUs, 1 in default.\n"
      },
      "source": "https://raw.githubusercontent.com/yhadevol/Assexon/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Filter poorly aligned coding sequences:",
        "parent_header": [
          "TUTORIAL",
          "FURTHER PROCESSING",
          "Filtering"
        ],
        "type": "Text_excerpt",
        "value": "Dependencies:\n* BioPerl v1.007001 or higher\n* Mafft v7.294b or higher (rename it as `mafft` and put it in `$PATH`)\n\nCoding sequences are input. Only remove poorly aligned sequences, and `Oreochromis_niloticus` is reference:\n\n\t$ filter.pl \\\n\t--indir merged_nf_aligned \\\n\t--filtered merged_nf_filtered \\\n\t--ref_taxa \"Oreochromis_niloticus\" \\\n\t--cpu 12\n\nOutput:\n* merged_nf_filtered: Dir containing filtered alignments which are aligned in codon\n\nInvolved options:\n\n* --indir: Dir containing unfiltered alignments\n*\t--filtered: Dir containing filtered alignments\n*\t--ref_taxa: A space delimit list of reference taxa\n* --cpu: Limit the number of CPUs, 1 in default\n\n**NOTE:** Remember to check filtered alignments. Please tuning the parameters, if too much alignments are filtered. Use `-h` or `--help` to access detailed parameter\n"
      },
      "source": "https://raw.githubusercontent.com/yhadevol/Assexon/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Filter poorly aligned flanking sequences:",
        "parent_header": [
          "TUTORIAL",
          "FURTHER PROCESSING",
          "Filtering"
        ],
        "type": "Text_excerpt",
        "value": "Dependencies:\n* BioPerl v1.007001 or higher\n* Mafft v7.294b or higher (rename it as `mafft` and put it under `$PATH`)\n\nFilter sequences with flanking regions in `f_aligned`, and only files and sequences co-exist in `f_aligned` and `nf_filtered` will be written to `f_filtered`. Sequence of `Oreochromis_niloticus` is reference. Run script with 4 process:\n\n\t$ flank_filter.pl \\\n\t--flank f_aligned \\\n\t--nonflank_filtered merged_nf_filtered \\\n\t--flank_filtered f_filtered \\\n\t--ref_taxa \"Oreochromis_niloticus\" \\\n\t--cpu 4\n\nOutput:\n* f_filtered: Dir containing well-aligned coding sequences with flanks\n\nInvolved options:\n\n*\t--flank: Dir containing unfiltered alignments with flanks\n*\t--nonflank_filtered: Dir containing well-aligned coding sequences\n*\t--flank_filtered: Dir containing well-aligned coding sequences with flanks\n*\t--ref_taxa: A space delimit list of reference taxa\n*  --cpu: Limit the number of CPUs, 1 in default\n"
      },
      "source": "https://raw.githubusercontent.com/yhadevol/Assexon/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Filter loci for different purposes:",
        "parent_header": [
          "TUTORIAL",
          "FURTHER PROCESSING"
        ],
        "type": "Text_excerpt",
        "value": "1. Users can pick out loci which topologies are not congurence with provided monophyletic group using `monophyly_test.pl`. This analysis needs unconstrained ML tree and ML tree constrained by provided monophyletic group for each locus, which can be generated using `construct_tree.pl`.\n\n**NOTE:** Format of input file after `--constrain` (option in `construct_tree.pl`) can be found in `pipeline_scripts/postprocess/monogroup.txt`\n\n2. Some analysis need genes follow the molecular clock hypotheses (like construction of time-recalibrated tree). Users can filter loci which disobey the molecular clock hypotheses using `clocklikeness_test.pl`\n"
      },
      "source": "https://raw.githubusercontent.com/yhadevol/Assexon/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Phylogenetic analysis",
        "parent_header": [
          "TUTORIAL",
          "FURTHER PROCESSING"
        ],
        "type": "Text_excerpt",
        "value": "Several scripts were provided to reformat filtered alignments as input of phylogenetic analysis. Alignment files can be rearranged and input for analysis in following procedure:\n\nConcatenated tree:\n\n\t                 Filter alignments\n\t                         \u2193\n\t  Codeoncatenate loci into master gene (concat_loci.pl)\n\t                         \u2193\n\t            Build concatenated tree (RAxML)\n\nSpecies tree:\n\n\t                 Filter alignments\n\t                         \u2193\n\t    Construct trees for each loci (construct_tree.pl)\n\t                         \u2193\n\t Merge resulting gene trees into one file (\"cat\" command)\n\t                         \u2193\n\t             Build species tree (ASTRAL)\n\nSNP-based analysis:\n\n\t      Trimmed reads            Filter alignments\n\t            |                           \u2193\n\t            |              Generate majority consensus\n\t            |               reference (consensus.pl)\n\t            |                           |\n\t            \u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\n\t                         \u2193\n\t           Call SNPs from reads (gatk.sh)\n\t                         \u2193\n\t          Reformat vcf file (vcftosnps.pl)\n\t                         \u2193\n\t            BEAST, STRUCTURE, dudi.pca\n"
      },
      "source": "https://raw.githubusercontent.com/yhadevol/Assexon/master/README.md",
      "technique": "header_analysis"
    }
  ]
}