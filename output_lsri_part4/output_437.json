{
  "application_domain": [
    {
      "confidence": 32.63,
      "result": {
        "type": "String",
        "value": "Computer Vision"
      },
      "technique": "supervised_classification"
    }
  ],
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/biomag-lab/hypocotyl-UNet"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2019-04-26T12:12:18Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2023-10-06T17:07:20Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 0.9815311251058653,
      "result": {
        "original_header": "A deep learning-based approach for high throughput plant phenotyping",
        "type": "Text_excerpt",
        "value": "This repository is the companion for the paper [A deep learning-based approach for high throughput plant phenotyping, \nDobos et al.](http://www.plantphysiol.org/content/181/4/1415).  \n"
      },
      "source": "https://raw.githubusercontent.com/biomag-lab/hypocotyl-UNet/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9900346803402101,
      "result": {
        "original_header": "Using a trained model for measuring hypocotyls <a name=\"measuring\"></a>",
        "type": "Text_excerpt",
        "value": "Additionally, you can specify the following:\n- `--min_object_size`: the expected minimum object size in pixels. Default is 0. Detected objects below this size will be filtered out.\n- `--max_object_size`: the expected maximum object size in pixels. Default is `np.inf`. Detected objects above this size will be filtered out.\n- `--dpi` and `--dpm`: to export the lengths in *mm*, it is required to provide a *dpi* (dots per inch) or *dpm* (dots per millimeter) value. If any of this is available, the pixel units will be converted to *mm* during measurements. If both *dpi* and *dpm* is set, only *dpm* will be taken into account.\n- `--device`: device to be used for the UNet prediction. Default is `cpu`, but if a GPU with the CUDA framework installed is available, `cuda:$ID` can be used, where `$ID` is the ID of the GPU. For example, `cuda:0`. (For PyTorch users: this argument is passed directly to the `torch.Tensor.device` object during initialization, which will be used for the rest of the workflow.)\n- `--visualize`: set to True to export a visualization of the results. For each measured image, the following images are exported along with the length measurements.  \n<p align=\"center\">\n  <img src=\"docs/img/vis_bbox.png\" width=\"256\">\n  <img src=\"docs/img/vis_seg.png\" width=\"256\">\n  <img src=\"docs/img/vis_skl.png\" width=\"256\">\n</p> \n"
      },
      "source": "https://raw.githubusercontent.com/biomag-lab/hypocotyl-UNet/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9285770528480028,
      "result": {
        "original_header": "Generating your own training data <a name=\"annotating\"></a>",
        "type": "Text_excerpt",
        "value": "In case the algorithm performs poorly, for instance if the images were taken under very different conditions than the ones provided to the available model during training, the UNet backbone model can be retrained on custom data. This process is called *annotation*, which can be done easily with ImageJ. \nStep 1. Organize your images to be annotated such that each image is contained in a separate folder with common root. The folder should be named after the image. For example:\n```bash\nimages_folder\n   |-- image_1\n       |-- image_1.png\n   |-- image_2\n       |-- image_2.png\n   |-- ...\n``` \nStep 2. Open the image to be annotated in ImageJ.  \n![](docs/img/step_02.png) \nStep 5. Draw the outline of the part which is part of the plant and should be included during the measurements. Press *t* or click on the *Add [t]* button to add the selected part to the ROI manager.  \n![](docs/img/step_05.png) \nStep 6. Repeat the outlining with all of the selections, adding them one by one. When it is done, select all and click *More > OR (Combine)*.  \n![](docs/img/step_06.png) \n"
      },
      "source": "https://raw.githubusercontent.com/biomag-lab/hypocotyl-UNet/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9181518358719413,
      "result": {
        "original_header": "Training a model on your own images <a name=\"training\"></a>",
        "type": "Text_excerpt",
        "value": "If custom annotated data is available, the containing folder should be organized into the following directory structure:\n```bash\nimages_folder\n   |-- images\n       |-- img001.png\n       |-- img002.png\n       |-- ...\n   |-- masks\n       |-- img001.png\n       |-- img002.png\n       |-- ...\n```\nThe mask images should have identical name to their corresponding image. After the training data is organized, the `src/train.py` script can be used to train a custom UNet model. The required arguments are\n- `--train_dataset`: path to the folder where the training data is located. This should match with the `--export_folder` argument given to the `src/preprocessing/mask.py` script during Step 11. of the previous point. \nThe optional arguments are\n- `--epochs`: the number of epochs during training. Default is 1000, but this is very dependent on the dataset and data augmentation method used.\n- `--batch_size`: the size of the batch during training. Default is 1. If GPU is used, it is recommended to select batch size as large as GPU memory allows.\n- `--initial_lr`: initial learning rate. Default is 1e-3, which proved to be the best for the training dataset used. (Different datasets might have more optimal initial learning rates.)\n- `--model_name`: name of the model. Default is *UNet-hypocotyl*.\n- `--trained_model_path`: to continue training of a previously trained model, its path can be given.\n- `--val_dataset`: path to the folder where the validation data is located. During training, validation data is used to catch overfitting and apply early stopping.\n- `--model_save_freq`: frequency of model saving. Default is 200, which means that the model is saved after every 200th epoch.\n- `--device`: device to be used for the UNet training. Default is `cpu`, but if a GPU with the CUDA framework installed is available, `cuda:$ID` can be used, where `$ID` is the ID of the GPU. For example, `cuda:0`. (For PyTorch users: this argument is passed directly to the `torch.Tensor.device` object during initialization, which will be used for the rest of the workflow.) \n"
      },
      "source": "https://raw.githubusercontent.com/biomag-lab/hypocotyl-UNet/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/biomag-lab/hypocotyl-UNet/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 2
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/biomag-lab/hypocotyl-UNet/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "biomag-lab/hypocotyl-UNet"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "A deep learning-based approach for high throughput plant phenotyping"
      },
      "source": "https://raw.githubusercontent.com/biomag-lab/hypocotyl-UNet/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "images": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/biomag-lab/hypocotyl-UNet/master/docs/img/vis_bbox.png"
      },
      "source": "https://raw.githubusercontent.com/biomag-lab/hypocotyl-UNet/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/biomag-lab/hypocotyl-UNet/master/docs/img/vis_seg.png"
      },
      "source": "https://raw.githubusercontent.com/biomag-lab/hypocotyl-UNet/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/biomag-lab/hypocotyl-UNet/master/docs/img/vis_skl.png"
      },
      "source": "https://raw.githubusercontent.com/biomag-lab/hypocotyl-UNet/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/biomag-lab/hypocotyl-UNet/master/docs/img/step_02.png"
      },
      "source": "https://raw.githubusercontent.com/biomag-lab/hypocotyl-UNet/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/biomag-lab/hypocotyl-UNet/master/docs/img/step_03.png"
      },
      "source": "https://raw.githubusercontent.com/biomag-lab/hypocotyl-UNet/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/biomag-lab/hypocotyl-UNet/master/docs/img/step_04.png"
      },
      "source": "https://raw.githubusercontent.com/biomag-lab/hypocotyl-UNet/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/biomag-lab/hypocotyl-UNet/master/docs/img/step_05.png"
      },
      "source": "https://raw.githubusercontent.com/biomag-lab/hypocotyl-UNet/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/biomag-lab/hypocotyl-UNet/master/docs/img/step_06.png"
      },
      "source": "https://raw.githubusercontent.com/biomag-lab/hypocotyl-UNet/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/biomag-lab/hypocotyl-UNet/master/docs/img/step_07.png"
      },
      "source": "https://raw.githubusercontent.com/biomag-lab/hypocotyl-UNet/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/biomag-lab/hypocotyl-UNet/master/docs/img/step_08.png"
      },
      "source": "https://raw.githubusercontent.com/biomag-lab/hypocotyl-UNet/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/biomag-lab/hypocotyl-UNet/master/docs/img/step_09.png"
      },
      "source": "https://raw.githubusercontent.com/biomag-lab/hypocotyl-UNet/master/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/biomag-lab/hypocotyl-UNet/master/docs/img/step_10.png"
      },
      "source": "https://raw.githubusercontent.com/biomag-lab/hypocotyl-UNet/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "invocation": [
    {
      "confidence": 0.8089965046064806,
      "result": {
        "original_header": "Using a trained model for measuring hypocotyls <a name=\"measuring\"></a>",
        "type": "Text_excerpt",
        "value": "To apply the algorithm on custom images, the folder containing the images should be organized into the following directory structure:\n```bash\nimages_folder\n   |-- images\n       |-- img001.png\n       |-- img002.png\n       |-- ...\n```\nThe `src/measure.py` script can be used to run the algorithm. The required arguments are\n- `--images_path`: path to the images folder, which must have the structure outlined above.\n- `--model`: path to the UNet model used in the algorithm.\n- `--result_folder`: path to the folder where results will be exported.   \nFor instance, an example is the following:\n```bash\npython3 measure.py --images_path path_to_images \\\n    --model ../models/unet \\\n    --result_folder path_to_results \\\n    --device cuda:0\n```\n \n"
      },
      "source": "https://raw.githubusercontent.com/biomag-lab/hypocotyl-UNet/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.855084710788198,
      "result": {
        "original_header": "Training a model on your own images <a name=\"training\"></a>",
        "type": "Text_excerpt",
        "value": "If custom annotated data is available, the containing folder should be organized into the following directory structure:\n```bash\nimages_folder\n   |-- images\n       |-- img001.png\n       |-- img002.png\n       |-- ...\n   |-- masks\n       |-- img001.png\n       |-- img002.png\n       |-- ...\n```\nThe mask images should have identical name to their corresponding image. After the training data is organized, the `src/train.py` script can be used to train a custom UNet model. The required arguments are\n- `--train_dataset`: path to the folder where the training data is located. This should match with the `--export_folder` argument given to the `src/preprocessing/mask.py` script during Step 11. of the previous point. \n"
      },
      "source": "https://raw.githubusercontent.com/biomag-lab/hypocotyl-UNet/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/biomag-lab/hypocotyl-UNet/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ""
      },
      "technique": "GitHub_API"
    }
  ],
  "license": [
    {
      "confidence": 1,
      "result": {
        "name": "MIT License",
        "spdx_id": "MIT",
        "type": "License",
        "url": "https://api.github.com/licenses/mit",
        "value": "https://api.github.com/licenses/mit"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "type": "File_dump",
        "value": "MIT License\n\nCopyright (c) 2020 BIOMAG - Szeged\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
      },
      "source": "https://raw.githubusercontent.com/biomag-lab/hypocotyl-UNet/master/LICENSE",
      "technique": "file_exploration"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "hypocotyl-UNet"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "Organization",
        "value": "biomag-lab"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 46770,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/biomag-lab/hypocotyl-UNet/master/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "requirements": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Usage, dependencies <a name=\"usage\"></a>",
        "parent_header": [
          "A deep learning-based approach for high throughput plant phenotyping"
        ],
        "type": "Text_excerpt",
        "value": "For measuring hypocotyls and training a custom model, it is required to have\n- Python >= 3.5\n- PyTorch >= 0.4\n- NumPy >= 1.13\n- Pandas >= 0.23\n- scikit-image >= 0.14\n- matplotlib >= 3.0\n\nTo use the hypocotyl segmentation tool, clone the repository to the local machine:\n```bash\ngit clone https://github.com/biomag-lab/hypocotyl-UNet\n```\n`src/measure.py` can be used for applying the measuring algorithm on custom images, while `src/train.py` are for training the UNet model on custom annotated data. (Detailed description on them can be found below.)\n"
      },
      "source": "https://raw.githubusercontent.com/biomag-lab/hypocotyl-UNet/master/README.md",
      "technique": "header_analysis"
    }
  ],
  "somef_missing_categories": [
    "installation",
    "citation",
    "acknowledgement",
    "run",
    "download",
    "contact",
    "contributors",
    "documentation",
    "faq",
    "support",
    "identifier",
    "has_build_file",
    "executable_example"
  ],
  "somef_provenance": {
    "date": "2024-11-04 03:17:48",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 11
      },
      "technique": "GitHub_API"
    }
  ],
  "usage": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Usage, dependencies <a name=\"usage\"></a>",
        "parent_header": [
          "A deep learning-based approach for high throughput plant phenotyping"
        ],
        "type": "Text_excerpt",
        "value": "For measuring hypocotyls and training a custom model, it is required to have\n- Python >= 3.5\n- PyTorch >= 0.4\n- NumPy >= 1.13\n- Pandas >= 0.23\n- scikit-image >= 0.14\n- matplotlib >= 3.0\n\nTo use the hypocotyl segmentation tool, clone the repository to the local machine:\n```bash\ngit clone https://github.com/biomag-lab/hypocotyl-UNet\n```\n`src/measure.py` can be used for applying the measuring algorithm on custom images, while `src/train.py` are for training the UNet model on custom annotated data. (Detailed description on them can be found below.)\n"
      },
      "source": "https://raw.githubusercontent.com/biomag-lab/hypocotyl-UNet/master/README.md",
      "technique": "header_analysis"
    }
  ]
}