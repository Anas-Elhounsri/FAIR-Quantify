{
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/chjiao/TAR-VIR"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2018-01-31T19:19:41Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2020-05-01T12:41:55Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 0.9632441522588442,
      "result": {
        "original_header": "TAR-VIR",
        "type": "Text_excerpt",
        "value": "TAR-VIR is developed to classify RNA viral reads from viral metagenomic data and and also to produce the assembled viral strains (i.e. haplotypes) from classified reads.  It mainly has two components: (1) Viral read classification using partial or remotely related reference genomes; (2) *de novo* assembly of viral haplotypes from recruited reads with PEHaplo, which is a haplotype reconstruction tool. As TAR-VIR has a modular structure, the users have options to use other assembly tools after read classification in step (1).  \nTo use TAR-VIR, you need to have two types of data. (1) read set, such as viral metagenomic data containing reads from viruses. (2) a reference sequence, which can be a gene or a related genome. In the first step, you need to align the reads against the reference sequence using a read mapping tool. We recommend to use Bowtie2 with default parameters and the allowed error function \"L,0,-0.6\". The output of this step is a sam file. This sam file and the read data set will be used as input to TAR-VIR.  \nWe provide two methods for installing TAR-VIR and PEHaplo. You can directly install these tools following the instructions below. In addition, we also provide packaged TAR-VIR and PEHaplo via Anaconda, which makes the installation more straightforward. \n \n"
      },
      "source": "https://raw.githubusercontent.com/chjiao/TAR-VIR/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9923888477818633,
      "result": {
        "original_header": "New version",
        "type": "Text_excerpt",
        "value": "If you installed TAR-VIR via conda. New version is available now. please use `conda install -c kennethshang overlap_extension` to update. In the new version of TAR-VIR, we provide a new parameter that allow TAR-VIR run in parallel to save time. If you want to run TAR-VIR on a large dataset, this might be helpfull. The information is shown below:\n```\nParameter:\n  -t  number of threads\n\nNote:\n   Due to the inplementation of TAR-VIR, the number of '-t' satisfy the equation:\n                                   k = nt     (n = 1, 2, 3 ...)\n   k is a paramter represents partations of Index. n is any positive integer\n```\n \n"
      },
      "source": "https://raw.githubusercontent.com/chjiao/TAR-VIR/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9491020926493469,
      "result": {
        "original_header": "Preprocessing",
        "type": "Text_excerpt",
        "value": "1. You need to conduct error correction for the reads. By dafault, we use karect (\"Karect: accurate correction of substitution, insertion and deletion errors for next-generation sequencing data\", Bioinformatics)\n2. As mentioned earlier, please use Bowtie2 to align the input reads against the reference sequence. Use all the default parameters except the error function \"L,0,-0.6\". The output sam file will be used as input to the next step. \n \n"
      },
      "source": "https://raw.githubusercontent.com/chjiao/TAR-VIR/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/chjiao/TAR-VIR/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 4
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/chjiao/TAR-VIR/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "chjiao/TAR-VIR"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "TAR-VIR"
      },
      "source": "https://raw.githubusercontent.com/chjiao/TAR-VIR/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "installation": [
    {
      "confidence": 1,
      "result": {
        "type": "File_dump",
        "value": "\n# Guidance for Installing TAR-VIR and PEHaplo via conda\n\nThis is a guidance for installing TAR-VIR and PEHaplo via conda. Noted that all the dependencies for these two tools are avaliable on anaconda.cloud, which means you can easily install them by using conda. The whole pipeline for installing them via conda is shown below. To make this self-contained, we also briefly introduce the two tools before giving detailed instructions for installation. \n\n## Introduction\n\n### [TAR-VIR](https://github.com/chjiao/TAR-VIR)\n\nTAR-VIR is developed to classify RNA viral reads from viral metagenomic data and also to produce the assembled viral strains (i.e. haplotypes) from classified reads. It mainly has two components: (1) Viral read classification using partial or remotely related reference genomes; (2) de novo assembly of viral haplotypes from recruited reads with PEHaplo, which is a haplotype reconstruction tool. TAR-VIR has a modular structure. Once the reads are classified by the first component, users can choose to assembly them using other assembly tools. In general, for producing strain-level viral assemblies, we recommend to use the default assembly tool PEHaplo. If a user is only interested in getting a consensus sequence, many other assembly tools can be chosen. In that case, users do not need to install PEHaplo. \n\nTo use TAR-VIR, you need to have two types of data. (1) read set, such as viral metagenomic data containing reads from viruses. (2) a reference sequence, which can be a gene or a related genome. In the first step, you need to align the reads against the reference sequence using a read mapping tool. We recommend to use Bowtie2 with default parameters and the allowed error function \"L,0,-0.6\". The output of this step is a sam file. This sam file and the read data set will be used as input to TAR-VIR.\n\n### [PEHaplo](https://github.com/chjiao/PEHaplo)\n\nPEHaplo is a *de novo* assembly tool for recovering virus haplotypes from virus quasispecies sequencing data. It utilizes overlap graph and paired-end information to recover virus haplotypes. Unlike many existing assembly tools, PEHaplo targeted at strain-level assembly for reads sequenced from viruses. \n\nIt requires paired-end reads file as input and outputs contigs that are part of or full haplotypes.\n\nPEHaplo does not need any reference genomes and thus can be applied for identifying new haplotyps or haplotypes that are remotely related to characterized ones.\n\n## Preparation - Installing Anaconda/Miniconda\n\nThe webiste of Anaconda provides a nice summary: \"Anaconda is a free and open-source distribution of the Python and R programming languages for scientific computing (data science, machine learning applications, large-scale data processing, predictive analytics, etc.), that aims to simplify package management and deployment. Package versions are managed by the package management system conda. You can easily create several individual environments with different python version such as 2.7, 3.5, 3.6.\". \n\nSince there are some required dependencies for PEHaplo and TAR-VIR, you are suggested to install them using [Anaconda](https://www.anaconda.com/distribution/) or [miniconda](https://docs.conda.io/en/latest/miniconda.html) so that you can easily create a well equipped environment.\n\n*Please note that, **ALL** the modules we used in installing PEHaplo and TAR-VIR **ONLY** supply on **Linux**. So please make sure your OS is correct.*\n\n\n1. Go to [Anaconda] (https://www.anaconda.com/distribution/). Choose \"Linux\". Then you see a title named  **Anaconda 2018.12 for Linux InstallerDownload**. Download the .sh file by clicking the **Download** buttons. Both Python 3.7 and 2.7 versions are OK. \n2. Bash the .sh file and install anaconda to your computer.\n3. Add the anaconda to your PATH. \nThe following is from the FAQ of Anaconda. Conda will not work until you add the PATH manually. To add the PATH manually, open a text editor and open the file .bashrc or .bash_profile from your home directory. Add the line `export PATH=\"/<path to anaconda>/bin:$PATH\" ` . NOTE: Replace \\<path-to-anaconda>\\ with the actual path of your installed anaconda file.\n4. If you are using a high performance computing center's cluster, it is possible that conda had been installed previously. To check this, use commands\n```\n  >module spider conda\n \n ----------------------------------------------------------------------------\n  Anaconda2: Anaconda2/4.2.0\n----------------------------------------------------------------------------\n    Description:\n      Built to complement the rich, open source Python community, the\n      Anaconda platform provides an enterprise-ready data analytics\n      platform that empowers companies to adopt a modern open data science\n      analytics architecture. \n\n\n    This module can be loaded directly: module load Anaconda2/4.2.0\n \n >module load Anaconda2/4.2.0\n```\n\nYou can test whether the installation of anaconda is successful by typing some of the following commands. You will need to use some of them when installing TAR-VIR. Detailed information about conda commands can be found in this [link](https://conda.io/en/latest/)\n\n+ See what enviroments you have already had\n\n  > conda info -e\n\n+ List all the packages in your current enviroments\n\n   > conda list\n   \n+ Search if there is a avalible package in your channel\n\n   > conda search\n\n+ Create a new enviroment (replace [env_name] with your name and [version] with python version\n\n   > conda create -n [env_name] python = [version]\n\n+ Activate an enviroment\n  \n   > conda activate [env_name]\n   \n+ Install a new module\n  \n   > conda install [module_name]\n\n+ Add a new resource to your channel (replace [link of channel] with the resource website). Once you have added the channels for your conda, You can use it to search packages forever for every environment.\n\n   > conda config --add channels [link of channel]\n\n## Build an environment and install dependencies\n\nIf the above commands work, this indicates that you have successfully installed conda. You are ready to install the tools now. There are only a few commands to run.\n\nStep 1. Add some resource for your local channel\n\n```\n    conda config --add channels defaults\n    conda config --add channels conda-forge\n    conda config --add channels bioconda\n    conda config --add channels kennethshang\n\n```\n\nStep 2. Create a new environment with python2.7\n\n```\n    conda create -n bio2 python=2.7     # You can replace bio2 to any name you like\n    conda activate bio2                 # Activate your env\n    source activate bio2                # Sometimes you need to use this command to activate the environment. Try conda activate first. \n```\n\nStep 3. Install Python module: [networkx 1.11](https://github.com/networkx/networkx/releases/tag/networkx-1.11)\n\n```\n    pip install networkx=1.11           # currently TAR-VIR only works with this version. Under some systems, use pip install networkx==1.11. Type both and see the hints. \n\n```\nStep 4. Install dependencies and other needed tools [Karect](https://github.com/aminallam/karect), [Readjoiner](http://www.zbh.uni-hamburg.de/forschung/gi/software/readjoiner.html), [Apsp](https://github.com/chjiao/Apsp), [SGA](https://github.com/jts/sga), [Samtools](http://samtools.sourceforge.net/), [Bowtie2](http://bowtie-bio.sourceforge.net/bowtie2/index.shtml)\n\n```\n    conda install Karect bamtools==2.4.0 apsp sga samtools bowtie2 overlap_extension genometools-genometools\n```\n\n# Installing TAR-VIR and PEHaplo\n\nTo download the source code:\n```\ngit clone --recursive https://github.com/chjiao/TAR-VIR.git\n```\nOutput of this command might look like \n```\nCloning into 'TAR-VIR'...\nremote: Enumerating objects: 3, done.\nremote: Counting objects: 100% (3/3), done.\nremote: Compressing objects: 100% (3/3), done.\nremote: Total 37 (delta 0), reused 0 (delta 0), pack-reused 34\nUnpacking objects: 100% (37/37), done.\nSubmodule 'Overlap_extension' (https://github.com/chjiao/Overlap_extension.git) registered for path 'Overlap_extension'\nSubmodule 'PEHaplo' (https://github.com/chjiao/PEHaplo.git) registered for path 'PEHaplo'\nCloning into 'Overlap_extension'...\nremote: Enumerating objects: 64, done.\nremote: Total 64 (delta 0), reused 0 (delta 0), pack-reused 64\nUnpacking objects: 100% (64/64), done.\nSubmodule path 'Overlap_extension': checked out '371909a3bcd0792b5f93f39970e2612f8010de7a'\nCloning into 'PEHaplo'...\nremote: Enumerating objects: 200, done.\nremote: Total 200 (delta 0), reused 0 (delta 0), pack-reused 200\nReceiving objects: 100% (200/200), 10.74 MiB | 0 bytes/s, done.\nResolving deltas: 100% (126/126), done.\nSubmodule path 'PEHaplo': checked out '861fbd6c7ab281ee7864014209d7733afa9bd887'\n```\n\n# Testing TAR-VIR\n\n*Please note that, **your env should be activated** when testing. If not, please do `conda activate [env_name]`* \n\n\n1. Run the example for testing read classification by TAR-VIR\n```\ncd TAR-VIR/Overlap_extension/\nbuild -f test_data/virus.fa -o virus\noverlap -S test_data/HIV.sam -x virus -f test_data/virus.fa -c 180 -o virus_recruit.fa\n```\n-S is followed by the sam file, which is the output of Bowtie. -c is followed by the overlap threshold. -o is followed by the output file name (recruited reads). -x is followed by the index. -f is followed by the read data set. \n\nThe output contains the number of recruited reads for each iteration, e.g.\n```\n...\nIteration: 55, recruited reads number: 1294\nSeeds number: 1294\nIteration: 56, recruited reads number: 1198\nSeeds number: 1198\nIteration: 57, recruited reads number: 1258\nSeeds number: 1258\nIteration: 58, recruited reads number: 1260\nSeeds number: 1260\nIteration: 59, recruited reads number: 1160\nSeeds number: 1160\nIteration: 60, recruited reads number: 1106\nSeeds number: 1106\nIteration: 61, recruited reads number: 1075\nSeeds number: 1075\nIteration: 62, recruited reads number: 986\nSeeds number: 986\nIteration: 63, recruited reads number: 1052\nSeeds number: 1052\n...\n```\n\nIf everything is good, the recruited reads number should be 81326.\n\n\n# Testing PEHaplo\n\n*Please note that, **your env should be activated** when testing. If not, please do `conda activate [env_name]`* \n\nRun the example for testing (it takes about 3 minutes to get the results)\n```\ncd TAR-VIR/PEHaplo\nmkdir assembly\ncd assembly\npython ../apsp_overlap_clique.py ../processed_test_data/Plus_strand_reads.fa ../processed_test_data/pair_end_connections.txt 180 250 600 210\n```\n\n180: initial overlap threshold before merging cliques\n    \n    \n250: read size\n    \n    \n600: paired-end insert size\n    \n    \n210: overlap threshold after merging cliques\n\nOutput:\n    \n    Contigs.fa: the produced contigs\n    Contigs_clipped.fa is the output after contig correction - we applied one more step to align reads to assembled contigs and try to break some misjoined contigs.\n    PEG_nodes_sequences.fa: the nodes sequences in the graph before doing any assembly.\n\n# A running Example For Whole TAR-VIR (read recruting and strain assembly)\n\n*Please note that, **your env should be activated** when Running. If not, please do `conda activate [env_name]`* \n\n1. Commands for generating sam file\n```\ncd test_data\nmkdir index\nbowtie2-build -f HIV_ref.fa index/HXB2\nbowtie2 -x index/HXB2 -f virus.fa --score-min L,0,-0.05 -t -p 4 -S result.sam\n```\nTo get only the mapped reads (to save loading time for large data set):\n\n```\nsamtools view -F 4 result.sam >result_mapped.sam\n```\n\n2. Using the Overlap component in TAR-VIR to recruit reads from given references.\n\n```\ncd ..\nbuild -f test_data/virus.fa -o virus\noverlap -S test_data/result.sam -x virus -f test_data/virus.fa -c 180 -o virus_recruit.fa\n```\nThe output contains the number of recruited reads for each iteration, e.g.\n```\n...\nIteration: 55, recruited reads number: 1294\nSeeds number: 1294\nIteration: 56, recruited reads number: 1198\nSeeds number: 1198\nIteration: 57, recruited reads number: 1258\nSeeds number: 1258\nIteration: 58, recruited reads number: 1260\nSeeds number: 1260\nIteration: 59, recruited reads number: 1160\nSeeds number: 1160\nIteration: 60, recruited reads number: 1106\nSeeds number: 1106\nIteration: 61, recruited reads number: 1075\nSeeds number: 1075\nIteration: 62, recruited reads number: 986\nSeeds number: 986\nIteration: 63, recruited reads number: 1052\nSeeds number: 1052\n...\n```\n\nIf everything is good, the recruited reads number should be 81326.\n\n2. Copy the output file form the Overlap to PEHaplo\n\nSince we need to use the output file from the Overlap as the input of PEHaplo, we need to copy it to the PEHaplo dictionary. Do the following command.\n\n```\ncp virus_recruit.fa ../PEHaplo\n```\n\n3. Preprocessing your raw data into correct form for PEHaplo\n\n```\ncd ../PEHaplo\nmkdir test\ncd test\npython ../tools/get_read_pairs.py ../virus_recruit.fa\n```\nOutput of this command should be:\n```\nThe number of read pairs is: 11590, single-end reads is: 58146\n```\nAnd it will output three files: single_end.fa, pair1.fa, and pair2.fa. \n\n4. Running PEHaplo with your input data (It will take a few minutes to get the results)\n\n```\npython ../pehaplo.py -f1 pair1.fa -f2 pair2.fa -l 180 -l1 210 -r 250 -F 600 -std 150 -n 3 -correct yes\n\nOutput:\nContigs.fa: the raw output contigs\nContigs_clipped.fa: the contigs after error correction\nPEG_nodes_sequences.fa: the nodes sequences in the graph\n```\n# FAQ\n0. If you only want to recruite reads using TAR-VIR, you do not need to use conda because TAR-VIR has very few dependencies and can be installed easily. Most of the dependencies are for PEHaplo, the assembly step. \n\n1. If you see an error, very likely it is caused by missing packages/dependencies. For example, if you see an error like below when running PEHaplo:\nTraceback (most recent call last):\n  File \"/mnt/home/yannisun/TAR-VIR/PEHaplo/tools/identify_misjoin_contigs.py\", line 5, in <module>\n    from scipy import stats\nImportError: No module named scipy\nTraceback (most recent call last):\n  File \"../pehaplo.py\", line 157, in <module>\n    contigs_mapped.sam 250 600 150' returned non-zero exit status 1\n The message **ImportError: No module named scipy** means that you did not have scipy installed. In this case, run the following command will solve this problem. \n\n```  \n> pip install scipy\n```\n2. Sometimes, just try to re-run the packaging installing command will solve most issues.\nFor example, we find that we need to reinstall sga when we test our program under one environment. In this case, you can uninstall the old packages and reinstall the new one. \n```\nconda uninstall sga\nconda install sga\n```\n3. If you cannot install all packages in one command line, please try to install them seperately.  \n4. You can add the following links as your local channels to accelerate when you are in mainland China.\n\n```\n    conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/ \n    conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/\n    conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/\n    conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/r/\n    conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/bioconda/\n    conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/msys2/\n    conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/menpo/\n    conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/\n  \n```\n"
      },
      "source": "https://raw.githubusercontent.com/chjiao/TAR-VIR/master/Guidance%20for%20Installing%20PEHaplo%20and%20TAR-VIR.md",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Installing via conda (recommended if you want to install both TAR-VIR and PEHaplo)",
        "parent_header": [
          "TAR-VIR"
        ],
        "type": "Text_excerpt",
        "value": "Noted that all the packages can be found on anaconda.cloud, which means you can easily install them by using conda. You can follow the [Guidance](https://github.com/chjiao/TAR-VIR/blob/master/Guidance%20for%20Installing%20PEHaplo%20and%20TAR-VIR.md) to install step by step. \n"
      },
      "source": "https://raw.githubusercontent.com/chjiao/TAR-VIR/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Installation without using conda",
        "parent_header": [
          "TAR-VIR"
        ],
        "type": "Text_excerpt",
        "value": "If you would like to install all the programs without using conda, please still take a look at the [Guaidance](https://github.com/chjiao/TAR-VIR/blob/master/Guidance%20for%20Installing%20PEHaplo%20and%20TAR-VIR.md), which contains a running example.\n\nTo download the source code:   \ngit clone --recursive  https://github.com/chjiao/TAR-VIR.git   \n\n1. Install Overlap extension module   \nThis program requries the supports of C++11.   \ncd TAR-VIR   \ncd Overlap_extension   \nmake    \n\n2. Install PEHaplo   \nPlease look at the ReadMe file for PEHaplo at:   \nhttps://github.com/chjiao/PEHaplo   \n"
      },
      "source": "https://raw.githubusercontent.com/chjiao/TAR-VIR/master/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 0.9999999997572786,
      "result": {
        "original_header": "TAR-VIR",
        "type": "Text_excerpt",
        "value": "We provide two methods for installing TAR-VIR and PEHaplo. You can directly install these tools following the instructions below. In addition, we also provide packaged TAR-VIR and PEHaplo via Anaconda, which makes the installation more straightforward. \n \n"
      },
      "source": "https://raw.githubusercontent.com/chjiao/TAR-VIR/master/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9999999999968736,
      "result": {
        "original_header": "New version",
        "type": "Text_excerpt",
        "value": "If you installed TAR-VIR via conda. New version is available now. please use `conda install -c kennethshang overlap_extension` to update. In the new version of TAR-VIR, we provide a new parameter that allow TAR-VIR run in parallel to save time. If you want to run TAR-VIR on a large dataset, this might be helpfull. The information is shown below:\n```\nParameter:\n  -t  number of threads\n\nNote:\n   Due to the inplementation of TAR-VIR, the number of '-t' satisfy the equation:\n                                   k = nt     (n = 1, 2, 3 ...)\n   k is a paramter represents partations of Index. n is any positive integer\n```\n \n"
      },
      "source": "https://raw.githubusercontent.com/chjiao/TAR-VIR/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/chjiao/TAR-VIR/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ""
      },
      "technique": "GitHub_API"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "TAR-VIR"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "User",
        "value": "chjiao"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 906,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/chjiao/TAR-VIR/master/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "somef_missing_categories": [
    "citation",
    "acknowledgement",
    "run",
    "download",
    "requirements",
    "contact",
    "contributors",
    "documentation",
    "license",
    "faq",
    "support",
    "identifier",
    "has_build_file",
    "executable_example"
  ],
  "somef_provenance": {
    "date": "2024-11-04 05:32:55",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 8
      },
      "technique": "GitHub_API"
    }
  ],
  "usage": [
    {
      "confidence": 1,
      "result": {
        "original_header": "Usage",
        "parent_header": [
          "TAR-VIR"
        ],
        "type": "Text_excerpt",
        "value": "1. Overlap extension   \nAfter compilation, there will be two binary files: build and overlap   \n(1) build reads index    \n./build -f reads.fa -o prefix   \n(2) recruite reads   \n./overlap -S align.sam -x prefix -f reads.fa -c overlap_cutoff -o recruited_reads.fa   \nalign.sam is the alignment results of reads.fa on available reference   \n\nTest data and running examples   \nThe test data sets are in folder Overlap_extension/test_data/.   \nvirus.fa   \nThis data set contains simulated viral reads from HIV-1, HCV genotype 1, and HGV.   \nHIV.sam   \nThis SAM file contains a small subset of aligned HIV-1 reads. With these aligned (287) reads, more HIV-1 reads can be recruited from the viral metagenomics data set.   \n\nExample:   \ncd Overlap_extension/   \n./build -f test_data/virus.fa -o virus   \n./overlap -S test_data/HIV.sam -x virus -f test_data/virus.fa -c 180 -o virus_recruit.fa   \nIf everything is good, the recruited reads number should be 8008.   \n\n2. Assemble   \nThe recruited reads usually contain both single- or paired-end reads, use the '-f' option of PEHaplo to input one fasta file.    \nFor details, please look at https://github.com/chjiao/PEHaplo.\n\n\n"
      },
      "source": "https://raw.githubusercontent.com/chjiao/TAR-VIR/master/README.md",
      "technique": "header_analysis"
    }
  ]
}