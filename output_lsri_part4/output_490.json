{
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/cga-harvard/Hypermap-Registry"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2015-12-17T16:20:43Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2024-07-01T21:34:59Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "Hypermap Registry, remote map services made easy for your SDI  "
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 0.9967497558848516,
      "result": {
        "original_header": "Hypermap Registry",
        "type": "Text_excerpt",
        "value": "Hypermap Registry is a platform that manages OWS, Esri REST, and other types of map service harvesting, and orchestration and maintains uptime statistics for services and layers. \n"
      },
      "source": "https://raw.githubusercontent.com/cga-harvard/HHypermap/master/README.md",
      "technique": "supervised_classification"
    }
  ],
  "documentation": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/cga-harvard/HHypermap/tree/master/docs"
      },
      "technique": "file_exploration"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/cga-harvard/HHypermap/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 21
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/cga-harvard/Hypermap-Registry/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "cga-harvard/Hypermap-Registry"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "Hypermap Registry"
      },
      "source": "https://raw.githubusercontent.com/cga-harvard/HHypermap/master/README.md",
      "technique": "regular_expression"
    }
  ],
  "has_build_file": [
    {
      "confidence": 1,
      "result": {
        "format": "docker_compose",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/cga-harvard/HHypermap/master/docker-compose.yml"
      },
      "source": "https://raw.githubusercontent.com/cga-harvard/HHypermap/master/docker-compose.yml",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "format": "dockerfile",
        "type": "Url",
        "value": "https://raw.githubusercontent.com/cga-harvard/HHypermap/master/Dockerfile"
      },
      "source": "https://raw.githubusercontent.com/cga-harvard/HHypermap/master/Dockerfile",
      "technique": "file_exploration"
    }
  ],
  "has_script_file": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/cga-harvard/HHypermap/master/wait-for-postgres.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/cga-harvard/HHypermap/master/config/celerybeat_start.sh"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/cga-harvard/HHypermap/master/config/celery_start.sh"
      },
      "technique": "file_exploration"
    }
  ],
  "installation": [
    {
      "confidence": 1,
      "result": {
        "type": "File_dump",
        "value": "# Harvard WorldMap installation\n\nYou could use GeoNode WorldMap to consume the Hypermap Registry layers in web maps.\nHere is a procedure to install it in Ubuntu 16.04 LTS.\n\n## Requirements\n\nWe are assuming a Ubuntu 16.04 LTS development environment, but these instructions can be adapted to any recent Linux distributions::\n\n    # Install Ubuntu dependencies\n    sudo apt-get update\n    sudo apt-get install python-virtualenv python-dev libxml2 libxml2-dev libxslt1-dev zlib1g-dev libjpeg-dev libpq-dev libgdal-dev git default-jdk postgresql postgis\n\n    # Install Java 8 (needed by latest GeoServer 2.14)\n    sudo apt-add-repository ppa:webupd8team/java\n    sudo apt-get update\n    sudo apt-get install oracle-java8-installer\n\n## Virtual environment creation and installation of Python packages\n\nCreate and activate the virtual environment::\n\n    cd ~\n    virtualenv --no-site-packages env\n    . env/bin/activate\n\nNow install GeoNode from source code::\n\n    git clone https://github.com/geonode/geonode.git\n    cd geonode\n    pip install -r requirements.txt\n    pip install pygdal==1.11.3.3\n    pip install -e .\n    paver setup\n\n## Create the databases\n\n```txt\nsudo su postgres\npsql\npostgres=# CREATE ROLE worldmap WITH LOGIN SUPERUSER PASSWORD '***';\nCREATE ROLE\npostgres=# CREATE DATABASE worldmap WITH OWNER worldmap;\nCREATE DATABASE\npostgres=# \\c worldmap\nYou are now connected to database \"worldmap\" as user \"postgres\".\nworldmap=# CREATE EXTENSION postgis;\nCREATE EXTENSION\nworldmap=# CREATE DATABASE wmdata WITH OWNER worldmap;\nCREATE DATABASE\nworldmap=# \\c wmdata\nYou are now connected to database \"wmdata\" as user \"postgres\".\nwmdata=# CREATE EXTENSION postgis;\nCREATE EXTENSION\n```\n\n## Environment variables setup\n\nSet the following environment variables as needed (change SITE_NAME and SERVER_IP s needed. Also HYPERMAP_REGISTRY_URL and SOLR_URL may be different). Even better, create a file and source it::\n\n      export USE_WORLDMAP=True\n      export SITE_NAME=worldmap\n      export SERVER_IP=localhost\n      export PG_USERNAME=worldmap\n      export PG_PASSWORD=worldmap\n      export PG_WORLDMAP_DJANGO_DB=worldmap\n      export PG_WORLDMAP_UPLOADS_DB=wmdata\n      export OWNER=$PG_USERNAME\n      export ALLOWED_HOSTS=\"localhost, $SERVER_IP, \"\n      export GEOSERVER_LOCATION=http://localhost:8080/geoserver/\n      export GEOSERVER_PUBLIC_LOCATION=http://$SERVER_IP/geoserver/\n      export SOLR_URL =http://localhost:8983/solr/hypermap/select/\n      export HYPERMAP_REGISTRY_URL =http://localhost:8001\n      export MAPPROXY_URL=http://localhost:8001\n\n\nYou can install GeoNode WorldMap in two different ways:\n\n1) By installing GeoNode itself\n2) By using the recommended way of a geonode-project\n\n## GeoNode/WorldMap without a geonode-project\n\nCopy the included local_settings.py file and customize it to your needs::\n\n    cp local_settings.py.worldmap.sample local_settings.py\n\n## GeoNode/WorldMap with a geonode-project\n\nYou will use a geonode-project in order to separate the customization of your instance from GeoNode.\n\nCreate your geonode project by using the WorldMap geonode-project as a template  (https://github.com/cga-harvard/geonode-project). Rename it to something meaningful (for example your web site name)::\n\n    cd ~\n    django-admin startproject $SITE_NAME --template=https://github.com/cga-harvard/geonode-project/archive/master.zip -epy,rst\n    cd $SITE_NAME\n\nCreate a local_settings.py by copying the included template::\n\n    cp $SITE_NAME/local_settings.py.sample $SITE_NAME/local_settings.py\n    make build\n    paver setup\n\n## Start the Server\n\nStart GeoNode with Worldmap using pavement::\n\n    python manage.py runserver 0.0.0.0:8000\n    paver start_geoserver\n\nTo upload layers you can login with the default GeoNode administrative account:\n\nuser: admin\npassword: admin\n\n## Configuring instance for production\n\n### uwsgi\n\nCreate a worlmap.ini script for running uwsgi. For example create it like this in /home/ubuntu:\n\n```sh\n[uwsgi]\nplugins = python\nprocesses = 4\nmaster = true\nhttp-socket = 0.0.0.0:8000\nchmod-socket = 664\nbuffer-size = 32768\nlog-date = true\nlogto = /tmp/%n.log\nchdir = /home/ubuntu/worldmap\nmodule= worldmap_site.wsgi\nenable-threads = true\nworkers = 10\nvirtualenv = /home/ubuntu/env\nvacuum = true\nsocket = /tmp/worldmap.sock\nmax-requests = 5000 # respawn processes after serving 5000 requests\nlimit-as = 1024 # avoid Errno 12 cannot allocate memory\n\n## Env Variables\nenv = USE_WORLDMAP=True\nenv = SITE_NAME=worldmap\nenv = SERVER_IP=your-ip\nenv = SITEURL=your-ip\nenv = PG_HOST=localhost\nenv = PG_USERNAME=worldmap\nenv = PG_PASSWORD=***\nenv = PG_WORLDMAP_DJANGO_DB=worldmap\nenv = PG_WORLDMAP_UPLOADS_DB=wmdata\n#env = GEOFENCE_URL=postgresql://worldmap:***@localhost:5432/geofence\nenv = DEFAULT_BACKEND_DATASTORE=datastore\nenv = ALLOWED_HOSTS=['localhost', 'your-ip', ]\nenv = GEOSERVER_LOCATION=http://your-ip:8080/geoserver/\nenv = GEOSERVER_PUBLIC_LOCATION=http://your-ip/geoserver/\nenv = GEOSERVER_ADMIN_PASSWORD=geoserver\nenv = SOLR_URL=http://hypermap-ip:8983/solr/hypermap/select/\nenv = USE_HYPERMAP=True\nenv = HYPERMAP_REGISTRY_URL=http://hypermap-ip/\nenv = MAPPROXY_URL=http://hypermap-ip/\nenv = GOOGLE_API_KEY=***\nenv = DEFAULT_BACKEND_UPLOADER=geonode.importer\nenv = GEONAMES_USER=***\n```\n\nTest the .ini file (browse to your-ip:8000 to see if it works correctly):\n\n\n\nCreate a service script in /etc/systemd/system/worldmap.service like this:\n\n```sh\n[Unit]\nDescription=uWSGI instance to serve GeoNode WorldMap\nAfter=network.target\n\n[Service]\nUser=ubuntu\nGroup=www-data\nExecStart=/usr/bin/uwsgi --ini /home/ubuntu/worldmap.ini\n\n[Install]\nWantedBy=multi-user.target\n```\n\nNow start the uwsgi process:\n\n```sh\nsudo service worldmap start\n```\n\nTo automatically start the process at server boot:\n\n```sh\nsudo systemctl enable worldmap.service\n```\n\n### nginx\n\nIf still not installed, install nginx:\n\n```sh\nsudo apt install nginx\n```\n\nDisable the default site (by removing the symbolic link in sites-enabled) and create a site for GeoNode by creating the following file in /etc/nginx/sites-available/geonode:\n\n```sh\nserver {\n    listen 80;\n    index index.html index.htm;\n    root   /usr/share/nginx/html;\n    server_name your-ip;\n\n    location /uploaded {\n      alias /home/ubuntu/worldmap/worldmap_site/uploaded/;\n      expires 30;\n    }\n\n    location /geoserver {\n      proxy_pass http://localhost:8080/geoserver;\n      proxy_redirect     off;\n      proxy_set_header   Host $host;\n      proxy_set_header   X-Real-IP $remote_addr;\n      client_max_body_size 100M;\n      proxy_read_timeout 30000;\n    }\n\n    location /solr {\n      proxy_pass http://hh.worldmap.h-gis.jp:8983;\n      proxy_redirect     off;\n      proxy_set_header   Host $host;\n      proxy_set_header   X-Real-IP $remote_addr;\n      client_max_body_size 100M;\n      proxy_read_timeout 30000;\n    }\n\n    location / {\n    root /home/ubuntu/ritsumei;\n    proxy_pass http://0.0.0.0:8000/;\n    add_header Access-Control-Allow-Origin \"*\";\n\n    if ($request_method = OPTIONS) {\n      add_header Access-Control-Allow-Methods \"GET, POST, PUT, PATCH, OPTIONS\";\n      add_header Access-Control-Allow-Headers \"Authorization, Content-Type, Accept\";\n      add_header Access-Control-Allow-Credentials true;\n      add_header Content-Length 0;\n      add_header Content-Type text/plain;\n      add_header Access-Control-Max-Age 1728000;\n      return 200;\n    }\n    client_max_body_size 100M;\n    client_body_buffer_size 128K;\n    add_header Access-Control-Allow-Credentials false;\n    add_header Access-Control-Allow-Headers \"Content-Type, Accept, Authorization, Origin, User-Agent\";\n    add_header Access-Control-Allow-Methods \"GET, POST, PUT, PATCH, OPTIONS\";\n    proxy_set_header X-Forwarded-Protocol $scheme;\n    proxy_read_timeout 30000;\n    proxy_redirect     off;\n    proxy_set_header   Host $host;\n    proxy_set_header   X-Real-IP $remote_addr;\n    proxy_set_header   X-Forwarded-For $proxy_add_x_forwarded_for;\n    proxy_set_header   X-Forwarded-Host $server_name;\n  }\n}\n```\n\nEnable the site by creating a symbolic link in sites-enabled and restart nginx.\n\n### Tomcat\n\n```sh\ncd /opt\nsudo wget http://mirrors.koehn.com/apache/tomcat/tomcat-8/v8.5.37/bin/apache-tomcat-8.5.37.tar.gz\nsudo tar -xvzf apache-tomcat-8.5.37.tar.gz\nsudo mv apache-tomcat-8.5.37 tomcat\nsudo chown -R ubuntu:ubuntu tomcat\n```\n\nCreate a service script in /etc/systemd/system/tomcat.service (modify parameter as per your needs):\n\n```\n[Unit]\nDescription=Tomcat\nAfter=network.target\n\n[Service]\nType=forking\n\nEnvironment=CATALINA_PID=/opt/tomcat/tomcat.pid\nEnvironment=JAVA_HOME=/usr/lib/jvm/java-8-oracle/\nEnvironment=CATALINA_HOME=/opt/tomcat\nEnvironment=CATALINA_BASE=/opt/tomcat\nEnvironment='CATALINA_OPTS=-Xmx4800m -Xms3000m -server\nEnvironment='JAVA_OPTS=-Xmx4096m -Xms3000m -XX:MaxPermSize=4096m -XX:+UseConcMarkSweepGC -XX:+UseParNewGC -XX:ParallelGCThreads=4 -DGEOSERVER_DATA_DIR=/home/ubuntu/gs_data -DGEOWEBCACHE_CACHE_DIR=/home/ubuntu/gs_data/gwc -Djava.library.path=/usr/local/lib/ -DGEOMETRY_COLLECT_MAX_COORDINATES=50000 -Djavax.servlet.request.encoding=UTF-8 -Djavax.servlet.response.encoding=UTF-8 -Dfile.encoding=UTF-8 -Duser.timezone=GMT -Dorg.geotools.shapefile.shapefile.datetime=true -Dgeofence.dir=/home/ubuntu/gs_data/geofence -Djava.security.egd=file:/dev/./urandom'\n\nExecStart=/opt/tomcat/bin/startup.sh\nExecStop=/opt/tomcat/bin/shutdown.sh\n\nUser=ubuntu\nGroup=ubuntu\n\n[Install]\nWantedBy=multi-user.target\n```\n\nDeploy the .war to Tomcat webapps and then start the Tomcat service:\n\n```sh\ncp ~/geonode/downloaded/geoserver-2.14.x.war /opt/tomcat/webapps/\nmv /opt/tomcat/webapps/geoserver-2.14.x.war /opt/tomcat/webapps/geoserver.war\nsudo service tomcat start\n```\n\nNow start the Tomcat service and check if GeoServer is up and running.\n\nTo automatically start the process at server boot:\n\n```sh\nsudo systemctl enable tomcat.service\n```\n\nHypermap Registry\n=================\n\nGeoNode with the WorldMap contribute module requires a Hypermap Registry (Hypermap) running instance.\n\nYou can install Hypermap by following these instructions (use the \"Manual Installation\" section): https://github.com/cga-harvard/HHypermap/blob/master/_docs/developers.md\n\nNote that you can bypass Java 8 installation as it was installed previously. As a search engine you should install Solr, as we haven't tested Elasticsearch with WorldMap so far. Create a specific virtual environment for Hypermap in order not to interfere with the GeoNode/WorldMap virtual environment.\n\nAfter installing Hypermap, start it on a different port than 8000, for example::\n\n    python manage.py runserver 0.0.0.0:8001\n\nIn another shell start the Celery process as well::\n\n    cd HHypermap\n    celery -A hypermap worker --beat --scheduler django -l info\n\nTest the stack\n==============\n\nNow that GeoNode/WorldMap and Hypermap are both running, test the stack by uploading a layer.\n\nLogin in GeoNode (admin/admin) and upload a shapefile from this page: http://localhost:8000/layers/upload\n\nMake sure the shapefile is correctly displayed in GeoNode by going to the layer page.\n\nNow login in Hypermap (admin/admin) and go to the admin services page: http://localhost:8001/admin/aggregator/service/ Add a service like this:\n\n    * Title: My GeoNode WorldMap SDI\n    * Url: http://localhost:8000/\n    * Type: GeoNode WorldMap\n\nGo to the Hypermap service page and check it the service and the layer is there:\nhttp://localhost:8001/registry/\n\nIn order to have layers in the search engine (Solr) there are two options:\n\n1) from task runner press the \"Index cached layers\" button\n2) schedule a task in celery\n\nWe recommend the second option, which can be configured in the next section.\n\nSchedule Celery tasks\n=====================\n\nGo to the Periodic Task administrative interface: http://localhost:8001/admin/django_celery_beat/periodictask/\n\nCreate the following two tasks:\n\nIndex Cached Layer Task\n-----------------------\n\nThis task will sync the layers from the cache to the search engine. Layers are sent in the cache every time they are saved:\n\n    * Name: Index Cached Layer\n    * Task (registered): hypermap.aggregator.tasks.index_cached_layers\n    * Interval: every 1 minute (or as needed)\n\nCheck Worldmap Service\n----------------------\n\nThis task will do a check of all of WorldMap service:\n\n    * Name: Check WorldMap Service\n    * Task (registered): hypermap.aggregator.tasks.check_service\n    * Interval: every 1 minute (or as needed)\n    * Arguments: [1] # 1 is the id of the service. Change it as is needed\n\nNow upload a new layer in GeoNode/WorldMap and check if it appears in Hypermap and in Solr (you may need to wait for the tasks to be executed)\n\nUpdate Last GeoNode WorldMap Layers\n-----------------------------------\n\nIf your GeoNode/WorldMap instance has many layers, it is preferable to runt the check_service not so often, as it can be time consuming, and rather use the update_last_wm_layers.\n\nAs a first thing, change the interval for the check_service task you created for GeoNode/WorldMap to a value such as \"one day\" or \"one week\".\n\nThen create the following periodic task:\n\n    * Name: Sync last layers in WorldMap Service\n    * Task (registered): hypermap.aggregator.update_last_wm_layers\n    * Interval: every 1 minute\n    * Arguments: [1] # 1 is the id of the service. Change it as is needed\n"
      },
      "source": "https://raw.githubusercontent.com/cga-harvard/HHypermap/master/docs/installation_wm.md",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "File_dump",
        "value": "# Installation\n\nYou can have a development working setup using one of the following methods:\n\n* Manual Installation (last tested: 01/11/2019)\n* Docker Installation (last tested: June 2017)\n\nPlease provide feedback opening a ticket if these instructions are failing.\n\n## Manual Installation\n\nWe will assume you are installing every Hypermap Registry component (web application, search engine, RDBMS and task queue) on a single server, but they can be installed on different servers as well.\n\n### Requirements\n\nWe are assuming a Ubuntu 16.04.1 LTS development environment, but these instructions can be adapted to any recent Linux distributions.\n\nInstall the requirements:\n\n```sh\nsudo apt-get update\nsudo apt-get install gcc postgresql rabbitmq-server python-virtualenv git python-psycopg2 libjpeg-dev python-dev libxml2-dev libxslt-dev libxslt1-dev libpq-dev libgeos-dev memcached libmemcached-dev\n```\n\n### RDBMS\n\nAs the database, we recommend to use PostgreSQL, but any RDBMS supported by Django can be used.\n\nCreate PostgreSQL database:\n\n```sh\nsudo -i -u postgres\npsql\nCREATE ROLE hypermap WITH SUPERUSER LOGIN PASSWORD 'hypermap';\nCREATE DATABASE hypermap WITH OWNER hypermap;\npostgres=# \\q\n```\n\n### Search Engine\n\nNow you need to install a search engine, which can be Solr or Elasticsearch. Both of them require Java.\n\nInstall java8:\n```sh\nsudo add-apt-repository ppa:webupd8team/java\nsudo apt-get update\nsudo apt-get install oracle-java8-installer\n```\n\nNow follow the instrcutions for Solr or Elasticsearch, depending on your scenario.\n\n#### Solr (Recommended)\n\nInstall and start Solr, and create the hypermap schema:\n\n```sh\nexport SOLR_VERSION=7.3.0\ncd /opt\nsudo wget http://archive.apache.org/dist/lucene/solr/$SOLR_VERSION/solr-$SOLR_VERSION.tgz\nsudo tar xzf solr-$SOLR_VERSION.tgz solr-$SOLR_VERSION/bin/install_solr_service.sh --strip-components=2\nsudo ./install_solr_service.sh solr-$SOLR_VERSION.tgz\nsudo -u solr solr/bin/solr create -c hypermap\n# in older version than 7.5.0: sudo -u solr solr/bin/solr config -c hypermap -p 8983 -property update.autoCreateFields -value false\nsudo -u solr solr/bin/solr config -c hypermap -p 8983 -action set-user-property -property update.autoCreateFields -value false\n```\n\n#### Elasticsearch\n\nInstall and start Elasticsearch:\n\n```sh\nwget -qO - https://packages.elastic.co/GPG-KEY-elasticsearch | sudo apt-key add -\necho \"deb https://packages.elastic.co/elasticsearch/2.x/debian stable main\" | sudo tee -a /etc/apt/sources.list.d/elasticsearch-2.x.list\nsudo apt-get update && sudo apt-get install elasticsearch\nsudo sed -i -e 's/#ES_HEAP_SIZE=2g/ES_HEAP_SIZE=1g/' /etc/default/elasticsearch\nsudo service elasticsearch start\n```\n\nTODO explain how to create a schema in Elasticsearch.\n\n#### Web Application\n\nInstall Hypermap, which is a web application based on Django, using a virtual environment.\n\n```sh\ncd ~\nvirtualenv --no-site-packages env\nsource env/bin/activate\ngit clone https://github.com/cga-harvard/Hypermap-Registry.git\ncd Hypermap-Registry\npip install -r requirements.txt\n```\n\nTo set the environment variables, create an env_vars and copy and paste the lines below to the end (change the lines according to your configuration)\n\n```sh\nexport DATABASE_URL=postgres://hypermap:hypermap@localhost:5432/hypermap\nexport BROKER_URL=amqp://guest:guest@localhost:5672/\nexport CACHE_URL=memcached://localhost:11211/\nexport BASE_URL=http://localhost\nexport ALLOWED_HOSTS=['localhost',]\nexport REGISTRY_SEARCH_URL=solr+http://localhost:8983\nexport REGISTRY_CHECK_PERIOD=120\nexport REGISTRY_SKIP_CELERY=False\nexport REGISTRY_LIMIT_LAYERS=0\nexport REGISTRY_INDEX_CACHED_LAYERS_PERIOD=1\nexport REGISTRY_HARVEST_SERVICES=True\nexport C_FORCE_ROOT=1\nexport CELERY_DEFAULT_EXCHANGE=hypermap\n```\n\nSource the env_vars file\n\n```\nsource env_vars\n```\n\nExecute migrations, which will generate the schema in the database:\n\n```sh\npython manage.py migrate\n```\n\nFinally, load fixtures\n```sh\npython manage.py loaddata hypermap/aggregator/fixtures/catalog_default.json\npython manage.py loaddata hypermap/aggregator/fixtures/user.json\n```\n\nIf using Solr, update the schema:\n\n```sh\npython manage.py solr_scheme\n```\n\nRun the Django server:\n\n```\npython manage.py runserver 0.0.0.0:8000\n```\n\n#### Celery and RabbitMQ\n\nUsing another shell, start rabbitmq and the Celery process after activating the virtualenv:\n\n```\nsudo service rabbitmq-server start\ncd HHypermap\ncelery -A hypermap worker --beat --scheduler django -l info\n```\n\nYou may need to create a vhost and a user in RabbitMQ. For example, if the value for BROKER_URL is amqp://guest:guest@localhost:5672/\n\n```\nsudo rabbitmqctl add_vhost hypermap\nsudo rabbitmqctl add_user hypermap hypermap\nsudo rabbitmqctl set_user_tags hypermap administrator\nsudo rabbitmqctl set_permissions -p hypermap \".*\" \".*\" \".*\"\n```\n\nNow if you browse to http://localhost:8000, Hypermap should be up and running.\n\n## Docker Installation\n\nYou can have an Hypermap Registry instance up and running using Docker.\n\nInstall Docker and Docker Compose:\n\n```\nwget https://get.docker.com/builds/Linux/x86_64/docker-latest.tgz\ntar -xvzf docker-latest.tgz\nsudo mv docker/* /usr/bin/\ncurl -L https://github.com/docker/compose/releases/download/1.8.0/docker-compose-`uname -s`-`uname -m` > docker-compose\nchmod +x docker-compose\nsudo mv docker-compose /usr/bin/\nsudo usermod -aG docker $(whoami)\n```\n\n### Increase virtual memory map area (Linux)\n\n```\nsudo sysctl -w vm.max_map_count=262144\n```\n\n### Run docker in daemon\n\n```sh\nsudo dockerd\n```\n\n### Deployment of hhypermap within docker\n\n```sh\ngit clone https://github.com/cga-harvard/Hypermap-Registry.git\ncd Hypermap-Registry\nmake up\nmake sync\n```\nFor Ubuntu:\n```\nmake up .\nmake sync\n```\nWait for the instance to be provisioned (about 3/4 minutes).\n\nThen connect to: http://localhost/registry and your instance should be up and running.\n\nYou can edit the files with your IDE from your host, as the directory /code on the guest is synced with your host. Make sure to check the ```REGISTRY_SKIP_CELERY``` environment variable is set to False for debugging. If this value is set to False, it is always necessary to restart the celery container executing\n\n```sh\ndocker-compose restart celery\n```\n\n## Running Hypermap in production\n\nWhen running Hypermap in production it is highly recommended to use a proper web sever (nginx or Apache httpd) in place of the Django server.\n\nYou can find a sample configuration for nginx and uwsgi in the config directory (nginx_sample and uwsgi_sample files).\n\nIn case you want to automate this, there are ansible script for the deployment in the deploy/ansible directory (which need to be updated).\n\nHere is how you can deploy Hypermap Registry using nginx and uwsgi in Ubuntu 16.04 LTS.\n\nInstall requirements:\n\n```sh\nsudo apt install nginx supervisor\n```\n\n### wsgi configuration\n\nCreate a wsgi .ini file to run the Hypermap application, for example /home/ubuntu/hypermap.ini. Copy in it the content from hyperma/config/uwsgi_config and adapt it to your needs. Make sure it correctly works by running:\n\n```sh\n/home/ubuntu/env/bin/uwsgi --ini hypermap.ini\n```\n\nNow create a service for the wsgi process by adding a file in /etc/systemd/system/hypermap.service like this:\n\n```sh\n[Unit]\nDescription=uWSGI instance to serve Hyermap Registry\nAfter=network.target\n\n[Service]\nUser=ubuntu\nGroup=www-data\nExecStart=/home/ubuntu/env/bin/uwsgi --ini /home/ubuntu/hypermap.ini\n\n[Install]\nWantedBy=multi-user.target\n```\n\nTo enable the server to start at server boot:\n\n```sh\nsudo systemctl enable hypermap.service\n```\n\n### nginx configuration\n\nNow create the nginx configuration file in /etc/nginx/sites-enabled/hypermap using the template in hypermap/config/nginx and restart nginx.\n\n### celery/rabbimq configuration\n\nFor Celery we will use supervisor in order to run the celery process and the celerybeat process.\n\nCreate a supervisor configuration for the celery process in /etc/supervisor/conf.d/celery.conf:\n\n```sh\n[program:celery]\ncommand=/home/ubuntu/Hypermap-Registry/config/celery_start.sh\n\nautostart=true\nautorestart=true\n\nuser=www-data\n\nstdout_logfile=/tmp/celery.log\nredirect_stderr = true\n```\n\nCreate another supervisor configuration for the celerybeat process in /etc/supervisor/conf.d/celerybeat.conf:\n\n```sh\n[program:celerybeat]\ncommand=/home/ubuntu/Hypermap-Registry/config/celerybeat_start.sh\n\nautostart=true\nautorestart=true\n\nuser=www-data\n\nstdout_logfile=/tmp/celerybeat.log\nredirect_stderr = true\n```\n\nNow if you restart supervisor (sudo service supervisor restart) you should notice two process running in it:\n\n```sh\nsudo supervisorctl\ncelery                           RUNNING   pid 1717, uptime 0:06:02\ncelerybeat                       RUNNING   pid 1718, uptime 0:06:02\nsupervisor>\n```\n\n## For developers\n\n### Testing Hypermap Registry\n\nIf you want to provide pull requests to Hypermap-Registry, you should make sure that your changes don't break tests before submitting the pull request.\n\n*Unit tests* check the correct functionality of Hypermap workflow when an endpoint is added: some services and their layers are created, then the tests check\n if the correct metadata are harvested and stored in DB and indexed in the search backend.\n\n To run the unit tests:\n\n```sh\nmake test-unit\n```\n\n*Solr backend tests* check that the Solr search engine implementation works correctly: tests index layers in Solr and test the Hypermap search API is working properly.\n\n```sh\nmake test-solr\n```\n\n*Elasticsearch backend tests* check that the Elasticsearch search engine implementation works correctly: tests index layers in Elasticsearch and test the Hypermap search API is working properly.\n\n```sh\nmake test-elastic\n```\n\n*Selenium Browser tests* emulate the user interaction in Firefox with some basic actions to test the correct functionality of the Django admin site and registry UI. Tests cover the following actions:\n\n 1. admin login (user sessions works as expected)\n 2. periodic tasks verifications (automatic periodic tasks are created on startup in order to perform important automatic tasks like check layers, index cached layers on search backend and clean up tasks)\n 3. upload endpoint list (file with endpoint list is correctly uploaded and stored in the database, and triggers all harvesting actions like: create endpoints, create services and their layers, index layers in search backend and firsts service checks)\n 4. verify creation of endpoint, service and layers\n 5. check if the layers created in test are in the search backend url\n 6. browser /registry/ (services created are being display to users correctly)\n 7. browser service details (check basic service metadata present on the page)\n 8. reset service checks (correct functionality should start new check tasks)\n 9. create new service checks and verification (trigger the verification tasks and verifies it in service listing page)\n 10. browser layers details (check basic service metadata present on the page)\n 11. reset layer checks (correct functionality should start new check tasks)\n 12. create new layer checks and verification (trigger the verification tasks and verifies it in service layers listing page)\n 13. clear index (tests the clean up indice functionality)\n\nTo run these tests:\n\n```sh\nmake test-endtoend-selenium-firefox\n```\n\nSelenium and Firefox interaction can be viewed by connecting to VNC protocol, the easiest method is to use Safari.\n\nJust open up Safari and in the URL bar type `vnc://localhost:5900` hit enter and entry `secret` in the password field. Other method is using VNCViever: https://www.realvnc.com/download/viewer/\n\n*CSW-T tests* check the correct functionality of CSW transaction requests.\n\n1. inserts a full XML documents with `request=Transaction` and verifies layers are created correctly. This test use a fixture which can be found here: `data/cswt_insert.xml`\n2. verifies the listing by calling  `request=GetRecords` and asserting 10 Layers created.\n3. verifies the search by calling `request=GetRecords` and passing a `q` parameter.\n4. as that harvesting method also sends the layers to the search backend, a verification is made in order to assert the 10 layers created.\n\n```sh\nmake - test-csw-transactions\n```\n\nTo run all tests above in a single command:\n\n```sh\nmake test\n```\n\n#### Style guide enforcement\n\nThe modular source code checker for `pep8`, `pyflakes` and `co` runs thanks to `flake8` already installed with the project requirements and can be executed with this command:\n\n```sh\nmake flake\n```\n\n#### Continuos integration\n\n`master` branch is automatically built on https://travis-ci.org/ Travis can be configured in the `.travis.yml` file placed in the project root.\n\nIf you want to run tests in your local containers first, execute travis-solo (`pip install travis-solo`) in directory containing .travis.yml configuration file. It\u2019s return code will be 0 in case of success and non-zero in case of failure.\n\n### Translating Hypermap\n\nAs a first step, make sure your language files are included in WorldMap. Languages file are in the hypermap/hypermap/locale directory.\n\nIf your locale file is not there, you can generate it with the Django makemessages command. For example for Italian:\n\n```\ncd ~/hypermap.git\npython manage.py makemessages -l it\n```\n\nOpen the locale file you want to translate, in this case hypermap/hypermap/locale/it/LC_MESSAGES/django.po, and edit the translation strings as needed, for example:\n\n```\n#: hypermap/aggregator/templates/aggregator/layer_checks.html:126\n#: hypermap/aggregator/templates/aggregator/search.html:11\n#: hypermap/aggregator/templates/aggregator/service_checks.html:134\nmsgid \"seconds\"\nmsgstr \"secondi\"\n```\n\nOnce you have translated the strings you want, you need to compile them before you see them in the site. For this purpose you can use the Django compilemessages command:\n\n```\npython manage.py compilemessages\n```\n\nNow if you browse the site you should see your translations correctly in place.\n\nThe makemessages and compilemessages needs the GNU gettext toolset to be installed on your computer. For Ubuntu 16.04 LTS this can be done in this way:\n\n```\nsudo apt-get install gettext\n```\n"
      },
      "source": "https://raw.githubusercontent.com/cga-harvard/HHypermap/master/docs/installation.md",
      "technique": "file_exploration"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/cga-harvard/Hypermap-Registry/issues"
      },
      "technique": "GitHub_API"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": ""
      },
      "technique": "GitHub_API"
    }
  ],
  "license": [
    {
      "confidence": 1,
      "result": {
        "name": "MIT License",
        "spdx_id": "MIT",
        "type": "License",
        "url": "https://api.github.com/licenses/mit",
        "value": "https://api.github.com/licenses/mit"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "type": "File_dump",
        "value": "The MIT License (MIT)\n\nCopyright (c) 2015 President and Fellows of Harvard College\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
      },
      "source": "https://raw.githubusercontent.com/cga-harvard/HHypermap/master/LICENSE",
      "technique": "file_exploration"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "Hypermap-Registry"
      },
      "technique": "GitHub_API"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "Organization",
        "value": "cga-harvard"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "JavaScript",
        "size": 2298731,
        "type": "Programming_language",
        "value": "JavaScript"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Python",
        "size": 338289,
        "type": "Programming_language",
        "value": "Python"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "CSS",
        "size": 93364,
        "type": "Programming_language",
        "value": "CSS"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "HTML",
        "size": 50759,
        "type": "Programming_language",
        "value": "HTML"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Makefile",
        "size": 3713,
        "type": "Programming_language",
        "value": "Makefile"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Shell",
        "size": 1249,
        "type": "Programming_language",
        "value": "Shell"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "name": "Dockerfile",
        "size": 73,
        "type": "Programming_language",
        "value": "Dockerfile"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/cga-harvard/HHypermap/master/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "releases": [
    {
      "confidence": 1,
      "result": {
        "author": {
          "name": "capooti",
          "type": "User"
        },
        "date_created": "2017-11-07T20:25:45Z",
        "date_published": "2017-11-10T02:49:55Z",
        "description": "Release 0.3.12",
        "html_url": "https://github.com/cga-harvard/Hypermap-Registry/releases/tag/0.3.12",
        "name": "v0.3.12",
        "release_id": 8461247,
        "tag": "0.3.12",
        "tarball_url": "https://api.github.com/repos/cga-harvard/Hypermap-Registry/tarball/0.3.12",
        "type": "Release",
        "url": "https://api.github.com/repos/cga-harvard/Hypermap-Registry/releases/8461247",
        "value": "https://api.github.com/repos/cga-harvard/Hypermap-Registry/releases/8461247",
        "zipball_url": "https://api.github.com/repos/cga-harvard/Hypermap-Registry/zipball/0.3.12"
      },
      "technique": "GitHub_API"
    }
  ],
  "somef_missing_categories": [
    "citation",
    "acknowledgement",
    "run",
    "download",
    "requirements",
    "contact",
    "contributors",
    "usage",
    "faq",
    "support",
    "identifier",
    "executable_example"
  ],
  "somef_provenance": {
    "date": "2024-11-04 03:40:18",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.5"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 38
      },
      "technique": "GitHub_API"
    }
  ]
}